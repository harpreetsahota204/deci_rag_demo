{"Solutions Briefs/data": {"86fe0a86-1d46-49f9-a8a9-80c3dc3f9c0f": {"__data__": {"id_": "86fe0a86-1d46-49f9-a8a9-80c3dc3f9c0f", "embedding": null, "metadata": {"file_name": "Solution-Brief_Workstations_Entertainment.pdf", "publication_date": "December 2021", "referenced_websites": ["https://www.supermicro.com/en/products/superworkstation"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro Workstation Family Media and Entertainment is a broad and diverse industry where companies are required to work and collaborate seamlessly to succeed. The ability to accelerate production workflows and gain value faster are top goals for today\u2019s media companies. To stay ahead of the competition, leaders in the industry are implementing cutting-edge workstations to modernize their work environments. Advancements in virtual production, rendering, simulation, and artificial intelligence (AI) continue to propel the future of entertainment. Next generation workstations are the ideal foundation to reinvent how content is created, distributed, and consumed. These platforms combine robust compute technology, CPU and GPU acceleration, more memory, increased storage, and comprehensive management software to unlock high performance levels. 1 Partnering for Success 2 Modernizing A State-of-the-Art Production Environment 3 Summary 5 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. 2 Next generation workstations are powering the most advanced, visually rich feature films and television shows ever created. The latest platforms are engineered to deliver unparalleled compute and graphics capabilities. As a result, companies across the industry are seeing dramatic improvements in how they operate, using applications such as computer-aided design (CAD) and 2D and 3D design and animation. Media companies can gain significant advantages by adopting accelerated workstations: \u2022 Achieving cinematic quality results in less time, even using complex datasets \u2022 Increasing photo-realistic rendering throughput to accelerate creative design-making \u2022 Eliminating tedious or repetitive tasks so that artists can focus on high- value work Moving forward, visual computing solutions will be crucial to empower teams of artists, editors, and directors across disparate locations. The ideal work environment will be able to run a wide variety of applications with speed and precision. Partnering for Success Supermicro and NVIDIA are pioneering the next generation of visual computing to empower creativity and innovation. Together, we provide the correct visual computing solutions to improve the quality and speed of any production. Supermicro is a global leader in high-performance, high-efficiency technology, offering the broadest product portfolio for robust workstations. The goal is to enable the success of all customers. Supermicro achieves this through extensive engineering expertise and the industry\u2019s broadest product portfolio, which offers green computing technologies that reduce energy costs, effectively allocate resources to tackle complex media workflows and drive down operational costs. In partnership with NVIDIA, we offer a range of performance-boosting solutions to help media companies work better, smarter, and faster. We build IT environments that deliver the efficiency, acceleration, and reliability that media teams depend on to share rapidly, review, and edit content. Leveraging first-to-market innovations from Supermicro and NVIDIA RTX technology, these workstations are purpose-built for unprecedented rendering, graphics, AI, and performance at scale to enhance any application. These server-grade workstations are expertly designed to optimize any application so that companies can complete critical projects in record time. Our joint technologies prepare media teams with computing power to execute a broad range of complex tasks: \u2022 Create highly sophisticated models, characters, and environments in real-time \u2022 Iterate more and render faster with unprecedented performance \u2022 Collaborate in real-time across popular content creation applications Media production requires powerful compute and graphics capabilities wherever you need to work: \u2022 High throughput and low latency to power diverse applications \u2022 Increased operational performance and reliability \u2022 Rapid refresh rates and up to 8K screen resolution \u2022 Greater memory and bandwidth to boost productivity 3 \u2022 Power massive virtual production stages in extended reality (XR) Supermicro workstations based on NVIDIA RTX technology provide high throughput over the previous generation, dramatically accelerating production pipelines, enabling higher-fidelity workflows, from interactive rendering to real-time virtual production. These applications enable a range of tasks, such as advanced scene composition for animated content, allowing companies to interactively assemble, light, simulate, and render scenes in real-time. That\u2019s why major movie studios, post houses, and VFX studios trust Supermicro and NVIDIA workstation solutions to deliver the reliability, performance, and scalability they need to succeed. Modernizing A State-of-the-Art Production Environment Supermicro offers a comprehensive portfolio of workstations to meet the escalating demand for diverse and high-quality content. Supermicro workstations are fast, reliable, and cost-effective, utilizing enterprise-grade technologies tested and validated to meet an organization's specific application requirements. Each platform features a wide range of industry standard components that can be optimally configured to fit needs\u2014 including NVMe storage, industry-leading CPUs, and the extreme processing power of NVIDIA RTX. Solutions from Supermicro and NVIDIA offer a high degree of flexibility and upgradability fueled by unprecedented performance to support the rising need for graphics and AI wherever an enterprise's media teams need to work. Supermicro workstations are assembled and tested at a production facility in the USA. For EMEA and APAC companies, Supermicro builds workstations at production facilities in the Netherlands and Taiwan. Now, media companies worldwide can configure and deploy the ideal workstation to accelerate their unique workloads. Workstations from Supermicro and NVIDIA deliver the right tools to help media companies thrive: \u2022 Optimal application performance: Dramatically accelerate production pipelines, from previsualization through final frames \u2022 Rich, expansive visual workspaces: Increase production value on set while enabling real-time iterations \u2022 Proven reliability and improved manageability: Enterprise-class IT manageability, including configuration, monitoring, and diagnostic tools, with both local and remote access 4 5039A-I 5049A-T 5014A-TT Single-processor workstations provide exceptional power to execute graphics-intensive workloads at scale Entry-level configurations are engineered to be cost-efficient and efficient to empower teams using 3D modeling and design applications. Workstations are fully configurable and provide greater acceleration with server-grade reliability Mainstream configurations with advanced graphics capabilities deliver unparalleled performance for rendering. Designed for critical speed and compute capacity to optimize the most data-intensive workloads at scale, all with an energy efficient power supply Expert configurations with robust visual computing capabilities are designed to optimize high-end applications such as larger-scale rendering. - Intel Xeon W-2200 processor, up to 18 cores - 64GB DDR4-2933 Memory - NVIDIA RTX A4500 - 1TB M.2 NVMe + 6TB HDD - Windows 10/11 Pro 64 - 2nd Gen Intel Xeon Scalable processor, up to 28 cores total - 128GB DDR4-3200 Memory NVIDIA RTX A4500 - 2TB M.2 NVMe + 4x 3.8TB SSD - Windows 10/11 Pro 64 - AMD Ryzen Threadripper PRO 3900WX processor, up to 64 cores - 512GB DDR4-3200 Memory NVIDIA RTX A6000 - 3x 2TB M.2 PCIe Gen 4 NVMe in RAID 5 + 15TB U.2 PCIe Gen 4 SSD - Windows 10/11 Pro 64 5 Summary Supermicro and NVIDIA empower the media and entertainment industry to work, collaborate, and create content with incredible speed and stunning quality. Some of the largest production houses have adopted state-of-the-art workstations to work better, smarter, and faster than ever before. With solutions that are purpose-built to deliver competitive price-performance as well as reliable security and flexibility, media companies can execute any project with confidence as they push the boundaries of today\u2019s artistic creations. In addition, organizations can benefit from solutions and capabilities that are the best in the industry: \u2022 Best performance: Highest memory and storage capacities available in a single tower system, featuring up to four passively cooled GPUs in tower form factor. Supermicro is the only manufacturer to offer up to four NVIDIA A100 Tensor Core GPUs in multiple models, with up to 80 cores, 4TB of memory, 61.44TB of NVMe, and optional DCPMM support. \u2022 Best expandability Up to six PCIe Gen4 x16 expansion slots, or up to four PCIe Gen4 M.2 with optional hardware RAID 0/1/5/10 support. \u2022 Best component selection: Supermicro validates a wide variety of memory, storage, and networking components with different specifications to help configure an optimized system for demanding needs without locking into one brand. \u2022 Best assembly and local support: All workstation systems shipped in the Americas are built and tested at Supermicro headquarters in San Jose, California, and include technical support services by in-house Supermicro engineers and product managers. Whether the team is building intricate 2D and 3D models, rendering photo-realistic designs, or simulating scenes, Supermicro and NVIDIA have the best product selections and configurations to boost a team's productivity. These solutions create an environment that allows media companies to scale faster and deliver the ultimate application experience to artists, editors, and directors everywhere. Together, Supermicro and NVIDIA can help anyone deploy the ideal workstation to optimize for specific media projects, from intensive graphics work to the cutting-edge of AI. It\u2019s time for organizations to disrupt the entertainment industry. Visit Supermicro online to learn how.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "ffe7d5a1-85e7-4c34-a03e-4f663f0f1489": {"__data__": {"id_": "ffe7d5a1-85e7-4c34-a03e-4f663f0f1489", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA_5G_Telco_GPU_Computing.pdf", "publication_date": "April 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "DRIVING REVOLUTIONARY 5G TELCO APPLICATIONS WITH HIGH-DENSITY GPU COMPUTING Disruptive, first and only: Unrivaled Supermicro NEBS Level 3 certified GPU solutions The expansion of 5G has sparked a significant shift in the telecommunications market as companies and users race to build and utilize applications in exciting new ways. Telcos are retooling and leveraging their infrastructures for increasingly sophisticated applications such as artificial intelligence (AI), augmented reality (AR), and virtual reality (VR). As a result, they face escalating pressure to build a technology delivery system that is capable of the extreme bandwidth, low latency, and high availability required to effectively support the seemingly endless streams of information from these new applications and services. Supermicro is working with NVIDIA to enable innovation with powerful, market-leading solutions that provide robust Edge to Core to Cloud performance in the 5G network. Supermicro brings proven expertise in optimized server hardware to enhance these evolving deployments, delivering a broad portfolio of offerings to accelerate the most complex 5G workloads and applications. 1 New Age of Innovation 1 Accelerating Data-Driven Performance 2 Success Built on Industry-Leading Computing 2 A New Breed of 5G Solutions 3 Conclusion 4 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. 2 The New Age of Innovation 5G applications change the way we travel, work, play, manage our health, and engage the world. Advancements in computing technologies continue to facilitate diverse workloads, enabling revolutionary performance, efficiency, and breakthrough acceleration to unlock the promise of the 5G environment. These developments have given rise to a host of data-centric applications to yield real-time insights and life-changing capabilities. Autonomous vehicles, robotics, factory automation, cloud gaming, telemedicine, AI, and AR/VR are just some of the applications that are transforming the world today. The increasing demand for computing power and processing speed poses a significant hurdle for existing telecommunications environments. Legacy infrastructures lack the compute density, especially at the Edge, to execute complex data workloads as effectively as hardened solutions, which can support rigorous service level agreements (SLAs) in harsh operating conditions. Many companies are slow to innovate due to limited expertise in this new generation of technology. To succeed, telcos must invest in the right partner with a new class of solutions to harness the full force of 5G. Accelerating Data-Driven Performance Telcos will require new and cutting-edge innovations to modernize their technology, enhance network performance with high availability, and realize next-generation architectures. Supermicro is working with NVIDIA to incorporate the ideal technologies for 5G to deliver peak computing agility, capacity, and resilience to power revolutionary services and applications. Supermicro is the only provider with NEBS Level 3 compliance in a small form factor, GPU dense platform. Our first-to-market platforms set the standard for 5G network architecture, helping telcos innovate with ease. Initially, with the inclusion of NVIDIA V100 or V100S Tensor Core GPUs, these solutions achieve maximum acceleration in a compact form factor for groundbreaking performance and durability with optimal cost-efficiency; the roadmap will soon include support for NVIDIA A100 Tensor Core GPU, NVIDIA A40 GPU for Visual Computing, and other NVIDIA Ampere GPU solutions. Now, Supermicro and NVIDIA customers can transform their operations to handle diverse workloads and adapt to evolving 5G demands. Success Built on Industry-Leading Computing Supermicro has extended its leadership in the GPU server market, offering the broadest portfolio of high-performing and customizable solutions to equip telcos for success. Supermicro is dedicated to building 5G solutions that enable telcos to solve their complex and evolving challenges. Supermicro pursues ongoing research and development to drive technology advancement in vital areas of innovation: NEBS Certification \u2022 Telcos worldwide require their technology deployments to have proven quality and reliability to support their SLAs. \u2022 Supermicro has NEBS Level 3 certification on the broadest suite of telco products, with more on the way, leading the industry to ensure that our customers have sustainable and highly available performance. \u2022 NEBS Level 3 demands robust performance/survival with thermal (55\u00b0C), shock, vibration (including simulated earthquake), fire, and emissions requirements. It is the gold standard for telcos in the USA. 3 Form Factor and Flexibility \u2022 Supermicro\u2019s telco-optimized solutions are powerful and scalable enough to manage various workloads while conforming to multiple form factors for central office, micro data center, and outdoor environments. Power \u2022 Supermicro solutions provide either redundant AC or DC power supplies (1+1 configuration) to keep platforms running continuously. This approach offers simpler, more resilient, and highly efficient power to support an extended temperature range. The inclusion of Titanium Level power supplies delivers the highest efficiency rate on the market of 96%, so companies can operate with the utmost confidence. A New Breed of 5G Solutions Supermicro has significantly expanded its 5G product suite with a full portfolio of solutions powered by NVIDIA accelerators and networking, and software solution stacks such as Areal for 5G vRAN acceleration. Enhanced by the processing capacity of NVIDIA GPUs, Supermicro solutions are unlike anything available on the market. These innovations are tightly configured in different chassis sizes, including a 1U rackmount with four NVIDIA V100 or V100S GPUs only offered by Supermicro with NEBS Level 3 certification. Our short- depth servers are designed with customer challenges in mind to satisfy space constraints. Combined with Supermicro\u2019s newly-released front IO platform and our hardened IP-65 server enclosures, customers can take advantage of massive scalability backed by unparalleled GPU acceleration in nearly any environment, from the network Edge to the Core. With strategic performance optimization to facilitate high- level applications, our GPU solution architectures guarantee quality and effectiveness to rapidly execute the most complex, data-centric workloads. Mellanox networking components provide superior agility, elasticity, and automation to bolster dense GPU compute so that applications can run at the greatest possible performance and efficiency. This powerhouse combination of acceleration technologies makes Supermicro servers the foundation for smarter, more adaptable architectures. The latest 5G solution announced from Supermicro enables GPU workloads in a NEBS Level 3 hardened chassis, the only one of its kind on the market. The SuperServer 1029GQ-TRT-NEBS is a first step of a long-term strategy that will be expanded with NEBS Level 3-certified systems by Supermicro with support for NVIDIA Ampere technology in months to come. The server also features Mellanox storage interconnects to deliver 10X better performance than comparable offerings while freeing up 100% of CPU cores. SUPERSERVER 1029GQ-TRT-NEBS 4 The 1029GQ is the only 1U 4x V100 GPU-enabled server available with NEBS Level 3 certification, having met stringent qualifications of the GR-1089 and GR-63 suite of tests for full Level 3 compliance. This robust solution is purpose-built to handle a variety of operating conditions and data complexity and extends the operating temperature to 55\u00b0C \u2014 achieving a 30\u00b0C improvement over the closest competitor, and it is 100% made in the U.S. Conclusion Supermicro leads the market in high-performance, high-efficiency computing. We offer the broadest portfolio of customizable solutions and expert support from around the globe to help customers create their ideal infrastructure. We are continually developing comprehensive technologies and capabilities to handle today\u2019s workloads and prepare for tomorrow\u2019s challenges. Groundbreaking computing solutions from Supermicro are empowering telcos to lead the next wave of 5G innovation. Our latest server platforms are NEBS Level 3 certified and application-optimized, enabling our customers to transform their operations confidently and efficiently. Backed by the unmatched acceleration of NVIDIA GPUs, NVIDIA networking, and software SDKs, these solutions provide immense power, agility, and flexibility to bolster diverse workloads. A new age of intelligence is waiting. Visit Supermicro today to learn how you can harness the power of advanced computing for 5G.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "d2ee3dd3-0b19-4519-995b-35a771683964": {"__data__": {"id_": "d2ee3dd3-0b19-4519-995b-35a771683964", "embedding": null, "metadata": {"file_name": "Solution-Brief_Supermicro_Veeam.pdf", "publication_date": "August 2022", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro, Scality, and Veeam modernize data centers through virtualization, storage, and cloud technologies to meet business objectives while lowering costs. The combination of Supermicro better, faster, greener storage-server solutions with Scality RING system architecture and Veeam Backup & Replication offer the latest technologies to keep pace with today\u2019s massive data growth while meeting end-user requirements. Increasing IT investment is no longer suitable for assembling data and application availability. With data growth increasing from 30% to 50% per year, increasing IT investment isn\u2019t keeping pace with end-user data and application availability demands. This opens several gaps, one of \u201cAvailability\u201d between \u201cAlways-On Enterprise\u201d requirements and IT\u2019s ability to deliver on those requirements. With the power of Supermicro, better, faster, greener storage solutions, coupled with Scality RING and Veeam Platform, provide an Availability Solution for Enterprises that delivers recovery time and point objectives (RTPOTM) of less than 15 minutes for ALL applications and data. 1 Modernize your Data Center with Storage, Virtualization and Cloud Technologies 2 Supermicro SuperStorage Servers, Scality RING and Veeam Backup and Replication 2 Solution Overview: Scality RING Architecture 3 Conclusion 6 Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy- efficient, environmentally friendly solutions available on the market. 2 Supermicro SuperStorage, Scality RING, and Veeam Backup & Replication offer the latest technologies to keep pace with today's massive data growth. At the same time, with Supermicro Super storage, the solution combines Veeam's backup and recovery application software with Scality's RING software that delivers 14x9's durability, 100% availability, and lower TCO. Supermicro SuperStorage Servers, Scality RING with Ransomware Protection, and Veeam Backup & Replication Supermicro SuperStorage Simply Double, with Scality RING and Veeam Backup & Replication, offers maximum storage capacity, using double the hot-swap drive bays and IOPS in the same space as an industry-standard 2U storage server. Additional bays are located on the top of the Simply Double SuperStorage server in a patented Riser Bay for easy access and servicing. Simply Double supports leading-edge, high-performing INTEL XEON-scalable processors in a dual-socket 2nd Gen Intel Scalable processors configuration, thus delivering optimal performance. To maximize availability, high-speed recovery, and data-loss avoidance, Supermicro offers two supported solutions: First is a 2U chassis supporting the Simply Double half-populated formatting with 24x3.5\u201d drives for a total storage capacity of 560TB and 192GB of memory; the second is a fully populated server offering that provides a maximum storage configuration of 1120TB and 384GB memory, with a maximum capacity of 3TB for both half and complete configurations. Supermicro SuperStorage top-loading 60-bay is an easy deployment solution in a 4U rack dual socket 2nd Gen Intel scalable processors category, supporting high performing Intel Xeon scalable processors with 205W TDP, providing a higher base frequency with more cores and delivering optimal performance for throughput and IOP. The solution is available as a six-node cluster configuration in a fully populated, best-in-class offering, built with 12GB/s SAS technology for optimal performance and holding a total capacity of 2880TB to meet the highest storage demands of increased data capacity. Included in the configuration are six NVMe bays and 384TB of memory for a maximum of 3TB per node. Supermicro SuperStorage plus Scality RING and Veeam Backup & Replication offer High Availability while reducing the total cost of ownership (TCO) by up to 90%. Veeam Backup & Replication leverages Scality RING as a single backup repository for any data and application. You can increase your Supermicro SuperStorage backup by adding standard additional storage to the Scality RING. By leveraging the combined features of Supermicro SuperStorage, Scality RING, and Veeam Backup & Replication, your solution is engineered to provide high-speed and verified recovery \u2014 allowing an organization to achieve RTOs of less than 15 minutes with Veeam SureBackup and automatically verifying every backup recovery. Additionally, Scality\u2019s RING self-healing and fast hard drive recovery ensure that it will always meet your infrastructure\u2019s service-level agreements (SLAs). Supermicro SuperStorage, Scality, and Veeam ensure data loss avoidance. In addition, Veeam Backup & Replication provides multiple options to meet your data management demands and ensure the fastest, most efficient backups. Combining solutions, you can replicate either on-site for High Availability or offsite for disaster recovery, with the addition of erasure coding by Scality as an option to protect your data (single-site or multi-site), thus increasing ROI. Supermicro, Scality, and Veeam allow you to close the \u201cAvailability Gap\u201d to meet your Always-On Enterprise requirements. Veeam\u2019s tight integration with Scality RING ensures the highest application availability level while lowering costs and simplifying IT operational management. 3 Solution Overview The following table describes two complete solutions for Supermicro Systems, Scality RING, and Veeam: Solution Specifics Ransomware: The importance of data protection with Supermicro, Scality, and Veeam Ransomware directly targets and infects your infrastructure. It encrypts data so malicious authors can demand a ransom payment in exchange for decryption keys. The ransomware threat is a primary, ubiquitous, and growing concern; attacks are becoming more frequent, larger, and more sophisticated. Supermicro, Scality, and Veeam have partnered to provide industry- leading data protection solutions and validation of ransomware-mitigation capabilities. Scality RING offers enhanced ransomware protection with support for Amazon S3 Object Lock API, which renders data immutable by preventing it from being deleted or overwritten. In addition, Veeam delivers ransomware remediation, automated backup verifications, and fast, reliable recovery. Reference Solution Name Simply Double for Scality RING Top Loading 60-Bay for Scality RING Base Server SKU SSG-620P-E1CR24H SSG-640SP-E1CR60 Approx. Usable Capacity with 6-node Cluster Fully Populated Systems: 1834TB Half-Populated Systems: 917TB Fully Populated System: 4585TB Half-Populated Systems: 2292TB Half-Populated System: 1440TB Form Factor 2U x 24x 3.5\" Drive Bays 4U x 60x 3.5\" Drive Bays + 4 NVMe Bays System Dimensions WxHxD 17.2\" (437mm) x 3.5\" (89mm) x 34\" (863mm) 17.6\" (447mm) x 7\" (178mm) x 34.1\" (866mm) TPM 2.0 (optional) (optional) CPU 3rd Gen Intel Xeon Scalable processors Memory 192GB (Supports up to 4TB per node) 348GB (Supports up to 4TB per node) Storage Controller Broadcom 3908-based Hardware RAID controller Broadcom SAS 3916- Based Hardware Raid controller NIC 2x 25GbE SFP28 Broadcom BCM57414, AIOM Form Factor Storage Devices 3.5\" 18TB SAS-3 7200 RPM drives Populated Fully Populated Systems: 24x Half-Populated Systems: 12x Fully Populated System: 60x Half-Populated Systems: 30x Half-Populated System: 30x NVMe Cache Device2 6-node cluster or larger: IntelD7-P5520 1.92TB NVMe per node 6-node cluster or larger: 2x 7400 PRO 3.84TB NVMe per node OS/Boot Devices 2.5\" SATA 960GB boot per node 4 Key Benefits With the Supermicro, Scality, and Veeam Solution \u2022 Enterprise-grade ransomware protection \u2014 By supporting Amazon S3 Object Lock, Scality allows administrators to lock down data for specific retention periods. Once set, these object locks prevent anyone, including internal users and administrators with even the highest credentials, from modifying or deleting data until the retention period expires. As a result, Veeam delivers secure ransomware protection with immutable and air-gapped backup and Instant Recovery at the scale of any workload in a multi-cloud infrastructure. \u2022 Lower cost and smaller-capacity entry points \u2014 Scality, Veeam, and Supermicro offer high availability while reducing TCO by up to 90%. Veeam Backup & Replication leverages Scality RING as a single-backup repository for any data or applications. Running on Supermicro servers and available in single-node capacities, at a starting size of as little as 50TB, Scality solutions provide low-cost solutions for immediate ransomware protection. \u2022 3-2-1-1-0 Rule for data protection \u2014 The Supermicro, Scality, and Veeam solutions comply with Veeam\u2019s 3-2-1-1-0 Rule, which requires three data copies, with two on different media types, one offsite, one offline or immutable, and 0 errors with recovery verification. These multiple protection layers protect your data against malicious attacks or natural disasters. \u2022 Ease of use \u2014 Configuring ransomware protection can be done in just a few clicks with Veeam and Scality. The Veeam user interface allows easy connection to external object storage, and the Scality user interface provides data immutability to be easily enabled at bucket level as required. \u2022 Higher Availability \u2014 Supermicro, Scality, and Veeam help guarantee High Availability. Veeam's high-speed and verified recovery process allows your organization to achieve RTOs of less than 15 minutes. With Veeam SureBackup, you can automatically verify the recoverability of every backup. Scality\u2019s RING self-healing and fast hard drive recovery allow you to scale your infrastructure while always meeting availability SLAs. Scality Ring Architecture Scality is a software-defined storage (SDS) solution that turns a pool of x86 Linux-based servers into an unbounded scale-out storage system that supports object- and file-based applications with various use cases. Scality RING architecture consists of three layers: the scale-out access layer, the local and geo-protection layer, and the Scale-out object storage layer. 5 Figure 1 - Scale-Out File Systems 6 To scale both storage capacity and performance to massive levels, the Scality RING software is designed as a distributed, parallel, scale-out architecture with a set of intelligent services for data access and presentation, data protection, and systems management to implement these capabilities. Conclusion Supermicro is a leading provider of high-performance, high-density, and high-capacity SuperStorage servers. SuperStorage configurations provide maximum power and performance, ideal for enterprise, data center, and cloud-computing environments. Scality offers solutions for today\u2019s hybrid and multi-cloud data management environment, a recognized leader in distributed file and object storage. Veeam is the global leader in backup, recovery, and data management solutions that deliver Modern Data Protection. Veeam provides a single platform for cloud, virtual, physical, SaaS, and Kubernetes environments that is simple, flexible, reliable, and powerful. In addition, Supermicro, Scality, and Veeam offer enterprise-class availability solutions that help protect against ransomware.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "7bbdbd71-932e-4a0c-9900-b8f3aea6739d": {"__data__": {"id_": "7bbdbd71-932e-4a0c-9900-b8f3aea6739d", "embedding": null, "metadata": {"file_name": "Solution-Brief_OLTP.pdf", "publication_date": "March 2023", "referenced_websites": ["https://www.tpc.org/1809"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "` Supermicro AS -1124US-TNRP Server Introduction The TPC Benchmark C (TPC-C) is a server benchmark that measures online transaction processing (OLTP) performance. TPC-C consists of a set of basic operations that exercise system functionalities in a complex OLTP environment. TPC-C benchmark provides a representative wholesale supplier with several geographically distributed sales districts and associated warehouses to model an order fulfillment system where the database receives requests for data, adds new data, and makes multiple changes to the data from a large number of users. The primary metrics are: \u2022 Transactions per minute (expressed as tpmC). Introduction 1 World Record Performance 2 System Under Test (SUT) 2 Cluster Configuration 3 Benchmark Workload 3 High Per-Core Performance 3 Results 4 Conclusions 4 Footnotes 5 Additional Resources 5 \u2022 The associated price per transaction (expressed as $/tpmC). The tpmC metric measures how many New-Order transactions per minute a system generates while executing business transactions under specific user response time requirements. World Record Performance Independent testing performed by Telecommunications Technology Association (TTA)2 yielded a world-record performance of 507,802 tpmC on Supermicro A+ Server 1124US-TNRP servers powered by 3rd Gen AMD EPYC processors, which is ~33% faster compared to 2nd Gen AMD EPYC processor- based server1. Please see Table 2 below for detailed results. System Under Test (SUT) Supermicro , the leading innovator in high-performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy- efficient, environmentally-friendly solutions available on the market. Figure 1: Supermicro TPC-C (SUT) 3 3rd Gen AMD EPYC Servers Excel at OLTP Benchmarks Cluster Configuration Table 1: Hardware and Software Stack Benchmark Workload TPC-C provides verifiable online transaction processing (OLTP) performance, price-performance, and availability metrics for a complex compute OLTP environment where a population of users runs and executes business transactions against a database. Effective OLTP systems require both large memory capacities to support large datasets and high-performance compute and storage resources. Supermicro A+ Server 1124US-TNRP\u2019s world record TPC-C result leverages 3rd Gen AMD EPYC support for up to 8 TB of high-speed DDR4 memory per socket to demonstrate excellent OLTP performance with a database using large datasets with the support of large memory capacity. TPC-C also allows direct comparison of different software and hardware solutions for complete OLTP environments. High Per-Core Performance Match core count with application needs without compromising processor features. The Supermicro A+ Server 1124US-TNRP powered by 3rd Gen AMD EPYC processors built with 7nm technology offers a consistent set of features across a range of choices from 8 to 64 cores, including both 128 lanes of PCIe Gen 4 and 8 memory channels with access to up to 4 TB of high- speed memory. The balanced set of resources found in 3rd Gen AMD EPYC processors allows users to right-size server configurations to their workloads. In addition, 3rd Gen AMD EPYC includes models that offer high per-core performance BENCHMARK CONFIGURATION Hardware Database Server Web Application Server 1 x Supermicro A+ Server AS -1124US- TNRP \u2022 2 x AMD EPYC 7343 (2x16 Cores) \u2022 8 TB DDR4-2933 MHz (32 x 256 GB) \u2022 2 x 7.6 TB PCIe Gen4 \u2022 LSI LOGIC SAS-3 3108 MEGARAID CONTROLLER \u2022 6 x 7.68 TB SATA connected to LSI 3108 \u2022 1x Supermicro AOC-MCX4121A-ACAT Dual Port 25GbE SFP28 NIC 2 x Supermicro A+ AS -1114S-WN10RT Server Each with: \u2022 1 x AMD EPYC 7713 (64 Cores) \u2022 128 GB DDR4-2667 MHz (8x 16 GB) \u2022 1 x 1.92 TB PCIe Gen4 \u2022 1x Supermicro AOC-MCX516A-CDAT Dual Port 25GbE SFP28 NIC Software Goldilocks v3.1 Standard Edition Red Hat Enterprise Linux Server Release 8.3 Red Hat JBoss Web Server Network 1 x Mellanox SN2700 100GbE Open Ethernet Switch 4 3rd Gen AMD EPYC Servers Excel at OLTP Benchmarks optimized for frequency-sensitive and single-threaded workloads, which can help optimize TCO for core-based software licenses. Results Table 2 shows the detailed test results. Configuration cores-per-chip / # of sockets CPU Model Memory tmpC Supermicro A+ Server 1124US- TNRP 24 / 2P 2nd Gen AMD EPYC 7F72 16 x 256GB (4TB) 380,475 Supermicro A+ Server 1124US- TNRP 16 / 2P 3rd Gen AMD EPYC 7343 32 x 256GB (8TB) 507,802 Cross-generational Performance Gain ~33% Table 2: Supermicro TPC-C results showing leading OLTP performance Figure 3: Generational TPC-C performance gains (3rd Gen vs. 2nd Gen AMD EPYC processors)1 Conclusions 3rd Gen AMD EPYC 7343 processors show exceptional per-core and per-node performance for in-memory database applications that require large memory capacity. In addition, servers powered by 3rd Gen AMD EPYC processors set a world performance record performance for non-cluster systems with 507,802 tpmC, which is ~33% faster than 2nd Gen AMD EPYC processor-based server1. These capabilities make the AMD EPYC family of processors an excellent choice for running OLTP applications. 5 March. 2023 Supermicro Ultra servers powered by AMD EPYC 7003 Series Processors help leading enterprises reduce time-to-solution across a wide range of applications, provide enhanced security features, and allow running all workloads either on-premises or in a public or private cloud. Supermicro offers many certified solutions and reference architectures that empower organizations to create deployments that deliver data insights faster than ever before. These solutions include servers optimized for: \u2022 AI/ML/DL training inference \u2022 Hyperconverged infrastructure (HCI) \u2022 Software-defined infrastructure (SDI) \u2022 Software-defined storage, such as CEPH, VMWare vSAN, and Weka.IO. \u2022 Data management, such as Oracle 19c, Apache Hadoop, and Cassandra. \u2022 HPC application optimization, such as Ansys Fluent, OpenFOAM, and WRF. Footnotes 1. Supermicro A+ Server 1124US-TNRP AMD EPYC 7343 507,802 tpmc Supermicro A+ Server 1124US-TNRP AMD EPYC 72F2 380,475 tpmc 2. Telecommunications Technology Association (TTA) is the leading IT standardization association in Korea and collects, analyzes, researches, and distributes diverse information on cutting-edge domestic and foreign telecommunication technologies and their standardizations.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "924abb07-0347-4dea-bfd1-3a5560150f24": {"__data__": {"id_": "924abb07-0347-4dea-bfd1-3a5560150f24", "embedding": null, "metadata": {"file_name": "Solution_Brief_Excelero-GPU-NVMe.pdf", "publication_date": "July 2020", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 NVMESH BIGTWIN DIRECT-ATTACHED REFERENCE ARCHITECTURE SPECS 4 FULLY FLEXIBLE STORAGE ARCHITECURES DESIGNED WITH NVMESH 5 SOLVING YOUR GPU BOTTLENECK 5 NVMESH - ELASTIC NVME 6 PERFORMANCE SUPERSERVER STORAGE APPLIANCES DELIVER ELASTIC NVME FOR AI WORKLOADS BigTwin, Ultra, or All-Flash Storage Servers with Direct-Attached Low-Latency NVMe Expand your GPU Storage Pool - Supermicro SuperServers running Excelero\u2019s Elastic NVMe enable AI data scientists to process massive amounts of data in minutes, rather than hours or days. Optimized to eliminate compute performance bottlenecks and storage overhead, the BigTwin, Ultra, and All-Flash Storage Servers supporting NVMesh deliver up to 20x faster data processing for GPU compute nodes. This reference architecture enables you to swiftly add direct-attached NVMe storage capacity to your GPU server, as one single pool of storage without performance penalty. Supermicro SuperServer Storage Appliances Deliver Elastic NVMe for AI Workloads 2 NVMESH BIGTWIN DIRECT-ATTACHED REFERENCE ARCHITECTURE SPECS Supermicro has been a leader in introducing NVMe support and advanced NVMe features in our product portfolio and BigTwin continues that tradition. BigTwin supports 24 hot-swappable 2.5\u201d U.2 NVMe drives, or mixed configurations with SAS3 and SATA3 drives (varies by different BigTwin models). The key benefit of BigTwin is the no-compromise design. Historically multi-node systems traded off features and capacity for higher density. They were deployed for workloads that did not require the highest performance or the highest memory density on a single node. The new 2U BigTwin design is a breakthrough multi-node system that supports the highest performing CPUs, full 24 DIMMs of memory and up to 24 all-flash NVMe SSD drives. This NVMesh direct-attached Elastic NVMe GPU storage reference architecture leverages the Supermicro BigTwinTM architecture, featuring a 2U 4-node system that delivers the highest performance and efficiency per rack unit. The system comes with 24 All-Flash NVMe drives, totaling 368.64 TB of raw capacity. NVMesh enables users to scale infrastructure by adding more systems. CONFIGURATION WITH HIGH AVAILABILITY (HA): 2U 4-Node server with 24 NVMe drives that enables an HA solution with MeshProtect-0, 1, 10 & 6 @ 8+2 Supermicro SKU DESCRIPTION QTY SERVER SYS-2029BZ-HNR BigTwin 3UPI 2U 4-Node, 6x2.5\" NVMe per node, X11DPT-BH, 217BHQ+ 1 CPU P4X-CLX4216-SRFBB CLX 4216 2P 16C/32T 2.1G 22M 9.6GT 100W 3647 L1 8 MEMORY MEM-DR416L-CL02- ER29 16GB DDR4-2933 1RX4 LP ECC RDIMM 48 M.2 CARRIER AOC-SMG3-2H8M2- B-O 2x Hybrid NVMe/SATA M.2 Carrier for Big Twin,HF,RoHS 4 BOOT DRIVE HDS-IMT0- SSDSCKKB960G8 Intel D3 S4510 960GB M.2 SATA 6Gb/s 3D TLC 22x80mm 1DWPD 8 NVME DRIVES** HDS-MUN- MTFDHAL15T3TDP1A Micron 9300 PRO 15.3TB NVMe PCIe 3.0 3D TLC U.2 15mm 24 IB/NIC* AOC-MCX556A-ECAT MCX556A-ECAT, CX-5 VPI,EDR IB,100GbE,2p,QSFP28,PCIe3x16 8 SIOM NIC AOC-MGP-I4M-O SIOM 4-port GbE RJ45, Intel i350 with 1U bracket 4 SYSTEM MANAGEMENT SOFTWARE SFT-DCMS-SINGLE Supermicro System Managment Software Suite node license,HF,RoHS/REACH,PBF 4 NVMESH SFT-EX-SWCCI24-3YR NVMesh per-chassis subscription license, up to 24 NVMe devices. Includes unlimited Clients. 3 year subscription including Premium Support. 1 SVC-EX-PSINSTALL On-site, NVMesh Installation Services, per day, per 100 Client and/or Target Nodes 1 Supermicro SuperServer Storage Appliances Deliver Elastic NVMe for AI Workloads 3 - CONFIGURATION WITHOUT HIGH AVAILABILITY (NON-HA): 1U 10 drive bay server with 10 NVMe drives that allows a non-HA solution with MeshProtect-0 & 6 @ 8+2 Supermicro SKU DESCRIPTION QTY SERVER SYS-1029U-TN10RT X11DPU, 119UTS-R1K02P-N10T, AOC-URN6-I2XT 1 CPU P4X-CLX4216-SRFBB CLX 4216 2P 16C/32T 2.1G 22M 9.6GT 100W 3647 L1 2 MEMORY MEM-DR416L-CL01- ER29 16GB DDR4-2933 2RX8 LP ECC RDIMM 6 BOOT DRIVE HDS-IMT0- SSDSCKKB960G8 Intel D3 S4510 960GB M.2 SATA 6Gb/s 3D TLC 22x80mm 1DWPD 1 NVME DRIVES** HDS-MUN- MTFDHAL15T3TDP1A Micron 9300 PRO 15.3TB NVMe PCIe 3.0 3D TLC U.2 15mm 10 IB/NIC* AOC-MCX556A-ECAT MCX556A-ECAT, CX-5 VPI,EDR IB,100GbE,2p,QSFP28,PCIe3x16 2 SYSTEM MANAGEMENT SOFTWARE SFT-DCMS-SINGLE Supermicro System Managment Software Suite node license,HF,RoHS/REACH,PBF 1 NVMESH SFT-EX-SWCCI12-3YR NVMesh per-chassis subscription license, up to 12 NVMe devices. Includes unlimited Clients. 3 year subscription including Premium Support. 1 SVC-EX-PSINSTALL On-site, NVMesh Installation Services, per day, per 100 Client and/or Target Nodes 1 EDSFF-SHORT E1.S SERVER Supermicro SKU Description Qty SERVER SSG-1029P-NES32R CSE-121EF + X11DSF-E-P 1 CPU P4X-CLX4210-SRFBL CLX 4210 2P 10C/20T 2.2G 13.75M 9.6GT 85W 3647 R1 2 MEMORY MEM-DR416L-SL04- ER26 16GB DDR4-2666 1Rx4 LP ECC REG DIMM,HF,RoHS 12 BOOT DRIVE HDS-MMT- MTFDDAV960TDS1AW Micron 5300 PRO 960GB, SATA, M.2, 22x80mm,3D TLC,1.5DWPD 2 AOC AOC-SLG2-2TM2-T-O OEM LP PCI-E 2 2x 7pin SATA3 RAID 1 1 NIC CARD* AOC-MCX556A-ECAT Mellanox ConnectX-5 VPI adapter card, EDR IB(100Gb/s) & 100GbE, dual port QSFP28 2 NVME HDS-IEN0- SSDPEYKX040T8 Intel DC P4511 EDSFF E1.S TLC 5.9mm 4TB 32 SYSTEM MANAGEMENT SOFTWARE SFT-DCMS-SINGLE Supermicro System Managment Software Suite node license,HF,RoHS/REACH,PBF 1 NVMESH SFT-EX-SWCCI32-3YR NVMesh per-chassis subscription license, up to 32 NVMe devices. Includes unlimited Clients. 3 year subscription including Premium Support. 1 SVC-EX-PSINSTALL On-site, NVMesh Installation Services, per day, per 100 Client and/or Target Nodes 1 Supermicro SuperServer Storage Appliances Deliver Elastic NVMe for AI Workloads 4 FULLY FLEXIBLE STORAGE ARCHITECURES DESIGNED WITH NVMESH The essence of data-driven sciences such as artificial intelligence (AI), including machine learning (ML) and deep learning (DL), is the ability to process as much collected and simulated data as possible in the shortest amount of time. As data sets continue to grow exponentially, processing massive volumes of data at high speed has become one of the major challenges for modern data centers. GPUs have become the go-to compute resources behind AI workloads, and NVMe flash has become the standard for high-performance, low-latency storage. By providing GPUs with direct access to an elastic pool of NVMe, AI data scientists and HPC researchers can feed far more data to the applications \u2013 they no longer face data bottlenecks and can get to better results faster. Designed as a 100% software-defined storage solution, NVMesh gives customers full flexibility in designing the storage architecture that best meets their business and application requirements. This direct-attached NVMe storage reference architecture leverages the flexibility of NVMesh but aims to provide AI customers with the simplest and easiest-to-deploy solution for low-latency GPU storage. EDSFF-LONG E1.L SERVER Supermicro SKU Description Qty SERVER SSG-1029P-NEL32R 1U DP 32 EDSFF Long 1 CPU P4X-CLX4210-SRFBL CLX 4210 2P 10C/20T 2.2G 13.75M 9.6GT 85W 3647 R1 2 MEMORY MEM-DR416L-SL04- ER26 16GB DDR4-2666 1Rx4 LP ECC REG DIMM,HF,RoHS 12 BOOT DRIVE HDS-MMT- MTFDDAV960TDS1AW Micron 5300 PRO 960GB, SATA, M.2, 22x80mm,3D TLC,1.5DWPD 2 NIC CARD* AOC-MCX556A-ECAT Mellanox ConnectX-5 VPI adapter card, EDR IB(100Gb/s) & 100GbE, dual port QSFP28 2 NVME HDS-IEN0- SSDPEWNV153T8 Intel D5-P4326 E1.L PCI-E 3. 1x4QLC9.5mm15.36T 3D2 <0.5DWPD 32 SYSTEM MANAGEMENT SOFTWARE SFT-DCMS-SINGLE Supermicro System Managment Software Suite node license,HF,RoHS/REACH,PBF 1 NVMESH SFT-EX-SWCCI32-3YR NVMesh per-chassis subscription license, up to 32 NVMe devices. Includes unlimited Clients. 3 year subscription including Premium Support. 1 SVC-EX-PSINSTALL On-site, NVMesh Installation Services, per day, per 100 Client and/or Target Nodes 1 * InfiniBand or RoCE ** The architecture supports NVMe drives from all major manufacturers, including Micron, Intel, Kioxia, Samsung and Western Digital. Different drive sizes are supported. For Erasure- Coding configurations, NVMe drive families, including Western Digital SN200, Samsung 1725b & 1733, Kioxia CM5 & CM6 with 3 DWPD or more endurance are supported. DIRECT-ATTACHED NVME STORAGE APPLIANCE Add capacity to your GPU server(s) with an all NVMe storage appliance. Local (in GPU server) and remote (NVMe appliance) NVMe drives are joined in one single pool of high- performance storage with local latency, accessible through a local file system. This ensures no changes are required to your existing workflow. Supermicro SuperServer Storage Appliances Deliver Elastic NVMe for AI Workloads 5 - SOLVING YOUR GPU BOTTLENECK When data scientists are training machine learning models, they process hundreds of terabytes of data. A training dataset may contain thousands of satellite images, for example, to map the effects of climate change. The faster training runs are completed, the more they can be repeated and the better the training model becomes or the more models can be trained on the infrastructure. GPUs are a game changer for training on large datasets because they are so efficient for matrix multiplication and convolution. This is due to a combination of their parallel computing functionality and memory bandwidth. But the biggest advantage of modern GPU computing is also creating its biggest challenge: GPUs have an amazing appetite for data, and AI workloads need much more capacity than it is available locally in GPU systems. NVMesh solves the \u2018storage bottleneck\u2019 that AI and ML users report they often experience. It allows bypassing CPUs all the way from GPU memory to NVMe devices achieving frictionless access to NVMe\u2019s superior performance for shared NVMe storage at local speed. Excelero\u2019s elastic NVMe enables machine learning workloads to process more data, much faster. NVMesh delivers low-latency (5\u03bcs added to media\u2019s read latency), high bandwidth block storage for AI and ML workloads. This direct-attached architecture enables shared NVMe with a local file system. GPU-based systems benefit from the performance of local NVMe flash with the convenience of centralized storage while avoiding proprietary hardware lock-in and maximizing the overall GPU return on investment (ROI). NVMESH - ELASTIC NVME Excelero\u2019s NVMesh eliminates any compromise between performance and practicality, and allows GPU optimized servers to access scalable, high-performance NVMe flash storage pools as if they were local flash. This technique ensures efficient use of both the GPUs themselves and the associated NVMe flash. The end result ishigher ROI, easier workflow management, and faster time to results. BENEFITS OF ELASTIC NVME FOR MACHINE LEARNING AND AI: \u2022 Exceeds the performance and capacity limits of local flash on GPU servers \u2022 Accesses remote NVMe at local speed \u2022 Shares NVMe resources across multiple GPU servers \u2022 Eliminates the need to copy data locally, conserving time and drive endurance \u2022 Datasets can exceed the actual capacity of the GPU Server \u2022 Full CPU offload with Excelero\u2019s patented Remote Direct Drive Access (RDDA) technology Supermicro SuperServer Storage Appliances Deliver Elastic NVMe for AI Workloads 6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "772d64c8-a099-44b4-8330-361509d8b1a0": {"__data__": {"id_": "772d64c8-a099-44b4-8330-361509d8b1a0", "embedding": null, "metadata": {"file_name": "Solution_Brief_KoveSDM.pdf", "publication_date": "August 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro Multi-Node Infrastructure Solutions Data is the new oil, and datasets are constantly expanding. AI/ML HPC, Database, and Virtualization applications can all benefit from in-memory processing, driving memory requirements beyond what a single server can provide. Further, the need to over-allocate memory for headroom in many applications leads to stranded and underutilized memory assets. Supermicro, Kove, and Red Hat, have benchmarked a large in- memory application using Kove:SDM, spanning a multi-node cluster running Red Hat OpenShift on Supermicro BigTwin servers. This turnkey solution enables a new class of applications and greatly improves productivity by negating the need to chunk datasets and associated programs to fit into constrained memory. Capex and Opex are further improved by making underutilized server memory in HPC data centers available to any application on demand. 1 Demand for Massive In-Memory Applications 2 Options for Effective Memory Use 2 What We Need is a Better Software-Defined Memory 2 Welcome to Kove:SDM 3 Why Supermicro 4 Why Kove 4 Why Red Hat OpenShift Container Platform 5 Massive Memory Technical Implementation 5 Proof of Concept Testing 6 Benchmark Results 7 Conclusion 7 References 8 2 The Increasing Demand for Massive In-Memory Applications AI and Enterprise data sets are exploding in size. Processing that data is most efficient when all the data is fully resident in DRAM, avoiding the need to process the data in blocks or constantly page data to disk storage. However, while processor core counts are increasing, memory capacity and bandwidth are not scaling proportionally. To enable the broadest set of virtualized applications, servers are being built with the maximum possible memory, limited only by the physical PCB real estate. However, there is a dichotomy: Increasing memory size addresses memory-intensive applications and increases costs and the probability of stranding memory. Meanwhile, to protect against possible server crashes, memory is often under-utilized, so you don\u2019t run out of it. As a result, while many applications can benefit from more memory than can be provisioned on a single server node, many servers have underutilized memory, depending on workload. Options for Effective Memory Use Effective memory can be increased by accessing memory secondary memory on the server, often by paging to block storage. The problem: This results in a massive slowdown. It could be up to 125x slower, even using the fastest SSDs. The outcome: A 4- hour job running in SWAP could take more than 20 days to complete, rendering certain workloads impractical. A common workaround is to rewrite the application to process the data in manageable chunks and then assemble the result. But this approach is fraught with numerous problems as it is error prone, creates developer costs, and may not solve the run time issues. What is needed is a way to improve direct access to offboard memory by providing on-demand access to memory across servers. The industry has recognized this and has been working on a software-defined memory solution for many years in the form of CXL. However, CXL 3.0, which provides complete caching capability, is still several years away, will require new server architecture, and will only be available in forthcoming generations of hardware. What We Need is a Better Software-Defined Memory Workloads at the heart of everything from HPC to AI have significant memory requirements. But designers struggle to make use of the additional cores available in modern CPUs. The leap forward in the number of CPU cores is mismatched with a lack of memory bandwidth. And it continues to worsen due to the limited physical space to incorporate more memory and the limited access to additional memory beyond the motherboard. Concerns about latency compromises are surfacing, too. Even CXL 3.0 is still piggybacking on the PCI Express (PCIe) physical layer and relying on physical memory paired with PCIe, so one would ordinarily incur a penalty on a key critical metric\u2014latency. Generally, the farther the memory is from the CPU, the higher the latency and the poorer the performance. To embrace scaling, memory must be moved outside of the server. Yet, current options that include block storage and cloud services aren\u2019t viable solutions. 3 Meanwhile, software-defined memory helps ease pressure on DRAM while increasing computing efficiency and performance. This subset of software-defined technologies is unlocking a new age of disaggregated memory, mirroring the revolution that came with disaggregated storage. Welcome to Kove:SDM \u2013 The Software-Defined Memory Solution Your days of memory limitations are over. Kove:SDM is a breakthrough technology that gives enterprises the memory size and performance they need when and where they need it on any hardware. It empowers individual servers to draw from a shared memory pool, including amounts far larger than could be contained within any physical server, so each job receives exactly the memory it needs while reducing your power consumption. With Kove:SDM, for instance, you can allocate 10x 64 GiB for ten containers on a compute node with only 64 GiB of memory, create containers with larger memory than the physical hypervisor, or burst to allocate 40 TiB to a single server for an hour. Control memory in real-time, on-demand, using easy-to-configure provisioning rules. Memory capacity scales up to CPU addressable limits beyond the limits of local physical DIMM slots. Kove:SDM solves memory stranding by pooling memory into a global resource, shareable and reusable across the data center. In other words, it decouples or \u201cdisaggregates\u201d memory from standard servers, aggregating memory into a shared memory pool resource. SDM policies then structure the access to the memory pool. After use, Kove:SDM securely zeros out and returns memory to the pool for reuse. As a result, Kove:SDM also provides strong security against attacks targeting memory penetration. Kove:SDM Works with Any Server Unlike CXL, no special chips or hardware are required to run Kove:SDM. Rather, it decouples memory from servers, pooling memory into an aggregate, provisionable, and distributable resource across the data center using unmodified Supermicro hardware. Like a Storage Area Network (SAN) provisioning storage using policies, Kove:SDM delivers a RAM Area Network (RAN) that provisions memory using policies. Both provide a global, on-demand resource exactly where, when, and how it is needed. For example, an organization might: \u2022 Use a Kove:SDM policy to allocate up to 2 TiB of need-based memory for any of 200 servers between 5 pm-8:30 pm; \u2022 Develop a provisioning rule that would provision a virtual machine with larger memory than the physical hypervisor, such as a 64 GiB RAM physical server (hypervisor) hosting a 512 GiB RAM virtual machine; and \u2022 Provision a 40 TiB server for a few hours or a 100 TiB RAM disk with RAID backing store for a temporary burst ingest every morning. Kove:SDM uses three transparent software components: 1) Management Console (MC) that orchestrates memory pool usage; 2) Host Software that connects applications to a memory pool; and 3) XPD software that converts servers into memory targets to form a memory pool. Users and applications do not ever need to know that it is present. As a result, Kove:SDM enables technology leaders and their enterprises to do things they could not have done before \u2013 including finally maximizing the performance of their infrastructure and people. 4 Why Supermicro Supermicro, a Total IT Solution Provider for Cloud, AI/ML, Storage, and 5G/Edge, offers the industry\u2019s most extensive portfolio of workload-optimized servers to support the highest computing density across the broadest range of applications. Supermicro servers are used for demanding workloads across the entire IT industry, including 5G workloads, a range of AI, HPC, visualization, Big-Data Analysis, virtualization, and enterprise workloads. Supermicro continues to innovate and design application-optimized solutions across the entire IT industry. By implementing Kove:SDM, Supermicro enables the class of very large dataset workloads to be efficiently and effectively processed in the shortest time possible. Even in some cases, enabling applications that would otherwise be impractical using standard methods. The Supermicro Twin family of products has been designed for the most demanding applications while reducing OPEX through innovative design that reduces electricity usage and E-waste. Supermicro Twin Family Multi-node systems are designed so that all servers (nodes) are located within a single chassis with shared power supplies and fans. Supermicro has developed a product family that takes advantage of the Twin product family's latest computing, storage, and networking technologies. The Twin Family is ideally suited to workloads enabled by Kove:SDM as it provides a dense cluster of computing, memory, and storage while supporting a full range of networking. Kove:SDM enables the cluster to operate as a single, very large memory machine. The Supermicro BigTwin infrastructure is perfect for this setup which can save 3-9x on infrastructure costs with OpenShift bare- metal. Additionally, each node can hold 6x NVMe to provide low-latency persistence storage for any workload. Why Kove After years of testing and validation, Kove premiered the world\u2019s first patented and mature software-defined memory solution (Kove:SDM). With Kove:SDM, your days of memory limitations are over. Users of Kove:SDM can now right-size memory to need, providing faster time to solution, better models, and the ability to do things they could not do before. Never again worry about fine-tuning datasets to fit hardware when you can dynamically size hardware to fit the datasets. With Kove:SDM, you can quickly scale up your memory for improved utilization, simplicity, efficiency, and performance and avoid the need to over-provision memory, risking underutilization and wasted resources. As a result, you can analyze any data size or computational need, no matter how large. With Kove:SDM, you can scale up your size and density on demand beyond server limits. Kove:SDM on Supermicro Big Twin is applicable across a wide range of demanding computing, bringing the benefits of larger effective memory to: \u2022 AI/ML - Provision resources to the model rather than forcing models to fit fixed resources. Enjoy deeper and faster lookups, analytics, and iterations. Improve your time on the solution and your return on your data scientists. \u2022 In-Memory Databases - Analyse databases 100s of times larger than physical servers. \u2022 Containers - Improve CPU utilization. Run more jobs in parallel on a single server, increasing workload capability by 20x. Gain the ability to run 7.5x more C3.ai containers. \u2022 High-Performance Computing - Run big data analytics, genomics, and Monte Carlo computations entirely in memory. Build trading systems in Java with <11 \u03bcs risk exposure. Use standard servers to create any size memory server on demand (e.g., 32-256 TiB in a few seconds). \u2022 Enterprise, Cloud, and Edge - Enables unlimited memory sizing. Any size computation can run entirely in memory. Achieve your green goals through 52% CO2 reduction and 33% floor space reductions. Create a hybrid cloud to keep sensitive data on-premises without cost and scaling concerns. Reduce your power consumption needs by 50%. Greater utilization makes edge computing financially viable. 5 Why Red Hat OpenShift Container Platform Red Hat OpenShift is a powerful container platform that offers several benefits when deployed along with Kove:SDM operator in bare metal environments such as the Supermicro systems. OpenShift\u2019s inherent scalability and flexibility for containerized applications make it ideal for managing applications in a software-defined memory environment. OpenShift\u2019s container orchestration capabilities enable seamless deployment and management of applications across the distributed memory infrastructure provided by Kove, ensuring optimal resource utilization, large amounts of memory available, and efficient workload distribution. This combination allows organizations to leverage the benefits of software-defined memory while maintaining the ease of managing containerized applications in a low-cost bare-metal environment. The combination of Red Hat OpenShift with Supermicro BigTwin systems provides additional performance, reliability, and resource utilization advantages. The Supermicro BigTwin 2U 4-Node form factor offers the most reliable 3-node cluster with an extra node as a bastion node in one chassis. Supermicro\u2019s BigTwin system with high-density and high-storage options compliments OpenShift\u2019s capabilities by providing a robust and scalable foundation to run containerized workloads. Massive Memory Technical Implementation The Logical Diagram for our collaborative proof of concept is shown below. It shows two host computers running the applications and 3 Kove memory targets. However, Kove:SDM scales linearly and is limited only by the network interconnect infrastructure that customers provide. Kove:SDM software allocates memory on demand and as needed to the Application Hosts. Figure 1 Kove:SDM Logical Diagram 6 The actual physical system for our collaborative proof of concept was implemented using two Supermicro 2U 4-Node BigTwin systems. \u2022 The first Host was running Red Hat OpenShift bare-metal with three nodes as control plane/compute nodes for the application host and a single node as a bastion node to access the control plane/compute nodes and provision them with the DNS server for the rest of the nodes and run the Kove:SDM management Console. \u2022 The second 2U 4-Node Supermicro BigTwin system ran the Kove software. Each node was equipped with 1TB of memory per node, enabling Kove:SDM to leverage the combined memory pool across the four nodes. This system will provide additional memory resources to any control plane/compute nodes as needed. \u2022 In the PoC, we used one 2U 4-Node Supermicro BigTwin for the targets. Additional targets can easily be added, as represented in the diagram. Figure 2 Proof of Concept Physical Diagram Most reliable OpenShift cluster in a single chassis: \u25aa The optimal number of nodes to create a small viable OpenShift cluster. \u25aa Run once, run anywhere with Red Hat OpenShift. \u25aa 1x bastion node to access the rest of the nodes and 3x control plane/compute nodes in a single chassis. \u25aa Fully optimized containerized environment to build and deploy cloud-native applications. High density for a larger pool of memory with the Kove software: \u25aa Four nodes are fully loaded with memory to provision more memory to client nodes. \u25aa Kove software running to monitor memory resources. \u25aa Kove target memory will automatically provision memory to any workload if necessary. \u25aa Workloads that need large amounts of memory will take full advantage of Kove's software-defined memory technology. Proof of Concept Testing During the testing phase, we subjected various scenarios to stress this environment using stress-ng. This tool facilitated targeted stress on the CPU and memory, enabling us to gather essential data for evaluating the compatibility and performance of Kove:SDM with Red Hat OpenShift. 7 Each scenario involved adjusting the CPU governor from performance to power save, with memory operated at different frequencies for each CPU governor setting. The initial phase involved stressing the system using local memory, while the second phase involved reducing physical memory to allow dynamic memory allocation by Kove:SDM to the control plane/compute nodes requiring more memory than physically available. In total, the tests were executed with 16 scenarios, each repeated seven times to ensure accurate data collection across 2.165 quadrillion results averaged. This proof of concept validated the seamless compatibility of Kove:SDM and Red Hat OpenShift in handling containerized workloads. Additionally, the test demonstrated the significant benefits offered by Kove:SDM in scenarios where workloads require memory capacities exceeding physical limitations while exhibiting minimal to no performance penalty. Benchmark Results Combined with Intel CPU governor settings, Kove:SDM provided 12 to 54% power savings, illustrated in Figure 3. Figure 3 Power Savings with Kove:SDM Conclusion Kove:SDM is fully integrated with Red Hat OpenShift. The Supermicro BigTwin multi-node is the ideal and most reliable minimal Red Hat cluster. The Supermicro BigTwin system is very well adopted across industries, given its density and versatility, and is suited to broad applications. With the Supermicro BigTwin deployments, many nodes are typically concentrated in a single cloud instance. Many of these nodes will have spare available memory. Kove:SDM allows memory in nearby nodes to be dynamically allocated to a single Supermicro BigTwin node enabling it to perform very large in-memory workloads well over the memory capacity of a single node. The testing shows that memory can be dynamically and transparently assigned to a workload by Kove:SDM. The latency of memory across nodes is negligible compared to traditional memory management methods enabling applications that would otherwise be impractical given very long run times without Kove:SDM. Memory Kove MHz A B C Total 1 TiB Server + Target 256 \u2192 64GiB Idle -34 -32 -32 -33 -26 -31 -40% Busy -47 -46 -46 -46 -23 -42 -50% Idle -5 -6 -7 -6 -6 -6 -14% Busy -5 -6 -6 -6 -7 -6 -14% Idle -38 -36 -37 -37 -31 -35 -44% Busy -49 -49 -50 -49 -29 -45 -54% Idle -4 -7 -7 -6 -6 -6 -14% Busy -3 -3 -2 -3 -6 -3 -12% Performance \u2192 Powersave 1 \u2192 3 3200 \u2192 2200 Performance 1 \u2192 4 3200 \u2192 2200 Performance \u2192 Powersave 1 \u2192 2 3200 Powersave 2 \u2192 3 3200 \u2192 2200 Kove Benefit [Percent %] CPU Governor Workload Compute Node [64 GiB] Totals Test 8", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "3ad2dd55-4b47-40e6-9177-242646ef40ae": {"__data__": {"id_": "3ad2dd55-4b47-40e6-9177-242646ef40ae", "embedding": null, "metadata": {"file_name": "Solution-Brief_DAOS.pdf", "publication_date": "July 2021", "referenced_websites": ["https://www.intel.com/content/dam/www/public/us/en/documents/solution-briefs/high-performance-storage-brief.pdf", "http://io500.org", "https://www.intel.com/content/www/us/en/products/details/memory-storage/data-center-ssds/d7-series.html", "https://www.intel.com/content/www/us/en/high-performance-computing/daos-high-performance-storage-brief.html", "https://www.supermicro.com/en/products/system/Ultra/1U/SYS-120U-TNR", "http://daos.io"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Hardware and Intel DAOS Supermicro 1 Introduction Several years ago, the Intel HPC storage team began to address the challenges found in Lustre scalability. Being experienced with massive scale deployments, we saw the limitations of large installations' file system performance scalability. As storage media had evolved over the years with SSD technologies, these limitations came mainly from the filesystem software stack rather than limited storage media technology. The fundamental limitations of the legacy storage software stack became even more apparent later when much faster Non-Volatile Memory technologies appeared in the market. There were several bottlenecks in the legacy software stack, but the most prominent of these are the POSIX interface and block-based IO. To ensure data consistency, the definition of the POSIX interface requires pessimistic locking, proactively locking in any situation where a conflict might occur. Imagine if tens of thousands of clients were writing to the same file and the amount of serialization that would arise if locking occurred on every relevant operation, even if none of these writes would generate a conflict? This pessimistic approach just does not scale, so it became necessary to consider other ways to provide data consistency to unlock the filesystem for scalability. Introduction 1 DAOS Overview and Details 2 Supermicro Reference Configuration for DAOS 6 Supermicro Ultra 6 Key Results 10 References 11 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. Supermicro Ultra Supermicro Hardware and Intel DAOS Supermicro 2 Similarly, all persistent I/O up to this point has been done on media that we write to in large size blocks. This poses a real performance dilemma for I/Os smaller than the block size, including file system metadata as small IOs sharing a block would then be cause for more locking and serialization of activity and less parallelism. Again, this could not be solved with software alone but needed a change with both software and storage media to overcome. The work resulted in developing a fundamentally new software stack called DAOS (Distributed Asynchronous Object Storage) based on the new platform technologies to leverage persistent memory and NVMe SSD capabilities and ground up software development without legacy design overhead. DAOS Overview DAOS (Distributed Asynchronous Object Storage) software stack is designed from the ground up for performance, combining persistent memory and NVMe SSDs with direct access through the Persistent Memory Development Kit and the Storage Performance Development Kit user space libraries to interface to the media directly, and provides a high efficiency software stack with rich functionality over RDMA-enabled fabric. DAOS engine can be described as a highly efficient, highly performant object store. Data stored in KV format efficiently balances between PMEM and NVMe tiers for the most advantage of access time, IOPS, and bandwidth. Moreover, users can interface to various datasets (DAOS Containers) using corresponding middleware, which provides compatibility with existing applications and innovative capabilities. Those are POSIX, MPI-IO, HDF5, HDFS connector for Apache Spark and Hadoop, DAOS Python integration, and the native DAOS API that\u2019s already adopted by some HPC codes. For example, POSIX adapter provides file access and full POSIX support for existing and legacy applications, usually considered a starting point for DAOS deployments. Other adapters such as HDF5 and MPI-IO are standard for HPC codes and proved an easy way to integrate those. With the DAOS Python library, users can integrate DAOS access into Python applications. DAOS containers are identified by unique UUIDs. Users can assign specific features to containers or objects inside those, such as a replica factor, access control ACL, checksum, etc. Containers are part of the DAOS Pool, a set of DAOS hardware allocated and managed by the DAOS admin. DAOS Software Eco-system Figure 1 - DAOS Software Ecosystem Supermicro Hardware and Intel DAOS Supermicro 3 DAOS Storage Server Hardware Design Architecture Intel Optane Persistent Memory (PMem) is a fundamental technology that DAOS builds upon. Unlike SSDs, Intel Optane Persistent Memory offers low latency byte-granular access, which means that applications can now access small pieces of data in parallel, free from the locking required by blocks. DAOS takes advantage of this by storing two different data types in the persistent memory \u2013 metadata and small I/Os, which the DAOS policy engine defines. This allows it to optimize bulk data writes to NVMe SSDs for better SSD performance where larger block size delivers better bandwidth and SSD endurance which is dependent on the write pattern. In addition, this enables customers to use less expensive SSDs, such as moving from high- endurance SSDs to mid-endurance or standard-endurance drives or even moving between technologies such as TLC-based NAND SSDs to QLC SSDs. Breaking through these barriers would never be possible without this storage hardware innovation, the transition away from legacy SATA interface to NVMe, and the appearance of persistent memory, as well as coordinated software stack innovation for data management and data placement. This paper focuses on DAOS server node design based on the 3rd Generation Intel Xeon Scalable Processors, Intel Optane Persistent Memory 200 series, and modern PCIe Gen4 NVMe SSDs. The server platform advantages over 2nd Generation Intel Xeon Scalable Processors and Optane Persistent Memory 100 series are translated into substantial DAOS server performance improvement with higher TCO advantages for users. All DAOS I/O operations on the critical performance path involve Intel Optane PMem. So, the optimal server design and the hardware layout are the keys to delivering the DAOS server performance and scaling it across the distributed installation. With gen over gen performance improvements of the Persistent Memory 100 series vs. 200 series are up to 32% average improvement for random 70/30 mix operations. The new server platform design based on the 3rd Gen Intel Xeon Scalable processor significantly improves overall memory bandwidth by providing eight memory channels instead of the six provided on the prior generations. It\u2019s important to note several improvements in the PMEM module design and their contribution to DAOS performance. The most significant improvement comes from the module speed, growing from 2666 MT/s (Mega Transfers Per Second) from the previous generation to 3200 MT/s with a full two DIMMs per channel population. Figure 2 - Generation over Generation Performance Improvement Supermicro Hardware and Intel DAOS Supermicro 4 Also, data had to be flushed from the processor caches using the WPQ Flush command in the past. However, PMEM 200 Series introduced a new platform level capability called eADR. In a platform that supports the energy store needed, eADR allows the platform to flush the data from the processor's caches, so the program need not. This allows DAOS, via PMDK, to eliminate a point of synchronization and deliver more IOPs on writes. Finally, the current server platform has a better I/O subsystem by introducing PCIe Gen4 support with 64 lanes per socket. This allows to leverage faster interconnect fabric such as InfiniBand HDR200 and could be utilized further to take advantage of PCIe Gen4 NVMe SSDs to drive bandwidth performance. Reference DAOS Storage Node configuration As highlighted earlier, for production DAOS installation, several hardware technologies are required. Those are Intel Optane Persistent Memory, NVMe class SSDs (3D NAND TLC or QLC), and low latency high performance fabric such as HDR200 InfiniBand from Mellanox. All DAOS servers are configured in the same way, and there are no dedicated metadata servers or head nodes, or monitoring nodes as part of DAOS design. Therefore, the DAOS server layout and capacity and performance ratios are essential to maintain optimal configuration. Traditional 2 socket server configurations are common for DAOS design. However, it\u2019s recommended to have a design fully balanced. This includes: \u2022 Intel Optane Persistent Memory is installed in a full population (2:2:2:2), i.e., each memory channel has DRAM and PMEM in the slot on both CPUs. Therefore, underpopulated PMEM leads to DAOS performance impact. \u2022 Two NVIDIA Mellanox InfiniBand interfaces are used, each connected to its own CPU. \u2022 Total SSD bandwidth should be matched to fabric bandwidth. This SSD sequential bandwidth is considered (read or write), as the PMEM layer is responsible for metadata I/O and small I/O data aggregation. Figure 3 - Extended ADR (eADR) to ADR comparison Supermicro Hardware and Intel DAOS Supermicro 5 \u2022 NVMe SSDs are equally distributed across CPU sockets to minimize cross-socket UPI traffic (preferable) The capacity ratio should also be maintained. For typical DAOS installations, Metadata size should stay within 3-6% of total data capacity. The unused metadata capacity is utilized for small I/O data aggregation, so the performance benefits an extra PMEM. Intel PMEM is available in 128GB/256GB/512GB capacity points per module. This results in 2TB/4TB/8TB total PMEM in the platform. For typical DAOS server configurations, 128GB and 256GB-based populations provide the highest Return on Investment. Intel PMEM total capacity Total Storage capacity (3-6%) Number of SSDs required (3.84TB each) Number of SSDs required (7.68TB each) 2048GB (16*128GB) 34TB-68TB 9-18pcs 5-9pcs 4096GB (16*256GB) 68TB-136TB 18-36pcs 9-18pcs Note that it is essential to consider an optimal SSD capacity while sizing DAOS server total capacity and performance. It might be preferable to use the lower per-drive capacity to achieve full fabric performance for a given total capacity. For example, if the target DAOS server capacity is 34TB and Intel SSD D7-P5510 Series 7.68TB selected, the table above clearly illustrates a potential underperforming problem. According to this corner case, only 5 SSDs are required to reach the capacity point, while not enough to drive the full dual HDR200 bandwidth (P5510 is 7GB/s SR and 4.2GB/s SW). In such examples, 10 x 3.84TB drives should be considered instead. Generally, 3D NAND TLC based standard endurance SSDs are the default choice for DAOS configuration. However, PMEM protects the endurance of SSDs in front by handling small I/O, so SSD writes are always optimal and aligned. This gradually improves SSD endurance and even allows DAOS implementations using QLC NAND technology. For more details, read that Intel whitepaper in the link section below. Figure 4 - DAOS Server node design Supermicro Hardware and Intel DAOS Supermicro 6 Supermicro Reference Configuration for DAOS Supermicro offers several platforms in different categories with balanced architecture and comprehensive NVMe and PMEM support. However, it is a complex design that includes many specific optimizations for overall power, and thermal and component layout placement. The Ultra server family offers the perfect balance between performance, flexibility, and economic benefits. Figure 5 - Memory Capacity with PMEM Supermicro Ultra in Every Way All X12 Ultra SuperServers fully support the highest performing 3rd Gen. Intel Xeon Scalable processors (up to 270 watts TDP) with 32 DIMM slots with a truly balanced architecture. In addition, when paired with Intel Optane Persistent Memory Module, X12 Ultra SuperServers can achieve a maximum of 12TB total memory capacity, which unlocks the processors' full potential and makes them the excellent choice for high-performance analytics in-memory application acceleration. Supermicro Hardware and Intel DAOS Supermicro 7 Figure 6 - Supermicro X12 Ultra Series Summary X12 Ultra SuperServers are designed with extreme configurability and efficiency: \u2022 1U Rackmount: o Up to 12x direct-attach, hot-swappable full hybrid (SATA/SAS/NVMe) drive bays; o 4x PCIe Gen 4 Add-on-Cards; o Flexible networking options via Ultra risers: 2x 25G or 4x 10G or 2x 10G or No NIC o Redundant Titanium (96% Efficiency) AC Power Supply: 800W, 1000W, 1600W, 2000W o Redundant -48V DC power supply option: 1300W \u2022 2U Rackmount: o Up to 24x direct-attach, hot-swappable drive bays (22x are NVMe hybrid); o 8x PCIe Gen 4 Add-on-Cards; o Flexible networking options via Ultra risers: 2x 25G or 4x 10G or 2x 10G or No NIC o Redundant Titanium (96% Efficiency) AC Power Supply: 800W, 1000W, 1600W, 2000W o Redundant -48V DC power supply option: 1300W For this DAOS solution, a 1U rackmount X12 Ultra SuperServer SYS-120U-TNR is used. The detailed configuration is shown below. Each CPU socket is configured with 8x 32GB DDR4-3200 DRAM + 8x 128GB PMEM, 5x Intel P5510 NVMe SSDs, and a Mellanox CX-6 200G InfiniBand network adapter. A dedicated HW RAID storage controller is also added for OS boot drives. Thanks to the balanced architecture, all resources can be accessed locally without using the UPI to minimize the data transfer bottleneck. Supermicro Hardware and Intel DAOS Supermicro 8 Figure 7 - Balanced Architecture Hardware Specifics Supermicro Hardware and Intel DAOS Supermicro 9 Software Bill of Materials Operating System openSUSE Leap 15.2 Open Fabrics Driver Mellanox 5.2-2.2.3.0 DAOS Version 1.3.101 Performance Evaluation on IO500 BIOS and OS Network tuning parameters BIOS Intel VT for Directed I/O (VT-d)\u2192Enable Network sysctl -w net.ipv4.conf.all.arp_ignore=1 sysctl -w net.ipv4.conf.ib1.rp_filter=2 sysctl -w net.ipv4.conf.ib0.rp_filter=2 sysctl -w net.ipv4.conf.ib1.accept_local=1 sysctl -w net.ipv4.conf.ib0.accept_local=1 The IO500 benchmark suite is an open-source benchmark used to compare HPC filesystems. The suite of tests both Object IO and Metadata IO in easy and hard ways using the standard benchmark tools IOR and Mdtest. The MPI based tests are designed to test system level performance between a group of HPC clients and an HPC Storage system and benchmark the system with both easy and hard io patterns. After all the different subsets are run, a final IO500 score is given. MDTEST is designed to stress the metadata performance. It\u2019s pretty common in HPC to see parallel access to many files opening for reads, writes, attribute updates, creation, or deletion, so the IO500 subsets test this. As a result, metadata performance can create a significant bottleneck in the file system performance and is weighted heavily in the IO500 total score. DAOS has strong metadata performance as locking is minimized within DAOS. IOR measures throughput performance. Unlike MDTEST, IOR deals with I/O operations, such as reading and writing data simultaneously using many clients. Therefore, the IOR subtests measure the actual bandwidth is as many clients read and write data. SYS-120U-TNR DAOS Data Node x4 IPMI AOC-653105A-HDAT AOC-653105A-HDAT SYS-120U-TNR Clients x10 IPMI P1 P1 AOC-653105A-HDAT P1 1G IPMI 10G MGMT 200G HDR InfiniBand- DAOS AOC-STG-i2T P1 P2 AOC-STG-i2T P1 P2 SYS-120U-TNR Admin x1 IPMI AOC-653105A-HDAT P1 AOC-STG-i2T P1 P2 Figure 8 - System Setup for IO500 Testing Supermicro Hardware and Intel DAOS Supermicro 10 We considered both metadata and object-based benchmarks for DAOS performance analysis with Intel Optane PMem to be critically important. This is because they are representative of the overall filesystem performance and provide clear guidance recognized by the industry. Below are the results achieved with 10 Clients and 4 Supermicro IceLake DAOS Servers. IO500 version io500-isc21_v1 (standard) [RESULT] ior-easy-write 113.491924 GiB/s : time 526.850 seconds [RESULT] mdtest-easy-write 3785.499014 kIOPS : time 603.215 seconds [RESULT] ior-hard-write 88.264742 GiB/s : time 418.255 seconds [RESULT] mdtest-hard-write 1000.790372 kIOPS : time 525.518 seconds [RESULT] find 2430.958209 kIOPS : time 768.913 seconds [RESULT] ior-easy-read 163.248695 GiB/s : time 415.989 seconds [RESULT] mdtest-easy-stat 4405.937075 kIOPS : time 531.058 seconds [RESULT] ior-hard-read 96.820899 GiB/s : time 383.658 seconds [RESULT] mdtest-hard-stat 2281.987628 kIOPS : time 356.409 seconds [RESULT] mdtest-easy-delete 1720.793799 kIOPS : time 968.443 seconds [RESULT] mdtest-hard-read 131.407871 kIOPS : time 2537.581 seconds [RESULT] mdtest-hard-delete 1476.884379 kIOPS : time 793.374 seconds [SCORE ] Bandwidth 112.174143 GiB/s : IOPS 1535.629705 kIOPs : TOTAL 415.039693 Subtest Descriptions: IOR-Easy-*: This is a single file per process workload where each thread writes a single file sequentially with large block IO. IOR-Hard-*: This is a single shared file workload where each thread writes in unaligned 47KB chunks. MDTEST-Easy-*: This is a unique directory per process workload where each thread in their own directory creates as many zero- sized files as possible. MDTEST-HARD-* This is a shared directory workload where each thread creates a small file in the shared directory. Key Results and Summary The Supermicro systems with 3rd Gen Intel Xeon Scalable processors have a high level of performance per server compared to earlier 2nd Gen Intel Xeon Scalable processors DAOS system. IOR-EASY-READ was measured at 163 GB/s, which is a little over 40GB/s streaming bandwidth per server used. In addition, the 2 Mellanox InfiniBand HDR fabric ports and 10 NVMe drives in this 1U chassis deliver high performance in a compact package. Supermicro Hardware and Intel DAOS Supermicro 11 Figure 9 - IO500 10-Node Challenge Also, in these tests, we can see that IOR-HARD-WRITE was performing at 77% of the IOR_EASY_WRITE. This is because DAOS and its innovative way of I/O allow this DAOS Solution to deliver high levels of IO performance even for complicated I/O patterns. It is not just limited to easy workloads. For users looking for all flash storage systems that can deliver solid metadata and object IO performance for easy and HARD workloads, a Supermicro DAOS solution should be at the top of the list to consider for your next HPC Flash storage system.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a172fcfb-4977-4d19-80f1-7f141afe659b": {"__data__": {"id_": "a172fcfb-4977-4d19-80f1-7f141afe659b", "embedding": null, "metadata": {"file_name": "Solution-Brief_WekaIO_X12_BigTwin.pdf", "publication_date": "April 2021", "referenced_websites": ["https://www.supermicro.com/en/products/bigtwin/", "https://www.weka.io/how-it-works/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro WEKAIO Reference Architecture EXTREME FILE SYSTEM PERFORMANCE ON SERVERS Award Winning Twin Servers with 3rd Gen Intel Xeon Scalable Processors Unstructured data has become the backbone of IT infrastructure for consumer apps, business intelligence, financial services, media & entertainment, logistics & transportation, municipal services, education, scientific research, healthcare, government operations, and national security. At the application level, end-users may not realize how much unstructured data impacts their everyday lives and how it influences how they operate in the virtual world. Clients are relentlessly hungry for the most up-to-date and precious information, yet they expect lower latency and 100% uptime. This creates a tremendous amount of pressure on our IT infrastructure with growing data sets at a global scale. Furthermore, the dynamic changes of hot, warm, and cold data challenge the IT infrastructure\u2019s ability to meet service level WEKA Solution Architecture Overview 2 Configuration 3 Quality, Serviceability, and Remote Management 6 WEKA Performance Overview 9 WEKA Validated X12 Supermicro Servers 11 Summary 12 Additional Resources 12 Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. 2 Supermicro WEKAIO Reference Architecture agreements for data mining, processing & analytics amongst Telecommunications, Enterprises, and Technology companies, supporting business operations, mobile applications, IoT, and AI. WekaIO (Weka) was founded on the idea that current storage solutions have forced IT organizations to choose complex solutions to address their highest storage need at the expense of other desirable capabilities. The three dominant architectures are block, file, and object, each servicing a different need: speed, shareability, and scalability in that order. In today's \"data-as-a-service\" market, organizations need a flexible infrastructure that addresses the many business needs within a single framework. The design philosophy behind the Weka file system \u2013 WekaFS - was to create a single storage architecture that runs on-premises or in the public cloud with the performance of all-flash arrays, the simplicity and feature set of network-attached storage (NAS), and the scalability and economics of object storage. WEKA Solution Architecture Overview Figure 1 - Weka File System Structure Weka's file system (WekaFS) is a fully distributed, parallel file system that was written entirely from scratch to deliver the highest performance file and object services by leveraging NVMe flash as its primary storage for persistent data across a wide range of applications. WekaFS will also, transparent to the application layer, seamlessly expand the filesystem namespace to include an extended layer built on any S3 compliant object storage system (see Figure 3 and Figure 4 for more details). There is no need for data migration software or complex scripts; all data resides in a single global namespace for easy access and management while maintaining the best performance. The intuitive graphical user interface allows a single administrator to quickly and easily manage hundreds of petabytes of data without any specialized storage training. Weka's software delivers a more powerful and straightforward solution that would have traditionally required several disparate storage systems to leverage existing technologies in new ways and augment them with engineering innovations. The resulting software solution provides high performance for all workloads (big and small files, reads and writes, random, sequential, and metadata heavy). Furthermore, it is designed to run on a server infrastructure that does not rely on specialized hardware assist. As future hardware innovations come to market, WekaFS is well-positioned to leverage emerging technologies for the continued delivery of best cost and performance. The system can be expanded online to handle more demanding performance or store more capacity with no service interruption. 3 Supermicro WEKAIO Reference Architecture Configuration In 2018, WekaIO set a number of benchmark records using the previous generation 2U 4-Node X11 BigTwin 1. Now, in 2021, Supermicro has launched next-generation X12 BigTwin hardware, featuring 3rd Generation Intel Xeon Scalable Processors supporting up to 40 cores, higher instructions per clock, and two 512-bit FMA units. This is a huge advantage, as AVX-512 doubles the data registers compared to the AVX2 extension for the x86 instruction set. Beyond the computing power, Supermicro X12 BigTwin can now access data faster with twice the NVMe storage & I/O performance utilizing PCI-E 4.0, increasing WekaFS performance significantly over the previous generation of NVMe drives. \uf0b7 There are two WEKA reference configurations to choose from, based on Supermicro\u2019s flagship green computing platform, X12 BigTwin. Both options offer top-tier performance with 6 or 12 NVMe PCI-E 4.0 storage drives, 256GB of memory, and 32 CPU cores per host. \uf0b7 Both options offer a raw capacity of up to 7.7PB/rack or 367TB/system, using 15.3TB NVMe PCI-E 4.0 storage drives o 2U 4-Node Capacity (21 systems x 6 drives x 4 nodes x 15.3TB = 7.7PB per 42U Rack) o 2U 2-Node Capacity (21 systems x 12 drives x 2 nodes x 15.3TB = 7.7PB per 42U Rack) \uf0b7 High-performance Kioxia NVMe PCI-E 4.0 drives with measured performance of 6.9 GB/s of throughput and 1.6 MIOPs vs. 3.3 GB/s of throughput and 800 KIOPs for NVMe PCI-E 3.0 drives. \uf0b7 Key Advantages: o 2U 4-Node X12 BigTwin offers up to 20% power efficiency than four traditional 1U servers and optimized cost models for entry-level to mid-sized deployments. Improved thermal performance over X11 BigTwin, as shown in Figure 2. o 2U 2-Node X12 BigTwin offers optimal performance, storage, and operational advantages for mid-sized to hyperscale deployments. Figure 2 \u2013 Optimized Thermal Performance of SYS-220BT-HNTR over SYS-2029BT-HNR Optimized Thermal Performance Incremental boost in cooling performance with finely tuned system architecture and intelligent fan curves. 15% improvement in thermal performance under light load. 20% improvement in thermal performance under heavy load. 4 Supermicro WEKAIO Reference Architecture An example of a validated high-density cluster solution using SYS-220BT-HNTR quad-node servers: Type Description Per System Per Cluster System SYS-220BT-HNTR X12 BigTwin 2U 4-Node, 6x U.2 NVMe PCI-E 4.0 1 2 CPU 3rd Gen Intel Xeon Scalable Processors 4314 16C/32T 2.4G 11.2GT 135W 8 16 Memory 16GB DDR4-3200 2Rx8 ECC Registered DIMM 64 128 Boot Controller M.2 NVMe HW RAID Controller 4 8 Boot Drive Toshiba XG6 512GB NVMe M.2 22x80 <1DWPD 8 16 Storage Drive Kioxia CM6 7.68TB NVMe PCI-E 4.0 2.5\" U.2 SSD 24 48 NIC1 & NIC2: Data Traffic Mellanox ConnectX-6, LP Dual-port VPI HDR 200GbE, QSFP56, PCI-E 4.0 8 16 AIOM Slot: S3 Traffic Broadcom BCM57414, OCP 3.0 Dual-port 25GbE, SFP28, PCI-E 4.0 4 8 Table 1 \u2013 4U Cluster Specifications with 8 Nodes Figure 3 shows how WekaFS can seamlessly expand the filesystem namespace on S3 compliant object storage via 25Gb network interfaces on each host. This 4U cluster includes eight nodes, each with a dual-port 25Gb NIC to offer sufficient bandwidth and redundancy for S3 APIs, such as GET, PUT, COPY, DELETE, POST, etc. For the data traffic, each node has two dual-port 200G HCAs to configure optimal performance and network redundancy. Figure 3 - Cluster Network Topology with WekaFS on SYS-220BT-HNTR 5 Supermicro WEKAIO Reference Architecture An example of a validated Twin-based cluster solution using SYS-220BT-DNTR dual-node servers: Type Description Per System Per Cluster System SYS-220BT-DNTR X12 BigTwin 2U 2-Node, 12x U.2 NVMe PCI-E 4.0 1 3 CPU 3rd Gen Intel Xeon Scalable Processors 6326 16C/32T 2.8G 11.2GT 185W 4 12 Memory 16GB DDR4-3200 2Rx8 ECC Registered DIMM 32 96 Optional Boot Controller M.2 NVMe HW RAID Controller 2 6 Boot Drive Toshiba XG6 512GB NVMe M.2 22x80 <1DWPD 4 12 Storage Drive Kioxia CM6 7.68TB NVMe PCI-E 4.0 2.5\" U.2 SSD 24 72 NIC1 for S3 Traffic Broadcom BCM57414, LP Dual-port 25GbE, SFP28, PCI-E 3.0 2 6 NIC2 for Data Traffic Mellanox ConnectX-6, LP Dual-port VPI HDR 200GbE, QSFP56, PCI-E 4.0 2 6 AIOM for Data Traffic Mellanox ConnectX-6, OCP 3.0 Dual-port VPI HDR 200GbE, QSFP56, PCI-E 4.0 2 6 Table 2 \u2013 6U Cluster Specifications with 6 Nodes Figure 4 shows how WekaFS can seamlessly expand the filesystem namespace on S3 compliant object storage via a 25Gb network on each host. This 6U cluster includes six nodes, each with a dual-port 25Gb NIC to offer sufficient bandwidth and redundancy for S3 APIs, such as GET, PUT, COPY, DELETE, POST, etc. For the data traffic, each node has two dual-port 200G HCAs to configure optimal performance and network redundancy. Figure 4 - Cluster Network Topology with WekaFS on SYS-220BT-DNTR 6 Supermicro WEKAIO Reference Architecture Quality, Serviceability, and Remote Management Since Supermicro launched its Intel-based Twin system architecture in 2007, our hardware and firmware design teams have built a variety of Enterprise features into the Twin Product Family, along with long-standing partners who continue to develop purpose-built appliances and private cloud infrastructure with X12 BigTwin. Critical use cases include hyperconverged infrastructure, scale-out object storage, scale-out block storage, and scale-out file systems. Through these significant partnerships and successes in the Enterprise server market, the design team has been able to go beyond just optimizing performance and put considerable emphasis on building quality, serviceability, and remote management. The X12 2U 2-Node BigTwin features built-in redundancies for power, PMBus, NVMe management, and M.2 boot drives, shown in Figure 5. Supermicro was one of the 1st server manufacturers to support NVMe technologies and has developed advanced capabilities for power controls, re-drivers, and re-timers. On SYS-220BT-DNTR, 12 NVMe PCI-E 4.0 drives deliver balanced performance with direct connections to the dual-processors on each node, as shown in Figure 6. Figure 5 \u2013 2U 2-Node System Reliability Diagram Figure 6 \u2013 Balanced NVMe Performance on SYS-220BT-DNTR Balanced Storage Performance (12 NVMe PCI-E 4.0 drives per Node) Modular Storage Adapters 16 Lanes for PCI-E 4.0 AIOM Up to 270W TDP Processors with Up 40 Cores per Socket 6 NVMe 6 NVMe 7 Supermicro WEKAIO Reference Architecture Not only do the direct NVMe connections help to deliver unrivaled storage performance, but they ensure strong signal integrity and the reliability to manage the NVMe drives through the BMC\u2019s web management interface, shown in Figure 7. Figure 7 \u2013 BMC Web UI View of Physical NVMe PCI-E 4.0 Drives For both WEKA reference configurations, each node features a redundant boot controller for two M.2 NVMe drives, managed via a dedicated sub-panel under Storage Monitoring in Figure 8. The controller may be managed from the BIOS with HII (Human Interface Infrastructure) support and Redfish APIs to integrate with infrastructure orchestration tools. Figure 8 \u2013 BMC Web UI View of M.2 NVMe Boot Controller With the new BMC web interface on X12 BigTwin, system administrators can quickly locate and identify each node in each 2U enclosure to streamline the deployment of WekaFS. Figure 9 shows the Logical Front View of 2 nodes on SYS-220BT- 8 Supermicro WEKAIO Reference Architecture DNTR, which can also help system administrators communicate more effectively with field technicians managing the infrastructure. Figure 9 \u2013 BMC Web UI for Multi-Node Logical View The backplane\u2019s CPLD can help recover any stalled bus to ensure the backplane\u2019s Embedded Controller (EC) can reliably manage firmware updates through the dedicated Firmware Management panel, shown in Figure 10. Figure 10 \u2013 BMC Web UI for Firmware Management X12 2U 2-Node BigTwin includes 2200W Redundant Power Supplies with Titanium Level 96% Power Efficiency. This is shared between the two nodes and offers about ~10% power efficiency advantage over two standard 1U servers with 12 NVMe drives. This helps to reduce e-waste by approximately 20% with its shared power, cooling system, and backplane 9 Supermicro WEKAIO Reference Architecture design. The system supports Smart Ride Through (SmarT) Power to \u2018ride through\u2019 a momentary loss of AC power while maintaining the highest possible power supply efficiency, which can be monitored through the Power sub-panel shown in Figure 11. In the event of a failure, each hot-swap node is easily accessible, making service calls a breeze, e.g., swap out a memory DIMM or installing a standard low-profile card without any tools, as shown in Figure 12. Figure 11 \u2013 BMC Web UI for Power Monitoring Figure 12 \u2013 Tool-less PCI-E Slots WEKA Performance Overview Using FIO IO generators on 12 clients, a massive performance of ~202GB/s throughput (33.6GB/s per host) and 8.5 million IOPS (1.4m IOPS per host) was measured on just three X12 BigTwin systems (six hosts), each with two 3rd Gen Intel Xeon Scalable Processors, 2x 200Gb/s ConnectX-6 PCI-E 4.0 host channel adapters, 12 Kioxia CM6 NVMe PCI-E 4.0 drives, and 10 Supermicro WEKAIO Reference Architecture WekaIO (3.11); configured with 49 Weka system cores and 3 containers per host. These results were limited by the number of clients in the test. The Weka storage cluster is capable of significantly more performance in this configuration but will require more clients to drive that performance. The eight host X12 BigTwin cluster, with two SYS-220BT-HNTR systems, is estimated to have similar performance to the six host cluster with three SYS-220BT-DNTR systems. With the same number of clients, the six host cluster will have slightly more throughput and slightly fewer IOPS at the limit when more clients are added. Figure 13 \u2013 Weka Performance Overview Figure 14 \u2013 File System with 331.76TB Usable Storage 11 Supermicro WEKAIO Reference Architecture WEKA Validated X12 Supermicro Servers SERVER SYS-220BT-HNTR Figure 15 - 2U 4-Node BigTwin Server Recommended Scale: Entry-level to Mid-sized Deployments, Requiring a minimum of 4U rack space SERVER SYS-220BT-DNTR Figure 16 - 2U 2-Node BigTwin Server Recommended Scale: Mid-sized to Hyperscale Deployments Requiring a minimum of 6U rack space 12 Supermicro WEKAIO Reference Architecture Summary Dramatic improvements in computational power and exascale needs for storage in today's digital mediums have meant that typical file systems traditionally used to address complex workloads are often impractical or inadequate to the task. WekaIO combined with Supermicro servers provides a stunning performance, protection, and data management story for Deep Learning, High-Performance Compute, and high-throughput low-latency storage workloads. WekaIO removes your computational storage bottlenecks by leveraging the power of NVMe and task-optimized servers, along with software designed for performance, scalability, and flexibility. The combination of Supermicro SuperSevers and WekaIO software provides customers with solutions that can leverage our building-block architecture to provide the most optimized CAPEX and OPEX. With Supermicro's professional services, our Rack Integration Team can fully rack, integrate, pre-test and tune, allowing you to be operational less than 30 minutes after receiving.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "70d43e15-268e-4c7a-b257-13d09bcbd612": {"__data__": {"id_": "70d43e15-268e-4c7a-b257-13d09bcbd612", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVMe_Storage_Pool.pdf", "publication_date": "June 2018", "referenced_websites": ["https://www.supermicro.com/solutions/", "www.supermicro.com/bigtwin"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "RSD HIGH-PERFORMANCE COMPOSABLE NVME STORAGE SOLUTION To gain a competitive edge and greater business agility, enterprise customers, Cloud Service Providers (CSPs) and telcos are rapidly adopting Artificial Intelligence (AI), Machine Learning, Deep Learning, Big Data and Edge Computing in all aspects of their businesses. Due to the vast amount of data collected by various data sources from computing systems, sensors, and IoT devices, AI platforms need to sift through mountains of data in the least amount of time possible and leverage increasingly sophisticated and evolving machine learning algorithms to transform learned data into market insights and actionable business strategies. The era of waiting for days or even weeks for actionable data analytics is over. With intelligent devices running AI applications ubiquitously such as autonomous driving, unmanned aerial vehicles and financial fraud detection, businesses require information instantly in order to take actions in real time. To achieve these goals, more and more forward-looking organizations are implementing modular, high performance compute and storage infrastructures as backbones for their AI platforms at their data centers and intelligent edges. Supermicro recently developed and validated a modular, high performance, high density, composable NVMe storage reference architecture consisting of Supermicro BigTwin systems and 1U 32 NVMe storage enclosures managed by Supermicro Rack Scale Design (RSD) software. This advanced architecture can scale for deployments ranging from a single 3U server building block at the intelligent edge to large scale, rack level deployments at the data center level. Fueling AI Platforms with \u201cBig and Fast\u201d Data KEY ADVANTAGES \u2022 Unprecedented compute power and storage capacity in just 3U, with 8 Intel Xeon Scalable processors, 56 NVMs SSDs, for close to 1.8PB of high performance storage with 32TB SSDs. \u2022 Dynamically composable compute nodes and disaggregated NVMe storage to meet ever- changing workloads \u2022 Balanced compute and storage designs that easily scale from one server building block to multiple racks managed by Supermicro RSD software Supermicro 1U 32 NVMe Storage Enclosure Supermicro 2U 4-Node All-Flash NVMe BigTwin 01_NVMe-Storage-Pool-Solution-Brief_180619 Specifications subject to change without notice. All other brands and names are the property of their respective owners. 1 of 4 Hot-swap BigTwin Nodes Node A Node B Node C Node D 6 NVMe Drives per Node CPU2 CPU1 Supermicro 100GbE PCI-E AOC Supermicro 100GbE Onboard SIOM PCI-E AOC 8 NVMe Drives per BigTwin Node RSD HIGH-PERFORMANCE COMPOSABLE NVME STORAGE SOLUTION Supermicro BigTwin (SYS-2029BT-HNR) is a 2U multi-node system that contains four independent high performance 2-socket compute nodes. Each node supports 24 DIMMs and up to 3TB of memory, 6 NVMe SSDs, and flexible networking options including 100G OPA or Ethernet. BigTwin features Supermicro\u2019s PowerStick fully redundant, high efficiency Titanium Level power supplies and shared cooling infrastructure. At just 1U rack space, Supermicro disaggregated NVMe storage enclosure (SSG-136R-N32JBF) supports 32 hot-swap 2.5\u201d NVMe SSDs and up to 1PB NVMe storage. With an innovative and elegant pull-out tray design for hot- swap and tool-less drive carrier, deploying and servicing the disaggregated NVMe storage in a Supermicro RSD deployment is extremely easy. The combination of BigTwin and disaggregated NVMe storage provides high-performance and high-capacity NVMe storage in a 3U building block for easy scale-out linear expansion. This solution is being embraced by numerous enterprises across many industry verticals to tackle the most pressing storage challenges in machine learning/deep learning, high throughput ingest, real time analytics, media and video streaming.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "2cc111cd-9fb3-4c7a-b6c8-dae996c3d096": {"__data__": {"id_": "2cc111cd-9fb3-4c7a-b6c8-dae996c3d096", "embedding": null, "metadata": {"file_name": "Solution-Brief_5G_Altiostar_O-RAN.pdf", "publication_date": "November 2019", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 - Management Applications Orchestration OpenRAN Software Suite NFVI Layer Open Hardware Platforms Figure 1. Altiostar/Supermicro O-RAN Solution 5G NR Distributed Unit (DU) Solution Based on O-RAN 5G is disrupting the mobile telecom network. To realize eMBB, URLLC, and mMTC, the top three use cases for 5G, mobile operators have to redesign their networks. Supermicro and Altiostar are leading the way to provide state-of-the-art platforms running best-in-class software infrastructure to ease the ability to deploy, manage, and orchestrate the mobile network. Solving the Challenges of 5G Networks One major change in 5G is the New Radio (NR). It will use much higher radio frequencies to achieve higher bandwidth required for the huge increase in connected devices and new use cases. Since higher frequencies will have shorter transmission range, more base stations will be required to cover existing areas. On top of this challenge, suppliers for Radio Area Network (RAN) equipment have been limited to a handful of large internation- al companies with proprietary solutions. Mobile network evolution has been slow while many innovations have happened with Internet and Cloud software. Service providers are migrating to open architecture-based RAN solutions for the transition to the 5G era. An open, cloud-native RAN concept has quickly gathered lots of interest and top global operators have formed the O-RAN alliance. O-RAN\u2019s mission is to build a new 5G RAN on a foundation of virtualized network elements, white-box hardware, and standard- ized interfaces that fully embrace O-RAN\u2019s core principles of intelligence and openness. As a contributing member of O-RAN, Supermicro is fully committed to contribute and deliver this solution. Altiostar is a software vendor that provides 5G-ready virtualized RAN solutions supporting open interfaces and a disaggregated hardware/software solution to build a multi-vendor web-scale network. Altiostar\u2019s OpenRAN software suite with open interfaces provides a high degree of programmability and automation. The combination of Altiostar\u2019s open software platform and Supermicro\u2019s commercial off-the-shelf (COTS) edge servers provides a reliable, flexible, scalable, and cost-compatible solution to realize the new RAN. Supermicro and Altiostar together can provide a complete open architecture reference model based on O-RAN, using best-in-class hardware and software. 2 5G NR Distributed Unit (DU) Solution Based on O-RAN - Printed in USA Please Recycle 01_5G-ORAN_2019-11_01-4 The Altiostar/Supermicro Solution Specifically, for the Distributed Unit (DU), the combined solution can support LTE or 5G with baseband functions decoupled from the hardware and deployed on network functions virtualization (NFV) infrastructure. RAN cloudification is one of the fundamental tenets of the O-RAN architecture. The operators\u2019 NFV and virtual infrastructure manager (VIM) requirements enhance virtualization platforms in support of various functional splits from 3GPP. The RAN DU sits between the Remote Radio Unit (RRU) and the Central Unit (CU) and includes real-time L2 functions, baseband processing, and radio frequency processing. Currently, Supermicro\u2019s Xeon D-based 1019D-FHN13TP server is being proposed in a draft configuration for the DU in O-RAN\u2019s white box working group. In this configuration, the DU will support 3 sectors of RRUs via a RIM card from Altiostar. The RIM card will provide CPRI-to-eCPRI conversion so that the baseband and radio frequency information can be transmitted over the IP network. In Figure 5, the DU will support 12 sectors of RRUs with multiple LTE bands, requiring a large amount of digital signal processing in real time to perform the CPRI-to-eCPRI conversion. This task can be offloaded to an FPGA card, specifically the Intel\uf0d2 FPGA Programmable Acceleration Card N3000. This card accelerates network traffic up to 100Gbps to support low latency and high bandwidth tasks such as FEC acceleration at the PHY layer. Conclusion Supermicro and Altiostar are working together to provide a cloud-native total solution for DU based on open architecture, open APIs, and open-hardware servers, benefiting from cloud computing innovations such as SDN, virtualization, and containerization. The benefits of FPGA plus x86 CPUs are exceeding early expectations on improving the LTE/5G workload using virtualized infrastructure. This scalable design will allow operators to have the flexibility to design their network, enable software-only remote upgrades to following generations, and make continuous implementation and deployment a reality. Figure 2. 1019P-FHN2T for controlled environments Figure 3. E403-9P-FN2T for deployment in more demanding environments Supermicro\u2019s new 1019P-FHN2T and E403- 9P-FN2T servers bring 2nd Gen Intel Xeon Scalable processors to the 5G NR RAN. They include the ability to support 2 or 3 PCI-E expansion cards for FH and MH interfaces. Figure 4. DU reference design for O-RAN White Box Figure 5. 2nd Gen Intel Xeon Scalable processor-based high-density deployment .", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "6766352f-50ae-4d7a-829e-548a47b7825d": {"__data__": {"id_": "6766352f-50ae-4d7a-829e-548a47b7825d", "embedding": null, "metadata": {"file_name": "Solution-Brief_Workstations_Manufacturing.pdf", "publication_date": "December 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Workstation Family In the manufacturing industry, companies are transforming their IT environments with workstation solutions built on compute technology, a new breed of CPUs and GPUs, more memory, increased storage, and comprehensive management software. By implementing cutting-edge workstations, manufacturers will have the ability to boost the performance of their critical applications to enhance product design. Today\u2019s companies are using advanced workstations to improve the speed and quality of their product development cycles. Significant improvements are already seen in graphics-intensive manufacturing applications, including computer-aided design (CAD), computer-aided engineering (CAE), 2D, and 3D design. 1 Choosing Trusted Partners 2 Building The Ideal Production Environment 3 Summary 5 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based on your requirements. 2 These tools are enabling manufacturers to accelerate their workflows with unmatched capabilities: \u2022 Bringing new products to market faster \u2022 Optimizing designs for appearance, performance, reliability, cost, and manufacturability \u2022 Enhancing collaboration with geographically dispersed teams to produce and accelerate optimal results Many manufacturers are using visual computing solutions to transform massive amounts of data into insights. High-performance workstations improve the productivity of high-level decision-makers and engineers by allowing them to make smarter decisions and take immediate action. These technologies deliver incredible performance to run manufacturing applications for predictive analytics, prescriptive analytics, and artificial intelligence (AI). The result is an ideal work environment for power users with high CPU and GPU computation core counts right at their desks to instantly identify, resolve, and even predict issues in production. Choosing Trusted Partners The world of professional visualization is changing quickly. Advanced requirements like real-time ray tracing, engineering simulation, immersive virtual reality (VR), and AI-augmented tools are common across the manufacturing sector. With professional workflows constantly evolving, workstations are pushed to the edge to optimize application performance. Supermicro and NVIDIA are delivering the next generation of visual computing to accelerate the future of manufacturing. Together, Supermicro and NVIDIA provide the right visual computing solutions to maximize the speed and precision of the manufacturing lifecycle. Supermicro is a global leader in high-performance, high-efficiency technology, offering the broadest product portfolio for robust workstations. With operations in more than 100 countries, Supermicro is a leader in enterprise, cloud, AI, edge, and IoT, developing state-of-the-art products that help manufacturers outpace the competition. The goal is to enable the success of every company. Supermicro achieves this through extensive engineering expertise and the industry\u2019s broadest product portfolio, which offers green computing technologies that reduce energy costs, effectively allocate resources to tackle complex design workflows, and improve the overall total cost of ownership. In addition, Supermicro provides a range of performance-boosting solutions to help manufacturers work better, smarter, and faster in partnership with NVIDIA. Supermicro is committed to building work environments that deliver industry-leading energy efficiency, acceleration, and stability. Leveraging first-to-market innovations from Supermicro and the NVIDIA RTX technology, Supermicro workstations are purpose-built for unprecedented performance at scale to enhance any application. These platforms are expertly designed to optimize manufacturing workflows that require powerful compute and graphics Manufacturers that partner with Supermicro and NVIDIA stand to gain an extraordinary competitive advantage: \u2022 Performance at scale: Leverage high throughput and low latency to ensure peak levels of efficiency while ramping up diverse data-centric workloads. \u2022 Enterprise reliability and enhanced manageability: Work with confidence with increased operational performance, durability, and longevity. \u2022 Rich, expansive visual workspace: Experience stunning imagery through movie-quality, anti-aliasing techniques, high-dynamic range (HDR) color support, rapid refresh rates, and up to 8K screen resolution. \u2022 Unmatched acceleration: Realize greater memory and bandwidth to boost productivity, creativity, and innovation. 3 capabilities so that companies can complete critical processes in record time. These solutions are already radically improving how teams design and collaborate to bring new products to market faster. Backed by GPU-powered workstations, manufacturers are applying VR, physically-based rendering, graphics virtualization, real-time simulation, and AI to optimize designs. These workstation solutions have the best product selections and configurations to ramp up production: \u2022 Building complex models \u2022 Rendering photo-realistic designs \u2022 Fueling real-time and predictive AI insights \u2022 Simulation product performance Product designers and engineers will experience a boost in productivity by enjoying a smooth graphics workflow using leading CAD/CAE software applications, even when working with complex 3D models on 4K displays. These game-changing technologies are empowering manufacturers to improve engineering efficiency to meet tight deadlines and project milestones. Now, enterprises can adopt the latest workstation solutions to power innovation anywhere. Building The Ideal Production Environment Supermicro workstations are fast, reliable, and cost-effective to meet the demands of any manufacturing operations. These workstations utilize enterprise-grade technologies which are tested and validated to meet specific application requirements. Solutions from Supermicro offer a high degree of flexibility and upgradability to support the rising need for graphics and AI wherever employees need to work. The workstations feature a wide range of industry standard components to optimally configure the system for enterprise needs\u2014including NVMe storage, the latest CPUs, and breakneck acceleration from NVIDIA GPUs. Supermicro offers recommended configurations to fit an enterprise's unique application requirements. Each Supermicro workstation is assembled and tested at a production facility in the USA. For EMEA and APAC companies, Supermicro builds workstations at production facilities in the Netherlands and Taiwan. All support issues are managed by local engineering experts, product managers, and global support services that include next-day onsite options. These workstations can deliver the best possible experience and performance for a range of demanding applications with optimized configurations, ultra-fast NVIDIA GPUs, and optimized drivers. Next generation workstations are designed with key capabilities in mind to improve manufacturing operations: \u2022 Purpose-built for the most demanding manufacturing workloads \u2022 Accelerated application performance to create tomorrow\u2019s products, today \u2022 Optimized workflows for powering innovation 4 Supermicro Workstations for Design Professionals SYS-5039A-I AS -5014A-TT SYS-740A-T Single-processor workstations provide exceptional power to handle the most demanding workflows Entry-level configurations are engineered to be cost-efficient while providing the right level of performance to empower teams using design and modeling applications. Most versatile workstation delivering full spectrum compute capability enables reduced render times, more creative iterations, faster simulation solving, quick assembly rebuilds, and smooth interactivity with 3D assets Mainstream configurations are an ideal choice for smaller electromagnetics, computational fluid dynamics (CFD), and mechanical simulation applications. Dual-processor workstations are fully configurable and provide high performance with server-grade reliability Expert configurations enable companies to harness the critical speed and compute capacity for larger electromagnetics, CFD, and mechanical simulation applications. - Intel Xeon W-2200 processor, up to 18 cores - 128GB DDR4-2933 Memory - NVIDIA RTX A2000 - 1TB M.2 NVMe + 6TB HDD - Windows 10/11 Pro 64 or Linux - AMD Ryzen Threadripper PRO 3900WX Series Processor, up to 64 Cores - 512GB DDR4-3200 Memory - NVIDIA RTX A6000 - 3x 1TB M.2 NVMe in RAID 5 + 2x 3.8TB U.2 PCIe Gen 4 SSD - Windows 10/11 Pro 64 or Linux - Dual 3rd Gen Intel Xeon Scalable processors, up to 76 total cores - 2TB DDR4-3200 Memory - NVIDIA RTX A6000DR4-3200 Memory - 2TB M.2 NVMe + 2x 7.6TB U.2 PCIe Gen 4 SSD - Windows 10/11 Pro 64 or Linux 5 Summary Supermicro and NVIDIA are empowering companies across the manufacturing industry to work better, smarter, and faster with solutions designed to boost productivity and insight. Today, these powerful workstations are created to help manufacturers deliver amazing new products and innovate without bounds. As a result, organizations can benefit from solutions and capabilities that are the best in the industry: \u2022 Best performance: Highest memory and storage capacities available in a single tower system, featuring up to four passively cooled GPUs in tower form factor. Supermicro is the only manufacturer to offer up to four NVIDIA A100 Tensor Core GPUs in multiple models, with up to 80 cores, 4TB of memory, 61.44TB of NVMe, and optional DCPMM support. \u2022 Best expandability Up to six PCIe Gen4 x16 expansion slots, or up to four PCIe Gen4 M.2 with optional hardware RAID 0/1/5/10 support. \u2022 Best component selection: Supermicro validates a wide variety of memory, storage, and networking components with different specifications to help configure an optimized system for an organization's needs without locking anyone into one brand. \u2022 Best assembly and local support: All workstation systems shipped in the Americas are built and tested at Supermicro headquarters in San Jose, California, and include technical support services by in-house Supermicro engineers and product managers. Whether building complex 3D models, rendering photo-realistic designs, or simulating product performance, workstation solutions from Supermicro and NVIDIA have the best product selections and configurations to accelerate overall productivity. Together, Supermicro and NVIDIA can help enterprises deploy the ideal workstation for specific requirements to optimize product design workflows, from intensive graphics work to the cutting edge of AI. Let Supermicro help organizations transform any environment. Visit Supermicro online to get started.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "c4b18504-abe3-474d-9f65-9e08f8f33d31": {"__data__": {"id_": "c4b18504-abe3-474d-9f65-9e08f8f33d31", "embedding": null, "metadata": {"file_name": "Solution-Brief_Memverge.pdf", "publication_date": "July 2022", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 According to IDC, real-time data will comprise almost 25% of all data by 2024. This Big Bang of real-time data is driving the expansion of real-time analytics and AI/ML applications into the mainstream. However, it\u2019s not uncommon for data sets to exceed the size of system memory, creating the need to read and write data to a from storage (storage I/O), making real-time analytics almost impossible, and extending the resource required for large data analytics. Therefore, implementing data-driven, software- defined architectures that meet the demands of those data sets is critical. Supermicro and the MemVerge Memory Machine solution offer integrated hardware and software that virtualizes DRAM and persistent memory so that all of the memory can be accessed without code changes and can scale out in clusters to provide the capacity needed by real-time analytics and AI/ML applications 1 Overview of MemVerge Technology 2 Supermicro \u2013 MemVerge Solution Advantages 2 Joint Solution Architecture 3 Use Cases 3 Case Study - Big Memory Accelerates Single-Cell RNA Sequencing 4 Solution Reference Architecture Configuration 5 Conclusion 7 2 and deliver enterprise-class data services for high-availability. Data has become one of the most significant drivers of our economy, businesses, and IT infrastructures. Leveraging a powerful, software defined architecture to aggregate the performance and capacity of DRAM and persistent memory eliminates the roadblocks and enables innovative workflows\u2014 an optimized platform with the architecture, integration, support, and managed services to ensure the success of critical applications Overview of MemVerge Technology MemVerge Memory Machine is an in-memory data management platform that creates a memory virtualization layer between applications and the underlying memory hardware. Its architecture assumes there are two tiers of memory, the first composed of DRAM and the second composed of DRAM or PMem. By intelligently managing the two tiers of memory, Memory Machine optimizes memory performance with reduced Total Cost of Ownership (TCO) of server infrastructure. In addition, it makes data manageable and provides higher availability with the unique ability to load, save, replicate, and recover terabytes of data in seconds, greatly accelerating the time to discovery. Figure 1 - MemVerge Memory Machine overview Supermicro \u2013 MemVerge Solution Advantages Supermicro and MemVerge have partnered to develop a best-in-class solution based on industry-leading SuperServers and Memory Machine. The solution delivers an Enterprise-Class Big Memory platform to dramatically expand the in-memory computing power with compelling new capabilities, clear Total Cost of Ownership metrics, and data durability. \u2022 Memory Virtualization Platform: Memory Machine virtualizes DRAM and Persistent Memory so that data can be accessed, tiered, scaled, and protected while in memory \u2022 Software-Defined Memory Service: Compatible with existing applications. Provides access to persistent memory without changes to applications. The persistent memory looks like DRAM to applications. \u2022 Tiered memory for maximum capacity and optimum performance: Unlike approaches that cache PMem data in DRAM, which lowers useable capacity, Memory Machine utilizes 100% of the DRAM and PMem capacity. For Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally- friendly solutions available on the market. 3 performance, hot data is intelligently moved to the DRAM \u201cfast tier\u201d while warm data is placed in the PMem \u201cpersistent tier.\u201d \u2022 Low-latency memory replication: For apps like Pub/Sub, Memory Machine uses RDMA to publish high volumes of messages to remote subscribers with ultra-low latency \u2022 Recover TBs of data in seconds: With ZeroIOTM memory snapshots: To protect large memory blast zones, Memory Machine provides memory snapshots & replication for lightning-fast crash recovery that requires zero IO to storage \u2022 Clone databases in seconds: Snapshots can be used for developers and other applications to clone terabyte database instances while sharing existing memory Joint Solution Architecture Supermicro MemVerge Memory Machine Ready Server Platforms solution architecture Diagram: Figure 2 - Supermicro and MemVerge Joint Solution Architecture MemVerge Use case: When customers have long-running, stateful applications that do not have robust checkpoint-restore functionality. If the application encounters a problem, the application must restart from the beginning. Memory Machine takes ZeroIO In- memory snapshots so that if an application instance encounters a problem, it can be restarted from any valid snapshot. Some analytical pipelines take a long time to complete because there is no easy way to parallelize some stages. Memory Machine can create an AppCapsule \u2014 all the in-memory state and data associated with a running application instance (including open files residing on SSD). AppCapsule can be used to instantiate additional application instances. Consecutive 4 pipeline stages that can be parallelized can be started simultaneously without requiring any storage I/O. Note: the degree of parallelization that can be achieved depends on the analytical pipeline and the dataset. Some applications cannot run because there is insufficient memory (e.g., bioinformatics pipelines with large datasets). Other applications take a long time to execute because of limited memory \u2014 datasets must be processed in batches. Intel Optane Persistent Memory (PMem) provides high-capacity memory but is not straightforward to use. Using Memory Machine, applications can access all the memory capacity (DRAM+PMem) without requiring code changes. Note: when used in Intel Memory Mode, the DRAM portion is unavailable to the application. Case Study - Big Memory Accelerates Single-Cell RNA Sequencing Working with a leader in Single Cell RNA Sequencing and Analytics, Analytical Biosciences, the big memory data science workbench can dramatically increase the productivity of the genomic computation pipeline. Using snaps instead of storage IO, the data loading time for every stage is significantly reduced, up to 800X for some stages. It can save the overall execution time by at least 60% and delivers higher productivity by allowing data scientists to roll back and branch to perform what-if analysis. Figure 3 - Example of Restore Time Comparison Figure 4 - Example of Execution Time comparison Solution Reference Architecture Configuration 233 490 507 492 515 738 788 804 810 805 810 1 1 1 1 1 1 1 1 1 1 1 0 100 200 300 400 500 600 700 800 900 Step 1 ImportData Step 2 MergeData Step 3 Quality Control Step 4 NormalizeData Step 5 HVG Step 6 Scale Step 7 RunPCA Step 8 FindNeighbors Step 9 FindClusters Step 10 UMAP Step 11 tSNE Time (s) to Restore a Compute Stage (for Parameter Tunning and Debugging) Reload from storage (Baseline) Restore from snapshot (MemVerge) 2167 1209 1216 1014 1108 2904 1894 1692 1750 3963 4190 1673 220 171 55 43 1321 342 87 100 2463 2491 0 500 1000 1500 2000 2500 3000 3500 4000 4500 Step 1 ImportData Step 2 MergeData Step 3 Quality Control Step 4 NormalizeData Step 5 HVG Step 6 Scale Step 7 RunPCA Step 8 FindNeighbors Step 9 FindClusters Step 10 UMAP Step 11 tSNE Execution Time (s) of Each Analysis Stage (Compute + I/O or Snapshot) Baseline (DRAM + Storage) MemVerge (DRAM + PMEM) 5 Supermicro MemVerge Memory Machine reference architecture comes with three options for different use cases, two with rackmount server and one with a multimode system. Each option has two different configurations based on the capacity of DRAM and PMEM. As a result, MemVerge Memory Machine Ready Server Platforms enable users to benefit from a two-tier memory hierarchy management to achieve improved performance when running any memory-intensive application on Linux. Figure 5 - Reference Architecture Configurations MemVerge Memory Machine Software: MemVerge has developed two versions of software for providing different levels of capabilities: Memory Machine Standard Edition The Memory Machine Standard Edition provides applications with transparent access to persistent memory that emulates DRAM and is volatile like DRAM. Memory Machine also powers lower-cost persistent memory to perform like DRAM: \u2022 Provides access to a pool of DRAM and (volatile) PMem without changes to apps \u2022 Delivers higher performance and capacity than Intel Memory Mode \u2022 More composable than Intel Memory Mode with visibility and control on a per-app basis \u2022 Runs on bare metal, in VMs, and Containers Memory Machine Advanced Edition The Memory Machine Advanced Edition includes all the capabilities of Memory Machine Standard Edition, plus transparent access to persistence via the industry\u2019s first enterprise-class data services for highly available memory: \u2022 The suite of services powered by in-memory snapshots \u2022 ZeroIO in-memory snapshots capture memory state in seconds \u2022 Built on industry-standard DAX APIs for accessing persistent memory \u2022 Supermicro systems configured in as a solution reference architecture 6 Supermicro MemVerge Memory Machine Ready Server Platforms: Entry - To provide baseline performance benefit brought from PMem and best cost-performance ratio out of three models (sizes) CloudDC SuperServer SYS-120C-TN10R \u2022 Dual sockets P+ (LGA-4189) 3rd Gen Intel Xeon Scalable Processors \u2022 Intel C621A Chipset \u2022 16 DIMMs up to 6TB 3DS ECC DDR4-3200: LRDIMM/RDIMM \u2022 Intel Optane Persistent Memory 200 series \u2022 2 PCI-E 4.0 x16 FHHL; 2 PCI-E 4.0 x16 AIOM (OCP 3.0); 2 PCI-E 3.0 x2 NVMe M.2 \u2022 Dual AIOM with NCSI (OCP 3.0) for networking, 1 dedicated IPMI LAN \u2022 10x 2.5\" hot-swap hybrid NVMe/SATA/SAS drive bays \u2022 6 counter-rotating 4 cm PWM fans with optimal fan speed control, 2 air shrouds \u2022 860W redundant Platinum level 100-240Vac and 200-240 Vdc power supplies \u2022 1 VGA, 1 COM, 2 USB 3.0 (rear), 2 USB 2.0 (front) High-End - To provide the most memory capacity of three models (sizes). Ultra SuperServer SYS-120U-TNR \u2022 Dual Socket P+ (LGA-4189) 3rd Gen Intel Xeon Scalable Processors \u2022 Intel C621A Chipset \u2022 32 DIMM Slots up to 8TB ECC DDR4-3200 LRDIMM/RDIMM; \u2022 Intel Optane Persistent Memory 200 series \u2022 1 Internal PCI-E 4.0 x16; 1 PCI-E 4.0 x16 (LP); 2 PCI-E 4.0 x16 (FH, 10.5\"L) \u2022 Flexible networking options \u2022 12x2.5\" hot-swap hybrid NVMe/SATA/SAS drive bays 7 \u2022 8 heavy duty fans with optimal fan speed control \u2022 1200W redundant Titanium level power supplies Multi-Node - To provide baseline performance benefit from PMEM and higher density of the compute cluster. This is the best space efficiency out of the three models (sizes). BigTwin SuperServer SYS-220BT-HNTR \u2022 Four hot-pluggable systems (nodes) in a 2U form factor. Each node: \u2022 Dual Socket P+ (LGA-4189) 3rd Gen Intel Xeon Scalable Processors \u2022 Intel C621A Chipset \u2022 16 DIMM Slots up to 6TB ECC DDR4-3200 LRDIMM/RDIMM; \u2022 Intel Optane Persistent Memory 200 series \u2022 2 PCI-E 4.0 x16 (LP) slot; Internal PCI-E 3.0 x8 for 2 M.2 NVMe/SATA support onboard; \u2022 Optional NVMe Boot Controller via AOC-SMG3-2M2-B \u2022 Network connectivity via AIOM (OCP 3.0 compliant) \u2022 6 Hot-swap 2.5\" drive bays; 6 PCI-E 4.0 NVMe/SATA 2.5\" drives \u2022 4 cooling fans per 2U enclosure, 16.5K RPM; Shared Cooling Design; Liquid Cooling Support \u2022 2600W Redundant Power Supplies Titanium Level (96%+); Shared Power Design Conclusion and Resources Real-time data is driving the expansion of real-time analytics and AI/ML applications into the mainstream and extending the need for large data analytics. Therefore, implementing data-driven, software-defined architectures that meet the demands of those data sets is critical. Supermicro and MemVerge offer a solution based on the MemVerge Memory Machine with integrated hardware and software that unlocks Intel Optane PMem Performance, Capacity, Availability & Productivity. By virtualizing DRAM and persistent memory, the memory can be accessed without code changes, scale-out in clusters to provide the capacity needed by real-time analytics and AI/ML apps, and deliver enterprise-class data services for high availability. Success will be assured with this optimized platform and the architecture, integration, support, and managed services it provides.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "fd1813f4-de07-4bf7-a85b-5071542441c9": {"__data__": {"id_": "fd1813f4-de07-4bf7-a85b-5071542441c9", "embedding": null, "metadata": {"file_name": "Solution-Brief_SAP-HANA.pdf", "publication_date": null, "referenced_websites": ["www.supermicro.com", "https://www.supermicro.com/en/solutions/sap"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro SAP HANA Certified Appliance Digital transformation is a top priority for any enterprise or business looking to gain a competitive advantage in the rapidly evolving information economy. Real time, actionable business insights and continuous operational improvements, once just wishful thinking, have become standard requirements for today\u2019s information-driven CEOs. Your digital corporation now requires a powerful, scalable platform for enterprise resource planning (ERP), supply chain management (SCM), or customer relationship management (CRM) to run. Your CEO requires the ability to manipulate, extract, and analyze large volumes of live transactional data, all in real time, without interruption to business operations. Supermicro and SAP are here to help. SAP HANA enables your digital transformation by providing a real-time, in-memory computing platform that is 10,000 times faster than traditional databases,* all while allowing real-time, On Line Transactional Processing (OLTP) and On Line Analytical Processing (OLAP) on the same system or environment. Supermicro has partnered with SAP to pre certify, validate, and architect single node SAP HANA scale-up appliances to power your digital transformation infrastructure. 1 2 Supermicro SAP HANA Certified Appliances 2 SAP HANA Appliance Certification 3 SAP HANA Appliance\u2014Tailored Data Center Integration 3 Supermicro SAP HANA Hardware Sizing and Consulting Supermicro SAP HANA Certified Appliance 2 Supermicro SAP HANA Certified Appliances The Supermicro 4 socket (SYS-2049U) and 8 socket (SYS-7089P) multi-processor (MP) SuperServers were designed for the most demanding, mission-critical workloads in use by top enterprises and cloud service providers. These 4 and 8 socket servers support the highest-performance Intel Xeon Scalable processors, the largest memory capacity available, the latest in Intel Optane DC persistent memory technology, and fastest all-flash NVMe or SSD storage options available for the SAP HANA platform. The combination of these cutting edge technologies makes Supermicro MP Servers the most powerful single-node SAP HANA platforms available on the market today. These SAP Appliances are the ideal building blocks for your SAP S/4HANA, BW/4HANA, or SAP HANA database deployments. Supermicro has partnered with Intel and SAP to certify Intel Optane DC persistent memory for use with SAP HANA version 2.0 SPS03, or higher, on 2nd Gen Intel Xeon Scalable Processors. Intel Optane DC persistent memory is an innovative memory technology that delivers affordable large capacity uniquely combined with support for data persistence. Data persistence technology allows for your entire data volume to reside on high speed Intel Optane DC persistent memory across work sessions and power downs without the need to write and read from a traditional disk. As validated by SAP and Intel, SAP HANA reboot time using a 6TB database was dramatically reduced from over 50 minutes down to 4 minutes\u2014a 12.5x improvement over traditional SSD to DDR load times. This makes Intel Optane DC persistent memory ideal for your SAP DevOps environment, where system restarts are frequently required. In addition to fast load times for DevOps, Intel Optane DC persistent memory delivers an optimized balance between persistence and performance at a lower cost per Gigabyte than DRAM. With the high cost of DDR, especially for large in-memory deployments, the use of Intel Optane DC persistent memory can dramatically lower the initial acquisition cost of your SAP HANA hardware. This cost savings increases exponentially as your SAP HANA cluster grows from system to rack scale. Intel Optane DC persistent memory is not only lower cost than DDR memory, but is also available in larger sizes, up to 512GB per unit. The combination of DDR memory plus Intel Optane DC persistent memory allows for much larger SAP HANA deployments, per socket, than use of traditional DDR memory alone (see graphic below). Please contact sapexpert@supermicro.com or your local Supermicro sales for up to date pricing and cost reduction comparison between Intel Optane DC persistent memory and DDR memory. SAP HANA Appliance Certification The SAP HANA Appliance certification guarantees that the S/4 HANA database software performs as intended on the certified system. SAP HANA Appliances are offered in various sizes with predefined, fixed BOMs and sizing as listed on SAP\u2019s HANA certified hardware directory. Scale-up appliances are specifically designed to run as a single autonomous compute node with internal or, connected to, external storage. To increase the size and performance of a scale up system, you simply upgrade the CPU, RAM, or Disk in the node. All SAP HANA Appliances are designed to be turn-key solutions. As such, Supermicro pre-installs the HW components, operating system, and SAP HANA (on a temporary key) before delivering the appliance. 2U 4 Socket SAP HANA Appliance (SYS-2049U-TR4) \u2022 Quad Socket 2nd generation Intel Xeon Scalable processors (Cascade Lake), up to 112 cores \u2022 Can be configured as 4 socket or 2 socket (upgrade ready) HANA Appliances \u2022 Appliance model supports up to 6 TB DRAM \u2022 Tailored Datacenter Integration (TDI) model supports up to 18 TB (DRAM + Intel Optane DC Persistent Memory) 7U 8 Socket SAP HANA Appliance (SYS-7089P-TR4T) \u2022 Octal Socket 2nd generation Intel Xeon Scalable processors (Cascade Lake), up to 224 cores \u2022 Can be configured as 8, 6, 4, or 2 socket (upgrade ready) HANA Appliances \u2022 Appliance model supports up to 12 TB DRAM \u2022 Tailored Datacenter Integration (TDI) model supports up to 24.6 TB (DRAM + Intel Optane DC Persistent Memory) Supermicro SAP HANA Certified Appliance 3 Specifications (BWoH, BW/4H, S/4H and DM) SYS-2049U-TR4 2 Socket configuration (Up to 56 cores) SYS-2049U-TR4 4 Socket configuration (Up to 112 cores) SYS-7089P-TR4T 2 Socket configuration (Up to 56 cores) SYS-7089P-TR4T 4 Socket configuration (Up to 112 cores) SYS-7089P-TR4T 8 Socket configuration (Up to 224 cores) 192 GB to 7.6 TB (12 \u00d7 128GB DDR4) + (12 \u00d7 512GB Intel Optane DC Persistent Memory) 192 GB to 15.4 TB (24 \u00d7 128GB DDR4) + (24 \u00d7 512GB Intel Optane DC Persistent Memory) 192 GB to 7.6 TB (12 \u00d7 128GB DDR4) + (12 \u00d7 512GB Intel Optane DC Persistent Memory) 192 GB to 15.4 TB (24 \u00d7 128GB DDR4) + (24 \u00d7 512GB Intel Optane DC Persistent Memory) 192 GB to 24.6 TB (48 \u00d7 256GB DDR4) + (48 \u00d7 256 Intel Optane DC Persistent Memory) System SAP HANA CERTIFIED APPLIANCES (SCALE FROM 192GB TO 24.6 TB AEP + DRAM) SAP HANA Appliance\u2014Tailored Data Center Integration All SAP Certified Appliances are eligible for Tailored Datacenter Integration (TDI) deployment, which allows the customer to build an SAP HANA server with their own choice of CPU, RAM, Disk, and add-on cards. The SAP HANA TDI option offers you more flexibility and freedom of choice to deploy SAP HANA hardware matching your existing data center infrastructure, licenses, and hardware. Again, to emphasize, SAP HANA Appliances are designed as fixed BOM turnkey solutions, whereas SAP HANA TDI deployments allow the customer to mix and match certified components. TDI open architecture allows the customer to cluster their HANA servers in their own preferred method for high availability and network storage. Customers choosing SAP HANA TDI may use their own resources or 3rd party to deploy and integrate Supermicro hardware with their existing infrastructure. Supermicro SAP HANA Hardware Sizing and Consulting To assist you on your SAP HANA infrastructure and hardware selection, Supermicro\u2019s SAP architects and solutions managers offer free hardware sizing and consulting services. Whether you are a greenfield customer considering SAP HANA adoption or brownfield customer looking to upgrade legacy SAP ECC to S/4 HANA, Supermicro\u2019s SAP HANA experts are here to guide you and help you optimize your hardware stack for performance and cost. To get started, please contact sapexpert@supermicro.com. Supermicro SAP HANA certified solutions:", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "443727e0-5a3d-423d-81c3-b9cf663425a8": {"__data__": {"id_": "443727e0-5a3d-423d-81c3-b9cf663425a8", "embedding": null, "metadata": {"file_name": "Solution-Brief_AMD_Oracle_Database_19C.pdf", "publication_date": "January 2021", "referenced_websites": ["https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/overview-of-oracle-linux-", "https://docs.oracle.com/en/database/oracle/oracle-database/19/unxar/administering-oracle-", "https://www.hammerdb.com/docs/ch04s02.html#d0e699", "https://www.hammerdb.com/docs/ch01s05.html", "https://www.hammerdb.com/docs/ch01s06.html#d0e382"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 AND AMD ACHIEVE OUTSTANDING LINEAR WORKLOAD SCALING FOR ORACLE DATABASE 19C AMD Powered Supermicro A+ Servers Accelerate Oracle Database 19c Performance Supermicro, working closely in partnership with AMD, has been a part of the AMD EPYC processor journey since the first launch of AMD's \u201cZen\u201d microarchitecture in 2017. Supermicro was one of the first server vendors to bring the 1st Gen AMD EPYC -processors to market with our H11 platforms. In 2019, Supermicro launched its first family of H12 generation AMD processor-powered Supermicro A+ servers optimized to deliver a new level of integration and superior performance for modern datacenters with the AMD EPYC 7002 Series Processors. The new A+ servers, powered by the 2nd Gen AMD EPYC 7002 series processors, deliver up to two times the performance with up to double the core count compared to 1st Gen AMD EPYC processor-based systems. With Supermicro\u2019s next-generation architecture, the A+ servers take full advantage of 2x data throughput of PCI-E 4.0 lanes that the new AMD processors provide, including the full spectrum of the latest components storage, networking, accelerators like GPUs. 1 Benchmarking with Oracle Database 19C 2 Hardware Configuration and Set Up 3 Hardware Linear Workload Scaling 4 Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally- friendly solutions available on the market. 2 Supermicro\u2019s expertise and experience in optimizing systems for the AMD EPYC architecture has led to 27 world record system performance benchmarks at launch, in , for 2nd Gen AMD EPYC 7002 series processors. World-record performance benchmarks were set on Supermicro\u2019s new H12 A+ Servers for TPCx-IoT and TPC-DS categories. For more detailed information on AMD EPYC World Records, please see the URL (1) in the Footnotes. For TPCx-IoT, the performance of 472,200.88 IoTps was established on Supermicro's H12 TwinPro 2U 4-node server where faster IoT gateway data analytics are critical for the coming explosion of IoT device numbers. This server delivers the highest performance and lowest performance per dollar for a 10TB database with 64% higher QphDS throughput (Composite Query per Hour Metric) and cost savings per QphDS over the previous world record holders, see the AMD EPYC 7002 Series Processors URL(2) in Footnotes. Supermicro offers an industry-leading portfolio of AMD EPYC based systems based on Server Building Block Solutions. From single-socket mainstream and WIO servers to high-end Ultra server systems and multi-node systems, including BigTwin and TwinPro, Supermicro enables customers to build application-optimized solutions with a wide range of configuration possibilities. AMD EPYC 7002 Series Processors Brings Flexibility, Performance, and Security Features AMD EPYC 7002 Series processors offer up to 64 x86 cores per socket for high-density requirements and can dramatically increase your system performance while running a number of concurrent and complex applications. With higher frequencies than the other offerings, the AMD EPYC 7Fx2 processors are optimized for frequency sensitive and single-threaded workloads. This efficiency and speed can help you to achieve significant savings in the total cost of ownership (TCO). Based on AMD Infinity Guard, the new 2nd Gen AMD EPYC 7002 series processors also feature advanced security, including Secure Memory Encryption and Secure Encrypted Virtualization. AMD EPYC 7Fx2 processors bring high frequencies and very high ratios of cache per core to the 2nd Gen AMD EPYC family of processors along with the large memory capacity, extreme memory bandwidth, and massive I/O, to deliver exceptional performance. The tested configuration is shown below in Table 1. The AMD EPYC 7Fx2 processors offer high frequency that is specifically designed to optimize per-core performance for frequency sensitive workloads and core-based software licensing models. AMD EPYC 7Fx2 Processors Demonstrate Superior Performance on Transactional Processing Workloads with Oracle Database 19c Oracle Database delivers leading-edge innovations in relational database management systems (RDBMS) for on-premises, cloud, and hybrid workloads with exceptional performance and ease-of-use. AMD\u2019s internal test results show that AMD EPYC 7Fx2 processor-based systems deliver high performance and outstanding scaling for Online Transaction Processing (OLTP) performance with Oracle Database 19c. Supermicro AS -1014S-WTRT server, powered by AMD EPYC 7F72 For this benchmark with Oracle Database 19c, we are using the Supermicro AS -1014S-WTRT server powered by AMD EPYC 7F52 and AMD EPYC 7F72. This system is a single socket, as shown in the table below. With AMD EPYC\u2019s core density, it is cost- effective and ideal solution for database processing and enterprise application workloads. 3 Server Form Factor System Memory Drive Bays Network Controllers AS-1014S- WTRT 1U Rackmount 8 x DDR4 slots up to 3200MHZ 4 x hot swap 3.5\u201d or 2.5\u201d SATA3 or NVMe drives Dual Broadcom 10G Base -TLAN ports Table 1: Benchmarks CPU Model Supermicro\u2019s AS -1014S-WTRT server\u2019s design philosophy was to provide a high density, single-socket server in a compact form factor (1U, 25.6\u201ddeep) that is powerful and robust enough to handle the most demanding enterprise applications while also maintaining cost efficiency. The AS -1014S-WTRT is a single socket system, in which customers may choose among AMD\u2019s 8, 16, 24, 32, and 64 cores, P variant CPU SKUs, which offer unique pricing discounts over dual socket capable AMD CPUs. We specifically selected this single-socket system for benchmarking with Oracle Database 19c because it offers a unique and strong value proposition, capable of predictable workload performance scaling. With AMD\u2019s 2nd generation cores, what used to require dual or multi-socket systems, can now be consolidated into a single scale-up server. AS -1014S-WTRT \u2013 Oracle Database 19c AMD EPYC 7Fx2 Processors Demonstrate Superior Performance on Transactional Processing Workloads with Oracle Database 19c Oracle Database delivers leading-edge innovations in relational database management systems (RDBMS) for on-premises, cloud, and hybrid workloads with exceptional performance and ease-of-use. AMD\u2019s internal test results show that AMD EPYC 7Fx2 processor-based systems deliver high performance and exceptional scaling for Online Transaction Processing (OLTP) performance with Oracle Database 19c. 4 Server Base Frequency Boost Frequency (up to)* Core Processor Memory Channels Maximum Memory/Socket(DDR4- 3200) PCIe Gen4 Lanes / System AMD EPYC 7F52 3.5 GHz 3.9 GHz 16 8 4 TB 128 AMD EPYC 7F72 3.2 GHz 3.7 GHz 24 8 4 TB 128 Table 2: Figure CPU's deployed Benchmarking with Oracle Database 19c and AMD EPYC 7Fx2 Processors These CPUs are optimized for higher frequency as in Table 2; they excel at single-threaded workloads where core count limitation is preferred. This workload models an order fulfillment system where the database receives requests for data, adds new data, and makes multiple changes to the data from a large number of users. The results show sustained transaction throughput and predictable scaling across 16-core and 24-core processors allowing one to right-size the compute power to the application needs and help lower total cost of ownership by only paying for cores needed to optimize core-based software licensing model costs. Table 3: TPC - C Benchmarks 5 This OLTP Workload, used for this benchmark, is derived from the TPC-C Benchmark, and as such, is not comparable to published TPC-C Benchmark results, as the OLTP workload results do not comply with the TPC-C Benchmarks in the above Table 3. Hardware Configuration and Setup 6 Supermicro AS -1014S-WTRT server is a 1U Rackmount Server supporting Single Socket with AMD EPYC 7002 Series Processors. Two different CPU models were used in this benchmark study to estimate a scaling efficiency due to the different number of cores contained. The same tests have been applied to the same server configuration, with the only difference being the CPU, per the two options listed below in Table 2. SuperMicro engineers executed these benchmarks with the Industry Standard HammerDB Benchmark Tool on a Supermicro AS -1014S-WTRT Server using 16-core AMD EPYC 7F52 and 24-core AMD EPYC 7F72 processors as displayed in Table 2. The same configuration used for the TPC-C Benchmark systems has been applied to both systems. The creation scripts for the database schema and execution scripts can be found in this document Appendix section. The tested Oracle Database version was 19.3.0.0.0. An Oracle Restart Instance was configured for the tests. o 4 Datacenter Class 1.8T NVMe SSDs were used for Oracle storage. o The 4 NVMe disks had been added to an Oracle ASM instance for use by Oracle Database. \u25aa 2 x 1.8 TB = DATA Disk Group \u25aa 2 x 1.8 TB = DATA Disk Group Firmware/BIOS configuration The Test configuration had been designed to get the most efficiency out of the Memory channels and interleaving on all 8 DIMMs, as shown in Figure 1: Firmware / Bios configuration. \u2022 Possible NUMA Nodes / Socket configuration was set as NPS1 \u2022 SMT was enabled 7 Figure 1: Firmware / Bios configuration Hardware Linear Workload Scaling A crucial step when building your solution is to calculate the total cost of ownership (TCO). Oracle Processor Licensing is calculated by multiplying the total number of cores on each processor by a licensing factor defined by the Oracle Processor Core Factor Table. In addition to the Core license, Oracle typically charges an additional 20% for service & maintenance. With this license model, customers can reduce license costs by selecting low core count CPUs with the highest frequencies, such as the AMD EPYC 7F52 and 7F72. Oracle Database Standard Edition licensing is based on a per-socket license model. For multi-CPU servers, such as dual and quad-socket systems, Oracle Database Standard Edition requires an individual license for each socket in the system. This makes the Supermicro AS-1014S-WTRT an ideal cost-optimized solution for small to mid-size Oracle Database deployments with linear CPU scaling. 8 APPENDIX A \u2013 Oracle Linux Configuration The recommended way to configure Oracle Linux for Oracle Database is by installing the Oracle Preinstallation RPM. The procedure can be found in Oracle\u2019s \u201cDatabase Installation Guide for Linux.\u201d, see the following regarding Oracle Database 19c. \u2022 configuration-with-oracle-rpms.html#GUID-693599D4-BD32-4E6A-9689-FA7D1CD75653 \u2022 Install Oracle Linux 7.6 with UEK 4 (4.14.35.1902.0.18) \u2022 Register your Linux distribution through Oracle\u2019s Unbreakable Linux Network (ULN) and download and configure the yum repository for your system using the Oracle Linux yum server for your Oracle Linux release. \u2022 Install the Oracle Preinstallation RPM with the RPM for your Oracle Grid Infrastructure and Oracle Database releases and update your Linux release. \u2022 Make sure that after the Oracle binaries are extracted to ORACLE_HOME and after executing root.sh, you have the following entries in your/etc/sysctl.conf file. Please add the vm.nr Hugepages at the end of /etc/syssctl conf based on your available DRAM, In our test case, the total DRAM was 512 GB, and we allowed the Hugepages size to occupy around 460GB. Please refer to Oracle Tuning SGA with Hugepages in the link below (Chapter A.7) \u2022 See database-on-linux.html#GUID-76C03D99-6025-41F2-8BE3-F6DCDB1DCEE0 9 # cat /etc/sysctl.conf # sysctl settings are defined through files in # /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/. # # Vendors settings live in /usr/lib/sysctl.d/. # To override a whole file, create a new file with the same in # /etc/sysctl.d/ and put new settings there. To override # only specific settings, add a file with a lexically later # name in /etc/sysctl.d/ and put new settings there. # # For more information, see sysctl.conf(5) and sysctl.d(5). # oracle-database-preinstall-19c setting for fs.file-max is 6815744 fs.file-max = 6815744 # oracle-database-preinstall-19c setting for kernel.sem is '250 32000 100 128' kernel.sem = 250 32000 100 128 # oracle-database-preinstall-19c setting for kernel.shmmni is 4096 kernel.shmmni = 4096 # oracle-database-preinstall-19c setting for kernel.shmall is 1073741824 on x86_64 kernel.shmall = 173741824 # oracle-database-preinstall-19c setting for kernel.shmmax is 4398046511104 on x86_64 kernel.shmmax = 4398046511104 # oracle-database-preinstall-19c setting for kernel.panic_on_oops is 1 per Orabug 19212317 kernel.panic_on_oops = 1 # oracle-database-preinstall-19c setting for net.core.rmem_default is 262144 net.core.rmem_default = 262144 # oracle-database-preinstall-19c setting for net.core.rmem_max is 4194304 net.core.rmem_max = 4194304 # oracle-database-preinstall-19c setting for net.core.wmem_default is 262144 net.core.wmem_default = 262144 # oracle-database-preinstall-19c setting for net.core.wmem_max is 1048576 net.core.wmem_max = 1048576 # oracle-database-preinstall-19c setting for net.ipv4.conf.all.rp_filter is 2 net.ipv4.conf.all.rp_filter = 2 # oracle-database-preinstall-19c setting for net.ipv4.conf.default.rp_filter is 2 net.ipv4.conf.default.rp_filter = 2 # oracle-database-preinstall-19c setting for fs.aio-max-nr is 1048576 fs.aio-max-nr = 1048576 # oracle-database-preinstall-19c setting for net.ipv4.ip_local_port_range is 9000 65500 net.ipv4.ip_local_port_range = 9000 65500 vm.nr_hugepages=236000 ( reduce it to memory available ) NR huge pages x 2MB / 1024 = 460 GB (In our test case our DRAM capacity used was 512 GB) 10 APPENDIX B \u2013 Oracle Database 19c Configuration \u2022 Oracle Database is tuned for this Benchmark using the profile parameters below: $ cat /u01/app/oracle/product/19.0.0/dbhome_1/dbs/initROMETPCC.ora 11 12 Preparing Benchmark Database Benchmark Database Creation Benchmark database has been created using the SQL Scripts below Tablespace creation Temporary Tablespace creation Create Users and grants 13 APPENDIX C \u2013 Configuration Validation for HammerDB Preparing Benchmark Client a. Install Oracle Database 19c client on Oracle Linux Install Oracle client software on the client machine and configure as per the below instructions Install Oracle Database 19c client software on the client machine and configure as per the below instructions HammerDB In Linux user\u2019s .bashrc , include the following line: export LD_LIBRARY_PATH= $ORACLE_HOME/lib:$LD_LIBRARY_PATH b. Install HammerDB on HammerDB Linux user The Installation instructions for HammerDB can be found on HammerDB website : \u201cSection 5 , Installing and Starting HammerDB on Linux\u201d Install HammerDB on the Local Test System (LTS) from: c. Benchmark Schema TPCC800 Data Creation Benchmark database had been created using HammerDB CLI ( command line interface). Commands used for schema creation are as below 14 15 Executing Benchmark runs Here is a sample script for HammerDB benchmark run with 256 Warehouses and 100 Virtual users. Conclusion Oracle Database Standard Edition licensing is based on a per-socket license model. For multi-CPU servers, such as dual and quad-socket systems, Oracle Database Standard Edition requires an individual license for each socket in the system. This makes the Supermicro AS-1014S-WTRT an ideal cost-optimized solution for small to mid-size Oracle Database deployments with linear CPU scaling. 16 Footnotes Performance measured with Oracle Database 19c on Oracle Linux 7.6 with UEK 4 (4.14.35.1902.0.18) using HammerDB version 22. Max boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating conditions for server systems. 1. AMD EPYC World Records: : AMD EPYC Processor World Records | AMD 2. AMD EPYC 7002 series Processors: EPYC-7002-TPC-DS-10TB-World-Record.pdf *Max Boost reference: Max boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating conditions for server systems.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "8d5b93df-fb39-4a77-8a7b-0885d709c468": {"__data__": {"id_": "8d5b93df-fb39-4a77-8a7b-0885d709c468", "embedding": null, "metadata": {"file_name": "Solution-Brief_EMACX.pdf", "publication_date": "May 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Over the last few years, corporations have been under the constant mandate to elevate the building operations to a high- performance sustainable platform through the tenets of \u201cYou can\u2019t manage what you don\u2019t measure\u201d interlocked with \u201cYou can\u2019t optimize what you don\u2019t manage.\u201d Emacx Systems Inc. developed a powerful and unique Carbon Footprint Monitoring and Control Software, ACIEX Pulse, running on a Supermicro Fanless IoT Gateway to provide building operations with the right tools. ACIEX Pulse specifically recognizes the infinitely distinctive facility operational modes dictated by occupancy and activities coupled with seasonal and hourly weather variations. This solution will proactively and incrementally adjust equipment operations and inputs/outputs to perform ongoing capture of those kWh being unnecessarily consumed. This enables Aciex Pulse to deliver persistent real-time performance optimization with this \u201ckWh harvesting\u201d technique based on long term operating experience and proven technical capabilities. 1 Challenges 2 The Solution 3 Conclusion 3 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. Supermicro\u2019s Fanless IoT Gateways teamed with EMACX\u2019s Aciex Platform 2 Challenges In 2019 New York City passed the Climate Mobilization Act, one of the most aggressive and rigorous carbon footprint reduction laws in the US. Local Law 97, the centerpiece of 2019\u2019s Climate Mobilization Act, calls for carbon footprint reductions of 40% by 2030 and 80% by 2050, affecting more than 50,000 buildings in NYC. Not meeting these strict greenhouse gas (GHG) emission standards will result in penalties of $268 per metric ton of CO2 over the mandated limits. If left unaddressed, the fines could reach hundreds of thousands of dollars per building each year. Thirty-five cities in the US have announced plans to follow suit with similar Carbon Footprint laws. Building owners and operators are asking the question; How best to mitigate potential greenhouse gas fines? What is the Energy Conservation Measure (ECM) one should put in place, and what are the lowest hanging fruits for kWh Harvesting? To successfully implement a reliable and efficient energy management infrastructure, organizations need to address energy usage and the changing electric grid, requiring a \u201cnext level of energy efficiency\u201d to mobilize energy savings beyond historical practice. The five most significant challenges to address are: 1. The amount of energy savings must increase dramatically. 2. Energy efficiency sources and savings must be diversified. 3. Robust Measurement and Verification (M&V) for energy savings must be common. 4. Energy efficiency savings must be integrated with a carbon reduction framework. 5. Energy efficiency must be part of an evolving grid, integrating renewables distributed energy resources (DERs) and intelligent load management. Aciex Panel powered by Supermicro Fanless Server Aciex Platform - Calculated Savings Interface SYS-E100-9W-IA-E 3 The Solution The ACIEX Pulse Software running on Supermicro\u2019s Fanless SYS-E100-9W-IA-E IoT Gateway provides seamless integration with any existing Building Management System on the market. The integrated platform will provide operators of commercial buildings, hospitals, universities, and other facilities with the means to monitor their posture regarding Local Law 97 and to take a proactive approach to reduce emissions. Real-Time Performance Optimization ACIEX Pulse will proactively and incrementally adjust equipment operations and inputs/outputs to perform the ongoing capture of those kWhrs being unnecessarily consumed while maintaining the strictest environmental conditions. This tool optimizes operations by responding to inherent systems overdesign and capitalizing on non-peak conditions to identify reduction potentials, ACIEX Pulse relies on integrated, proactive protocols, including the rotation of grouped loads identified and retained for kWh reduction. Correcting and capturing these inefficiencies is one of the main principles in delivering high performance sustainable building operations. With this unique kWh harvesting, technique building operators will be able to achieve persistent real-time performance optimization. The facility integration of the ACIEX Pulse platform begins with a thorough evaluation process. A meticulous granular load study is performed where all potential load assets that qualify for the kWh Harvesting technique are identified with all operating parameters documented. These pre-qualified load assets are keyed into the ACIEX Pulse system for the kWh- Harvesting protocol. Through a proprietary sophisticated feedback analysis, the software will know at any given time how the load is performing (speed %, HZ, kW, etc.) Facility operators have complete visibility to make decisions in real- time, turning the response to LL97 from reactive to proactive. The result is optimizing the portfolio of properties not just for the environment but also for the bottom line. Conclusion Deploying Real-Time Carbon Footprint Monitoring and Control Software has never been more accessible and more lucrative. With Supermicro Fanless IoT Gateways and EMACX\u2019s ACIEX Platform, enterprises can comply with the strict greenhouse gas emissions laws and achieve significant cost savings through kWh Harvesting and demand control. KEY BENEFITS \u2022 Quantify and assess building GHG emissions relative to legal limits in real time, and by sources of energy \u2022 Gain full transparency from the building level down to individual meter levels, across billing cycle, year and compliance periods \u2022 Calculate and forecast building penalties or surpluses across compliance periods \u2022 Identify high-energy-consumption meters/tenants for targeted reduction \u2022 Facilitate noncompliance gap closure scenarios \u2022 Enable carbon emissions reporting & audit requirements \u2022 Maximize demand response revenue earnings capabilities \u2022 Improved risk management \u2022 Improved tracking and performance reporting \u2022 Reliable and durable E100-9W-IA-E fanless server to ensure peak performance for mission critical deployments \u2022 Key Features: 8 USB Ports, Dual GbE LAN, 3 M.2 Slots, up to 64GB DDR4 2400MHz SODIMM, and dual displays. ABOUT EMACX Is a real-time energy management software and technology company providing the next generation of Demand Side Management (DSM) solutions to energy intensive businesses in North America. Emacx\u2019s energy management solutions empower users to intelligently manage their energy consumption, adjusting both the timing and the quantity of their electricity use in real- time, without degrading mission critical operations.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "28a96997-1204-4a98-9799-19bd446ddb81": {"__data__": {"id_": "28a96997-1204-4a98-9799-19bd446ddb81", "embedding": null, "metadata": {"file_name": "Solution-Brief_OSNEXUS.pdf", "publication_date": "April 2023", "referenced_websites": ["www.osnexus.com", "https://www.osnexus.com/ceph-", "https://www.supermicro.com/en/solutions/osnexus.", "https://www.osnexus.com/zfs-designer?conf=smc"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Solution Overview The Supermicro OSNexus Storage Solution powered by the QuantaStor storage platform delivers scale-out and scale-up storage capabilities to meet the needs of a broad spectrum of workloads and applications. This includes workloads such as general backup and archive, disaster recovery, virtualization, media & entertainment, ERP, OLTP, etc. In addition, quantaStor installs on all major Supermicro server platforms giving customers the choice and flexibility needed to reduce storage costs and leverage the latest hardware advancements. Grid Technology QuantaStor\u2019s storage grid technology provides unified management of QuantaStor servers and clusters. The grid management system is built into every system so that administrators can log in and manage their storage grid from any system without installing and maintaining additional software. Solution Overview 1 Grid Technology 1 Unified File, Block & Object Storage 2 End-to-End Encryption and Security 3 Open Storage Foundation 3 Designing Scale-out & Scale-up QuantaStor Clusters 4 Supermicro is a global leader in high performance, green computing server technology and innovation. We provide our global customers with application-optimized servers and workstations customized with blade, storage, and GPU solutions. Our products offer proven reliability, superior design, and one of the industry\u2019s broadest array of product configurations, to fit all computational need. 2 Each grid can scale to over 100PB and may contain multiple scale-out and scale-up storage clusters. Storage grids can also span sites and data centers. In addition, QuantaStor has robust access control, encryption, and security compliance features, making it easy to secure. Unified File, Block & Object Storage Some workloads, such as service providers, research data, on-prem cloud, and multi-stream backup, are better suited for use with a scale-out storage architecture, while others are more cost-effective and faster using a scale-up design. For example, all- flash configurations are great for databases and virtualization, and hybrid configurations are ideal for media archives, Veeam backup storage, and home directories. QuantaStor delivers both. Scale-out configurations provide high-performance NAS and S3-compatible object storage with scalability to over 50PB per cluster. Scale-up configurations provide SAN and NAS storage with less hardware, making them more cost-effective but generally limited to 6PB or less per cluster. End-to-End Encryption and Security QuantaStor delivers end-to-end security coverage, enabling multi-layer data protection on the wire and for data at rest. With NIST 800-53, 800- 171, HIPAA, CJIS compliance, and FIPS 140-2 certification, QuantaStor provides advanced security features required by government and regulated industries. Figure 1: QuantaStor\u2019s hardware integration spans a broad selection of Supermicro servers and JBODs. Grid technology makes it easy to manage all storage systems within and across sites. 3 Open Storage Foundation OSNexus is dedicated to advancing open-source storage technologies and is a member of the Ceph Foundation and Linux Foundation. QuantaStor integrates with mature enterprise open-source storage technologies like Ceph and OpenZFS to deliver rapid innovations at a lower cost and without the vendor lock-in that comes with proprietary file systems. Figure 2: QuantaStor\u2019s end-to-end security coverage, enabling multi-layer data protection on the wire and for data at rest. (Image Courtesy of OSNexux) 4 For more certified Supermicro servers and details, please check out the solution page at Scale-out Solutions Scale-up Solutions Scale-out solutions provide cost-effective NAS and S3- compatible scale-out object storage that delivers high performance. In addition, scale-out solutions provide the ability to start small and grow to over 50PB in a single cluster. Scale-up storage clusters provide highly-available SAN/NAS storage designed around a two-server cluster model using SAS & NL-SAS shared storage from JBODs/JBOFs. All-flash configurations are great for databases and virtualization. In contrast, hybrid configurations provide low-cost, high-density NAS for various use cases such as media archives, Veeam backup storage, and home directories. All major block (iSCSI/FC/NVMe-oF) and file (SMB3/NFS4) protocols are supported. ABOUT OSNEXUS OSNexus QuantaStor enables organizations to replace traditional SAN/NAS systems with standard servers to deliver robust, reliable, and highly scalable object, file, and block storage solutions that are easy to manage. To start designing a QuantaStor solution, see our web- based design apps at for scale-up solutions, and designer?conf=smc for scale-out solutions. Go to osnexus.com/freetrial for Trial Edition licenses or write to us at info@osnexus.com", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "edcee397-75b8-4588-8b9a-99d89249d537": {"__data__": {"id_": "edcee397-75b8-4588-8b9a-99d89249d537", "embedding": null, "metadata": {"file_name": "Solution-Brief_WekaIO.pdf", "publication_date": "November 2020", "referenced_websites": ["https://bit.ly/35UHLDk"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 WEKAIO MATRIXTM 3 AN ENGINEERED SOLUTION 4 CHOOSE A PRE-CONFIGURED SOLUTION THAT DELIVERS PERFORMANCE, FLEXIBILITY, AND VALUE 5 DERIVE BENEFITS FOR YOUR BUSINESS STORAGE APPLIANCES STORAGE SERVER CONFIGURATION Supermicro is a global leader in high performance, green computing server technology and innovation. We provide our global customers with application-optimized servers and workstations customized with blade, storage, and GPU solutions. Our products offer proven reliability, superior design, and one of the industry\u2019s broadest array of product configurations, to fit all computational need. Distributed File Storage Deployment with Optimized Supermicro All-Flash NVMe Systems Featuring WekaFSTM Software The boom of Big Data in today\u2019s world has created amazing new opportunities for innovation but unforeseen problems as well, particularly in the areas of artificial intelligence (AI), machine learning (ML), deep learning (DL), and high- performance computing (HPC) workloads. These workloads hold the promise of finding solutions for significant challenges across industries, including healthcare and financial services. To accelerate the process of obtaining insight from mountains of data, these workloads require a modern infrastructure with extreme performance in compute, storage, and networking resources. Supermicro has teamed with WEKAIO to create a solution that addresses these needs and can help you gain the insight that you need to gain a competitive advantage, deliver customer value, and grow your business. The Supermicro Storage Appliances, featuring WekaFS, the world\u2019s fastest and most scalable file system, are preconfigured and optimized for maximum acceleration of AI workloads and reduced training times, delivering unmatched performance at scale. This family of appliances is ideal for today\u2019s data-intensive applications in artificial intelligence and technical computing. It has proven scalable performance, delivering over 10x more performance than blade-based, all-flash, scale-out NAS, and 3x more than locally attached NVMe SSDs. This solution supports deep learning workloads that are akin to HPC but with unique storage requirements. Because these workloads may consist of billions of small files, the storage system must deliver high throughput, low latency, and excellent metadata performance at extreme scale to keep graphics processing units (GPUs) and applications saturated with data. This requirement is unattainable with legacy storage systems but made possible with WekaIO\u2019s modern NVMe\u2010 optimized, distributed, and parallel file system running on Supermicro servers. 2 WekaIO MATRIXTM WekaIO\u2019s Matrix is the world\u2019s fastest and most scalable file system, ideal for today\u2019s data-intensive applications in artificial intelligence (AI) and technical computing. It has proven scalable performance, delivering over 6x more performance than blade-based all flash scale-out NAS and 2x more than locally attached NVMe SSDs. Matrix uses a clean-sheet design with an optimized network stack that runs Ethernet (100Gbit and above) or InfiniBand, so data locality is no longer a necessary factor for performance. The software presents a POSIX file system that distributes both data and metadata across the entire storage cluster to ensure massively parallel access. Using NVMe flash technology ensures the highest performance and lowest latency. AN ENGINEERED SOLUTION Based on Supermicro\u2019s A+ Server, BigTwin, and Ultra servers, WekaIO\u2019s Matrix software, and Mellanox\u2019s network adapters, the engineered solution provides industry-leading performance and value. The BigTwin is the first and only 2U multi-node system supporting the highest performance processor, memory, storage, I/O, and an incredible 30% better thermal capacity. Mellanox ConnectX- 5/6 adapters provide the choice of either Infiniband or Ethernet to deliver 100Gb/s bandwidth in a single port, the lowest available latency, 150 million messages per second, and application hardware offloads, satisfying even the most demanding application requirements. CHOOSE A PRE-CONFIGURED SOLUTION THAT DELIVERS PERFORMANCE, FLEXIBILITY, AND VALUE Based on the Supermicro A+ Server, Ultra SuperServer and BigTwin server platforms, WekaFS software, and Mellanox network adapters, you can take advantage of a plug\u2010and\u2010play engineered solution that helps extract greater value from data. This solution is available in a set of appliances that allows you to easily select a choice that best suits your performance, capacity, and footprint requirements. You can make your decision based on your need for: \u2022 Entry-level capacity with granular scaling of nodes (1U model) 3 \u2022 The best value per GB with granular scaling of nodes (1U model) \u2022 Best performance density per RU (2U model) The 1U models offer flexibility, an attractive entry price, and the highest number of drives and performance per server node; the 2U model provides the highest performance density per rack unit and great power and space economy. The Supermicro BigTwin 2U Storage Appliance is the industry\u2019s first 2U multi\u2010node system with high-performance processors, memory, storage, and I/O. Furthermore, it can lower energy consumption in the data center with an incredible 30 percent better thermal capacity. Performance and capacity can be easily increased with expansion storage for each appliance and drives for partially populated appliances. WekaFS is a POSIX-compliant file system that distributes both data and metadata evenly across the entire storage cluster to ensure massively parallel access. WekaFS reduces time to innovation by delivering more data to the applications that need it, faster than any other storage system. With a single namespace that can offer on-premises storage and cloud connectivity, the software delivers simplified storage management and data protection. Its performance is 3x that of local file systems and 10x that of traditional NAS. Mellanox adapters provide the choice of either InfiniBand or Ethernet to deliver 100Gb/sec bandwidth in a single network port, the lowest available latency, 150 million messages per second, and application hardware offloads, satisfying even the most demanding application requirements. The SPEC SFS20141 results show that WekaFS has performance that is far superior to all competitors in Overall Response Time (ORT) for database, Electronic Design Automation (EDA), Video Data Acquisition (VDA), Virtual Desktop Infrastructure, and software build workloads. Derive Benefits For Your Business These high-performance storage solutions not only address your specific needs based on workload types and performance and capacity requirements but go beyond that to provide more significant overall benefits for your business: \u2022 Optimization of your IT environments with a modern storage infrastructure and simplified storage management \u2022 Datacenter agility with faster data access and effective resource utilization \u2022 Data transformation for machine learning and analytics with faster time to value and insight. In partnership with Weka, Supermicro and Weka deliver a differentiated solution beyond current market and performance standards for storage and the best solutions for your IT and business challenges. 1 SPEC SFS2014 Results: 4 STORAGE APPLIANCES (8-NODE MINIMUM) 2 *NVMe capacity options include 1.92TB, 3.84TB, 7.68TB, and 15.36TB. For different capacities, drives request, please contact weka-pm@supermicro.com. 3 Estimated. 4 Estimated. A+ Server BigTwin Ultra SMC SKU 8x AS-1114S- WN10RT 2x SYS-2029BT-HNR 8x SYS-1029U-TN10RT Total Rack Units 8U 4U 4U 8U 8U Software License (per Usable TB) 323TB 193TB 64TB 161TB 64TB Storage Media NVMe2 80 (10x 7.68TB/node) 48 (6x 7.68TB/node) 16 (2x 7.68TB/node) 80 (10x 3.84TB/node) 32 (4x 3.84TB/node) CPU 8x AMD Rome 7402P 16x Intel 4214R 16x Intel 4214R 16x Intel 4214R 16x Intel 4214R Memory 2048GB 1536G 768GB 1536G 768GB Network 16x single-port Mellanox CX-6 200G VPI 16x single-port Mellanox CX-5 100G VPI 8x single-port Mellanox CX-5 100G VPI 16x single-port Mellanox CX-5 100G VPI 8x single-port Mellanox CX-5 100G VPI 4K Read IOPs 6.8M3 4.9M 1.6M 6.8M 2.7M Bandwidth 320GB4/s 119GB/s 40GB/s 160GB/s 80GB/s 4K Read IO Latency Sub-400\u03bcs Sub-400\u03bcs Sub-400\u03bcs Sub-400\u03bcs Sub-400\u03bcs Data Protection \u2022 Distributed Data Protection (N+2 or N+4) \u2022 Drive Hot Sparing \u2022 Error Detection: End-to-end Data Protection \u2022 In-flight and at-rest Data Encryption Protocols POSIX, NFS, SMB, S3 gateway Snapshots and Clones File System Level, Up to 1024 Snapshots Tiering S3 Compatible Cloud Object Store (Public or Private), and Ceph System Monitoring Cloud-based Monitoring and Analytics for Application Tuning and Remote Support Software Subscription 1-year or 3-year 5 STORAGE SERVER CONFIGURATION5 \u2013 MINIMUM 8 NODES A+ Server \u2013 1 node BigTwin \u2013 4 nodes 5 Configuration details subject to change without notice. Please contact weka-pm@supermicro.com for custom configuration details. COMPONENTS SPECIFICATIONS QUANTITY Supermicro Storage Enclosure AS-1114S-WN10RT 1 CPU(s) AMD Rome 7402P, 2.8GHz 1 RAM 32GB DDR4-3200 8 Networking Mellanox ConnectX-6 VPI Single Port PCIe 2 NVMe(s) 3.84TB U.2 10 Boot Drive 960GB or larger M.2 SATA 1 COMPONENTS SPECIFICATIONS QUANTITY Supermicro Storage Enclosure SYS-2029BT-HNR 1 CPU(s) Intel Xeon 4214R 2.4GHz 8 RAM 16GB DDR4 48 Networking Mellanox ConnectX-5 or later 100Gbit/s VPI Single Port PCIe 8 NVMe(s) 3.84TB U.2 24 Boot Drive 480GB or larger M.2 SATA 4 Supermicro I/O Module AOC-MTG-i2TM-O 4 6 Ultra Server \u2013 1 node COMPONENTS SPECIFICATIONS QUANTITY Supermicro Storage Enclosure SYS-1029U-TN10RT 1 CPU(s) Intel Xeon 4214R 2.4GHz 2 RAM 16GB DDR4 12 Networking Mellanox ConnectX-5 or later 100Gbit/s VPI Single Port PCIe 2 NVMe(s) 3.84TB U.2 10 Boot Drive 480GB or larger M.2 SATA 1", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "dc710347-f01c-4a75-bada-e0a1f1d8107f": {"__data__": {"id_": "dc710347-f01c-4a75-bada-e0a1f1d8107f", "embedding": null, "metadata": {"file_name": "Solution-Brief_5G_T-Systems_2020.pdf", "publication_date": "April 2020", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Figure 1. German IT services and consulting company, T-Systems T-Systems Edge Platform Delivers Low Latency with Supermicro Founded in 2000, T-Systems is a German global IT services and consulting company. It is a subsidiary of Deutsche Telekom, one of the world's leading integrated telecommunications companies with more than 184 million mobile customers across 50 countries. T-Systems recently unveiled EdgAIR, an Edge Computing platform that delivers low latency for IoT applications at enterprise facilities. Edge Computing brings computation and data storage closer to the location where the data is generated in order to reduce latency, maintain network reliability, save bandwidth and comply with data security regulations. This enables companies to use innovative, real-time applications in production, logistics and retail, and includes automated, guided vehicles and augmented and full virtual reality. The EdgAIR platform works directly on-site, which means that the data is not sent via a central computer center or Cloud. Supermicro offers a range of highly-configurable and powerful servers optimized for Intelligent Edge computing, and is working with T-Systems to develop an EdgAIR solution. Challenges As a leading provider of mobile and internet services to its customer base, T-Systems delivers content via an extensive network with a carrier-grade reliability environment - 99.9999%, which means less than 3 seconds of downtime per month. Achieving this reliability standard while providing critical connectivity and applications requires significant investments in capital and network management. As 5G ramps up globally, T-Systems is challenged to deliver not just high-speed services and applications, but also support a larger number of devices that attach to the network. Current network architectures are being set up to achieve the breadth, depth and growth required to meet the demands while providing competitive pricing and returns on investments. 2 T-Systems Edge Platform Delivers Low Latency with Supermicro - Printed in USA Please Recycle 14_5G-T-Systems_2020_01-7 Solutions Supermicro\u2019s wide range of embedded solution technologies appealed to the EdgAIR development team for a number of reasons: the Intel Xeon D Edge-based architectures with the Intel FPGA Programmable Acceleration Card N3000 are able to manage the heavy workloads that T-Systems requires to deliver low-latency applications, powerful processing, reliability in the field, and a highly-responsive support team. Enabling multiple workloads on a single edge platform that is self-healing, self-managing and has common building blocks to reduce risk while increasing ROI is a valuable asset for expanding the T-Systems network. Working as a partner with T-Systems, Supermicro is not just providing hardware-based architectures, but introducing its wide range of ecosystem partners to enable these Edge- based services. How can using Supermicro\u2019s products help T-Systems better serve their customers? T-Systems understands that common motherboards will reduce test workloads by providing solutions that enable multiple applications for customer services, and enable network functions on the same Edge device, providing increased returns. With Supermicro, enabling a modular, building-block type system with software infrastructure for VNFs, virtual machines and containerized workloads provides growth and options for end users at a lower total cost of ownership and with increased power efficiency. Supermicro has recently launched its first server in an IP65-rated protective enclosure to meet the needs of outdoor environments such as cell towers and microcell sites. Along with a broad portfolio of data center solutions and edge platforms all will help to serve the needs of T-Systems\u2019 customers in the future. Products under evaluation T-Systems is currently evaluating multiple systems \u2013 Supermicro Edge Compute and Storage servers running Intel Xeon D processors and N3000 FPGA accelerator cards \u2013 for AI and analytics. The evaluation has been running well in their lab. \u2018We are extremely pleased with the performance and feel this can have potential for wide-spread deployment,\u2019 said Thomas Weber, Principal Consultant, T-Systems. Figure 2. Supermicro Servers for the Intelligent Edge, based on Intel Xeon D and 2nd Gen Intel Xeon Scalable Processors and supporting the Intel FPGA Programmable Acceleration Card N3000 . Figure 3. Thomas Weber, T-Systems", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "5007af9b-ef9e-46f6-9091-cc33ade7bcf7": {"__data__": {"id_": "5007af9b-ef9e-46f6-9091-cc33ade7bcf7", "embedding": null, "metadata": {"file_name": "Solution_Brief_Media_And_Entertainment_AMD.pdf", "publication_date": "September 2023", "referenced_websites": ["www.supermicro.com/H13", "https://www.supermicro.com/en/products/system/gpu/4u/as-4125gs-tnrt", "https://www.supermicro.com/en/products/system/hyper/2u/as-2125hs-tnr", "https://www.supermicro.com/en/products/system/storage/1u/asg-1115s-ne316r"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Studios and content creation creators always look for innovative ways to create new and exciting videos and other forms of entertainment. The process of delivering a fantastic end user experience relies heavily on the latest technologies, including computer servers, storage, and software. Collaboration among creative specialists is critical, resulting in a more engaging creative process and end result. Content Creation Components Supermicro servers with 4th Gen AMD EPYC processors offer an optimized solution for creative organizations that need VDI, Rendering, and fast storage to create immersive experiences and engaging content. Virtual Desktop Infrastructure (VDI): VDI is a desktop virtualization technology that separates the desktop environment and associated application software from the physical client device used to access it. This IT architecture means the desktop environment and applications are hosted on a central server and delivered to users' devices over a network. A VDI environment can increase employee access security, 1 Content Creation Components 1 Supermicro Solutions for VDI, Rendering, and Storage 2 4th Gen AMD EPYC Processors are Ideal for M&E Workloads . 4 Summary 4 2 reduce IT costs, and increase collaboration. In addition, employees can access their desktops with the needed applications from different devices without being physically tied to a single device. However, these benefits require the right servers to process requests, securely store data, and maintain SLAs. Rendering: The rendering process, whether for computer generated imagery or to enhance or modify live action video, requires high performance servers that can modify the digital image at high resolutions. With videos being viewed at 60 frames/second, tremendous processing power is necessary to create or modify each frame for a seamless experience. The servers used for rendering must contain more than just a fast CPU but require large amounts of memory, GPUs, fast storage access, and networking to keep the CPUs and GPUs busy, which reduces the Total Cost of Ownership. Storage: Integrating high speed storage into the content creation environment is critical to a smooth running data center. The ability to retrieve information from a storage hierarchy for processing needs to be integrated into the rendering or VDI environment. Delays in the CPU or GPU accessing or storing the required data can significantly reduce productivity in an innovative environment. Supermicro Solutions for VDI, Rendering, and Storage VDI: The 4U GPU Server with up to 8 PCIe GPUs The AS -4125GS-TNRT server features a dual-root PCIe architecture that directly connects each of 8 GPUs to CPUs with 16 lanes of connectivity so that nothing stands in the way of data flow to the accelerators. This server is ideal for VDI and other workloads that are very I/O intensive and need a balance of CPU and GPU performance. Direct connectivity is also provided to two 16-lane PCIe 5.0 slots, and the server includes support for up to 4 NVMe and 2 SATA drives. Supermicro AMD GPU Server AS -4125GS-TNRT - Dual AMD EPYC 9004 Series Processor up to 360W TDP - NVIDIA RTX 6000 GPUs - Up to 8 direct attached double width, full length GPUs - Up to 24 DIMM Slots, 6TB DDR5 memory - Up to 4x 2.5\" Hot-swap NVMe drive bays 3 Rendering: 2U Hyper for render; highest core density per U. The H13 Hyper systems are the new flagship data center systems, certified to run major enterprise applications while affording you a flexible range of computing, networking, storage, and I/O expansion capabilities. Choose NVMe, SATA, or SAS storage to achieve the number of I/O operations per second(IOPS) your applications need to perform at their best. And use Open Compute Project (OCP) 3.0 add-in modules (AIOMs) for consistent and standard networking capabilities across all data center server deployments. Supermicro Hyper AS -2125HS-TNR - Dual 4th Gen AMD EPYC 9004 processors - 24 DIMMs, up to 6TB of memory - Flexible PCIe 5.0 configurations - Up to 24x Hot-swap 2.5\u201d NVMe/SAS/SATA drives - Redundant Titanium 1600W Power Supplies Learn More about the Supermicro H13 Hyper Series Storage: AMD based Petascale system - Supermicro has launched a new line of petascale class storage platforms based on the extreme performance of 4th Gen AMD EPYC processors for customers who recognize the need for more data closer to computing. These storage systems are designed to store, process, and move vast amounts of data that today\u2019s enterprises need. So whether you need a distributed scale-out storage server or a highly parallel virtualized environment, the Supermicro Petascale storage systems are a valuable asset in the data center. Supermicro AMD Petascale Systems - Single Socket 4th Gen AMD EPYC 9004 processors, up to 300W TDP - Up to 6TB memory \u2013 24 DIMMS with 2DPC - 16 x hot-swap E3.S (7.5mm) NVMe drive bays - Redundant Titanium 1600W Power Supplies 4 4th Gen AMD EPYC Processors are Ideal for M&E Workloads The 4th Gen AMD EPYC processors can help IT professionals everywhere excel. Performance + Efficiency are the new metrics for success in IT. Servers powered by EPYC 9004 CPUs can deliver faster time to results, helping provide more and better insights for decisions and driving better business outcomes. AMD EPYC CPUs \u2013 performant, efficient, and on time. - Efficient: With EPYC 9004 CPUs, IT professionals can use fewer servers compared to previous generations of CPUs to get the job done, helping data centers be more energy efficient. The proverbial \u201cdo more with less\u201d comes true. - Latest Technology: The 9004 Series AMD EPYC CPUs amplify the AMD history of x86 architecture innovations, high performance, and the latest technology, with support for high performant DDR5 DIMMs and fast PCIe Gen 5 I/O. EPYC 9004 CPUs support 12 memory channels with 2 DIMMs/channel capability, delivering the resources needed for memory hungry AI, ML, HPC, and large in-memory computations. These EPYC CPUs also provide 128 PCIe5 lanes in a 1-socket server and up to an astounding 160 PCIe5 lanes in 2-socket servers. This number of PCIe lanes enables the high performant demands of today\u2019s AI and ML applications and the increasing use of accelerators, GPUs, FPGAs, and high capacity LAN cards natively with 4th Gen EPYC CPUs\u2019 high PCIe5 lane counts. - 4th Gen EPYC processors are available in eleven two-socket and two one-socket EPYC 9004 series packages - Results Oriented: From print/file to databases and analytics, to HCI, HPC (now including AVX512 support), AI, and machine learning, AMD EPYC 9004 powered servers deliver faster time to results than previous generations with exceptional energy efficiency. - AMD EPYC 4th Gen processors deliver out-of-the-box performance \u2013up to an estimated 30% more performance per watt for 64 core processors gen over gen. Summary New technologies, including Supermicro servers with 4th Gen AMD EPYC processors, are enhancing the creativity of content creators. The low latency responses for interactive work with the increasing rendering performance allow new ideas to be brought to production. High speed storage enables access to terabytes of data needed for collaboration and interactive work to integrate into existing workflows seamlessly. 5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "6e692e30-9b52-4af4-bd7d-e29e6d9c9831": {"__data__": {"id_": "6e692e30-9b52-4af4-bd7d-e29e6d9c9831", "embedding": null, "metadata": {"file_name": "Solution_Brief_SuperMicro_Archimedes.pdf", "publication_date": "August 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Challenges 2 The Solution 2 Main Applications 3 Key Benefits 4 Conclusion 4 Supermicro paired with Archimedes Controls to provide turn-key facility management systems that help reduce downtime and operating expenses of IT/computing environments. These systems provide monitoring utility in any location, whether co-lo, cloud, edge, micro, or enterprise, and provide end-to-end monitoring and control of energy and environment for any space or asset. With its Archimedes 100% wireless sensors and Supermicro\u2019s preconditioned servers, these solutions can be installed in almost any environment and quantity, allowing for high granularity of data and, even more importantly, higher fidelity in building automation and control. As a result, Supermicro and Archimedes Control\u2019s joint offerings are increasing in popularity in data centers and used in industrial automation, agriculture, food storage, healthcare, transportation, and more. Supermicro and Archimedes\u2019 one-stop wireless and cloud solution offers infrastructural visibility, transparency, and control with granularity to a server, shelve, and rack levels accurately in real time, which are critical aspects for managing cloud and IT infrastructure not only for enterprise CIOs and ITs but also for industrial IoT, automation and control, agriculture and food safety, healthcare, transportation as well as unmanned remote building/facility control and management solutions. As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to- end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. Supermicro\u2019s IoT Gateway Servers Teamed with Archimedes A150 System . Challenges With the complexity of today\u2019s cloud and IT infrastructure, including facilities, power systems and distributions, environmental control, IT and computing equipment, which are usually located in many different locations globally, a reliable and cost-effective physical security and environmental monitoring and management system is a critical part of the entire network infrastructure operating in five 9s up-time. Common Challenges When it comes to selecting and deciding on an infrastructure monitoring system, IT and FM professionals are usually facing the following obstacles: \u2022 An integrated monitoring solution that provides all physical security monitoring must protect the operational environment and valuable IT assets in many locations globally. \u2022 A physical security monitoring system does not require altering the existing infrastructure and interrupting networking operations when installed and provisioned. \u2022 The monitoring system must provide flexibility to protect investment for the long term for upgrades and expansion. \u2022 A system solution that supports multi-site and global operations for the entire organization operating in different time zones. \u2022 A secured system that operates alone and does not connect anything to any portion of the customer\u2019s network. \u2022 A one-stop shop that offers hardware sensors, gateways, cloud servers, and connectivity. \u2022 Last but not least, a reliable, easy to manage, and cost-effective solution with the latest technology from a trusted partner that can be relied on for many years. Solution \u2022 Supermicro-Archimedes\u2019 cloud and wireless sensor based A150 system solution consist of two main hardware bases \u2013 a wireless sensors network and a dedicated IoT cloud server for each customer with an option for a backup server. Each wireless sensor includes a built-in temperature and humidity sensor and two external ports accepting the following sensing probes: \u2022 Extended Range Temperature and Humidity Probe: for applications beyond normal environmental monitoring, such as industrial temperature/humidity oven automation, manufacturing process data recording, greenhouse monitoring, etc. \u2022 Access Probe: for monitoring door open/close status such as rack/cabinet access door, closet door, building window and entrance door, etc. \u2022 Tamper probe: for monitoring unauthorized vibration and tempering (vibration, shake, tilt, move, etc.) of valued assets. \u2022 AC or DC Current Probe: for monitoring AC or DC electrical current for real time power consumption, power wire overheating without breaking the line and inserting a current meter. | ARCHIMEDES SYS-E100-12T A150 Controller & A150 Sensor Supermicro\u2019s SYS-E100-12T Edge Server and Archimedes Controls\u2019 A150 Wireless IoT Sensors and Controller 2 . Water Leak Detection: For a path of 10 ft to 100 ft., if there is any water or specific liquid greater than 1\u201d diameter along any portion of the sensing rope, a warning message will be generated to alert the user. The Water Leak sensing probe can be placed and fixed on the floor (either wood or concrete), around a water pipe joint, a window or a door, underneath a rack/cabinet, etc., where a water leak is a concern. Others: Custom sensing probes are available upon request. Each Controller includes an optional built-in air pressure detector and an optional airborne particle monitor. It also serves as a gateway for the wireless sensors and external probes. Each controller supports up to hundreds of wireless sensors. Multiple controllers also form a wireless mesh network with sensors to provide redundancy. All sensing probes above support both the wireless sensor and the controller. Each controller also provides three (3) general purpose IO ports and one analog input port. These general-purpose IO ports can be remotely programmed via ARCOS for digital input or digital output, active high or active low, or analog input for interfacing with 3rd party sensing and controlling devices. Dry relays are available for controlling 3rd party devices (such as alarms, flashlights, auto-dialers, etc.) when IO ports are configured as digital output and connected to one or more of the alarm triggering conditions. In addition, a wireless AC sensor is available for the controller. The wireless sensor monitors and sends current and wire temperature data to the controller directly. It operates using energy harvesting technology, so a battery is not needed. A150 system also supports IP based security cameras as part of the total security solution. Any camera captured videos or pictures are sent and saved in ARCOS for email/SMS warning notification, remote reviewing, archiving, and reporting. Cloud software ARCOS offers a wide variety of functions and capabilities, including monitoring in dashboards and 3D heatmaps, histograms, data tables, warning recording and reports, CRAC performance, and data center PUE monitoring. F Figure1: Sample figure or caption text with sample image Visitor Sign- in Kiosk with NFC & Fever Det Temp & Humid Mon Power Current Access/ Door Det Water Leak Det Tamper/ Move/Tilt/ Shake Det Vibration@ xxxxHz 4G/5G Up to hundreds of sensors to 0.5 mile A150 CONTROLLER 4 IO Ports for Sensing Probes and 3rd Party Control Devices ARCOS SENSING PROBE EXAMPLES WiFi, Eth(SSL), 4G/5G Power Consumption/ Wire Overheating IoT Server Built-in Wireless Sensors: - Temperature/Humidity - Vibration/Move/Tilt/Shake - Rock, Tree, Object Fall - Mud/landslide/Disaster - Water Leak - Per Request (Brightness, CO2, etc.) WiFi/ETH Co-Lo or Private Data Center Wireless Sensor with 2AA Batteries and 2 IO Ports Built-in Sensors: -Temp/Humidity -Airborne Particles -Air Quality -Smoke -Nearby fires -Explosive Gasses -CO2 -HCOC -Panic button Airflow Speed Under Ground/Above Ground Water Level/Fuel Level https:// SMS/Email Disaster Detector LEO SATELLITES 3 . Main Applications KEY BENEFITS \u2022 High fidelity high granularity environment security monitoring. Highly accurate monitoring of ambient air temperature, humidity, airflow speed, air pressure and air-quality plus all physical security measures via wireless sensors. These sensors can be deployed at any and multiple locations for rack level, sub-rack level, even specific blade/server level granularities. \u2022 Remote management and IT asset tracking via cloud software. Highly robust cloud-based software that allows operators to access real-time and past- time physical and environmental monitoring data. Data available in variety of formats including 3D visualizations, graphs, tables, etc. \u2022 Multi-facility management. If desired, data center operators with multiple deployments, can manage all of their deployments on the same A150 account or software platform. These deployments can be subdivided in any way the operator sees fit (e.g., individual racks in a co-lo or racks across multiple co-los). \u2022 Advanced reporting on energy/environmental metrics. In addition to automated alerts for hazards and faults, the A150 software can also generate tailored advanced energy/environmental reports. These include analyses on Power Use Effectiveness (PUE), HVAC performance parameters including airflow indices, cooling indices, rack power and usage, etc. Data from other devices or the operator may be needed and integrated for some of these reports. Conclusion Supermicro\u2019s IoT focused servers are the ideal workhorses for any smart building infrastructure. Archimedes Controls 100% wireless sensors and cloud software perfectly compliment and build on-top of Supermicro computing hardware to provide a turn-key security, energy, environment, and asset management system that is a plug-n-play, efficient user experience. 4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "3d8b2b17-3c26-48d4-b185-ad61d32451bf": {"__data__": {"id_": "3d8b2b17-3c26-48d4-b185-ad61d32451bf", "embedding": null, "metadata": {"file_name": "Solution-Brief_Veeam.pdf", "publication_date": "March 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 & VEEAM BACKUP AND REPLICATION SOLUTIONS SUPERSTORAGE The Data Revolution In the 21st century a company\u2019s data is one of the most valuable assets it possesses, whether it be on-site, hybrid, private or public cloud. Today, data requires continuous uptime and 24x7 access on a global scale. The Digital Transformation has brought new challenges to the modern data center, where organizations of today are looking to reduce costs and enhance the user experience while developing the right strategy for consistent data availability. In today\u2019s complex technology landscape, having a streamlined storage solution is the key to unlocking complexity and at the same time increasing efficiency. As an organization\u2019s dependency on data growth increases having the right solutions simplifies IT, reduces risk, and lowers the TCO while enhancing availability for applicants and enterprise data. Storage automation management increases productivity across cloud and IT environments, allowing increased scaling while maintaining a high level of application availability. Companies without a cohesive data management strategy expose themselves to a higher risk of failure, whereas when a catastrophic data loss scenario hits, half of all businesses affected end up closing within a 2-year time frame. Supermicro the Power of Green Supermicro\u2019s High-Performance Storage Server Solutions include everything required to build a rock-solid storage infrastructure. Individual models are designed to meet the demands of the toughest storage environments, from latency-sensitive caching applications to large capacity data environments requiring large files for media-driven libraries and Big Data. Supermicro\u2019s SuperStorage products support both scale-up and scale-out deployment strategies that maximize CPU and storage resources to scale and meet your organization\u2019s diverse storage and application requirements. As an organization\u2019s dependency on data growth increases, having the right solutions simplifies IT, reduces risk, lowers the TCO, and enhances availability for applications and enterprise data. The Data Revolution 1 Supermicro the Power of Green 1 Solution Overview 2 Supermicro SuperStorage with Veeam 3 Conclusion 3 2 Solution Overview A Supermicro and Veeam-partnered solution provides organizations with both availability and data integrity to manage data growth while delivering High Availability across virtual, physical and cloud workloads while addressing your organization\u2019s recovery time objectives (RTOs) and recovery point objectives (RPOs). The Supermicro SuperStorage and Veeam Backup & Replication series delivers high performance storage backup and recovery for your organization\u2019s critical applications and data, ensuring you maintain the highest level of availability to meet your application and service level objectives. Veeam Backup Repository Veeam Backup & Replication Boost Performance All-Flash NVMe Highest Performing High Density Top Loading Storage Density Maximized General Purpose Storage Application Optimized Proxy server Supermicro Production Environment Veeam Backup & Replication console Veeam Backup Repository Optimized General Purpose Storage Application Optimized Supermicro Ultra Server 3 Supermicro SuperStorage with Veeam Hyper-V Having the right backup strategy and infrastructure is paramount in today\u2019s data-driven IT and cloud environments. Supermicro SuperStorage is designed to meet the demands to support both scale up and scale out deployments and the SuperStorage systems are application optimized while delivering reliability and serviceability on a highly available storage platform for all your general-purpose computing requirements. Veeam\u2019s backup and replication, and storage management delivers availability for your virtualized configurations when paired with Supermicro SuperStorage, application optimized high-performance storage solutions for cloud, virtual and physical workloads. Veeam delivers availability, simplicity and scale: \u2022 High-speed reliable backup \u2014 Speed-driven backups \u2022 Multi-VM Instant Recovery \u2013 Downtime reduced for restore of individual disks for large VM\u2019s \u2022 Verified Recoverability \u2013 Verifiable recovery for all your VM\u2019s while backup is in progress \u2022 IT monitoring and Reporting \u2013 Tools to power your infrastructure for monitoring, reporting and resolutions Veeam Backup & Replication is targeted at addressing an organization\u2019s day-to-day operational challenges while providing a comprehensive set of enterprise grade data protection capabilities. Matched with SuperMicro SuperStorage solutions, Veeam delivers end-to-end data protection for data centers, branch and remote office locations. Fast, efficient and verified backups with Veeam flexible recovery capabilities make it the right choice to simplify IT, minimize data and avoid costly downtime. Conclusion Supermicro is a leading class provider of high performance, high density and high capacity SuperStorage servers. SuperStorage configurations provide maximum capacity and performance which is ideal for the Enterprise, Data Center and Cloud Computing environments. Coupled with Veeam software-defined best-in class solutions offering flexible, reliable, fast backup and restore so that customers can focus on driving business objectives.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "8cf38e48-7157-4faf-8aa8-750c552c0951": {"__data__": {"id_": "8cf38e48-7157-4faf-8aa8-750c552c0951", "embedding": null, "metadata": {"file_name": "Solution_Brief_SUSE-Ceph.pdf", "publication_date": "May 2020", "referenced_websites": ["https://www.supermicro.com/white_paper/white_paper_SSG-SUSE-Storage-Guide.pdf", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Total Solution for SUSE Enterprise Storage Highly Scalable and Resilient Software-defined Storage Powered by Ceph IPMI Switches 2x SSE-G3648BR Data Switches 2x SSE-X3648SR Admin Node 1x SYS-5019P-WTR GW Nodes 2x SYS-5019P-WTR Monitor Nodes 3x SYS-5019P-WTR Storage Nodes 4x SYS-6029U-E1CR4 SUSE ENTERPRISE STORAGE SOLUTIONS \u2022 Simple to setup and deploy \u2022 Adaptable to physical and logical constraints \u2022 Resilient to changes in physical infrastructure \u2022 Capable of providing optimized object and block services FOR MORE DETAILS SUSE Enterprise Storage v5 Implementation Guide \u2022 System requirements \u2022 Architectural overview \u2022 Step-by-step implementation \u2022 Architectural best practices Software-defined storage solutions enable the transformation of enterprise infrastructures by providing a unified platform where structured and unstructured data can co-exist and can be accessed as files, blocks, or objects depending on the application requirements. The combination of open-source software such as Ceph and Supermicro SuperServer based on industry standard x86 architecture can reduce overall cost while providing a solid foundation to unlimited scalability for future demands. COMPONENTS OVERVIEW This solution is built and validated with Supermicro SuperServers, SuperStorage systems, and Ethernet switches that are optimized for performance and designed to provide the highest levels of reliability, quality and scalability. This cloud-ready storage solution has been rigorously tested and validated in Supermicro labs, integrating best-in class hardware platforms with enterprise- ready, software-defined storage capabilities. 01_SUSE-Ceph-Solution-Brief_200424_Rev1 Specifications subject to change without notice. All other brands and names are the property of their respective owners. FOR MORE INFORMATION SUSE Enterprise Storage v5 Implementation Guide For Supermicro SuperServer Platforms For a complete bill-of-materials and thorough description of the highlighted reference architecture, as well as a step-by-step guide on how to implement an installation, please download the guide using the URL below, or scan the QR code on the right: INFRASTRUCTURE ARCHITECTURE Supermicro validated reference configurations for software-defined storage are cloud optimized for scale-out and high performance at maximum density. These Supermicro systems feature Intel Xeon Scalable processors and DDR4 memory. The storage nodes utilize the 2U Ultra Server systems with Intel P4610 1.6TB NVMe PCI-E SSDs for high throughput and low latency storage. SOLUTION ARCHITECTURE SUSE Enterprise Storage provides unified block, file, and object level access based on Ceph, a distributed storage solution designed for scalability, reliability and performance. Ceph\u2019s foundation is the Reliable Autonomic Distributed Object Store (RADOS), which provides applications with object, block, and file system storage in a single unified storage cluster, making Ceph flexible, highly reliable and easy to manage. NETWORKING ARCHITECTURE To achieve a reliable and robust infrastructure, Ceph offers both: (a) separation of cluster (backend) and client-facing network traffic and isolates Ceph OSD daemon replication activities from Ceph client to storage cluster access, and, (b) redundancy and capacity in the form of 40GbE bonded network interfaces from the storage nodes to the switches. PERFORMANCE DATA A comprehensive set of storage performance tests are documented in the Implementation Guide. Presented data can be used as", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a945bce4-5e4d-44e8-ab32-e41bae6628e6": {"__data__": {"id_": "a945bce4-5e4d-44e8-ab32-e41bae6628e6", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA_Omniverse_Enterprise.pdf", "publication_date": "March 2022", "referenced_websites": ["https://www.supermicro.com/en/products/nvidia-omniverse"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Reshaping 3D Design for Scalability 2 Engineered Solutions for 3D Design Teams 3 Three Deployment Configuration Examples 4 Bringing In the Right Skills 5 RIGHT-SIZING 3D DESIGN RESOURCES WITH NVIDIA OMNIVERSE ENTERPRISE Supermicro workstations and servers power workloads for small, large, on-premises or remote teams 3D design environments provide powerful visualization and simulation capability for many industries. Projects in media production, oil and gas exploration, medical imaging, electronic design automation (EDA) and mechanical computer-aided design and engineering (CAD/CAE) need advanced image rendering for design and analysis. For teams in these and other industries, NVIDIA is transforming real-time collaboration around 3D designs with NVIDIA Omniverse Enterprise. It provides photorealistic 3D rendering and simulation in a workflow maximizing rendering iterations, streamlining review cycles, and enabling work from anywhere, on-premises or remote. Supermicro is innovating solutions for Omniverse Enterprise deployments on a range of workstation and server hardware, right-sizing 3D design resources for each team. Three deployment configuration examples show a 6-user single workstation combining all needed capability, a pooled GPU 78- user rack-level deployment, and a new jointly developed OVX reference platform handling 64 heavy users or 256 light users in a rack-level solution with Ethernet or InfiniBand connectivity. As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. 2022 Copyright Super Micro Computer, inc. . 2 Reshaping 3D Design for Scalability 3D design acceleration began in the \"box-on-desk\" deployment model, with applications running on a workstation. Scaling a design team meant adding a designer and investing in another 3D graphics workstation for them. Workflows kicked off rendering jobs over lunch or at the end-of-day for overnight runs, followed by changes and more rendering. This 1:1 coupling between designer and workstation has limited scalability and made remote work difficult. NVIDIA Omniverse Enterprise changes the 3D design scalability and remote work equation. It enables collaboration for creative teams on enterprise 3D visualization projects like never before. This new technology reduces costs and waste by enabling a simultaneous workflow, maximizes creativity by allowing new iterations without opportunity cost, and accelerates time to production by eliminating import-export workflows. Highlights of the Omniverse architecture: \u2022 Rendering builds on advanced NVIDIA RTX accelerated real-time ray-tracing technology and adds dynamic allocation of graphics processing unit (GPU) cores, even from separate machines, for rendering jobs. \u2022 Collaborative scene composition is enabled by Pixar's Universal Scene Description (USD), an extensible, open- source file framework that allows the interchange of 3D assets. \u2022 NVIDIA Omniverse Nucleus database and collaboration engine manage data such as geometry, lights, materials, textures, and more for defining a virtual \"world\" in and around a design, including its environment. \u2022 NVIDIA Omniverse Connect allows 3rd party client applications access to the Nucleus database using publish- subscribe messaging, letting many designers author live changes that everyone connected sees in real-time. \u2022 NVIDIA Omniverse Kit is a toolkit for lightweight plugins building applications and microservices. \u2022 NVIDIA Omniverse Create enables world-building, using advanced USD workflows such as layers, variants, instancing, animation caches, and more. \u2022 NVIDIA Omniverse View lets non-technical users review 3D content interactively in full, photorealistic fidelity. Using Supermicro hardware platforms, 3D design teams can select a hardware topology and mix and match configurations for an Omniverse Enterprise solution best fitting their needs. For example, \"creators\" can tap into the full capability needed for design, while \"reviewers\" can run on lighter hardware platforms at a reduced software licensing cost. In addition, deployments are open to various workstations, deskside, and rack-scale servers right-sized for teams, projects, and workloads. Figure 1 - NVIDIA Omniverse Software Stack - Image Courtesy of NVIDIA 2022 Copyright Super Micro Computer, inc. . 3 Engineered Solutions for 3D Design Teams Supermicro's server technology is proven through years of deployments in enterprise, data center, cloud computing, 5G telecom infrastructure, high-performance computing (HPC), edge computing, and other IT applications. US-based engineering and manufacturing teams provide innovative features, and ISO 9001-certified quality customers expect. These teams design and produce Supermicro motherboards, power supplies, enclosures and racks, and other components, increasing supply chain control. The firmware allows unlocked peripheral integration at the factory or by customers. Supermicro selects the right technology for delivering better price/performance with improved energy efficiency through its partnerships. A key enabler for 3D design is NVIDIA's graphics processing unit (GPU) technology. Supermicro currently offers over 60 workstation and server configurations with installed NVIDIA graphics cards such as the NVIDIA RTX A6000 or NVIDIA A40. With the debut of NVIDIA Omniverse Enterprise, Supermicro is fine-tuning new workstation and server configurations matching hardware allocation to user performance profiles, maximizing resource usage. Flexing GPU muscle for a variety of workloads Supermicro excels at creating denser NVIDIA RTX GPU-based configurations targeting light to heavy Omniverse Enterprise workloads. The combination of cutting-edge AMD or Intel chipsets, fast PCI Express slots, Supermicro-designed high efficiency 80 Plus Titanium power supplies, and thermally simulated system cooling designs enable multi-GPU workstations and servers. In addition, high-speed Ethernet switching and IPMI 2.0 remote management help connect and manage deployments. Some possible use cases for various Supermicro hardware configurations: \u2022 A 1:1 model, with a single GPU in an entry-level workstation for each designer, still works for light 3D design workloads \u2022 Small 3D design teams can render on-demand using a more powerful workstation with several GPU cards installed \u2022 Multi-location teams can use one medium-sized server with multiple GPU cards, connecting remotely over Ethernet \u2022 A heavy media entertainment workload can deploy a rack-scale solution with up to 64 pooled GPUs from several servers Expertise for Omniverse Enterprise deployments Omniverse Enterprise is rapidly growing and being adopted quickly by customers as a new and exciting solution. NVIDIA featured Omniverse Enterprise during its CES 2022 presentation. Supermicro, as an NVIDIA ecosystem partner, keeps pace with new GPU applications, including artificial intelligence (AI) and on-demand 3D rendering. Initial deployments of the use cases above built vital Supermicro expertise with Omniverse Enterprise, and Supermicro can help deploy more solutions now. A typical Omniverse Enterprise engagement with Supermicro looks like this: \u2022 A Supermicro solution architect interviews customer teams about roles, workloads, and deployment options \u2022 Supermicro technology enablement teams look at specific requirements and configurations for workstations/servers \u2022 Supermicro product teams install Omniverse Enterprise at the factory and launch clients on the customer's premises During these engagements, the goal is always to provide efficient compute power where a team needs it for their workflow. For example, a solution architect can help size a platform for a Nucleus database and its Large File Transfer (LFT) technology, allocating disk storage and memory-based cache. Another example includes a rack-mount Ethernet switch for remote connections \u2013 each remote 4K display needs at least 1Gbit of Ethernet bandwidth to run at 60fps without latency. Supermicro is the first solution provider to partner with NVIDIA on an OVX reference platform for low user count and high- intensity use cases. No other hardware vendor has yet deployed Omniverse Enterprise in rack-scale, high user counts solutions. Offering a wide variety of options, Supermicro can address more scenarios for Omniverse Enterprise deployments with results customers can count on \u2013 like three described next. 2022 Copyright Super Micro Computer, inc. . 4 Three Deployment Configuration Examples For small teams of up to six users, one Supermicro A+ SuperWorkstation hosts a Nucleus server, an NVIDIA RTX Virtual Workstation (vWS), and VMware virtualization software. A 64-core AMD RYZEN Threadripper Pro 3995WX processor handles threading in this configuration. Virtualization storage comes from 4x mirrored, striped 3.84TB m.2 SSDs, while 2x 7.68TB U.2 SSDs provide a Nucleus file store. Two NVIDIA RTX A6000 GPUs handle rendering. Dual-port 25GbE handles virtual connections for remote users. Resource allocation creates a dedicated workspace for each user on the workstation, plus threads and storage for the Nucleus server and the vWS licensing server. NVIDIA Omniverse Enterprise Nucleus Server VM: 32 vCPU threads, 52GB DRAM, 6TB Gen4 NVMe mirror NVIDIA RTX vWS license server VM: 4 vCPU threads, 8GB DRAM, 20GB SSD 6x User VM, each with: 10 vCPU threads, 32GB DRAM, 16GB vGPUs frame buffer, 960GB Gen4 NVMe Image 1 - AS -5014A-TT Workstation For a flexible GPU pool handling up to 78 users, a Supermicro rack-scale solution includes a standalone Nucleus server, 13 rendering servers, and a 100GbE switch. The Omniverse Enterprise Nucleus Server is a 1114S-WN10RT, running an AMD EPYC 73F3 with 16 cores at 3.5GHz and 128GB DDR4-3200 DRAM. Storage is 6x 3.84TB U.3 SSDs. Two dual-port 100GbE connections feed the Ethernet switch for smooth database access. Thirteen 2U-2 node user servers are either 2114GT-DNR (Intel Xeon W-3365 with 32 cores at 2.7GHz) or 210GP-DNR (AMD RYZEN Threadripper Pro 3975WX with 32 cores at 3.5GHz), each with 256GB DDR4-3200 DRAM, two 1.92TB U.3 SSDs, and two NVIDIA A40 GPUs. Dual-port 25GbE handles virtual connections. Resource allocation creates a dedicated workspace for each user. 78x User VM, each with 16 vCPU threads, 80GB DRAM, 16GB vGPU frame buffer, 960GB SSD Developed jointly with NVIDIA, the SYS-420GP-TNR OVX reference platform targets heavy rendering or simulation requirements with GPU passthrough capability. A 4U server houses eight NVIDIA A40 GPUs, each dedicated to a user or virtualized for multiple users. Processing is two Intel Xeon SP 8362 with 32 cores at 2.8GHz, backed by 1TB of DDR4 ECC DRAM. Storage is two 960GB NVMe boot drives and two 7368TB NVMe storage drives. In addition, two Mellanox ConnectX-6 VPI cards provide Ethernet/InfiniBand connectivity at up to 200 GB/sec. Eight Supermicro SYS-420GP-TNR servers can be combined with a 220U-TNR standalone Nucleus server and an Ethernet/InfiniBand switch in a rack-scale solution for mixed resource deployments. In a heavy usage scenario, each user gets a full NVIDIA A40 GPU for a total of 64 users per rack. The NVIDIA A40 GPUs can be virtualized with allocated CPU threads and storage for up to 256 users in a rack for medium and light resource usage. Image 2 \u2013 13 x 2U-2Node Servers Image 3 - 8 x SYS-420GP-TNR 2022 Copyright Super Micro Computer, inc. . 5 Bringing In the Right Skills NVIDIA Omniverse Enterprise breaks out of the 1:1 model where a 3D design workstation dedicated to every single user was the only option. It relieves the hassle of planning workflows around scheduled rendering iterations. Instead, it enables on-demand rendering from workstations or servers available to all users in real-time. It also allows teams to staff and scale with flexibility. Teams can grab design and project talent with the right skills based anywhere with high-speed internet access. Supermicro is a natural fit as a solution provider for Omniverse Enterprise deployments. With an in-depth understanding of architecting deployments from small teams to large media entertainment projects, Supermicro can match a team's use case to right-sized solutions saving energy and reducing the total cost of ownership. These solutions continue to evolve, as seen in a new, jointly developed reference platform: \"Supermicro's success in Omniverse Enterprise deployments ranging from small design teams to large, geographically distributed project teams caught our attention,\" says Bob Pette, Vice President, Professional Visualization at NVIDIA. \"We created the NVIDIA OVX SYS-420GP-TNR reference platform working together for a proven configuration that ships quickly, getting customers up and running on Omniverse Enterprise faster.\" The range of solutions Supermicro brings to 3D design and simulation teams \u2013 workstations, servers, and rack-scale \u2013 is formidable. It comes from years of experience supplying IT applications. With access to advanced parts from NVIDIA, AMD, Intel, and many other providers, plus in-house design capability for motherboards, power supplies, enclosures, and more, Supermicro can draw configurations together with the quality, deliverability, and performance needed. Teams turning to Omniverse Enterprise should focus on revolutionizing their 3D content creation and simulation pipelines. Having wrong-sized hardware can get in the way of success. Worry-free projects start with a call to Supermicro, tapping into Omniverse Enterprise capability and deployment expertise no other solution provider offers.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "dc8d9ce7-39da-4a5b-b0da-27f7cfd87bcb": {"__data__": {"id_": "dc8d9ce7-39da-4a5b-b0da-27f7cfd87bcb", "embedding": null, "metadata": {"file_name": "Solution-Brief_H12_HPC_AI_SuperBlade_AMD_Instinct.pdf", "publication_date": "March 2022", "referenced_websites": ["https://spec.org/jbb2015/results/res2020q2/jbb2015-20200402-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 FOR HPC AND AI/ML WORKLOADS, AND AMD DELIVER: \u2022 Up to 20 hot-pluggable nodes with Supermicro integrated enclosures \u2022 Single 2nd or 3rd-Gen AMD EPYC processor with up to 280W TDP per node \u2022 One AMD Instinct MI100 or MI210 GPU Accelerator per node \u2022 8 DIMM slots for up to 2 TB of memory per node \u2022 Integrated InfiniBand fabric for up to 200-Gbps HDR bandwidth \u2022 Redundant 2200W Titanium Level power supplies Supermicro SuperBlade SBE-820H Enclosure with SBA-4119SG Nodes SCALE UP YOUR HPC, AI, AND ML WORKLOADS WITH SUPERBLADE Put up to 1.68 petaFLOPs per rack of supercomputing capacity into your data center with our performance and density-optimized solution with a resource-saving architecture Enterprise data centers have long considered on-premises supercomputing capabilities a dream that is out of reach. Today, dreams can become reality with the Supermicro A+ SuperBlade platform powered by AMD EPYC processors and AMD Instinct MI100 accelerators. Equipped with the highest-performing x86 server CPU1 and the world\u2019s fastest HPC GPU2, you can run your AI/ML applications and reduce turnaround time with high 16-bit floating-point (FP16) matrix operations, speeding AI model training and inferencing. You can run high- performance computing (HPC) workloads and accelerate run times for processes such as EDA simulations with fast 64-bit floating-point (FP64) arithmetic. Even traditional enterprise workloads including database management systems and virtual desktop environments benefit from the computing density the platform delivers. Supercomputing Within Reach A single 48U rack of six SuperBlade platforms can support up to 120 SuperBlade nodes. When powered by 64-core AMD EPYC 7763 processors, you have up to 300 teraFLOPs of maximum theoretical computing power at your service. When you configure an AMD Instinct MI100 GPU in each node, you add 1380 teraFLOPs of maximum theoretical 64-bit floating-point performance per rack. The stunning total: 1.68 petaFLOPs per rack to speed your most compute-intensive AI, ML, and HPC workloads to completion. The SuperBlade Node prepares you for the future by being ready to accommodate the AMD Instinct MI210 GPU when available. This density-optimized solution includes 200-Gbps InfiniBand for cluster connectivity and 25 Gigabit Ethernet switching for traditional IP traffic. The platform\u2019s resource-saving architecture significantly reduces initial and operational expenses through shared power and cooling, network management, and unparalleled node density. 2 . Supermicro, SuperBlade, and the Supermicro logo are trademarks and/or registered trademarks of Super Micro Computer, Inc. AMD, the AMD Arrow, CDNA, Instinct, ROCm, and EPYC are trademarks of Advanced Micro Devices, Inc. SPEC and SPECjbb are registered trademarks of the Standard Performance Evaluation Corporation. All other trademarks are the property of their respective owners. LE-77806-02 03/22 FOOTNOTES 1. SPECjbb2015-Distributed critical-jOPS comparison based on highest system results published as of 03/12/2021. Configurations: 20-node, 1x AMD EPYC 7763 (2561044 SPECjbb2015-Distributed critical-jOPS, 2919887 SPECjbb2015-Distributed max-jOPS, https:// spec.org/jbb2015/results/res2021q1/jbb2015-20210225-00615. html) versus 2-node, 1x AMD EPYC 7702P (1877397 SPECjbb2015- Distributed critical-jOPS, 2656878 SPECjbb-Distributed max jOPS, 00533.html) for ~1.36x the performance. MLNWR-115 2. Calculations conducted by AMD Performance Labs as of Sep 18, 2020 for the AMD Instinct MI100 (32GB HBM2 PCIe card) accelerator at 1,502 MHz peak boost engine clock resulted in 11.54 TFLOPS peak double precision (FP64), 46.1 TFLOPS peak single precision matrix (FP32), 23.1 TFLOPS peak single precision (FP32), 184.6 TFLOPS peak half precision (FP16) peak theoretical, floating-point performance. Published results on the NVidia Ampere A100 (40GB) GPU accelerator resulted in 9.7 TFLOPS peak double precision (FP64). 19.5 TFLOPS peak single precision (FP32), 78 TFLOPS peak half precision (FP16) theoretical, floating-point performance. Server manufacturers may vary configuration offerings yielding different results. MI100-03 SCALE UP TO 1.68 PETAFLOPS AND BEYOND We deliver the broadest portfolio of the most high-performing, reliable servers with hyper-dense configurations that don\u2019t sacrifice the versatility you need to get your work done. For workloads including training, inferencing, and HPC, the key getting more work done in a day is the AMD Instinct MI100 GPU Accelerator. The AMD Instinct MI100 GPU is AMD\u2019s most advanced accelerator with all-new AMD CDNA architecture with Matrix Core technology that offers superior performance for a full-range of mixed-precision operations. It\u2019s the world\u2019s fastest HPC accelerator with up to 11.5 TFLOPs of FP64 performance. Sixteen lanes of PCI-E 4.0 connectivity links the GPU with the CPU for maximum I/O bandwidth. Ultra-fast HBM2 GPU memory helps eliminate bottlenecks, with 1.2 TB/s of GPU memory bandwidth to support your largest data sets. The AMD ROCm open software platform supports the libraries your software needs, with optimized versions of PyTorch and TensorFlow. Update your software to use the ROCm platform once, and you can run it anywhere. A+ SuperBlade SBE-820H Enclosure Form Factor \u2022 8RU, up to 20 hot-pluggable half-height 1-socket SuperBlade Nodes Ethernet \u2022 Up to 2 hot-pluggable 25/10/1 Gigabit Ethernet switches InfiniBand \u2022 Single 200-Gbps InfiniBand switch with one 200-Gbps link to each node and up to 20 200-Gbps uplinks Chassis Management \u2022 1 chassis management module for remote system management Power and Cooling \u2022 4, 6, or 8 hot-swappable 2200W Titanium Level (96% efficiency) power supplies SBA-4119SG SuperBlade Node Form Factor \u2022 Up to 20 nodes in one 8U enclosure Processor Support \u2022 Single socket SP3 for AMD EPYC 7002 and 7003 Series processors; up to 64 cores, up to 280W Memory Capacity \u2022 8 DIMM slots, DDR4-3200, up to 2 TB registered ECC Expansion \u2022 1 PCIe 4.0 x16 mezzanine card slot for optional high-performance networking \u2022 2 PCI-E 4.0 x16 full-height full-length slots for 1 double-wide or 2 single-wide GPUs Storage \u2022 1 NVMe/SATA3 M.2 I/O Ports \u2022 2x 25 Gigabit Ethernet LAN-on motherboard (LOM) System Management \u2022 IPMI 2.0 Aspeed 2500 / KVM over IP / Redfish API/TPM 2.0 / Supermicro SuperCloud Composer / Remote Chassis Management Module (CMM) / signed firmware AMD Instinct MI100 GPU At a Glance Compute Units Stream Processors Peak BFLOAT16 Peak INT4/INT8 Peak FP16 Matrix 120 7,680 Up to 92.3 TFLOPs Up to 184.6 TFLOPs Up to 184.6 TFLOPs Peak FP32 Matrix Peak FP32 Peak FP64 Memory Size Memory Bandwidth Up to 46.1 TFLOPs Up to 23.1 TFLOPs Up to 11.5 TFLOPs 32 GB HBM2 Up to 1.2 TB/s", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "f30a3347-4d2c-4a5e-8ccc-e518c203b6cd": {"__data__": {"id_": "f30a3347-4d2c-4a5e-8ccc-e518c203b6cd", "embedding": null, "metadata": {"file_name": "Solution_Brief_DOCSIS_VCMTS.pdf", "publication_date": "October 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro and Intel have jointly demonstrated an industry- leading download data throughput speed of 317 Gbps while consuming 847 Watts of power over a DOCSIS access plant workload on the Supermicro 2U Hyper E platform (SYS-220HE- FTNR). This system is powered by dual 3rd Gen Intel Xeon Scalable processors. This achievement underscores Supermicro\u2019s commitment to customers and partners that need to deliver industry-leading solutions at a competitive cost. In addition, Supermicro is the first-to-market partner of Intel with servers that are developed and manufactured in San Jose, CA. The Supermicro hardware platform demonstrates the latest innovation in system design to meet power efficiency and green computing technology. The Supermicro enterprise computing, storage, and networking solutions combine flexible configuration and tool-less modular designs to give the best-in- class performance, accessibility, and serviceability. 1 Challenges 2 The Solution 3 Results 5 Conclusion 7 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. Supermicro Hyper-E Edge Server 2 Introduction Traditional cable access networks are usually built around Cable Modern Termination Systems (CMTS) or Converged Cable Access Platform (CCAP), locked into the technology's hardware-bound limitations. The Intel Access Network Dataplanes project will host access network data plane reference implementations optimized for high-performance packet processing on Intel architecture and deployable on the Network Function Virtualization (NFV) platform. The Intel Dataplane function is a complete solution and mimics the DOCSIS data plane. The vCMTS tool reserves CPU cores for the control plane, scheduler, OS, and telemetry function, as shown in Figure 1. It is a simulation tool with no high availability and redundancy, maximizing the throughput on a single server. The 3rd Gen Intel Xeon Scalable processor is used for these tests is an Intel Xeon 8368 processor, which contains 38 cores and has a base clock rate of 2.4 GHz. Figure 1 - Reserving Cores for Different Functions The system used for this development consists of a dual socket Supermicro HYPER-E server SYS-220HE-FTNR. Each of the 38 cores per socket is assigned to execute specific tasks. By assigning specific tasks on a per core basis, the entire system is used, reducing both CAPEX and OPEX costs. The following list describes the number of cores that are dedicated to various tasks. \u2022 2 cores per socket for OS, telemetry, and infrastructure service \u2022 4 cores reserved for DOCSIS control plane traffic \u2022 5 cores reserved for US Scheduler \u2022 27 cores for DP traffic to run 18 Service Groups \u2022 18 cores for Downstream Service Group \u2022 9 cores for Upstream Service Group 3 Service group (SG) configuration: \u2022 6OFDM channel configuration \u2022 AES, SW only \u2022 IMIX2 traffic simulation Supermicro Hyper-E Server The Supermicro Hyper-E is a compact, high-performance, highly configurable edge server designed for a wide range of telco installations. The Hyper-E supports dual 3rd Gen Intel Xeon Scalable processors and can be configured with multiple FPGA GPU cards for Edge AI/ML applications such as predictive analytics, helping companies quickly tackle operational issues with predictive tools identify future problems before they become service bottlenecks. In addition, it equips telecom-standard features, including optional NEBS Level 3 compliance, AC and DC power version, and a short-depth front I/O chassis for deployment in central offices and micro data centers. Figure 2 - Supermicro Hyper-E Server The Hyper-E (SYS-220HE-FTNR) is an excellent system for vCMTS for the following reasons: \u2022 2U short-depth design (574mm for 600mm rack) \u2022 Dual socket support for 3rd Gen Intel Xeon Scalable processors up to 270W \u2022 Front-access I/O & tool-less design for best serviceability \u2022 Redundant DC or AC power supplies to support high-availability operation \u2022 Up to 8 x PCI-E 4.0 slots, which can support the 2x Intel 200G and the 4x Intel QAT cards used in the vCMTS implementation \u2022 2x slim AIOM (OCP 3.0 compatible) slots for additional networking connections The components of the vCMTS solution include: 4 Supermicro Product ID Description Qty SYS-220HE-FTNR 2U Hyper-E server with redundant 2000W AC PSU 2 P4X-ICX8368-SRKH8 Intel Xeon 8368 2P 38C/76T 2.4G 57M 11.2GT 270W 4189 D2 4 MEM-DR416L-HL02-ER32 16GB DDR4-3200 ECC Memory 32 HDS-I2T0-SSDSC2KG019T8 Intel D3-S4610 1.92T SATA 6Gb/s 3D TLC 2.5\" 7mm 3DWPD Rev.3 2 N/A Intel 200G Chapman Beach NIC 4 N/A (optional) Intel 8970 QAT 4 N/A QSFP28 to QSFP28 cable - Intel PN: DQF8503-4E05-IN 4 The reference architecture for the Dataplane and NFV stack for the Cable Access Network is shown below: Figure 3 = Reference Architecture 5 Figure 4 - Software Layers On the vCMTS data plane node, multiple Docker containers host DPDK-based DOCSIS MAC upstream and downstream data plane processing for individual cable service groups, allowing them to be instantiated and scaled independently. On the CMTS traffic-generation node, Docker containers host DPDK Pktgen-based traffic generation instances, which simulate upstream and downstream traffic into corresponding vCMTS data plane instances. Under Kubernetes, each vCMTS data plane POD represents a service group with separate containers for downstream DOCSIS MAC data plane processing. The DOCSIS control plane is simulated through a JSON file containing subscriber cable-modem information. DOCSIS upstream scheduling is simulated through the generation of UEPI-encapsulated cable-modem DOCSIS stream segments using PCAP files. Telemetry functions run in Docker containers as a Daemonset under Kubernetes. A comprehensive set of vCMTS data plane statistics and platform KPIs are gathered by the open-source Collectd daemon. A Grafana dashboard is provided to visualize these metrics via InfluxDB. The reference platform also contains a power manager, which reduces the power consumption of the CPU cores during quiet network periods. The entire system is orchestrated by Kubernetes, which is an open source container manager and orchestrator. It automates the deployment, scaling, and operational functions associated with application containers. Intel plugins for Kubernetes are used for infrastructure management functions such as CPU core management and assignment of SR-IOV interfaces for NICs. 6 Results Using the Supermicro Hyper-E Servers (as described above), the I/O speed was measured at 317.2Gbps on a single server, and the system uses 849Watt of power consumption. The figure below compares Upstream (US) and Downstream (DS) performance and resulting performance with 1% and 2% line rates. Figure 5 - Performance of DS and US Figure 6 - Comparing Legacy CMTS with a Virtual CMTS 7 Benefits of a Virtual CMTS: \u2022 Cost effective: Save cost from legacy CMTS deployment \u2022 Reduce footprint: Reduce the footprint by 7x \u2022 Power efficiency: Save power by 3.5X within the same service group \u2022 Best performance: achieved 8Gbps per service group \u2022 Higher Service Group density: Reach 3X more Service Groups per RU space Conclusion The Intel vCMTS tool demo aims to help service providers to understand the potential of a virtualized architecture and simulate the result. Supermicro offers a compact and optimized hardware platform that exceeds the Intel vCMTS reference design guide\u2019s requirement and delivers world-class performance and efficiency for Multiple System Operators (MSO) CMTS application workloads.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "35853b02-f478-4cb5-9551-8f92c37027d6": {"__data__": {"id_": "35853b02-f478-4cb5-9551-8f92c37027d6", "embedding": null, "metadata": {"file_name": "Solution-Brief_Kioxia_in_SMCI.pdf", "publication_date": "April 2022", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Datacenter applications generate large quantities of data that have increased storage requirements and, in turn, require increased speed to access this data. IT administrators are tasked with delivering fast processing and storage performance to support the many applications and workloads that users demand. This has created a need for denser storage solutions. As a result, the amount of data generated within a data center has become very large to manage, space-limited to store, and more challenging to access. With the recent availability of E1.S Enterprise and Datacenter Standard Form Factor1 (EDSFF) servers and SSDs, the data center objective of higher performance and increased storage density has become more attainable. E1.S Form Factor SSD The PCIe interface and NVMe protocol drive E1.S form factor servers and SSDs \u2013 proven to deliver strong throughput, input/output operations per second (IOPS), and latency performance compared to legacy hard drive interfaces and protocols. 1 E1.S Form Factor SSD 1 NoSQL4 Mongo Database 2 Performance Benefits of E1.S Form Factors 3 Summary and Appendix 5 Supermicro is the leading innovator in high- performance, high-efficiency server and storage technologies and a premier worldwide provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative by providing customers with the most energy-efficient, environmentally friendly solutions available on the market. Supermicro SSG-1029P-NES32R 2 Though many server and storage vendors are developing E1.S form factor platforms, there are very few solutions available per the date of this publication. One innovative server solution available in the E1.S form factor is the Supermicro SSG-1029P-NES32R, a Petascale storage server. It enables very dense storage installations with potentially greater density2 versus media deployed with 2.5-inch or 3.5- inch3 drives and features KIOXIA XD6 Series PCIe 4.0 data center NVMe SSDs. These E1.S form factor SSDs take advantage of PCIe Gen4 speeds and are designed to the Open Compute Project (OCP) NVMe Cloud SSD Specification. The Supermicro SSG-1029P- NES32R Storage Server coupled together with Kioxia XD6 Series E1.S SSDs is now available under the Supermicro Petascale Product Family. The combination of solid read performance and a rich feature set help position this as the leading E1.S storage solution in the market. KIOXIA XD6 Series E1.S driven by synthetic tests This presents E1.S server/storage performance relating to latency and throughput and delivers this high performance without relying solely on system memory. Although many applications can benefit from this powerful E1.S solution, these results demonstrate how the system can perform running a NoSQL4 MongoDB database driven by synthetic tests. NoSQL MongoDB Database In a large-scale MongoDB database, the data is sharded across many storage devices and storage nodes, and database transactions traverse networking infrastructure, impacting latency. Every component in the architecture can act as a benefit or detriment to the overall performance. Recognizing that most of the key infrastructure has been removed for this drive during the internal system test, the raw performance of the individual drive remains the most critical metric to overall database performance at scale. 3 Performance Benefits of E1.S Form Factors To demonstrate the performance of XD6 Series SSDs in a Supermicro SSG-1029P-NES32R server, the system was tested with synthetic benchmarks in KIOXIA\u2019s lab environment. A test database was created on the MongoDB application consisting of three hundred million records and synthetic tests run through Yahoo! Cloud Serving Benchmark (YCSB) software. One database test was conducted where a workload of two billion operations (50% reads and 50% updates) was run against the NoSQL MongoDB database. A 50% read/50% update workload is reasonably standard for database applications. This test measured four metrics: Run Time, Average Read, Latency, Average Update Latency, and Operations Throughput. The Supermicro Petascale storage server CPUs are PCIe 3.1-capable, so the XD6 Series SSD was tested at PCIe Gen3 speed. The results of the synthetic tests yielded the following results: Run Time This metric represents the total time required in hours to complete the workload consisting of two billion read and update operations against the MongoDB database. This measurement is heavily dependent on factors such as database size. As databases become larger, the amount of time it takes to perform a read operation successfully can increase as the system has to query the database and find all of the data it needs through the vast records stored in the database. For update operations, the system needs to traverse the entire database of records until it finds the record that needs to be updated and then performs the necessary changes to the data. The low latency and high performance that the SSD provides enable the database to retrieve the records quickly from the SSD, which is critical in reducing the time it takes for each individual update to complete. With a database consisting of three hundred million records, the system took 18.33 hours to complete two billion operations within the database workload. Average Read Latency This metric represents the time it takes to perform a read database operation. It includes the average time it takes for the YCSB workload generator to issue the read operation and the time it takes for the operation to be successfully completed. This is an important metric to present as it can positively impact database performance and application response times that can translate into a better user database experience. The average read latency delivered was 5.54 milliseconds (ms), indicating very fast database performance. 18.33 0.00 5.00 10.00 15.00 20.00 Time (hours) Run Time XD Series 4 Average Update Latency This metric represents the time it takes to perform an update database operation. It includes the average time it takes for the YCSB workload generator to issue the update operation and the time it takes for the operation to be successfully completed. This metric can also affect database performance and application response times, translating into a better user database experience. The average update latency delivered was 11.34 ms, indicating very fast database performance. Operations Throughput This metric represents the number of operations per second a system can complete on average. It also measures how quickly a given server solution can process incoming database queries related to database throughput. This is a critical metric to discern if the number of incoming queries is much higher than the achievable database throughput. If this occurs, the server can overload, creating longer waiting times per query, negatively impacting application performance and the user experience. It is essential when a mix of operations, such as reading and updating operations from a large group of users, must be simultaneously processed at sub-second response times. The throughout delivered was 30,316.44 operations per second, indicating fast database performance. 5.54 0.00 2.00 4.00 6.00 Time (ms) Average Read Latency XD Series 11.34 0.00 5.00 10.00 15.00 Time (ms) Average Update Latency XD Series 5 Summary Though E1.S platforms are being supported by a number of server and storage vendors, there are very few tested solutions available today. The Supermicro Petascale storage server and KIOXIA XD6 Series SSDs represent an E1.S server/storage solution currently available and well-suited for database applications showcased by these test results. This E1.S server/storage combined with XD6 Series SSDs demonstrated very low read and update latencies, fast workload throughput, and high overall performance. This Supermicro and KIOXIA solution can support up to 6 terabytes5 (TB) of system memory and up to 32 KIOXIA XD6 Series SSDs. As XD6 Series SSDs are available in 1 TB, 2 TB, and 4 TB storage capacities, the solution can hold up to 128TB in the 1U Supermicro SSG-1029P-NES32R E1.S server. The E1.S form factor is a good fit for MongoDB enabling high storage density in a server, performance per watt, and IOPS per GB, in a fully populated system. With two NUMA balanced PCIe Gen3 x16 slots, up to 200Gb/s bandwidth is available to accommodate widely deployed 25g/50g/100g infrastructure. Hot-swap capabilities are also featured, making this E1.S solution well-suited for today's hyperscale and enterprise-class applications. The E1.S media features heat sink options at varying sizes integrated directly into XD6 Series SSDs, enabling SSD cooling options for applications requiring higher performance. This ensures that storage performance is not throttled due to heat, enabling XD6 Series SSDs to achieve optimal performance. In addition, since XD6 Series SSDs fit directly within the Supermicro Petascale storage servers without carriers (as with M.2 drives), the system provides very efficient cooling with high storage density. Additional Supermicro SSG-1029P-NES32R E1.S server information is available here. Additional XD6 Series SSD information is available here. Appendix Test Equipment The hardware and software equipment used to perform the synthetic test include: \u2022 Supermicro SSG-1029P-NES32R Server: One (1) dual-socket server with two (2) Intel Xeon Gold 6226R processors, featuring 16 processing cores, 2.90 GHz frequency, and 192 gigabytes5 (GB) of DDR4 DRAM \u2022 Operating System: 30,316.44 0.00 10,000.00 20,000.00 30,000.00 40,000.00 Throughput (ops/sec) Operations Throughput XD Series 6 Ubuntu v20.04.3 (Kernel 5.4.0-89-generic) \u2022 Application: MongoDB v5.0.3: Database size = 460.04 GB Maximum Allocated Memory = 150 GB Number of Connections / Threads = 256 Number of Records = 300 Million Number of Operations = 2 Billion \u2022 Test Software: Synthetic tests run through YCSB software (version 0.17.0) \u2022 Storage Devices (Table 1): One (1) KIOXIA XD6 Series PCIe 4.0 data center NVMe SSD with 3.84 TB capacitySpecifications XD6 Series Form Factor E1.S Package 9.5mm Interface PCIe 4.0 Capacity 3.84 TB NAND Flash Type BiCS FLASH3D flash memory Endurance Rating 1 Drive Write Per Day6 (DWPD) Endurance Time Frame 5 years Power <14W DRAM Allocation 192 GB Table 1: SSD specifications and set-up parameters Test Set-up The Supermicro SSG-1029P-NES32R E1.S server was configured with the Ubuntu v20.04.3 operating system and YCSB v0.17.0 test software. The YCSB software was used to create a database on the XD6 Series SSD to run a 50% read and 50% update YCSB workload against the MongoDB database. The 50%/50% mixed workload represented a common workload for many applications, including database applications. The Supermicro SSG-1029P-NES32R E1.S server using Intel Xeon Gold 6226R processors are PCIe 3.0 capable, so the XD6 Series SSD was tested at Gen3 speeds. The XD6 Series SSD connects directly to the Supermicro server via an E1.S connector. Test Procedures The benchmark test performed on the XD6 Series SSD included the following metrics: (1) Run Time; (2) Average Read Latency; (3) Average Update Latency; (4) Operations Throughput; The results of these metrics and others were recorded providing ample evidence the XD6 Series E1.S form factor SSD was a good fit for large scale, latency dependent applications. FOOTNOTES: 1 Developed by the Small Form Factor Technical Affiliate (SFF-TA) working group as part of the Storage Networking Industry Association (SNIA). 2 Source: Supermicro SSG-1029P-NES32R online product flyer - 6x E1.S drives = 2x U.2 drives in space utilization. 3 2.5-inch and 3.5-inch indicate the form factor of the SSD and not the drive\u2019s physical size. 4 A NoSQL database stores data in a format other than relational tables. 7 5 Definition of capacity - KIOXIA Corporation defines a kilobyte (KB) as 1,000 bytes, a megabyte (MB) as 1,000,000 bytes, a gigabyte (GB) as 1,000,000,000 bytes, a terabyte (TB) as 1,000,000,000,000 bytes, and a petabyte as 1,000,000,000,000,000 bytes. A computer operating system, however, reports storage capacity using powers of 2 for the definition of 1Gbit = 230 bits = 1,073,741,824 bits, 1GB = 230 bytes = 1,073,741,824 bytes, 1TB = 240 bytes = 1,099,511,627,776 bytes, and 1PB = 250 bytes = 1,125,899,906,842,624 bytes, and therefore shows less storage capacity. Available storage capacity (including examples of various media files) will vary based on file size, formatting, settings, software and operating system, and/or pre-installed software applications, or media content. Actual formatted capacity may vary. 6 Drive Write(s) per Day: One full drive write per day means the drive can be written and re-written to full capacity once a day, every day, for the specified lifetime. Actual results may vary due to system configuration, usage, and other factors.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "37b582cd-dbb9-4089-8711-4635b56ddd2c": {"__data__": {"id_": "37b582cd-dbb9-4089-8711-4635b56ddd2c", "embedding": null, "metadata": {"file_name": "Solution_Brief_Altair_Hyper.pdf", "publication_date": "July 2023", "referenced_websites": ["https://www.supermicro.com/en/products/aplus", "https://www.supermicro.com/en/products/hyper?pro=generation_new%3DH13"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Combining large datasets, advanced simulation techniques, and machine learning fuels scientific discovery and innovation across multiple industries. Altair makes data-intensive analytics operations easier for engineers and researchers to access and manage. Supermicro H13 Hyper systems afford Altair a flexible range of computing, networking, storage, and I/O expansion capabilities to perform at their best and accelerate engineering, research, and design on high-performance and high- throughput systems. In addition, using Altair on Supermicro servers reduces the total cost of ownership (TCO) and improves return on investment (ROI) by leveraging the optimized systems. Gain high performance, flexibility, scalability, and serviceability to demanding IT environments and to power mission-critical enterprise workloads. \u2022 Dual AMD EPYC 9004 Series Processors \u2022 Up to 6TB DDR5-4800MHz in 24 DIMMs \u2022 Flexible NVMe, SAS, and SATA drive options \u2022 Configurable PCIe 5.0 expansion capabilities with CXL 1.1+ memory expansion \u2022 AIOM slots with OCP 3.0 support \u2022 Titanium-Level efficiency power supplies 1 Solution Highlights 2 Supermicro H13 Hyper compute node configurations for Altair 2 Further Information 5 2 Solution Highlights Supermicro H13 Hyper systems support the AMD EPYC 9004 Series processors product line, offering 96 cores per CPU and 192 cores per server. The CPU's 128 lanes of PCIe 5.0 bandwidth enable massive amounts of parallel I/O in the system, and system configurations are available to meet just about any storage need, which supports various levels of Altair businesses, like high-throughput scheduling, cloud bursting, etc. Supermicro H13 Hyper compute node configurations for Altair Table 1 shows recommendations for computational fluid dynamics (CFD) applications such as Altair AcuSolve. Supermicro servers with 4th Gen EPYC processors with 12 memory channels per processor and support for AVX-512 instructions can deliver high throughput per node for CFD applications such as AcuSolve since they benefit from multicore parallelism and greater memory bandwidth. Server/Processor Memory Storage/Network Air Cooled \u2022 Dual Socket AS -2125HS- TNR \u2022 2x EPYC 9654P \u2022 Up to 192 cores/384T \u2022 2.0 GHz - 2.15 GHz \u2022 L3 Cache of 384MB \u2022 TDP 360W \u2022 24 DIMM slots \u2022 Up to 6TB: 3DS ECC Registered RDIMM, DDR5-4800MHz \u2022 24 Hot-swap 2.5\u201d NVMe/SAS/SATA \u2022 1 AIOM/OCP NIC 3.0 Slot Table 1: Recommended Supermicro H13 Hyper servers configurations for Altair AcuSolve Table 2 shows recommendations for structural analysis using implicit finite element analysis (FEA), such as Altair OptiStruct. Supermicro servers with lower-core count EPYC processors with high frequencies with support for AVX-512 instructions help efficiently utilize per-core software licenses and offer very high performance per core. Server/Processor Memory Storage/Network Air Cooled \u2022 Dual-Socket AS -2025HS- TNR \u2022 2x EPYC 9354 \u2022 Up to 192 cores/384T \u2022 2.30 GHz - 2.40 GHz \u2022 L3 Cache of 256MB \u2022 TDP 280W \u2022 24 DIMM slots \u2022 Up to 6TB: 3DS ECC Registered RDIMM, DDR5-4800MHz \u2022 12 Hot-swap 2.5\u201d NVMe/SAS/SATA \u2022 1 AIOM/OCP NIC 3.0 Slot Table 2: Recommended Supermicro H13 Hyper servers configurations for Altair OptiStruct Table 3 shows recommendations for crash applications using explicit FEA such as Altair Radioss. Supermicro servers with medium-core count EPYC processors with high frequencies and high cache-per-core and support for AVX-512 instructions offer very high performance per core to help efficiently utilize per-core software licenses. Server/Processor Memory Storage/Network 3 Air Cooled \u2022 Dual-Socket AS -2025HS- TNR \u2022 2x EPYC 9354 \u2022 Up to 192 cores/384T \u2022 2.30 GHz - 2.40 GHz \u2022 L3 Cache of 256MB \u2022 TDP 280W \u2022 24 DIMM slots \u2022 Up to 6TB: 3DS ECC Registered RDIMM, DDR5-4800MHz \u2022 12 Hot-swap 2.5\u201d NVMe/SAS/SATA \u2022 1 AIOM/OCP NIC 3.0 Slot Table 3: Recommended Supermicro H13 Hyper servers configurations for Altair Radioss How Supermicro H13 Servers Accelerate Enterprise Workloads You need high performance for your enterprise applications. The flexible selection of density and storage capacity gives you a high- performance server for every purpose, including: \u2022 Virtualization and cloud, including virtual desktop infrastructure with GPU acceleration \u2022 Hyperconverged infrastructure \u2022 Enterprise applications, including database, customer relationship management, and enterprise resource planning \u2022 High performance computing clusters You get consistent, tool-less deployment and maintenance of both the motherboard and the systems themselves. And our versatile motherboard powers all three of our H13 Hyper systems. Each system has configuration options that enable varying numbers of expansion slots and disk drives simply by ordering or swapping the appropriate kits. This feature means customers can have systems tailored to application needs but with complete architectural consistency. This helps to reduce the chance of errors that can cause downtime and ease the need for staff to train on multiple server types. With H13 Hyper systems, they are all based on the same infrastructure. Our open management APIs and tools are ready to support you. In addition to a dedicated IPMI port and a Web IPMI interface, Supermicro SuperCloud Composer software helps you configure, maintain, and monitor all of your systems using single-pane-of-glass management. If your DevOps teams prefer to use their own tools, industry-standard Redfish APIs provide access to higher-level tools and scripting languages. 4 H13 Generation Dual-Socket AS -1125HS-TNR Dual-Socket AS -2025HS-TNR Dual Socket AS -2125HS-TNR Form Factor 1U rackmount 2U rackmount 2U rackmount Processor Support \u2022 Dual SP5 socket for two AMD EPYC 9004 Series CPUs \u2022 Up to 96 cores \u2022 Dual SP5 socket for two AMD EPYC 9004 Series CPUs \u2022 Up to 96 cores \u2022 Dual SP5 socket for two AMD EPYC 9004 Series CPUs \u2022 Up to 96 cores Memory Slots & Capacity \u2022 Up to 6TB 3DS ECC DDR5-4800MHz in 24 DIMMs On-Board Devices System on Chip Hardware root of trust IPMI 2.0 with virtual-media-over-LAN and KVM-over-LAN support ASPEED AST2600 BMC graphics I/O Ports Integrated IPMI 2.0 plus KVM with dedicated LAN 2 USB 3.0 ports 1 VGA port 1 TPM 2.0 header Drive Bays \u2022 8 hot-swap 2.5\" NVMe/SAS/SATA drives1 (Option for up to 12 drives) \u2022 2 M.2 NVMe PCIe 3.0 x4 \u2022 12 hot-swap 3.5\" NVMe/SAS/SATA drives1 \u2022 2 M.2 NVMe PCIe 3.0 x4 \u2022 24 hot-swap 2.5\" NVMe/SAS/SATA drives1 \u2022 2 M.2 NVMe PCIe 3.0 x4 Expansion Slots \u2022 3 PCIe 5.0 x16 Slots \u2022 Configuration options for PCIe 5.0 Slots: \u2013 4 PCIe 5.0 x16 Slots \u2013 8 PCIe 5.0 x8 Slots \u2013 1 PCIe 5.0x16 Slot plus 6 PCIe 5.0 x8 Slots \u2013 2 PCIe 5.0x16 Slots plus 4 PCIe 5.0 x8 Slots \u2013 3 PCIe 5.0x16 Slots plus 2 PCIe 5.0 x8 Slots When configured with 24 NVMe drives: \u2013 1 PCIe 5.0 x16 Slot, 2 PCIe 5.0 x8 Slots When configured with 24 SATA drives: \u2013 4 PCIe 5.0x16 Slots, 8 PCIe 5.0x8 Slots, 1 PCIe 5.0x16 Slot plus 6 PCIe 5.0x8 Slots, 2 PCIe 5.0x16 Slots plus 4 PCIe 5.0x8 Slots, 3 PCIe 5.0x16 Slots plus 2 PCIe 5.0x8 Slots Networking 1 AIOM/OCP 3.0 network interface slot 1 AIOM/OCP 3.0 network interface slot, up to 2 AIOM slots with optional kit 1 AIOM/OCP 3.0 network interface slot, up to 2 AIOM slots with optional kit BIOS AMI Code Base 256 Mb (32 MB) SPI EEPROM Front Panel Power On/Off and System Reset buttons Power status, HDD activity, network activity, system overheating, fan failure, and UID LEDs System Management \u2022 Built-in server management tool (IPMI 2.0, KVM/media over LAN) with dedicated LAN port \u2022 Redfish APIs \u2022 Supermicro SuperCloud Composer \u2022 Supermicro Server Manager (SSM) and Supermicro Update Manager (SUM) Power & Cooling 1200W Redundant Power Supplies (Titanium Level)2 1600W Redundant Power Supplies (Titanium Level)2 1600W Redundant Power Supplies (Titanium Level)2 5 Further Information", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "31dfbc3e-e10a-4655-8287-fe458f064f26": {"__data__": {"id_": "31dfbc3e-e10a-4655-8287-fe458f064f26", "embedding": null, "metadata": {"file_name": "Solution-Brief_IntelSelect_VMWare_vSAN.pdf", "publication_date": "October 2019", "referenced_websites": ["www.supermicro.com", "www.intel.com/selectsolutions"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 HYPER CONVERGENCE SOLUTION FOR ENTERPRISE AND SMBS 3 BENEFIT OF SOLUTION INTEL SELECT SOLUTIONS FOR VMWARE VSAN - Enterprise Data Centers are experiencing demanding workloads that put stress on their infrastructure. In order to meet critical business objectives, IT teams need to look for new ways to transform their data centers to achieve optimal performance. Unfortunately, IT teams do not always have the time or resources to evaluate, select and purchase the necessary hardware and software components. To meet this challenge, Supermicro, a global data center solution provider, has partnered with Intel to offer a solution that addresses these customer pain points. The solution is based on the Ultra SuperServer System which belongs to the well accomplished flagship line of SuperServers. This Ultra SuperServer Platform provides the critical building block foundation base needed for uncompromised compute and storage performance demanded by the hyper-converged and next generation software defined data center environments. Supermicro Intel Select Solutions for VMware vSAN 2 HYPER CONVERGENCE SOLUTION FOR ENTERPRISE AND SMBS Supermicro\u2019s Intel Select Solutions for VMware vSAN is certified for VMware vSAN ReadyNode and tightly specified by Intel and VMware to deliver out-of-the-box high performance. IT teams can be rest assured that their solutions are already verified for balance and optimized performance \u2013 from the hardware up through the firmware stack to the VMware vSAN software so they can get right to work meeting the SLA\u2019s of their applications rather than wading through multiple component options or conducting extensive system level testing prior to deployment. In addition to fast load times for HANA database, Intel Optane DC persistent memory delivers an optimized balance between persistence and performance at a lower cost per Gigabyte than DRAM. For large in-memory deployments, the use of Intel Optane DC persistent memory can dramatically lower the initial acquisition cost of your SAP HANA hardware. Intel Optane DC persistent memory is not only lower cost than DRAM, but is also available in larger sizes, up to 512GB per unit. The combination of DRAM plus Intel Optane DC persistent memory allows for much larger SAP HANA deployments, per socket, than use of traditional DDR memory alone. BENEFIT OF SOLUTION \u2022 Delivers high performance that is optimized to a specific threshold across compute, storage and network \u2022 Reduces the amount of time and money spent on research, configuration and testing \u2022 Passes rigorous VMware vSAN ReadyNode certification \u2022 Customizable components for greater performance and capacity \u2022 Expedites the time to deployment Supermicro 2 Socket vSAN Ready node (SYS-1029U-TN10RT) \u2022 Processors: Dual Socket 2nd generation Intel Xeon Scalable processors- Gold 6230 \u2022 Memory: 12 x 32GB 2666 MHz DDR4 DIMM- 384GB \u2022 Storage: Cache Tier- 2x 375GB Intel Optane SSD DC P4800X Series with NVMe \u2022 Capcity Tier- 6 X 8TB Intel SSD DC P4610 Series with NVMe \u2022 Data Network: Dual 25Gbe SFP28 based on Intel Ethernet Controller XXV710-AM2 25GbE controller Supermicro Intel Select Solutions for VMware vSAN 3 - ABOUT SUPER MICRO COMPUTER, INC. Supermicro (NASDAQ: SMCI), the leading innovator in high-performance, high-efficiency server technology is a premier provider of advanced server Building Block Solutions for Data Center, Cloud Computing, Enterprise IT, Hadoop/Big Data, HPC and Embedded Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. ABOUT INTEL SELECT SOLUTIONS Intel is driving the next wave of data center innovation with Intel Select Solutions, based on Intel technologies. Intel Select Solutions are verified solutions configurations that are aimed to speed selection and deployment of data center and communications network infrastructure. The solutions are developed from deep Intel experience with industry solution providers, as well as extensive collaboration with the world\u2019s leading data center and service providers. No part of this document covered by copyright may be reproduced in any form or by any means \u2014 graphic, electronic, or mechanical, including photo- copying, recording, taping, or storage in an electronic retrieval system \u2014 without prior written permission of the copyright owner. Supermicro, the Supermicro logo, Building Block Solutions, We Keep IT Green, SuperServer, Twin, BigTwin, TwinPro, TwinPro\u00b2, SuperDoctor are", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "b3153eb7-9d8b-43c4-867c-2575ea33215f": {"__data__": {"id_": "b3153eb7-9d8b-43c4-867c-2575ea33215f", "embedding": null, "metadata": {"file_name": "Solution-Brief_TTTech.pdf", "publication_date": "April 2021", "referenced_websites": ["www.tttech-industrial.com/try-nerve"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Until now, industrial operations have been heavily reliant on inflexible, proprietary solutions that have limited their ability to update and improve machine applications at the Edge efficiently. Nerve Blue is a radically open software platform that enables machine builders and plant operators to manage software running on Supermicro devices remotely from the cloud. This empowers businesses to improve machine or plant performance and reduce the cost and complexity of industrial automation. 1 Introducing Nerve Blue on Supermicro Hardware 3 Nerve-Qualified Supermicro Devices 4 Solution Overview 6 Conclusion 7 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to- end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. SYS-E100-9AP-IA SYS-1019D-FHN13TP The Challenges Manufacturers Face Today, manufacturers must adapt to a changing technical landscape, where metrics for equipment performance and efficiency can provide insights that improve the bottom line and provide sustainability. If you are facing one or more of the following challenges, Nerve Blue on Supermicro edge devices will change the way you operate: \u2022 Maintaining software on devices at the Edge is time-consuming and costly \u2022 No consistent, global overview of the software installed on your entire fleet of edge devices \u2022 Proprietary solutions are constraining the use of best-in-class software from independent vendors \u2022 Installing or replacing edge devices requires intensive on-site work \u2022 Updating and upgrading software becomes more complex as your systems grow \u2022 Migrating legacy software from end-of-lifecycle hardware is complicated and costly Introducing Edge Computing Edge computing devices provide decentralized computational capacity on the shop floor, where machine data is generated. In a smart factory\u2019s edge computing architecture, cloud services are still available for consolidating large amounts of data, however, servers can be expensive to operate, and issues around latency and security can arise. Edge computing offers a local alternative where machine data is collected, stored, and analyzed at the source. The data is therefore available in real-time, and it is actionable, i.e., available for immediate use for operating the plant, optimizing processes, or preventing accidents. Edge devices can select the data needed for taking immediate actions. Once the operation has concluded, the edge device can discard data that is no longer needed or pass some or all of it on for storage and further analysis in the cloud. Figure 1 - Edge Applications to Cloud Management 3 Introducing Nerve Blue on Supermicro Hardware Nerve Blue is a highly flexible edge computing platform that runs on Supermicro edge hardware. Its open architecture provides the infrastructure needed to run and remotely manage software on the shop floor and deliver production data securely to the cloud. System information and software management features are available via an intuitive user interface accessible at the edge or in the cloud. Nerve Blue is specifically designed for industrial environments. In a typical application scenario, hundreds of Supermicro devices running Nerve Blue are located on machines in production facilities worldwide. Nerve Blue enables local connection to the various sensors and IOs on your machines and remote connection to the central Nerve Management System, which provides an overview of your entire fleet of devices and enables you to manage them. Nerve Blue provides a uniquely open platform for software applications. It offers you the flexibility to run Docker containers, Virtual Machines, and IEC 61131-3 PLC applications parallel to one device. Typical applications include Windows Virtual Machines that run HMI or SCADA applications, Docker containers running predictive maintenance code, or 61131-3 applications connected to fieldbus devices or control machines. Beyond this, Nerve Blue also provides a suite of Data Services that enable you to connect, collect, store and visualize data at the edge and in the cloud. SERVERS FOR NERVE BLUE SYS-1019D-FHN13TP SYS-E100-9AP-IA SYS-5029C-TN2 Supermicro servers validated and qualified with Nerve Blue Figure 2 - Machines Connected Worldwide to a central HQ 4 Nerve-Qualified Supermicro Devices Edge Device Processor RAM SSD/HDD SuperServer 1019D-16C-FHN13TP Intel Xeon D-2183IT 32 GB 2x 256GB SuperServer 5029C-T Intel Core i3-8100 16 GB HDD 2x 1TB SuperServer E100-9AP-IA Intel Atom x5-E3940 8 GB HDD 2x 1TB Why Supermicro Edge Devices? Supermicro Fanless Edge devices such as the SuperServer SYS-E100-9AP-IA are the ideal solution to address the demands of Industrial applications. The E100-9AP-IA provides legacy connectivity such as COM ports for RS-232/422/485 interfaces to bring management capability to existing manufacturing equipment. Easily DIN rail mounted within the equipment or remotely for convenience of installation, this fanless system is built to withstand the environmental conditions found in manufacturing facilities. With connectivity being an essential requirement for Nerve Node functionality, this system provides two Gigabit Ethernet ports and an expansion slot to add additional Ethernet and many other connectivity options for add on modules. The fanless system brings management and control capabilities to the equipment. The SYS-1019D-FHN13TP provides the compute functionality for the Nerve Management System, tying in all of the devices throughout a manufacturing facility. Based on the Intel Xeon-D SoC (System on Chip), the 1019D series of products offer superior performance in a long availability platform. With up to 16 CPU cores per device, the 1019D can serve as the node device for many individual systems or machines and run the management system for those devices. With 13 Ethernet connections and expansion capabilities to add, even more, plant operators can manage their entire facility or functional branches of their process with a single device, saving equipment cost and management effort. Another aspect of the connected factory is the storage of the data generated by the systems and sensors. To help manage this, TTtech utilizes the Supermicro SYS-5029C-TN2. This mini-tower system supports four hot swap, front-loading 3.5 inch storage bays. With support for Intel Core i9 down to an Intel Core i3, this system provides the storage required in connected factory applications and offers a high level of computing capability to perform operations on that data or offload other critical tasks in the factory. These products from Supermicro are part of the Embedded product lineup, allowing operators to choose a system with the confidence that it has the required features and will be available and supported for long life and availability. Benefits of Using Nerve Blue on Supermicro Edge Devices Nerve Blue offers a unique approach to edge software management, with features that can be combined with Supermicro edge devices to address real-world use cases found on the manufacturing shop floor: \u2022 Ease of use: Nerve Blue\u2019s software management workflow provides an optimal balance between IT administrators and the non-IT personnel on the shop floor. Software configuration parameters are set by IT administrators and encapsulated before deployment to reduce complexity for shop floor staff. The intuitive user interface then makes software deployment easy and minimizes the chance of user error. \u2022 Open ecosystem: Nerve Blue places no restrictions on which software can be hosted on your Supermicro edge device. Existing legacy applications can be hosted alongside newly developed solutions, and software can be sourced from automation specialists, 3rd party developers, or in-house. \u2022 Variety of application types: Nerve Blue supports a unique range of software formats. Applications can be hosted not only as Docker containers but also within Windows or Linux virtual machines (VMs). In addition, real-time applications 5 are supported via an integrated soft PLC (CODESYS). This allows the hosting of 61131-3 compliant, industrial real-time applications. \u2022 Open interfaces: Nerve Blue deeply integrates open-source software. The Hypervisor, Operating System, database, and visualization services are all open and standards based. Open APIs are provided for integration into your continuous integration (CI) / continuous development (CD) pipeline. \u2022 Comprehensive system overview: Nerve Blue offers IT-style monitoring and logging for industrial software. Pre- configured dashboards can be used to view centrally logged data from your entire fleet of devices, providing a complete system status overview. \u2022 Offline operation: Nerve Blue enables all operations also to be carried out locally. As mandated by many shop floor use cases, the system features are fully available via a local user interface if there is no connection to the cloud. Edge devices can operate autonomously for extended periods of time before reconnecting to the Nerve Management System. \u2022 Consolidation of devices: Nerve Blue reduces the number of devices needed on the shop floor. Several virtual machines and containers can be hosted on one Supermicro device when running Nerve Blue. Consolidating so many functions on one piece of hardware reduces hardware costs, required space, and system complexity. Solution Overview Nerve has two main elements: the centralized Nerve Management System and the Nerve Node software installed on each Supermicro device. Figure 3 - Nerve Main Elements 6 Figure 4 - Nerve Blue Functional Descriptions \u2022Nerve Node software is installed on an edge device. The system is Linux based with a User Space that makes use of a real-time hypervisor and Docker container support. In addition, Nerve Node software contains all services for communication with the Management System, remote access, logging, monitoring and patching. Nerve Node \u2022The Nerve Management System is an on-premise or cloud-based software for central management of connected nodes. It enables users to update Nerve Node software and deploy workloads, as well as offering remote connection to nodes for device monitoring and central logging. Nerve Management System \u2022The User Space is the place where all user applications (known as workloads) can be installed and run on nodes. Workloads can be Docker containers, Virtual Machines or CODESYS 61131-3 Soft PLC applications. User Space \u2022The Workload Repository holds the workload images and configurations that are available to deploy to nodes. Here, users can define settings and parameters for each workload. It also supports versioning of workloads for application updates Workload Repository \u2022Data Services are a collection of features supporting users with data connectivity, storage and visualization. A multi-protocol data gateway is available on each node. Data storage and visualization are available on each node and in the Management System. The integrated Soft PLC can also be used to connect to fieldbus devices. Nerve Blue comes with an SDK to easily create Python applications that communicate with the Data Services Data Services (Local and Central) \u2022Nerve Blue integrates a CODESYS soft PLC supporting PROFINET, EtherCAT and Modbus protocols at cycle times down to 1ms. Using the Soft PLC users can collect data and pre-process in IEC 61131-3 languages or run control applications for machines Soft PLC \u2022Management Services comprise all features that enable users to remotely manage their fleet of devices in the field. Management Services include device monitoring, centralized logging, remote screen viewing and remote network access, which offers similar functionality to an integrated VPN Management Services \u2022Node Services are installed on Nerve Nodes and act as the counterpart to the Management Services. Node Services include the software components necessary to enable remote monitoring, logging, and remote access from the central management system. Node Services also provide the local graphical management interface (Local UI) Node Services \u2022 The Nerve Management System can be controlled via an API to enable automation of repetitive tasks or integration in a CI/CD pipeline. Nerve Management System API \u2022 The Nerve Management System User Interface provides an intuitive overview of all central Management System functions Nerve Management System UI \u2022 The Local User Interface provides manageability of individual nodes in case access to the central Management System is not available. Local UI 7 Conclusion Running Nerve Blue on Supermicro edge devices helps to solve several challenges faced by manufacturers today. By enabling remote management of software installed on Supermicro devices, Nerve Blue allows users to reduce response times and maintenance costs. Installation of new devices and software can also be achieved with just the click of a button with Nerve Blue. Nerve Blue allows entire legacy software environments to be easily migrated from end-of-lifecycle hardware to a Supermicro edge device. Finally, Nerve Blue provides an open platform for running best-in-class software from independent vendors, with a global overview of the software installed on your entire fleet of Supermicro edge devices. Get started with Nerve on Supermicro today Nerve Blue is a proven in-use solution that fits perfectly with your Supermicro edge device. Start your free 30-day trial of Nerve Blue now. Go to to begin your journey with the Nerve Blue online demo or contact trynerve@tttech-industrial.com. TTTECH INDUSTRIAL TTTech Industrial develops innovative computing and connectivity solutions that help customers to modernize automation systems and become IoT leaders in their field. The company integrates open, standard technologies to offer flexible platforms for connecting, controlling and managing machines. TTTech Industrial operates under the umbrella of the TTTech Group, a technology leader in real-time networking and safety controls, with cross-industry experience from more than 20 years of operation. The company is based in Vienna, Austria - ideally situated in Europe\u2019s manufacturing heartland.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "94e5904d-7b0a-4bfd-ad0d-a806f83cc08d": {"__data__": {"id_": "94e5904d-7b0a-4bfd-ad0d-a806f83cc08d", "embedding": null, "metadata": {"file_name": "Solution-Brief_ASOCS.pdf", "publication_date": "January 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 PRIVATE 5G NETWORK SOLUTIONS FOR INDUSTRY 4.0 CYRUS 2.0 from ASOCS on Supermicro Servers Built for 5G Solutions Industry 4.0, the 4th industrial revolution, is driving technology investments and innovation in robots, drones, connected production lines, and process automation. Industrial IoT (IIoT) devices collect vast amounts of data that need to be processed quickly and securely \u2013 hence locally at the Edge. Industrial enterprises worldwide are adopting smart manufacturing and automation technologies as they prepare their manufacturing facilities for Industry 4.0. As part of this revolution, the manufacturing industry is breaking away from the traditional model of efficiency through automation, specialization, and scale and entering the world of big data. Every object in the factory will communicate with the others. Decisions and directions for assembly will be made at the product level and adapted to current conditions. 1 Industry 4.0 and 5G 2 CYRUS 2.0 2 About ASOCS 2 The ASOCS/Supermicro Solution 3 Conclusion 4 Supermicro is a global leader in high performance, green computing server technology and innovation. We provide our global customers with application-optimized servers and workstations customized with blade, storage, and GPU solutions. Our products offer proven reliability, superior design, and one of the industry\u2019s broadest array of product configurations, to fit all computational need. 2 Industry 4.0 and 5G Such automation and flexibility require high-performance wireless communication between machines, people, and even the walls and floors of the facilities themselves. Until recently, achieving the required level of connectivity was not possible. The number of devices that need to be connected, the amount of data that needs to be transferred, the reliability, latency, and the security requirements - all of these could not be achieved with previous technologies. That is where 5G comes in. 5G is seen by many in the manufacturing industry as a necessary driver for Industry 4.0 and the automation of manufacturing processes. Currently, connecting machines and devices on the factory floor requires specialized wireless equipment that fails to provide the reliability and security levels needed for such mission-critical applications. Welcome, New Spectrum! One of the key aspects of 5G is the fact that an operator is no longer a prerequisite for creating a local cellular network. There has been a worldwide move to allocate specific radio frequencies for public use without licensing. This means that with the proper equipment in place, you can set up your own private network that you fully control, without the need to rely on an external provider or share the network with others. ASOCS, an Israel-based software company, is a leader in cellular clouds and 5G private networks, enabling mobile connectivity at fiber-like speeds and bandwidth. The company\u2019s unique approach to cellular access is based on fully virtualizing cellular access, and utilizing the Open Radio Access Network (O-RAN) specifications, making its solution ideal for system integrators who wish to incorporate the cellular processing layer as part of their overall edge service offering. CYRUS 2.0 The CYRUS 2.0 solution is a single software stack for 5G cellular processing. CYRUS is fully virtualized across all layers; therefore, it can run on any standard server. It connects to radios based on the O-RAN 7.2 fronthaul interface, enabling multiple use cases. The CYRUS solution supports 4G technologies in the same architecture. While 4G (LTE) is less applicable to the industrial use case, in specific markets such as the USA, an interim use of 4G over the CBRS band may become a transitional step on the way to a full 5G SA network. In such a case, CYRUS can guarantee full backward and forward compatibility within this band without any forklifting. The virtual base station software runs as a virtual function on a standard IT hardware. Having the 5G access solution run as virtualized software, disaggregated from the radio units, ensures full flexibility and upgradability in any type of private network scenario. The CYRUS solution for 5G private networks can support the facility\u2019s full range of IoT devices while providing unlimited bandwidth to process and transfer massive amounts of data from these connected devices. Utilizing standard servers, CYRUS CYRUS 2.0 FOR PRIVATE NETWORKS 3 2.0 is managed like any other IT element. It enables industrial enterprises to easily implement 5G private networks with Time Sensitive Networking (TSN), high network reliability, low latency, and speed, making it ideal for innovative IIoT applications. About ASOCS ASOCS is disrupting the traditional RAN market with a cloud-native solution, delivering a 4G and 5G mobile network solution in a single software stack. Our cloud-native mobile connectivity solutions are delivered on commercial off-the-shelf IT hardware and O-RAN compliant radios, which allow industrial enterprises and operators alike to benefit from new levels of performance and reliability in Wide Area Networks or localized private networks. Privately-held ASOCS serves industrial enterprises, operators, tower companies and enterprises in retail, real estate, corporate offices, hospitality, hospitals, sports and entertainment markets, and has offices in Israel and the United States. The ASOCS/Supermicro Solution The CYRUS 2.0 system enables the industrial user to connect fixed or mobile devices to a centralized compute center via a 5G wireless system. As described in the drawing below, the hardware elements are based on two Supermicro 1019D-16C- FHN13TP servers, two switches, and standardized radios (O- RAN-RU). All the RAN and Core elements are implemented as software running on top of a virtualization layer. BENEFITS FOR INDUSTRY 4.0 The network you need High performance, high speed, high device density, low latency, elevated security, traffic prioritization, and network analytics \u2013 the infrastructure needed for the factory of the future. Complete flexibility ASOCS supports an Infrastructure-as-a-service business model, so industrial enterprises can enjoy complete control, flexibility and scalability. Tailored and prioritized cellular access ensure reliable cellular service specifically tailored to their specific needs and requirements. Wi-Fi-like installation \u2013 It\u2019s that easy Install a private cellular network as easily as other organizational IT systems - upgrade, scale up, and make changes as needed. /ASOCS 5G SOLUTION 4 Supermicro 1019D-16C-FHN13TP The Supermicro 1019D-16C-FHN13TP is a short-depth 1U rackmount server optimized for edge computing applications. It supports an Intel Xeon D D-2183IT 16-core processor and two PCI-E expansion cards, such as network accelerators and AI inferencing cards. 1019D-16C-FHN13TP Edge Server Benefits of the Supermicro/ASOCS solution \u2022 Utilizes Supermicro 1019D-16C-FHN13TP servers and white box switches \u2022 Radios connect via standard Ethernet cable (CatX) which delivers the power as well (PoE) \u2022 Radios are available in multiple cellular bandwidths (depending on the spectrum available in each country) \u2022 Easy-to-use management tool for site configuration, performance monitoring, fault management, and life cycle management. The network can also be managed via 3rd party management tools used in the factory Supermicro/ASOCS Private 5G Solution Conclusion Public and private 5G-based infrastructure is becoming more critical for both enterprise and Industry 4.0 evolution as it enables a new breed of applications that require high performance and low latency. Available now, the ASOCS CYRUS 2.0 platform combined with Supermicro\u2019s servers built for 5G provide a best-in-class next-generation private 5G wireless solution, enabling a clear path for customers to deliver their low-latency, secure IoT solutions.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "47fdbd38-cbb3-4447-89f9-7e33afddee38": {"__data__": {"id_": "47fdbd38-cbb3-4447-89f9-7e33afddee38", "embedding": null, "metadata": {"file_name": "Solution-Brief_SMCI-Intc-CloudGaming.pdf", "publication_date": "August 2022", "referenced_websites": ["https://www.supermicro.com/en/products/rackmount", "https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/data-center-gpu/flex-", "https://www.supermicro.com/en/accelerators/intel"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Cloud gaming is changing how people play computer games by directly streaming games onto players\u2019 devices without game download or software purchase. New services are emerging to address novel needs, such as live, low latency, video streaming of games to millions of online spectators. Cloud gaming brings new opportunities to service providers and game developers. Cloud gaming services increase value to players and game developers. Players can immediately access more sophisticated games using computers, mobile, Android devices, and proprietary consoles without paying for the latest hardware. In addition, game developers could reach more potential players on cloud platforms by easily supporting more devices. With advancements and democratization in networking, visual cloud, and artificial intelligence technologies, the gaming market has a CAGR of 13% 1 from 2021 to 2028. Supermicro offers all the system components for cloud service providers to build green, cost-effective, and profitable cloud gaming infrastructure. This paper describes the requirements, systems, and architecture to build cloud gaming infrastructure. 1 Cloud Gaming Market 2 Cloud Gaming Economics 2 Cloud Gaming Requirements, Systems Architecture 3 Supermicro Solutions for Cloud Gaming 4 Server Specifications 5 Intel Data Center GPU, Flex Series 6 Remote Management and Security 6 Call for Actions 6 References 6 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs and enables us to build and deliver application-optimized solutions based upon your requirements. 2 Cloud Gaming Market Cloud Gaming is a fast-growing technology segment with rapid technology changes, adoption, and increasing business opportunities for service providers and game publishers. Cloud gaming infrastructure serves a myriad of gaming devices - desktops, laptops, mobile tablets, mobile phones, and dedicated game consoles. Soon, virtual reality (VR), augmented reality (AR), and mixed reality (MR) will also be supported by the cloud gaming infrastructure, driven by technological advancements in data center servers and human-computer interfaces in client devices. A particular fast-growing segment of cloud gaming is Multiplayer Online Games (MMOG), which account for 28% of the global market share in 20192. Centralized servers in the cloud are needed to coordinate MMOG. Another significant segment is mobile games, which account for 52% of the gaming3 market. Cloud Gaming Economics CUSTOMERS & REVENUE NON-RECURRING COSTS OPERATING COSTS Streaming quality, Number of streams supported, Low Latency Systems with the latest technologies Hosting, network access Number of games, New games Latest accelerators Licenses, royalty fees X12 WITH INTEL DATA CENTER GPU FLEX SERIES SYS-620C-TN12R 2U Rackmount Dual Intel CPU Up to 6 GPUs SYS-210GP-DNR 2U, 2 server nodes Single Intel CPU / node Up to 3 GPUs per node SYS-210GT-HNTF 2U, 4 server nodes Single Intel CPU Up to 1 GPU per node SYS-220BT-DNTR 2U, 2 server nodes Dual Intel CPU Up to 4 GPUs per node SYS-420GP-TNR 4U Rackmount Dual Intel CPU up to 10 GPUs SBE-610P Series 6U, 10 Blade servers Single Intel CPU / blade Up to 2 x GPU per blade orting Intel Xe-HPG accators. Mobile - Android 44% Mobile - Others 8% PC - Windows 15% PC - Others 5% Console 28% 2021 Global Games Market $180B 3 Cloud Gaming Requirements \u2022 Worldwide Distributed Internet Infrastructure: Multiple data centers with central gaming platforms that serve numerous games and extensive caching and CDN infrastructure to support low latency content delivery to game users. \u2022 Reliable and manageable systems: Systems must be easily manageable and run reliably. \u2022 Systems options to support multiple architectures: Cloud gaming infrastructure has the following key software and systems: game platform services supporting game streaming, game servers, analytics, and AI. AIs automatically generate images and respond to game plays. \u2022 Support for latest Accelerators: GPU accelerators are crucial to delivering cloud gaming, video streaming, virtual desktop, and AI services. GPU Accelerators can efficiently encode and decode a high number of real- time video streams in high frame rates, using the royalty-free AV1 encoding, which also produces smaller files. By encoding video & graphics content in mainstream codecs, including the latest royalty-free AV1, to lower the bitstream size, network streaming latency and cost can be reduced. \u2022 Scalable architectures: Growing demand for new games drives the development of cloud gaming infrastructure, supporting high-speed, latest spine/leave Ethernet network architecture with scalable bandwidth. \u2022 Software platforms include Linux, Windows, virtualization, and containerization: Cloud gaming servers run on Linux or Windows, supporting CPU & GPU virtualization, containerization & orchestration. \u2022 Cloud Gaming Software Infrastructure: Cloud gaming providers develop and maintain their own gaming infrastructure. \u2022 Games and associated virtual goods are key to revenue generation and customer retention. Games are delivered to mobile, computer, and consoles. \u2022 User Experience: Low latency, responsiveness, high frame rates, and high visual fidelity graphics. Multiplayer gaming demands real-time response rates and supports multiple game engines. Cloud Gaming Systems Architecture \u2022 Gaming Platform in Cloud Data Center delivers game engines, updates to games, and analytics. \u2022 Edge Computing delivers ultra-low latency streaming, high performance rendering, and data collection to improve the platform QoS. \u2022 Clients deliver the gaming experience to each person. A client can be an Android device, a computer, or a console. 4 Supermicro Solutions for Cloud Gaming Working with Intel, Supermicro has identified multiple server solutions that offer the best tradeoffs to provide cloud gaming architecture. These systems support the latest Intel Data Center GPU Flex series accelerators. There are many support choices for SATA and NVMe storage, and support for high-speed networking up from 1 gigabit/s to 200 gigabit/s ethernet networks. Furthermore, these systems have optional TPM 2.0 security and Root-of-Trust hardware security features. With built-in out-of- band management, systems administrators can easily manage these servers with standard IPMI or Redfish interfaces. Support for Ubuntu Linux, Red Hat Linux, open-source Linux, and Windows Servers are available for these servers. To address the cloud gaming infrastructure, Supermicro offers the following: Requirements Supermicro Offering Reliable and manageable systems \u2022 Supermicro systems have proven reliability with built-in redundancies, including power, cooling \u2022 Systems come standard with remote manageability, support for IPMI, and Redfish v1.8 \u2022 Support for TPM 2.0 and Root-of-trust security Systems options to support multiple architectures \u2022 Choice of recommended systems to build the cloud gaming infrastructure, offering tradeoff for support for the maximum number of accelerators to rack density to cost-effectiveness \u2022 Choice of other platforms to run analytics and AI \u2022 Selection of different platforms to support database Support for latest accelerators \u2022 Support Intel Data Center GPU Flex Series Accelerators. Scalable architectures \u2022 Extensive support for latest PCIe GEN4 technologies that support the fastest I/O \u2022 Extensive support for networking from 1 gigabit/s to 200 gigabit/s, with support for a large number of network connectivity \u2022 Support up to a maximum of 10 Intel Data Center GPU Flex Series cards in SYS 420GP TNR \u2022 Supermicro offers support max number of servers in a single rack appropriate to the power and cooling available at the cloud gaming providers \u2022 Supermicro can scale the number of racks to support one or more data centers \u2022 Supermicro offers networking technologies up to 400 gigabit/s to support full scale spine/leave network architecture Software Platforms for virtualization and containerization \u2022 Supermicro systems are certified to support the Linux and Windows environment, as well as support for virtualization and containerization Cloud gaming software infrastructure and Games \u2022 Supermicro works with Intel, which is growing the ecosystem for cloud gaming software infrastructures and game availability CPU / GPU Ratio \u2022 Gameplay and Content Delivery Networks require CPU processing \u2022 Video transcoding, encoding, and graphics display use GPU 5 Server Specifications Supermicro Server Form Factor, Power CPU, PCIe Intel Data Center GPU Flex Series 4U GPU SuperServer SYS-420GP-TNR 4U, Redundant power Dual 3rd Gen Intel Xeon Scalable, 270W, 10 x PCIe Gen 4 x16 slots 10 x Flex Series 140 or 170 2U 2-Node SYS-210GP-DNR 2U, 2-node, each node 1U Shared redundant power Per node: Single 3rd Gen Intel Xeon Scalable processor, 270W 3 x PCIe Gen 4 x16 slots per node 3 x Flex Series 140 or 170 (per node) Total: 6 x GPUs per system 2U CloudDC SYS-620C-TN12R 2U, single or redundant power option Dual 3rd Gen Intel Xeon Scalable processor, 270W 4 x PCIe Gen 4 x16 slots 6 x Flex Series 140 or 4 x Flex Series 170 2U 4-Node GrandTwin SYS-210GT-HNTF 2U, 4-node, redundant power Per node: Single 3rd Gen Intel Xeon Scalable processor, 2 x PCIe Gen 4 x16 slots 2 x Flex Series 140 (per node) Total: 8 x Flex Series 140 per system 2U 2-Node BigTwin SYS-220BT-DNTR 2U, 2-node, Redundant power Per node: Dual 3rd Gen Intel Xeon Scalable processor 4 x PCIe Gen 4 x16 slots 2 x Flex Series 140 or 170 (per node) Total: 4 x GPUs per system 6U Blade Server SBE-610P Series 2U, single or redundant power option Per blade: Single 3rd Gen Intel Xeon Scalable processor 2 x PCIe Gen 4 x16 slots 2 x Flex Series 140 or 170 (per blade) Total: 20 x GPUs per system SYS-620C-TN12R SYS-420GP-TNR High Density SBE-610P Series Cloud Data Center SYS-210GP-DNR SYS-210GT-HNTF SYS-220BT-DNTR Edge Computing High Density 6 Intel Data Center GPU Flex Series Specification Intel has significantly innovated to develop 2 data center GPU accelerators to provide the best operations and performance for Cloud Gaming and Virtual Desktop Infrastructure. Also, Intel has added support for the royalty-free AV1 codec. The AV1 codec has been demonstrated to provide lower bandwidth requirements to transmit higher quality streaming graphics. Being royalty- free versus HVEC codecs, the use of Intel Data Center GPUs significantly reduces costs for the Cloud Gaming providers. Intel Data Center GPU Flex Series Flex Series 140 Flex Series 170 Memory w/ ECC 12GB, 1750 GT/s 16GB, 2250GT/s Fixed function Media units 4 28 transcode streams H.265 1080p60 1:1 2 14 transcode streams H.265 1080p60 1:1 AV1 Encode/Decode Implemented in Hardware Systolic Arrays (AI Inference) 1x Systolic Array 2.5x Systolic Arrays Long Life Support 5 years, 80% active at base frequency, 20% idle 5 years, 80% active at base frequency, 20% idle Operating Systems Ubuntu Linux, Debian Linux, RHEL, Windows Server 2019, 2022 Remote Management and Security Supermicro systems provide out-of-band and in-band monitoring. Using out-of-band IPMI and Redfish management, data center systems administrators efficiently manage the health and operation of each server in the clusters. The servers also come with optional TPM 2.0 and Root of Trust security features. Conclusion Supermicro systems with Intel Data Center GPU Flex Series offer comprehensive scalability options. Please contact your Supermicro sales representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "cf3486bf-2196-4496-ac4a-8fb56c902aa3": {"__data__": {"id_": "cf3486bf-2196-4496-ac4a-8fb56c902aa3", "embedding": null, "metadata": {"file_name": "Solution-Brief_Qumulo_Public.pdf", "publication_date": "August 2022", "referenced_websites": ["https://www.supermicro.com/en/solutions/qumulo.", "www.qumulo.com", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 A+ Single AMD EPYC 7003/7002 Series All-Flash NVMe Platform - AS -1114S-WN10RT Supermicro and Qumulo deliver a high-performance, distributed file system to meet the performance and capacity demands that public sector organizations need to store, manage and access sensitive file data on-prem and in the cloud. Qumulo\u2019s file data platform provides many built-in efficiencies to help organizations ease scaling complexities across the data center and cloud environments, enable migration to the cloud, reduce capital and operational costs, and proactively monitor and plan for future capacity and performance requirements. Qumulo supports public sector organizations across multiple use cases including, but not limited to: - Video surveillance and security - High-performance computing (HPC) 1 Qumulo File Data Platform 2 Massive Scalability 3 Scales Across On-Prem, Hybrid, Multi-Cloud Environments 3 Real-Time Analytics for Visibility and Control 3 Data Security and Protection 4 Conclusion 4 2 - Research computing - Video editing and production - Life Sciences Supermicro\u2019s Qumulo file storage solution easily integrates into existing environments supporting multiple protocols, including SMB, NFS, FTP, and REST. In addition, the file data software is designed for maximum performance running on Supermicro\u2019s All-NVMe platform and for flexibility to enable organizations to run one file system that can scale across on-prem, hybrid, and multi-cloud environments at a petabyte scale. Qumulo File Data Platform Qumulo\u2019s file data platform is designed with flexibility, supporting Supermicro's high-performant, economical platform. Supermicro , the leading innovator in high-performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. -friendly solutions available on the market. Figure 1 -Qumulo File Data Platform 3 Massive Scalability Qumulo\u2019s distributed file system is designed to scale to billions of files and store all file sizes efficiently. The scalable block store offers unprecedented scalability, optimized performance, and data protection. Qumulo\u2019s file data platform serves petabytes of data, millions of operations, and thousands of users. Qumulo\u2019s file data system scales in performance to meet the demands of the most challenging workloads. One file data lake in the cloud supports different workflows and applications without compromising manageability, flexibility, or performance. Users can scale capacity and performance up and down on the cloud to match workflows. Organizations can scale across their data center and the cloud without impacting performance. Qumulo linearly scales and automatically rebalances when additional nodes are added. The rebuild times get faster the more extensive the cluster. A single Supermicro 100 node cluster provides 15+PB of All-NVMe storage. Scales Across On-Prem, Hybrid, and Multi-Cloud Environments Qumulo\u2019s file data platform delivers a single file solution using the same software, whether your data is in the cloud, on-prem, or scaling across both. Users can burst compute in AWS or Google Cloud and shift primary workloads to the cloud without needing to rewrite the application, although studies have shown that this may not be economical. With continuous replication, organizations can quickly transfer data from an on-prem cluster to a cloud cluster to perform computations and then transfer the results back to the on-prem storage. In addition, Qumulo Shift for Amazon S3 is a feature that enables users to copy data to the Amazon S3 native format for easy access to AWS services, if the required services are not available in an on-prem data center. Supermicro All-NVMe Server model AS -1114S-WN10RT Form Factor 1U server Configurations 30TB, 76TB, 153TB per node CPU AMD EPYC 24 core 2.8 GHz Network Port 4 x 100GbE MGMT Port Base-T (RJ45) Memory 128GB Table 1 \u2013 A cluster requires a minimum of 4 nodes 4 Real-Time Analytics for Visibility and Control Qumulo\u2019s file data platform is designed for data intelligence, allowing users to predict usage trends and better manage capacity. With Qumulo\u2019s integrated, real-time analytics, storage administrators can easily monitor performance, including throughput, IOPS, and latency. Real-time analytics give administrators the insights they need to manage issues proactively, optimize workflows, and make well-informed planning decisions for the future. Data Security and Protection Qumulo\u2019s file data platform provides encryption for data in flight with SMBv3 and TCP secured by TLS and provides software- based encryption at rest via an AES-256 bit implementation. In addition, Qumulo provides FIPS 140-2 Level 1 encryption for data at rest. Integrated data protection is included via snapshot replication for simple, cost-effective backups. Qumulo provides the same file system and separate namespaces for active and backed-up data, no additional applications are required. Conclusion Supermicro and Qumulo Software-Defined file storage solution bundle provides data security and protection and unbeatable performance, and is highly and easily scalable across private, hybrid, and public cloud. It\u2019s an ideal data management platform for public sectors. To learn more, please visit: ABOUT QUMULO Qumulo is the leading file data platform for multi-cloud environments, providing unrivaled freedom, control and real-time visibility for file data at massive scale. Fortune 500 companies, major film studios, and the largest research facilities in the world trust Qumulo to help them innovate with their mission-critical digital files. The Qumulo experience makes file data management simple with continuous new features, a single solution for all workloads, and access to customer success experts on your schedule. SOLUTION BENEFITS \u2022 Simple Management \u2013 One single, easy-to-use file data management and storage system with a modern user interface that provides real visibility with integrated analytics. \u2022 Efficiency \u2013 100% of user-provisioned capacity is available for file storage, in contrast to the 70% to 80% usable capacity of legacy NAS. \u2022 Enhanced performance with All-NVMe \u2013 Tuned to optimize performance and capacity on Supermicro\u2018s All-NVMe platform \u2022 Real Visibility with Real-Time Analytics \u2013 Monitor performance, capacity, and usage of the entire file system with a real-time view at the directory/file level to simplify resource management and reduce costs. \u2022 All Inclusive and Transferable License \u2013 Qumulo\u2019s file software is a single subscription license with all functionality, future updates, and enhancements included. It is completely transferable to the cloud or to new hardware. \u2022 Customer Success \u2013 Customers are in direct contact with Qumulo Customer Success Managers who are experienced enterprise storage professionals or Qumulo file system engineers.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "f062cb4e-0faa-45f6-b677-456d8297ff05": {"__data__": {"id_": "f062cb4e-0faa-45f6-b677-456d8297ff05", "embedding": null, "metadata": {"file_name": "Solution_Brief_uCPE.pdf", "publication_date": null, "referenced_websites": ["https://www.supermicro.com/products/system/1U/1019/SYS-1019D-16C-FHN13TP.cfm", "www.supermicro.com", "www.intel.com/selectsolutions", "https://www.supermicro.com/", "www.intel.com/xeond", "https://www.supermicro.", "https://www.advaoptical.com/en/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro uCPE Solutions Supermicro has expanded its lineup of Intel Select Solutions for uCPE. The SuperServer 5019D-FN8TP, E300-9D-8CN8TP, and E300-9D are all verified Intel Select Solutions for uCPE in the base configuration. The SuperServer 1019D-16C-FHN13TP is verified in the plus configuration. Universal customer premises equipment (uCPE) is an emerging category of network functions virtualization (NVF)-based edge computing and service provisioning systems. This new generation of systems provides network platform suppliers, systems integrators, and software vendors the ability to quickly deliver managed services using software- driven and virtual network functions (VNFs). This, in turn, enables service agility for customers in the fields of software-defined-startup, telecom operators, service providers, or enterprise infrastructure. Now, with Supermicro\u2019s verified Intel Select Solutions for uCPE in both base and plus configurations, service providers are able to quickly and efficiently deploy various NFV applications with improved security and ease of operation. This solution eliminates the need for proprietary purpose-built servers that are hard to manage and maintain. Featuring tested and optimized configurations, Supermicro\u2019s solutions enable end users to save time, effort, and expense evaluating hardware and software options. Supermicro\u2019s verified Intel Select Solutions for uCPE will help end users simplify design choices by bundling hardware and software components for optimal performance. Whether using an Ubuntu OS or a neutral Orchestrator such as ADVA, Supermicro\u2019s uCPE products benefit all certified models. Ubuntu ADVA Base Confguration (5019D-FN8TP, E300-9D-8CN8TP, and E300-9D) * * Plus Confguration (1019D-16C-FHN13TP plus Intel QuickAssist Adapter 8970 Card) * * * certified/compatible with Ubuntu or ADVA (Ensemble Connector) 1 2 Easing Adoption of SD-WAN 4 Intel Select Solution for uCPE HW Configuration 5 Supermicro uCPE Solutions (Base) 6 Supermicro uCPE Solutions (Plus) 7 ADVA Ensemble Connector 7 Summary uCPE SOLUTIONS Supermicro uCPE Solutions 2 Figure 1. Intel Select Solutions are verified hardware and software stacks that are optimized for specific software workloads and are designed to be easy to deploy. Easing Adoption of SD-WAN Current generation network equipment is based on purpose-built proprietary hardware. These appliances are single function boxes that are complex to maintain as well as slow and expensive to upgrade. They inhibit network platform suppliers from dynamically offering new network services and functions. Adapting Supermicro\u2019s uCPE can help network service providers take advantage of technology innovation in software-defined networking (SDN) and NFV, which are complementary but increasingly co-dependent if the benefits of software-defined networking are to be fully realized. A network service provider with Supermicro\u2019s uCPE could run multiple VNFs\u2014such as a router, VPN, and a firewall\u2014on a general- purpose server based on end-user demand. They have the flexibility to deploy new network functions and services without deploying new hardware servers, allowing significant CAPEX & OPEX reduction as well as increased speed and ease in the deployment of new services. Supermicro\u2019s verified Intel Select Solutions for uCPE are designed and tested to enable easy integration with a variety of VNFs, including SD-WAN (software defined- WAN). SD-WAN has its roots in SDN, which is built on the underlying principle of abstracting the network hardware and transport characteristics from the applications Intel Select Solutions uCPE Plus Configuration SYS-1019D-16C-FHN13TP Intel Select Solutions uCPE Base Configuration SYS-E300-9D-8CN8TP Intel Select Solutions uCPE Base Configuration SYS-5019D-FN8TP Intel Select Solutions uCPE Base Configuration SYS-E300-9D Supermicro uCPE Solutions 3 that use the network. With this innovation, SD-WAN is able to deliver increased network agility and cost reduction compared to traditional WANs. Instead of manually configuring and managing all WAN devices, including those at remote locations, SD-WAN overlay architecture enables you to centrally manage WAN infrastructure through a single interface. A hybrid approach to WAN infrastructure in both MPLS (Multi-Protocol Label Switching) & SD-WAN will increase the variety and complexity of performance issues. The market still has serious challenges to address such as: 1. Is it better to adopt a fully managed SD-WAN or should control be preserved in- house? 2. Is there a middle-ground that alleviates much of the day-to-day burdens without risking availability or data integrity? 3. Will adopting a hybrid approach cause a bottleneck retrieving data from remote network locations back to headquarters? Supermicro\u2019s verified Intel Select Solutions for uCPE address these challenges to adopting SD-WAN by providing an integrated hardware and software platform, with verified performance, to ease decision making and speed deployments. SD-WAN/uCPE Application on Intel Xeon D Processor Platform Figure 2. SD-WAN, already used extensively for enterprise traffic management, can now deploy Intel Xeon D processor-based NFV platforms as branch nodes. FW DHCP Switch SBC Routing DPI IPSEC SD-WAN Controller Corporate Ofce Branch Ofce Control Channel Data Channel Data Channel Branch Ofce Branch Ofce Branch Ofce Branch Ofce Internet LTE MPLS Cloud/ SAS As an Intel Select Solution for uCPE, SMCI\u2019s Platform has been verifed to meet specifc measurements for workload-optimized performance on Intel Xeon D processors. Supermicro uCPE Solutions 4 CPU Plus Intel Xeon D-2177NT processor, 14C @ 1.9 GHz, 105W or higher SKU Memory 64 GB DDR4 @ 2667 MHz, 4x 16 GB (Total of 64 GB) Minimum all four memory channels populated (1 DPC) to achieve 64 GB (i. e., 4x 16 GB RDIMM) NIC 4x 10GbE Integrated Ethernet ports Intel QAT Integrated Intel QAT or Intel QuickAssist Adapter 8970 PCI Express* (PCIe*) add-in card or equivalent Intel C627 Series Chipset Intel QAT-Enabled PCIe* add-in card Storage Intel Solid State Drive Data Center S4500 512 GB 2.5\" Internal SSD (SATA or M.2) Intel Xeon D Processor Family Platform Specifcations Required Recommended Specifcations Required Recommended CPU Base Intel Xeon D-2123IT processor, 4C 2.2 GHz 60W, or higher SKU Memory 16 GB DDR4 2133 MHz, 4 * 4 GB Total of 16 GB Minimum all four memory channels populated (1 DPC) to achieve 16 GB (i.e., 4 * 4 GB RDIMM) NIC 2 x 10 GbE Integrated Ethernet ports Intel QAT Integrated Intel QuickAssist Technology or Intel QuickAssist Adapter 8970 PCIe* add-in card or equivalent third party Intel C62x Series Chipset Intel QAT-Enabled PCIe* add-in card Storage Intel Solid State Drive Data Center S3110 256 GB 2.5\" (SATA or M.2) Intel Xeon D Processor Family Platform INTEL SELECT SOLUTION FOR uCPE HW CONFIGURATION Supermicro uCPE Solutions 5 SuperServer 5019D-FN8TP SuperServer E300-9D SuperServer E300-9D-8CN8TP CPU Base Confguration Intel Xeon D-2146NT processor, 8-Core, 16 Threads with built-in Intel QuickAssist Technology for Crypto/ Compression acceleration Intel Xeon D-2123IT processor, 4-Core, 8 Threads Intel Xeon D-2146NT processor, 8-Core, 16 Threads with built-in Intel QuickAssist Technology for Crypto/Compression acceleration Memory Up to 512GB ECC LRDIMM or up to 256GB ECC/non-ECC RDIMM DDR4 2666MHz in 4 slots Up to 512GB ECC LRDIMM or up to 256GB ECC/non-ECC RDIMM DDR4 2666MHz in 4 slots Up to 512GB ECC LRDIMM or up to 256GB ECC/non-ECC RDIMM DDR4 2666MHz in 4 slots Storage Intel SSD DC S3500 Series in M.2 & S3520 series in 2.5\" for 256 GB or higher Intel SSD DC S3500 Series in M.2 & S3520 series in 2.5\" for 256 GB or higher Intel SSD DC S3500 Series in M.2 & S3520 series in 2.5\" for 256 GB or higher PCIe Expansion 1x M.2 M key for SSD in 2280 1x M.2 B Key for wireless communication card in 2242 1x Mini-PCI-E with mSATA Support 1 PCIe 3.0 x8 slot 1 onboard OCuLink port (or 1 PCI-E 3.0 x4 NVMe), 1 PCI-E 3.0 x8 (LP) open slot 1x M.2 M key for SSD in 2280 1x M.2 B Key for wireless communication card in 2242 1x Mini-PCI-E with mSATA Support 1 PCIe 3.0 x8 slot Network Interface Copper: 4x 1GbE and 2x 10G Based-T ports Fiber: 2x 10G SFP+ ports Copper: 2x 10G Based-T ports Copper: 4x 1GbE and 2x 10G Based-T ports Fiber: 2x 10G SFP+ ports Other I/O Interface 1x dedicated LAN for IPMI 2.0 1x VGA & 2x USB 3.0 1x dedicated LAN IPMI 2.0 1x VGA & 2x USB 3.0 1x dedicated LAN for IPMI 2.0 1x VGA & 2x USB 3.0 Cooling Fan 3x 40x28mm Delta 4-PIN PWM fans 3x 40x28mm 4-PIN PWM Fan 3x 40x28mm 4-PIN PWM Fan PSU 200 W Low-noise AC-DC power supply 120 W Lockable DC Power Adapter 150 W Lockable DC Power Adapter URL products/system/1u/5019/ SYS-5019D-FN8TP.cfm products/system/Mini-ITX/ SYS-E300-9D.cfm products/system/Mini-ITX/ SYS-E300-9D-8CN8TP.cfm uCPE SOLUTIONS Supermicro uCPE Solutions 6 SuperServer 1019D-16C-FHN13TP + Intel QuickAssist Adapter 8970 Card CPU Intel Xeon D-2183IT processor, 16-Core, 32 Threads with Intel QuickAssist Adapter 8970 card for Crypto/Compression application Memory Up to 512GB ECC LRDIMM or up to 256GB ECC/non-ECC RDIMM DDR4 2666MHz in 4 slots URL Plus Confguration Storage Intel SSD DC S3500 Series in M.2 & S4500 series in 2.5\" for 512 GB or higher 1x M.2 M key for SSD in 2280, 1x M.2 B Key for wireless communication card in 2242, 2 PCIe 3.0 x16 slot Network Interface Copper: 9x 1GbE and 2x 10G Based-T ports, Fiber: 2x 10G SFP+ ports Other I/O Interface 1x dedicated LAN for IPMI 2.0, 1x VGA & 2x USB 3.0 Cooling Fan 6x 40x28mm Delta 4-PIN PWM fans PCIe Expansion SD-WAN/uCPE Application on Intel Xeon D Processor Platform DPDK & Intel QAT Figure 3. Testing configuration for certification of the Supermicro uCPE platform with Intel QuickAssist Technology (Intel QAT) uCPE SOLUTIONS Enterprise Branch Node (DUT) Trafc Termination Endpoint Uplink Downlink Bi-Directional Link Host OS/HW OVS/DPDK DPI app Guest OS vDPI (VM) vIPSec (VM) virt io virt io vhost (dpdk) vhost (dpdk) IPSec app virt io virt io vhost (dpdk) vhost (dpdk) OVS/DPDK vhost (dpdk) vhost (dpdk) vhost i/f vhost i/f phys (dpdk) phys (dpdk) Host OS/HW phys (dpdk) phys (dpdk) QAT VF Supermicro SYS-5019D-FN9TP Guest OS DPI app Guest OS vIPSec (VM) vDPI (VM) virt io virt io IPSec app virt io virt io Guest OS QAT VF Packet phys port Packet phys port Intel Virtualization Technologyy for Directed I/O used for Intel QuickAssist Technology access from VM\u2019s DPDK vhost and virt io used for network access from VM\u2019s Supermicro uCPE Solutions 7 For More Information \u2022 Intel Xeon D Processors \u2022 Intel Select Solutions \u2022 Find a Solution for Your Workload builders.intel.com/ intelselectsolutions \u2022 Supermicro Authorized System Integrators com/wheretobuy/namerica. cfm?rgn=100 \u2022 ADVA Ensemble Connector products/network-virtualization/ ensemble-connector ADVA Ensemble Connector Supermicro and ADVA have partnered to integrate ADVA\u2019s Ensemble Connector with our uCPE systems. These combined platforms have been verified as Intel Select Solutions for uCPE in both base and plus configurations, bringing more pre-integrated NFV options to our customers. Summary Supermicro offers a variety of market-ready uCPE solutions with full validation in each BIOS, firmware, operating system, and VM level certification. For example, Supermicro servers, using Intel Xeon D-2100 processors and Intel Atom C3000 processors, are on the list of VMware HCL compatibility with latest ESXi 6.7, which means customers can easily apply virtual machines on the top of Supermicro uCPE. With the SuperServer 5019D-FN8TP, E300-9D-8CN8TP, E300-9D, and 1019D-16C-FHN13TP verified as Intel Select Solutions for uCPE, Supermicro now offers its customers a new, additional degree of confidence. Those looking to easily adopt SD-WAN can be assured that these systems offer, not just easy deployment, but also, verified, workload-optimized performance.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "1ecb7b94-3e1a-4280-9bfb-a2fcaf0dd584": {"__data__": {"id_": "1ecb7b94-3e1a-4280-9bfb-a2fcaf0dd584", "embedding": null, "metadata": {"file_name": "Solution-Brief_Kubernetes_Canonical.pdf", "publication_date": "December 2018", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Total Solution for Canonical with Kubernetes Container technology has brought about a step-change in virtualization technology. Organizations implementing containers see considerable opportunities to improve agility, efficiency, speed, and manageability within their IT environments. Kubernetes and containers are an exciting and evolving technology which can be daunting for teams and organizations to plan for and implement. Together, Supermicro and Canonical, the company behind the Ubuntu operating system, have partnered to deliver solutions that feature Kubernetes. This production-grade container orchestration solution, using Supermicro components has been tested and validated in Supermicro labs, with best-in class hardware components along with the world-class, enterprise-ready, Canonical Distribution of Kubernetes. The solution also features enterprise- ready software-defined storage capabilities using Ceph storage architecture. COMPONENTS OVERVIEW This solution is built and validated with Supermicro SuperServers, SuperStorage systems, and Supermicro Ethernet switches optimized for performance and designed to provide the highest levels of reliability, quality and scalability. Data Switches 2x SSE-C3632S Management Switches 2x SSE-G3648B Infrastructure Nodes 3x SYS-6019U-TN4RT Cloud Nodes 6x SYS-6029U-TR4T Implement your Kubernetes container solution with Supermicro and Canonical SPOTLIGHT ON CANONICAL KUBERNETES \u2022 Built from upstream source, clean Kubernetes \u2022 Security updates by Canonical, makers of Ubuntu, from kernel to Kubernetes \u2022 Upgrades guaranteed, consume the latest Kubernetes at your own pace \u2022 Robust encryption for all control plane components \u2022 Training, certification, support and remote management available SOLUTION BASICS \u2022 Up to 216 Compute Cores \u2022 Up to 3072 GB RAM memory \u2022 Up to 36 TB raw storage \u2022 Up to 40 GbE Data Networking \u2022 19U height \u2022 High performance caching using NVMe flash storage Supermicro Total Solution for Canonical with Kubernetes Containers INFRASTRUCTURE ARCHITECTURE Proven Supermicro configurations are cloud optimized for scale-out, high performance software defined storage (SDS). These Supermicro solutions feature the best enterprise grade components for reliability and availability. The cloud nodes are offered in three ready- to-deploy configurations to best suit different workloads: \u2022 Value Option: 32 compute cores; 36 TB data using 6x 6 TB SATA HDDs; 384 GB of RAM; and a 10 GbE Data Network with Cumulus OS \u2022 Balanced Option: 36 compute cores; 24 TB data using 6x 3.84 SATA SSDs; 512 GB RAM; and a 25 GbE Data Network with Supermicro OS \u2022 Performance Option: 36 compute cores; 12 TB data using 6x 2 TB NVMe PCIe 3.0 SSDs; 512 GB RAM; and a 40 GbE Data Network with Cumulus OS All cloud node options utilize Intel NVMe SSDs for high-performance caching. SOLUTION ARCHITECTURE Canonical Kubernetes The Canonical Distribution of Kubernetes (CDK) is pure upstream Kubernetes tested across the widest range of clouds \u2014 from public clouds to private data centers, from bare metal to virtualized infrastructure. Canonical also provides a rich ecosystem of tools, libraries, services, modern metrics, and monitoring tools to make CDK easy to consume so you can innovate faster. Ceph Storage The storage architecture provides unified block, file, and object access based on Ceph, a distributed storage solution designed for scalability, reliability, performance and manageability. SUPPORT AND SERVICES Enterprise support for Kubernetes is provided by Canonical in partnership with Supermicro where customers gain access to a global pool of knowledge & expertise. The partnership offers a Discovery and Design Service - together, we design your infrastructure to the required size and specifications. Implement your Kubernetes container solution with Supermicro and Canonical SOLUTION HIGHLIGHTS \u2022 Validated reference architectures \u2022 Certified components \u2022 Scale out \u2013 One rack to many racks \u2022 Greenest Servers for the Cloud \u2013 Save hundreds of dollars per server \u2022 Lowest Cost - Best Performance / Watt / $ / ft2 \u2022 Start as a pro by leveraging expert support and services", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "673c0621-8c38-4485-bf97-0f671903ee63": {"__data__": {"id_": "673c0621-8c38-4485-bf97-0f671903ee63", "embedding": null, "metadata": {"file_name": "Solution-Brief_Rakuten_Symphony.pdf", "publication_date": "March 2023", "referenced_websites": ["www.supermicro.com/x13", "https://www.supermicro.com/en/products/system/Hyper/2U/SYS-221H-TNR?mlg=0)", "https://www.supermicro.com/en/products/system/iot/2u/sys-221he-ftnrd)", "https://www.supermicro.com/en/products/system/iot/2u/sys-211e-frdn2t)", "https://www.supermicro.com/en/products/system/iot/2u/sys-211e-31d)", "https://www.supermicro.com/en/products/system/iot/1u/sys-111e-fdwtr)"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Solution Overview Rakuten Symphony is a recognized leader in providing solutions for the mobile industry. By reimagining telecom, Rakuten Symphony makes it possible to launch and operate advanced mobile services in a fraction of the time and cost of conventional approaches, with no compromise to network quality or security. Creating a new solution requires expertise in a number of domains. For example, understanding the networking, storage, and computing requirements of a telecommunication (telco) offering requires enormous expertise. Leveraging Supermicro servers for core and Open RAN, Rakuten has industrialized a transformational, highly automated, cloud-native network solution based on their \u201cMobile as a Software\u201d paradigm. With Rakuten Symphony utilizing Supermicro servers, customers get a proven, modern, and tested solution for the most demanding telco operations. Supermicro provides commercial servers with pre-validated solutions for Open RAN that will fit into different network deployment environments. Supermicro is a leading editor in the O-RAN ALLIANCE\u2019s White Box Working Group that defines the reference architectures for the industry. Open RAN Telco networks have, in the past, been closed and proprietary solutions. Whether the hardware or software was proprietary and closed, this system was not optimal. Individual components could not be replaced to use the latest technologies, which reduced performance over time and led to more expensive solutions. With Open RAN (Open Radio Access Network), the RAN Solution Overview 1 Open RAN 1 Key Components 2 Hardware Solution Features 3 Summary 3 Further Information 3 Contents 1 Solution Overview . Error! Bookmark not defined. Open RAN Error! Bookmark not defined. Key Components Error! Bookmark not defined. Hardware Solution Features . Error! Bookmark not defined. Summary Error! Bookmark not defined. Further Information Error! Bookmark not defined. 2 functionality is disaggregated using open standards. An O-RAN network enables service providers to use components from many vendors, encouraging innovations and lowering costs. In addition, by using industry-standard servers, Open RAN can quickly borrow innovations from other parts of the IT world and apply them to the wireless network edge, thus increasing RAN's performance and flexibility and bringing many applications from the cloud to the edge. Key Components An Open RAN solution for a telco environment consists of Distributed Units (DU) and Centralized Units (CU) for compute purposes. The DUs and CU perform different tasks and can be specified as different types of optimized servers. \u2022 Distributed Unit \u2013 The Open Distributed Unit (O-DU) sits close to, or even at, the Radio Unit (RU), which broadcasts the mobile network signal and processes data transmission between the RU and the CU. Hardware used for the O-DU task often is commercial off-the-shelf (COTS) edge servers that can function as a baseband processing unit to handle high PHY layer, MAC, and RLC layer with network function virtualization (NFV) or Containers. \u2022 Central Unit \u2013 The Open Centralized Unit (O-CU) sits between the core network and a series of Distributed Units. The Centralized Unit collects the relevant data from the Distributed Units and sends that data to the core data center. The overall architecture of a 5G Telco network is described below. In RAN, the DU, CU, MEC/RIC, and edge servers are all based on white box servers. Based on the location of the deployments (Cell Site, Central Offices, Local Data Center), or the amount of traffics to be supported (# of Radio Units, # of Subscribers), Supermicro has varieties of servers to fit into different scenarios. We highlight some of the servers below as examples. 3 Hardware Solution Features Supermicro servers have been selected, tested, and available as CU or DU systems as a key component of the Rakuten Symphony solution. \u2022 O-CU / SYS-220U-TNR: The powerful and flexible 2U Ultra system is deployed as a centralized unit, providing high compute performance with dual 3rd Gen Intel Xeon Scalable processors and 100 GbE connectivity. Default configuration: 2x Intel Ethernet Network Adapter E810 and 1x Intel Ethernet Network Adapter XXV710, Dual Intel Xeon Platinum 8358P w/ high flexibility and slot count, NUMA balanced architecture, full SW integration/management feature support. \u2022 O-DU / SYS-210TP-HPTR: The 2U, 4-node SuperEdge system functions as a distributed unit in deployments where performance and low latency are essential. Each node can be configured with a 3rd Gen Intel Xeon Scalable processor and a range of add-on cards. Default configuration: Intel Xeon Gold 6338N with 32 cores, 1x ACC100, and 1x Intel Ethernet Network Adapter XXV710 single socket w/ high density, ultra-low latency in packet processing. \u2022 O-DU / SYS-210P-FRDN6T: This ultra short-depth (299 mm / 17.2\u201d) system is able to deliver high-density performance in space constrained areas as a distributed unit. Default configuration: Intel Xeon Gold 6338N with 32 cores, 1x ACC100 and 1x Intel Ethernet Network Adapter XXV710, single socket short depth, ultra-low latency in packet processing. Rakuten symphony will start offering 4th Gen Intel Xeon Scalable processors-based products on the same footprint server listed above. Summary Supermicro and Rakuten together are creating a complete solution for O-RAN operators. With the combined state-of-the-art software, servers, and networking, new and highly performant RAN can be implemented in a fraction of the time compared to a piecemeal selection and integration effort. Further Information", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "b6f484ae-9679-4eff-aa11-3e4319e882ab": {"__data__": {"id_": "b6f484ae-9679-4eff-aa11-3e4319e882ab", "embedding": null, "metadata": {"file_name": "Solution_Brief_SMC-ft-BEIJER-iX-Software.pdf", "publication_date": "June 2022", "referenced_websites": ["https://www.supermicro.com/", "https://www07.beijerelectronics.com/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Along with the prevalence of Industry 4.0, more and more traditional factories adopt smart manufacturing solutions. IoT technologies simplify the collection and monitoring of data from the production line, and AI/ML technologies vastly improve product quality control processes. Supermicro SYS-E100-9W-IA and SYS-1019P-FHN2T integrated with Bejier iX software provide a powerful data acquisition and visualization edge computing solution. This solution enables factories to collect and exchange data from the PLC or controller and connect to production manufacturing systems like MES and ERP. Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally- friendly solutions available on the market. 1 Traditional Quality Control 2 The Supermicro-Beijer Solution 2 Integration of iX software on Supermicro Hardware 3 Why Supermicro Edge Devices? 4 Conclusion 5 SYS-E100-9W-IA SYS-1019P-FHN2T 2 Traditional Quality Control Manufacturers must transform into smart manufacturing to maintain the competitiveness of the enterprise. One of the key competitive benefits is ensuring product quality when production capacity increases faster. Unfortunately, traditional manufacturers are facing one or more of the quality control challenges below: \u2022 Unable to predict the quality issue before it happens \u2022 Not enough resources to track some critical process data, which limits the ability to identify the root cause of the quality failures clearly \u2022 Wasted cost and time while still delivering a failed quality product \u2022 Unexpected downtime due to quality failures and low OEE The Supermicro-Beijer solution IoT and AI technology create a revolutionary quality control procedure with Supermicro SYS-E100-9W-IA and Beijer iX software. Manufacturers can collect the process data from the controller by applying IoT technology in the production line and combining the work orders from the MES system to become a valuable production data center for advanced data analysis and historical data, which can be tracked if needed. The smart and flexible work order arrangement and optimized resources are the key factors for smart manufacturing. The process data from controllers are an important reference for the operation of the production equipment like OEE, running hours, alarm history for the risk of availability even the predictive maintenance information. These data combining the working orders can help the smart manufacturing system/management level analyze the optimized production plan and resources arrangement for both the manpower resource and the production equipment. For the basic function, factory operations can have more data to track and identify the failure process data from the production history when the operator is running product inspection procedures to filter the specific failure pattern of the product. Combining the data from work orders and the controller in machinery, we can have a complete track list for \u201cwhen,\u201d \u201cwhere,\u201d \u201cwhich machine or production line,\u201d \u201cwhat is the production recipe setting the record,\u201d and so on. If there is any failure or quality issue, there would be completed information to trace back all of the details, including operators, machinery, and setting factors/data for the recipe to analyze and filter the root cause. For advanced smart production, this is the concept of \u201cSmart Manufacturing\u201d for Industry 4.0. It is a new type of manufacturing. This is because, by analyzing the relationship between failure process data and failure pattern, operations can have the database to predict which failure process data will cause the specific product failure. The engineers can also implement the AI technology to build the AI model and do a training model with those prediction results. These features are for software. But such kind of software functions needs high computing power. A typical computer like IPC cannot afford it. It requires the performance as server grade. This is the core competence of Supermicro. The production system can get real- time notification when detecting abnormal process data by implementing AI inference into the process database. The administrator can take action before the workpieces go to the next work stage. The status of the production equipment can also be collected and stored in the database. The engineers can also implement the AI technology to do the predictive 3 maintenance to reduce the unplanned downtime and be notified when some critical parts of production equipment need to replace or maintain. Thanks to the excellent and steady hardware from Supermicro and powerful, flexible software from Beijer, the manufacturers can enhance their product quality, reduce the cost, and maintain high OEE without unplanned downtime. Integration of iX software on Supermicro Hardware iX Software is a comprehensive data acquisition and visualization software that runs on Supermicro edge hardware. iX software supports the most popular PLC drivers to communicate and read data from the various controller and IoT gateway types. In addition, iX software also contains many rich and vivid widgets for users to design their unique war-room dashboard. iX software is designed for industrial environments. It supports up to 90 different PLC drivers and can turn Supermicro hardware into a highly compatible edge server. Furthermore, by supporting additional PLC drivers, users can collect the data from the various controllers with different brands and protocols and display this data with a built-in Dashboard engine in the war-room dashboard. iX software empowers you with modern tools to communicate. The software combines top-class graphics and smarter functions that provide intuitive operation on the spot and have almost limitless connectivity to your other equipment through the extensive list of drivers. Figure 1 \u2013 Supermicro Industrial IoT solution architecture. 4 Why Supermicro Edge Devices? Supermicro Fanless Edge devices such as the SuperServer SYS-E100- 9W-IA are the ideal solution to address the demands of Industrial applications. The SYS-E100-9W-IA provides legacy connectivity such as COM ports for RS-232/422/485 interfaces to bring management capability to existing manufacturing equipment. Easily DIN rail mounted within the equipment or remotely for convenience of installation, this fanless system is built to withstand the environmental conditions found in manufacturing facilities. The SYS-1019P-FHN2T provides the computing power and data storage functionality for the iX war-room dashboard engine to visualize all the sensor data, MES, and ERP from the database. Based on the 2nd Gen Intel Xeon Scalable processor, the 1019P series of products offer superior performance in an extended availability platform. With up to 28 CPU cores per device, the 1019P can serve as the node device for many individual systems or machines and run the management system for those devices. In addition, with two PCIe x 16 slots for optional 4 x 10G Ethernet connections or optional AI accelerator, operation managers can manage their entire facility with a single device to optimize operational efficiency. From an operation technology perspective, the SYS-E100-9W-IA Fanless edge computer integrates different brand PLCs in all production line equipment in the factory for real-time monitoring of production operating information. In addition, the SYS-E100-9W-IA could also be interlocking to indicate lighting status on equipment and analyze downtime by C# script to predict unexpected downtime. The SYS-E100-9W-IA is unifying OT/IT protocol as cutting-edge smart manufacturing technology in PC-based automation control and seamlessly transforming factory floor information into the IT infrastructure. Execute data analysis software on SYS- 1019P-FHN2T edge server of each partition to analyze the big data of equipment operation and utilize AI inference module to optimize equipment production parameters in real-time. All production information is displayed on the digital board room, allowing the decision-makers to get insights at a glance with the visualized information for real-time decision making. Solution Overview This solution provides a single software platform to achieve the purpose of data collection and data visualization by running iX software on a Supermicro device. SERVER FOR IX SOFTWARE SYS-E100-9W-IA SYS-1019P-FHN2T Supermicro gateway and edge servers validated and qualified with iX software 5 Conclusion Now more than ever, companies need to accelerate the adoption of Industry 4.0 to transform into smart manufacturing. The Supermicro-Beijer solution enables a manufacturer to seamlessly capture edge data and transform it into insights. This integrated solution provides product quality prediction and predictive maintenance, allowing manufacturers to get real-time information from the shop floor and take action before failure occurs. This eliminates potential downtime caused by late detection, reduces costs, and improves efficiency. Moreover, the Supermicro-Beijer solution improves market competitiveness and reduces manufacturers' total cost of ownership.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "d66a1015-657b-46f4-99ca-956e9ae72b66": {"__data__": {"id_": "d66a1015-657b-46f4-99ca-956e9ae72b66", "embedding": null, "metadata": {"file_name": "Solution-Brief_SAP-HANA_VMware-vSAN.pdf", "publication_date": "June 2020", "referenced_websites": ["https://www.supermicro.com/en/products/system/2U/2029/SYS-2029U-E1CRT.cfm", "https://www.supermicro.com/products/system/2U/6029/SYS-6029U-E1CR4T.cfm", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 SOLUTION 2 WHY SAP HANA ON HCI 2 SOLUTIONS INTEGRATED WITH VMWARE VSAN 3 HCI SOLUTION FOR SAP HANA BENEFITS OF SAP HANA ON VMWARE VSAN - SAP customers have seen data center trends change, yet all still have one significant and common challenge; they are looking at more efficient ways to reduce complexity, maintenance, and costs of data center operations. With SAP HANA projects, customers are deeply reviewing their current infrastructure and its transformation to a more innovative solution such as hyperconverged infrastructure (HCI) recently Supermicro has certified by SAP for production systems. Hyperconverged infrastructure brings compute, storage, and the hypervisor together into a single system, which reduces data center complexity and increases scalability to break through all obstacles of conventional architecture, especially SAN and NAS storage, including their networking. HCI is a software-defined infrastructure model that delivers performance, reduces network overhead, and mainly comes with a simpler IT management and supports dynamic growth by adding all needed resources by merely adding one additional HCI node. With the certification of SAP HANA on hyperconverged infrastructure powered by VMware vSAN, Supermicro\u2019s customers can bring down their data center TCO by leveraging our best of breed systems. Benefits of SAP HANA on VMware vSAN 2 SOLUTION This document describes Supermicro\u2019s HCI Solution Supermicro PowerBlocks powered by VMware vSphere & vSAN for SAP HANA on the Ultra SuperServer 6029U-E1CR4T and 2029U-E1CRT. These systems are designed for large in-memory computing and mission-critical enterprise applications in density optimized 2U chassis. Those servers support enterprises that require the highest operational efficiency and maximum performance. WHY SAP HANA ON HCI With HCI, storage components share compute and memory with the server infrastructure. This eliminates the need for separate storage arrays, controllers, memory, SANs, and more. All storage technologies are fully integrated into the virtualization cluster. It\u2019s like creating a SAN storage out of the internal storage of vSAN cluster members. SAP HANA customers can take advantage of HCI, which is extremely simple, flexible, with a much higher degree of scalability to help reducing costs compared to old SAP infrastructure. With SAP support, customers are now ready to migrate or install their virtualized mission-critical SAP HANA systems on top of Hyperconverged Infrastructure powered by VMware vSAN. SOLUTIONS INTEGRATED WITH VMWARE VSAN Supermicro has a long-standing experience with VMware products such as vSphere and vSAN and which was constantly shown in ReadyNode certification of many different systems. It focuses on deploying VMware vSAN, a hyper-converged solution, as quickly as possible. Working with VMware, Supermicro delivers an alternative to traditional Fiber Channel SAN based storage infrastructure, which is known for its complexity and interoperability challenges. vSAN provides you with the ability to provision and manage compute, network and storage resources from a single pane of management: 1. vSAN integrated management panel with vSphere provides the simplicity, consistent user interface, ease of management and flexibility to spin up HANA instances quickly as required across the vSAN cluster. 2. vSAN enables the software defined storage with flexible customer defined per VM policy based management that can be tailored to test, development, QA instances and provides high availability as required. Especially with all flash deployments, Supermicro vSAN ReadyNode introduces a new high- performance storage tier optimized for enterprise-class virtual environments that is simple, resilient and efficient that reduces the total cost of ownership. It is a perfect solution for enterprises to efficiently grow and manage virtualized infrastructure for maximum ROI. Figure 1. Supermicro SYS-6029U-E1CR4T Benefits of SAP HANA on VMware vSAN 3 - HCI SOLUTION FOR SAP HANA The Supermicro HCI for SAP HANA certified systems are based on Supermicro vSAN ReadyNode systems with proven reliability and stability in high end environment. Because the SAP HANA certification has more demanding and different KPIs to meet, Supermicro assembled the most appropriate components to easily meet all certification requirements and pass the certification. Both certified systems are Ultra SuperServers that are designed to deliver the highest performance, flexibility, scalability and serviceability to demanding IT environments, and to power mission-critical Enterprise workloads. Benefits of the solution include: standardized and highly optimized for SAP HANA database workload SuperServer, combined with VMware vSAN for better TCO. Through SAP support portal, Supermicro is the single point of contact for HCI joint solution covering triage whenever needed The Ultra SuperServer SYS-2029U-E1CRT that is designed for large in-memory computing and mission critical enterprise applications in a density optimized 2U chassis. This server is designed for enterprises that require the highest operational efficiency and maximum performance. The system supports two 2nd Generation Intel Xeon Scalable Processors (Cascade Lake-SP) with up to 28 cores, support CPU TDP support 205W, dual UPI up to 10.4 GT/s, 24 DDR4-2993MHz DIMM slots (fast DDR4 technology with up to 3 TB), up to 24 Hot-swap 2.5\u201d drive bays including high performance NVMe drives, and 7 PCI-E 3.0 slots for diverse expansion options.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "c337cc2f-0b50-422f-a66c-b8bdc18ec840": {"__data__": {"id_": "c337cc2f-0b50-422f-a66c-b8bdc18ec840", "embedding": null, "metadata": {"file_name": "Solution-Brief_Workstations_Deep_Insights.pdf", "publication_date": "December 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro Workstation Family The digital universe is exploding in size and complexity, giving today\u2019s companies unprecedented opportunities to disrupt and lead their industries. At the same time, the demand for data science and artificial intelligence (AI) is escalating and urging companies to rethink how they utilize data to create smarter applications and functionality. Data scientists must analyze, visualize, and share insights in real- time to keep pace with data trends and remain one step ahead of the competition. These capabilities are critical to improving the productivity of high-level decision-makers, researchers, and developers by allowing them to make smarter decisions and take immediate action. However, traditional technologies often lack the computing power and scalability to seamlessly share data across disparate locations. 1 Partnering for Success 2 Building an Unparalleled Computing Environment 3 Summary 4 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 2 High-performance workstations can optimize a wide range of computationally intensive scientific and engineering applications, from advanced visualization work to AI. The latest workstation solutions are designed to execute workflows faster than ever before. As a result, companies that invest in these technologies will have an extraordinary opportunity to speed up decision-making, realize better outcomes, and reimagine how enterprises think, work, and collaborate. For data scientists, implementing a purpose-built workstation is crucial to operating quickly and effectively. Data science applications utilize capabilities such as scientific computing, predictive analytics, and prescriptive analytics to power a number of AI, machine learning, and deep learning uses. With the right technologies in place, companies can transform massive amounts of data into insights quickly: \u2022 Simplifying workloads for rapid data preparation, model training, and data visualization \u2022 Boosting productivity of data scientists by enabling quicker and more accurate predictions \u2022 Reducing model development and training time for faster deployment and business insights These technologies deliver incredible performance for a number of sophisticated applications. The result is an ideal work environment for data scientists, engineers, analysts, and other power users with high CPU and GPU computation core counts right at their desks. Partnering for Success Supermicro and NVIDIA are delivering the next generation of AI computing to accelerate insights on demand. Together, both companies provide the right computing solutions to maximize the speed and precision of any project. Supermicro is a global leader in high-performance, high-efficiency technology, offering the broadest product portfolio for next generation workstations. With operations in more than 100 countries, Supermicro is a leader in enterprise, cloud, AI, edge, and IoT, developing state-of-the-art products that help companies capture and operationalize deep insights everywhere. The goal is to enable the success of every company. Supermicro achieves this through extensive engineering expertise and the industry\u2019s broadest product portfolio, which offers green computing technologies that reduce energy costs, effectively allocate resources to tackle complex data workloads, and improve the overall total cost of ownership. In partnership with NVIDIA, Supermicro offers a range of AI-capable solutions to help companies work better, smarter, and faster. Leveraging first-to-market innovations from Supermicro and the massively parallel processing capacity of NVIDIA GPUs, together create IT environments that are purpose-built for data science and AI. As a result, every workstation delivers breakthrough performance at scale, so companies can execute critical workflows in record time using high-end compute and analytics capabilities. These joint solutions radically improve how remote users work, collaborate, and innovate. Next generation workstations are the ideal foundation to achieve critical insights when and where they are needed most: \u2022 Purpose-built for the most demanding data and AI workloads \u2022 Accelerated workflows deliver real-time and predictive insights \u2022 Application-optimized performance for increased visibility and control across operations 3 Building an Unparalleled Computing Environment Supermicro workstations are fast, reliable, and cost-effective to meet the demands of data science and AI. These workstations utilize enterprise-grade technologies tested and validated to meet enterprise specific application requirements, delivering unmatched performance wherever users need to work. Solutions from Supermicro offer a high degree of flexibility and upgradability with support for a wide range of industry standard components, so anyone can create the ideal work environment to run any application. Workstations are assembled and tested at a production facility in the USA. Supermicro builds workstations at production facilities in the Netherlands and Taiwan for EMEA and APAC companies. All support issues are managed by local engineers, product managers, and global support services, including next- day onsite options. Supermicro experts can also provide enterprises with recommended configurations based on their unique workflows. 540A-TR 5014A-TT 740GP-TNRT Single-processor workstations with support for multi-GPU to provide exceptional power to handle the most demanding workflow. Entry-level configurations are engineered to have excellent price-performance to facilitate AI, machine learning, and deep learning applications. This high-performance workstation is fully configurable and provides extreme acceleration and enterprise-class reliability and manageability. Mainstream configurations offer everything data scientists need to capture insights from immense datasets. Dual processor workstations are designed for critical speed and compute capacity to execute the most critical data-intensive work at scale. Expert configurations provide unprecedented CPU and GPU acceleration for deep learning workloads. - Intel Xeon W-3300 processor, up to 38 cores - 256GB DDR4-3200 Memory - NVIDIA A30/40 - 2TB M.2 NVMe + 2x 4TB SSD - Linux - AMD Ryzen Threadripper PRO 3900WX processor, up to 64 cores - 1TB GB DDR4-3200 Memory - 2x NVIDIA RTX A6000 - 2TB M.2 NVMe + 2x 3.8TB U.2 PCIe Gen 4 SSD - Linux - Dual 3rd Gen Intel Xeon Scalable Processor, up to 80 cores total - 4TB DDR4-3200 Memory - 4x NVIDIA (A100/A40/RTX A6000) - 2x M.2 NVMe (for OS) and up to 8x NVMe U.2 - Linux Supermicro workstations powered by NVIDIA technology gain an extraordinary competitive advantage: \u2022 Performance at scale toramp up diverse data-centric workloads \u2022 Enterprise reliability and enhanced manageability \u2022 Rich, expansive visual workspaces that support disparate power users \u2022 Unmatched acceleration to boost productivity and innovation 4 Summary Supermicro and NVIDIA empower companies in various industries to work better, smarter, and faster. These cutting-edge workstations are creating tomorrow today, allowing data scientists to unlock the full value of their data. Organizations can benefit from solutions and capabilities that are the best in the industry: \u2022 Best performance: Highest memory and storage capacities available in a single tower system, featuring up to four passively cooled GPUs in tower form factor. Supermicro is the only manufacturer to offer up to four NVIDIA A100 Tensor Core GPUs in multiple models, with up to 80 cores, 4TB of memory, 61.44TB of NVMe, and optional DCPMM support. \u2022 Best expandability Up to six PCIe Gen4 x16 expansion slots, or up to four PCIe Gen4 M.2 with optional hardware RAID 0/1/5/10 support. \u2022 Best component selection: Supermicro validates a wide variety of memory, storage, and networking components with different specifications to help IT managers configure an optimized system for any enterprise needs without locking into one brand. \u2022 Best assembly and local support: All workstation systems shipped in the Americas are built and tested at Supermicro headquarters in San Jose, California, and include technical support services by in-house Supermicro engineers and product managers. Whether using data analytics to enable faster decision-making or collecting deep insights to fuel the subsequent great discovery, workstation solutions from Supermicro and NVIDIA have the best product selections and configurations to empower an organization's success. Together, Supermicro and NVIDIA can help prepare for the cutting-edge of AI. Visit us online to begin the digital transformation.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "4c9958f3-f2ef-4c03-b6ae-6b1c812e2832": {"__data__": {"id_": "4c9958f3-f2ef-4c03-b6ae-6b1c812e2832", "embedding": null, "metadata": {"file_name": "Solution-Brief_Supermicro_Liquid_Cooling_Solution_Guide.pdf", "publication_date": "October 2023", "referenced_websites": ["www.supermicro.com/liquidcooling"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "SOLUTION GUIDE DIRECT TO CHIP LIQUID COOLING SOLUTIONS Liquid cooled rack solution that delivers superior performance and efficiency for large scale AI and cloud scale compute infrastructure \u2022 Full turn-key single source solution optimized from proven total solution blueprints of compute, GPU, storage, networking and power and cooling reference designs, with integrated power management tools \u2022 Support highest densities and highest TDP CPUs and GPUs with up to 100KW power and cooling per rack \u2022 Fully validated and tested at system (L10), rack (L11) and cluster (L12) levels \u2022 Accelerated lead times based on in-stock inventory with deployment in weeks versus years \u2022 Enterprise grade redundant cooling pump and power supplies, leak-proof connectors and leak detection RACK SCALE LIQUID COOLING SOLUTIONS REDUCTION Electricity Costs of Cooling Infrastructure in Server 92% U P T O REDUCTION in Electricity Costs for Entire Data Center 51% U P T O LIQUID COOLING ADVANTAGES DATA CENTER SCALE LIQUID COOLING REDUCES COSTS AND INCREASES PERFORMANCE The latest servers with multiple CPUs and GPUs are creating a significant challenge for data center operators. High end servers are now generating up to 10kW of heat, which must be removed from the server. Traditional air cooling through CRAC units, even with hot and cold aisle separation, are expensive and inefficient. Servers that are application optimized for AI, HPC, and Analytics require the latest in CPU and GPU technologies, which run hotter than previous generations. Multiple CPUs and GPUs per server are needed for performance intensive computing, driving up the electricity demands for the server as well as at the rack level. REDUCTION in Datacenter Server Noise 55% U P T O Supermicro Rack Scale Liquid Cooling Solutions 2 COMPONENTS OF AN EFFICIENT LIQUID COOLING SOLUTION Supermicro\u2019s liquid cooled rack solution is made of several components that are designed in house to achieve the highest level of performance and reliability. All the components are integrated as a rack level solution providing a true one-stop shop customer experience. The critical components of Supermicro\u2019s liquid cooled rack solution are: Coolant Distribution Unit (CDU) \u2013 contains the pumping system that circulates the coolant to the cold plates cooling down the CPUs and GPUs. The Supermicro CDU integrates 2 hot- swappable and redundant pumping modules and power supply modules guaranteeing nearly a 100% uptime to the operator. The CDU cooling capacity is up to 100kW enabling extremely high rack densities. The CDU also offers an easy-to-use touch screen to monitor and control the rack operation with WebUI access and integrated in Supermicro\u2019s Super Cloud Composer datacenter management software. The CDU control system optimizes power consumption while ensuring efficient cooling is delivered to all the CPUs and GPUs. An effective anti-condensation strategy is adopted to prevent any hardware degradation. Coolant Distribution Manifold (CDM) \u2013 The CDM are the distribution pipes that supply coolant to each server and collect the hotter coolant back to the CDU. There are two types of CDMs: Vertical \u2013 Vertical manifolds are placed at the back of the rack and directly connected to the CDU with hoses. They deliver coolant to the cold plates on systems with inlet and outlet hoses at the back of the rack. Horizontal \u2013 Horizontal manifolds are placed at the front of the rack in a 1U rack mount space. They connect the vertical manifolds at the rear of the rack to cold plates on systems with inlet and outlet hoses at the front of the rack (SuperBlades and 8U GPU servers) Hoses and Connectors \u2013 Flexible hoses are used to bring the cooler liquid to the CPUs and GPUs cold plates and return the hot liquid to the CDMs. The Supermicro connectors are single handed, 0 drip, quick disconnector, they allow operators to service liquid cooled systems safely and efficiently. Cold Plates \u2013 The cold plates are placed on top of the CPUs and GPUs; flowing coolants through their micro sized channels cools down the chips very efficiently. The Supermicro cold plates are designed to reduce hot spots on the chip and reach ultra-low thermal resistance. CPU Cold Plate GPU Cold Plate Supermicro CDU RACK SCALE ADVANCED ENGINEERING As the Rack becomes the unit for scalable computing, engineering a liquid cooled rack requires careful planning and expert assembly. A liquid cooling system needs to be flexible to handle a wide range of servers, while being able to cool an entire rack of high performance systems. RACK SCALE SOLUTION Rack Level \u2022 Design \u2022 Assembly \u2022 Configuration \u2022 Testing \u2022 Logistics Horizontal CDM 3 Solutions Guide | Supermicro Rack Scale Liquid Cooling Solutions SRS-48UDTN-SKU1-L1-SMCI SRS-48UBTW-SKU1-L1-SMCI SRS-48UBLD-SKU1-L1-SMCI Up to 4 GPU Servers (8U, 8 NVIDIA H100 HGX GPUs) per 42U Rack (32 NVIDIA H100 HGX GPUs total) Up to 76 Servers Nodes / 19 Systems in a 48U Rack Up to 80 Server Blades / 4 Systems in a 48U Rack Product Qty. Product Qty. Product Qty. Supermicro GPU Server SYS-821GE-TNHR 4 BigTwin (2U4N) 19 SuperBlade Enclosure (8U20N) 4 or 2U Hyper 21 SBI-421E-1T3N 80 or 1U Hyper (shown) 44 CDU 1 CDU 1 CDU 1 Vertical CDM 1 Vertical CDM 1 Vertical CDM 1 Horizontal CDM 4 Horizontal CDM 8 SWITCH 1 SWITCH 1 SWITCH 1 RACK SAMPLE CONFIGURATIONS Supermicro Rack Scale Liquid Cooling Solutions 4 SYS-221BT-HNTR & SYS-221BT-DNTR BigTwin The Supermicro BigTwin represents flagship performance for the most demanding appli- cations and HCI environments. The innovative design supports up to four nodes in a 2U enclosure with no-compromise support for processors, memory, and I/O. Each node can support dual 4th Gen Intel Xeon Scalable processors, up to 16 DIMMs of DDR5 memory, and up to twelve high speed NVMe drives. AIOM (superset of OCP 3.0) networking options include 10GbE, 25GbE, 100GbE, and InfiniBand (200 Gb HDR per port). Shared power and cooling maximize the resource savings of the multi-node design. D2C coolers are mounted on the processors within each BigTwin node and routed through a CDM loop to the Liquid Cooling CDU. A shared cooling, power, and networking infrastructure is key to the high density and server efficiency offered by the SuperBlade. Supermicro\u2019s high performance, density optimized, and energy-efficient SuperBlade supports up to 20 blade servers in an 8U chassis, with a choice of the 4th Gen Intel Xeon Scalable processors or 4th Gen AMD EPYC processors. With advanced networking options, including 200G HDR InfiniBand, Supermicro\u2019s new generation blade product portfolio has been designed to optimize the TCO of critical criteria for today\u2019s data centers, e.g., power efficiency, node density, and performance. A D2C cooler is mounted on each processor within the SuperBlade system and routed through a CDM loop to the Liquid Cooling CDU. Supermicro Hyper servers are designed to deliver the Hyper Family \u2013 The X13 Hyper series brings next-generation performance to Supermicro\u2019s flagship range of rackmount servers, built to take on the most demanding workloads along with the storage & I/O flexibility that provides a custom fit for a wide range of application needs. Supermicro Hyper systems are available in 1U or 2U versions, with up to 32 DIMM slots. With the cooling capacity to accommodate the highest performing CPUs, the Supermicro Hyper product family is optimized for maximum compute performance. Supermicro GPU systems are at the heart of today\u2019s AI and HPC excitement by combining the fastest processors, memory, and GPUs in a family of systems for AI/ML, Inferencing, and HPC. The 2U, 4U or 8U GPU systems support 4 or 8 NVIDIA H100 GPUs together with NVLink and NVSwitch respectively and are powered by up to the 4th Gen Intel Xeon Scalable processors or up to the AMD EPYC 9004 Series processors. In addition, up to 32 DIMMs of DDR5 memory can be installed, providing an extremely compact and powerful AI or HPC system. Finally, D2C coolers are mounted on each of the processors and GPUs within the GPU system and routed through CDM loops to the Liquid Cooling CDU. SuperBlade Hyper GPU SBI-421E-1T3N SYS-221H-TNR & SYS-121H-TNR | AS-2125HS-TNR & AS-1125HS-TNR SYS-421GU-TNXR, SYS-421GE-TNR & SYS-821GE-TNHR AS-8125GS-TNHR & AS-4125GS-TNRT The Supermicro FatTwin are high-density systems offering advanced multi-node 4U twin architecture with 8 or 4 nodes (single processor per node). These systems with a front-accessible service design allows cold-aisle serviceability, with highly configurable systems optimized for data center infrastructure with compute and storage density and options. In addition, the Supermicro FatTwin supports all-hybrid hot-swappable NVMe/ SAS/SATA hybrid drive bays with up to 6 drives per node (8-node) and up to 8 drives per node (4-node). FatTwin SYS-F511E2-RT & SYS-F521E3-RTB 5 Solutions Guide | Supermicro Rack Scale Liquid Cooling Solutions Product Family Server Description GPU SYS-821GE-TNHR Dual 4th Gen Intel Xeon Scalable Processor 8U, 32 DIMMs HGX H100 8-GPU SXM5 Multi-GPU Board AS -8125GS-TNHR Dual 4th Gen AMD 9004 Series Processors 8U, 24 DIMMs HGX H100 8-GPU SXM5 Multi-GPU Board SYS-421GU-TNXR Dual 4th Gen Intel Xeon Scalable Processor 4U, 32 DIMMs HGX H100 4-GPU SXM5 Multi-GPU Board SYS-421GE-TNR (PCIe) Dual 4th Gen Intel Xeon Scalable Processor 4U, 32 DIMMs GPU-NVH100-80,GPU-NVA100-80-NC AS -4125GS-TNRT (PCIe) Dual 4th Gen AMD 9004 Series Processors 4U, 32 DIMMs Up to 8 Double-Width/Single-Width Cards (Full Height Full Length) NVIDIA H100 and AMD MI200 series BigTwin SYS-221BT-HNTR Dual 4th Gen Intel Xeon Scalable Processor 2U, 4-Nodes, 16 DIMMs SYS-221BT-DNTR Dual 4th Gen Intel Xeon Scalable Processor 2U, 2-Nodes, 16 DIMMS FatTwin SYS-F511E2-RT Single 4th Gen Intel Xeon Scalable Processor, 4U, 8-Nodes, 16 DIMMs SYS-F521E3-RTB Single 4th Gen Intel Xeon Scalable Processor, 4U, 4-Nodes, 16 DIMMS SuperBlade SBE-820C/J/J2/L/H-820 8U Enclosure SBI-421E-1T3N Dual 4th Gen Intel Xeon Scalable Processor 16 DIMMS Hyper SYS-221H-TNR Dual 4th Gen Intel Xeon Scalable Processor 2U, 32 DIMMs SYS-121H-TNR Dual 4th Gen Intel Xeon Scalable Processor 1U, 32 DIMMs AS -2125HS-TNR Dual 4th Gen AMD 9004 Series Processors 2U, 24 DIMMs AS -1125HS-TNR 4th Gen AMD 9004 Series Processors 1U, 24 DIMMS Supermicro Rack Scale Liquid Cooling Solutions 6 GPU Server 8U 8 H100 SXM GPU GPU Server 4U 4 H100 SXM GPU Universal GPU 4U 8/10 GPU PCIe SYS-821GE-TNHR AS -8125GS-TNHR SYS-421GU-TNXR SYS-421GE-TNR AS -4125GS-TNRT BigTwin SuperBlade Hyper SYS-221BT-HNTR SYS-221BT-DNTR SBI-421E-1T3N SYS-121H-TNR AS -1125HS-TNR Hyper 4U 8 Node FatTwin 4U 4 Node FatTwin SYS-221H-TNR AS -2125HS-TNR SYS-F511E2-RT SYS-F521E3-RTB 7 Solutions Guide | Supermicro Rack Scale Liquid Cooling Solutions Supermicro SuperCloud Composer for a Liquid Cooled Data Center SuperCloud Composer\u2019s LCCM (Liquid Cooling Consult Module) is a powerful tool to collect vital information on physical assets and sensor data from a CDU (Cooling Distribution Unit), including pressure, humidity, pump and valve status, and more. CDU data is presented in real-time, enabling users to monitor operating efficiency of their liquid cooled racks. Using these insights, SuperCloud Composer (SCC) helps the user to set up alerts, manage firmware updates, and more. Supermicro\u2019s Rack Integration Services, Turnkey Cluster Level Liquid Solutions Supermicro\u2019s Rack Integration Services leverage application- optimized motherboards, chassis, cooling subsystems, networking components, cluster management tools, energy-efficient power supply technologies, and compact enclosures to design and develop customized and enterprise solutions. Supermicro understands the importance of today\u2019s fast pace business problems and customer requirements; therefore, we offer an end-to-end integration service that helps customers reduce overhead, maximize efficiency and quality, making this a competitive strategy and a quick go-to-market advantage. Supermicro works with leading organizations in all geographies to design, install, and test various liquid cooling solutions. The Supermicro process involves a rigorous set of phases that ensure the most optimized and tested solution for environments where liquid cooling is required for maximum performance. Liquid Cooling Tower The Supermicro Liquid Cooling Tower solution is versatile and energy efficient at removing the heat produced by today\u2019s latest servers. The system is optimized to transport and remove the heat from today\u2019s most powerful AI servers. Supermicro is pioneering a way to obtain a complete AI solution, from the servers to the cooling infrastructure. Supermicro Liquid Cooling Tower Solution Summary Worldwide, the amount of energy that data centers consume is increasing yearly. A significant portion of this is to cool the servers and storage systems. With the increased use of servers dedicated to AI training, traditional air cooling costs are skyrocketing, requiring liquid cooling to be considered. In fact, liquid cooling may be the only viable technology moving forward with the current trajectory of increasing TDP at the server and rack level. The ability of forced air systems to remove the heat generated in the entire data center requires significant investments in computer room air conditioning infrastructure, significantly increasing the TCO of a data center. Liquid cooling is significantly more efficient at the data center level and requires an entire solution to cool the systems. The Supermicro green computing total solution now includes a state-of-the-art integrated liquid cooling tower as part of the overall infrastructure. The Supermicro Liquid Cooling Tower solution is versatile and energy efficient at removing the heat produced by today\u2019s latest servers. The system is optimized to transport and remove the heat from today\u2019s most powerful AI servers. Supermicro is pioneering a way to obtain a complete AI solution, from the servers to the cooling infrastructure. The Supermicro Liquid Cooling Tower is designed for the modern data center with the following capabilities: \u2022 Closed Loop Design \u2022 Modular Design \u2013 available in different sizes with multiple cell configurations up to reach a maximum of 10MW per unit \u2022 Each cell can used separately, enabling cooling tower redundancy \u2022 Optimized for liquid cooling workloads \u2022 High Temperature Fills (>60C) \u2013 Higher temperature water can be returned to the cooling tower. \u2022 High Temperature range enabling higher efficiency \u2022 Low power consumption \u2013 6.2kW/MW of cooling \u2022 Low Water consumption \u2013 6.2GPM/MW of cooling \u2022 Long Lifetime: 15-20years with epoxy coated Stainless Steel for corrosion prevention \u2022 Quick deployments (weeks, not months) 1. Warm facility water is circulated by pumps through each Supermicro Liquid Cooled Racks, removing the heat from the coolant loop and cooling the servers. The heat is transferred from the coolant to the warm water through the CDU heat exchanger, and, as a result, the water exits at a higher temperature. 2. The cooling tower cools the warm water down to a temperature at which the water can be returned to the racks, and the cycle is then repeated. How Does the Supermicro Liquid Cooling Tower Solution Work? Accelerate Everything", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "f17c0ab3-f86e-4f2d-b4ea-62baf9280643": {"__data__": {"id_": "f17c0ab3-f86e-4f2d-b4ea-62baf9280643", "embedding": null, "metadata": {"file_name": "Solution_Brief_Supermicro_TPCxHCI.pdf", "publication_date": "February 2022", "referenced_websites": ["https://www.amd.com/en/processors/epyc-", "http://tpc.org/5801;", "https://blogs.vmware.com/performance/2021/12/tpcx-hci-benchmark-with-vmware-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro AS -1114S-WN10RT Optimum performance requires optimized hardware and software. TPCx-HCI is a powerful tool for measuring and optimizing HCI performance. This rigorous HCI benchmark exercises both hardware and software when measuring an HCI cluster's scheduling, load balancing, and overall performance. It also tests failover performance when the cluster suddenly loses a node. Supermicro is partnering with AMD and VMware to publish the world\u2019s first TPCx-HCI benchmark result using the VMware Hyper-Converged infrastructure (HCI) solution consisting of VMware vSphere 7.0 Update 2 virtualization, VMware vCenter management, and VMware vSAN 7 storage. This test used a cluster of four single-socket Supermicro WIO A+ (model AS 1114S-WN10RT) servers powered by 64-core AMD EPYC 7713 processors and 1TB of main memory. Enabling 1 Description of TPCx-HCI Benchmark 2 Testbed Configuration 2 Benchmark Implementation 6 Supermicro H12 A+ Servers 7 References and Additional Information 8 Supermicro is a global leader in high performance, high efficiency server technology and innovation that develops and provides end- to-end green computing solutions to the datacenter, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to build and provide a broad range of SKUs that are optimized to individual customer needs and workloads. 2 Simultaneous Multithreading (SMT) yielded 512 threads on the 256 processor cores. The VMs ran RHEL 7.7 and the PostgreSQL 10.6 Database Management System (DBMS). This solution achieved an industry-leading score of 4,790.18 tpsHCI @ $49.60 USD / tpsHCI. Supermicro WIO A+ servers are currently available for sale. About the TPC Express Benchmark HCI (TPCx-HCI) The Transaction Processing Performance Council (TPC) developed the TPC Express Benchmark HCI to measure HCI performance under a demanding database workload that stresses the virtualized hardware and software compute, storage, and networking resources. TPCx-HCI has two unique characteristics: \u2022 It has an elastic workload that varies the load delivered to each VM by as much as 16x while maintaining a constant load at the cluster level. Sustaining optimal throughput for this elastic workload on a multi-node HCI cluster typically benefits from frequent VM migrations to maintain load balancing across all nodes. TPCx-HCI measures VM migration efficiency and uniformity of data access from all nodes. \u2022 The Data Accessibility test abruptly powers down a node while continuing the benchmark on the other nodes. The test sponsor (Supermicro) must include a throughput graph for this test that demonstrates both the performance impact and recovery time required to regain resilience. Achieving good TPCx-HCI performance requires many optimizations, such as: \u2022 Software-defined storage (e.g., vSAN) \u2022 Live migration (e.g., VMware vSphere vMotion) \u2022 Load balancing (e.g., VMware vSphere Distributed Resource Scheduler (DRS)) \u2022 Hypervisor scheduler \u2022 Compute performance \u2022 Storage performance \u2022 Networking performance Testbed Configuration Each tested Supermicro AS -114S-WN10RT server included two disk groups. The first disk group used one mixed-use group of Kioxia CM6 3.84TB NVMe devices for the cache layer. The second group used read-intensive Kioxia CD6 3.84TB NVMe devices for the capacity layer. Figure 1 - Supermicro Cluster Configuration 3 The test cluster included a dual-port Broadcom BCM57416 NetXtreme-E 10GBASE-T RDMA Ethernet Controller with one port configured for external access. The vCenter Server Appliance accessed the nodes via the management network on the other port for the management network. Additionally, each server included a dual-port Mellanox ConnectX-5 EN 100GbE card with both ports connected to the 100GbE Switch, where: \u2022 One port carried the vSAN traffic and the transactions coming from the driver. \u2022 The other port carried the vMotion traffic. vSphere 7.0 includes many performance optimizations relevant to this workload. The following two subsections describe how this result used some of these optimizations. Figure 2 \u2013 Testbed network connectivity Inter- and intra-node Scheduling and Load Balancing TPCx-HCI workload tests data access uniformly and live VM migration speed by evaluating inter-node load balancing and VM migration. The TPCx-HCI Specification neither requires nor choreographs how, when, or where load balancing should occur. Instead, it fosters load balancing and live migration technologies by allowing a sponsor to benefit from an efficient load balancer. These tests have the following prerequisites: \u2022 A four-node implementation must use five tiles (see Benchmark Implementation on page 6). The benchmark run must start with all 60 VMs in the five tiles present on three of the four nodes, with the fourth node having no VMs. Midway through the warm-up period, the test sponsor may enable load balancing on the cluster to allow VMs to float to the idle node. \u2022 The benchmark elasticity feature changes the proportion of the overall load sent to each VM every 12 minutes while maintaining a constant overall load, as shown in Figure 31. AS-1114S-WN10RT 1x Loadgen IPMI BCM57416 MCX516A-CDAT AS-1114S-WN10RT 4x vSAN Node IPMI MCX516A-CDAT P1 P2 P1 P2 P1 P2 BCM57416 P1 P2 1G IPMI 10G MGMT 172.24.118.0/24 VM-vSAN 100G VLAN 914 192.168.9.0/24 vMTION 100G VLAN 916 192.168.10.0/24 vSAN TPCx-HCI Benchmarking Connectivity 4 Figure 3 \u2013 Each group\u2019s load varies from one phase to the next while the overall load remains at 100%. Imagine a use case where a private cloud serves multiple tenants whose workloads peak at different times of the year. The overall cluster load remains relatively constant, with VM resource allocation varying depending on which tenant workload is peaking. The hypervisor on each node must therefore choose the best resource allocation scheme to maximize the performance of all VMs in the node. However, having five tiles on four nodes causes per-node load fluctuations and requires inter-node load balancing to maintain good performance. Confining all five tiles to three nodes at the start of the test severely impacts performance without efficient load balancing. Figure 4 graphs the Supermicro FDR performance2. There are 60 VMs with load levels that vary by as much as 16x every 12 minutes. These VMs resided on three nodes when the test began. VMware DRS was enabled after 12 minutes, and some VMs migrated to the fourth node. DRS continued to migrate VMs throughout the two-hour run to maintain load balancing. Supermicro\u2019s testing shows that: \u2022 The 12-minute moving throughput average deviated from the reported throughput by as much as 7.5%. \u2022 The maximum deviation of the 1-hour moving average was only 1.2%. These results demonstrate the efficiency of the VMware ESXi scheduler and VMware DRS. 5 Figure 4 - tpsHCI throughput during the ramp-up period and two-hour measurement interval Recovery From a Lost Node The TPCx-HCI Data Accessibility test requires the cluster to continue processing after a node suffers an immediate, ungraceful shutdown. Figure 5 (reproduced from the Supermicro FDR) shows that processing continued with negligible performance after node loss. However, the cluster completed recovering to the pre-loss state after 2:05:38, easily surpassing all TPCx-HCI Data Accessibility requirements. VMware vSAN 7 Standard Edition was key to this rapid recovery 3. 6 Figure 5 \u2013 Transactions continue with slight performance loss following a node failure Benchmark Implementation TPCx-HCI is similar to other virtualization benchmarks in that it uses a tile-based architecture, where each tile is a unit of configuration and load distribution replication. A TPCx-HCI tile has 12 VMs with different characteristics. A tile consists of four groups, where each has one Tier A VM and two transaction-specific Tier B VMs, as shown in Figure 64. Figure 6 - Architectural layout of the driver and SUT 7 In the published report5, the driver consists of 650 customer emulator threads (VCEs) and 200 market exchange emulators threads (VMEEs). The SUT consists of nine tiles. VM1 of each group contains that group\u2019s Tier A, which runs the business logic application (database front end). VM2 is the Tier B VM that holds the DSS database and accepts the two storage-intensive DSS transactions. VM3 is the Tier B VM that holds the OLTP database and accepts the nine CPU-intensive OLTP transactions. The four groups have the same architecture but different load levels. Groups 1, 2, 3, and 4 contribute an average of 10%, 20%, 30%, and 40% of the tile's total throughput over the two-hour measurement interval. Each group\u2019s load varies over the measurement interval, as shown in a run time of the benchmark, as shown in Figure 3 above. Supermicro H12 Generation A+ Servers: Supermicro H12 Generation A+ servers support 3rd Gen AMD EPYC Series Processors up to 8TB of DDR4-3200MHz memory in 1U or 2U form factors that deliver high performance, flexibility, scalability, and serviceability that power mission-critical enterprise workloads in demanding IT environments. Users can select a wide array of storage and networking options to optimize performance and efficiency for their specific datacenter virtualization needs. Footnotes 1. Supermicro WIO cluster ran on four Supermicro AS 1114S-WN10RT servers, each with one AMD EPYC 7713 processor and 1TB of main memory. Overall, in the cluster, the processors had a total of 256 cores, with hyper-threading enabled for a total of 512 threads. Benchmark result using the VMware HCI solution vSphere 7 U2 virtualization, vCenter management, and vSAN storage. The VMs ran the Red Hat Enterprise Linux 7.7 operating system and PostgreSQL 10.6 database management system (DBMS). Achieving the score of 4,790.18 tpsHCI @ $49.60 USD per tpsHCI, is available immediately. World\u2019s first TPCx-HCI benchmark result in price and price-performance see also: world-records and hci.html 2. TPCx-HCI User's Guide 3. TPC Download Current Specs/Source 4. TPCx-HCI Result Highlights 5. Supermicro TPCX-HCI Related Information \u2022 Supermicro TPCX-HCI Full Disclosure Report (includes test data) \u2022 Supermicro TPCX-HCI Supporting Files \u2022 Supermicro A+ Products", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "d520f882-25d6-49a6-bed5-3eb727b98ecc": {"__data__": {"id_": "d520f882-25d6-49a6-bed5-3eb727b98ecc", "embedding": null, "metadata": {"file_name": "Solution-Brief_S2D_RA.pdf", "publication_date": null, "referenced_websites": ["http://www.supermicro.com/wssd", "https://www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Hyper Converged Infrastructure (HCI) Solution Using Microsoft Storage Spaces Direct (S2D) Supermicro\u2019s HCI offerings are Windows Server Software-Defined (WSSD) validated software-defined data centers (SDDC) premium solutions that are built on Supermicro\u2019s industry leading All-NVMe/Hybrid systems and Windows Server 2016. The solution family includes 1U Ultra-10 NVMe, 2U TwinPro and 4U FatTwin servers that deliver the full capability of a comprehensive software-defined data center by leveraging NVMe SSD drives, RDMA (Remote Direct Memory Access) enabled network components, Storage Spaces Direct (S2D), and satisfy customers\u2019 different needs for performance, capacity and cost. Highlights Supermicro HCI premium solutions provide the following benefits, \u2022 Performance: Over 3 million IOPS (4K, read) in a 4U rack space \u2022 Density: Support 40 VMs per server node \u2022 Features: Certified to support full Windows Server 2016 SDDC features \u2022 Ease of use: Factory validated and certified for Microsoft HCI Premium \u2022 Scalability: Easy to scale out with predictable storage efficiency and performance improvements Super Micro Computer, Inc Website: Company Size: 3000 Country or Region: Incorporated in USA Industry: Computer and IT Infrastructure Partner Profile: Supermicro (NASDAQ: SMCI), the leading innovator in high-performance, high-efficiency server technology is a premier provider of advanced server Building Block Solutions for Data Center, Cloud Computing, Enterprise IT, Hadoop/Big Data, HPC and Embedded Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. MICROSOFT WINDOWS SERVER SOFTWARE DEFINED SOLUTIONS Solution Features Below is the feature comparison between Supermicro HCI Premium Solutions and other WSSD offerings. Converged Software- Defined Storage HCI Standard Solution Supermicro HCI Premium Solutions Security BitLocker, Shielded Virtual Machines Windows Defender, Credential Guard, Device Guard Compute Hyper-V Network Software-defined networking capabilities NIC teaming, vSwitches, SMB Direct Storage Storage Spaces Direct software- defined storage Management Virtual Machine Manager Operations Manager Servers x86 industry standard hardware Supermicro's flagship server platforms are a perfect match to complement the flexibility and scalability offered by S2D with hot-swappable NVMe, SAS3 and SATA3 hybrid interfaces, so that the most cost and performance-optimized solutions can be customized and deployed at scale. 1U Ultra Supermicro Ultra SuperServers are designed to deliver the highest performance, flexibility, scalability and serviceability to demanding IT environments, and to power mission-critical Enterprise workloads. Figure 1: Supermicro 1U Ultra All-NVMe 2U TwinPro The Supermicro TwinPro architecture is based on the Supermicro proven Twin technology to provide exceptional throughput, storage, networking, I/O, memory and processing capabilities in a 2U form factor. Customers can further optimize Supermicro solutions to resolve the most challenging IT requirements and benefit from exceptional Total Cost of Ownership (TCO). Figure 2: Supermicro 2U TwinPro 2-node Server System MICROSOFT WINDOWS SERVER SOFTWARE DEFINED SOLUTIONS Specification Supermicro HCI premium solutions currently offer three SKUs. SYS-1028U-S2D is based on four 1U rackmount SYS-1028U-TN10RT+ Ultra servers; SYS-2028TP-S2D uses 2 2U SYS-2028TP-DNCTP TwinPro servers; SYS-F628R3-S2D has one 4U SYS-F628R3- RC0B+ FatTwin server. All three SKUs are equipped with dual Intel Xeon E5-2600 v4 processors, 128GB of DDR4 memory, NVMe SSDs (as cache devices), Supermicro 25GbE RDMA enabled network adapters on each server node. Category Hyper-Converged Infrastructure Premium Orderable BOM SYS-1028U-S2D SYS-2028TP-S2D SYS-F628R3-S2D Server SKU SYS-1028U-TN10RT+ SYS-2028TP-DNCTR SYS-F628R3-RC0B+ OS Windows Server 2016 Datacenter Edition Included Profile All-flash NMVe Hybrid Hybrid Scalability 4 nodes 4 nodes 4 nodes Form Factor 4x 1U 2x 2U 1x 4U RDMA Yes Yes Yes TPM 2.0 Yes Yes Yes CPU Intel Xeon processor E5-2600 v4 product family Memory 128GB (up to 3TB per node) 128GB (up to 3TB per node) 128GB (up to 2TB per node) HBA N/A LSI 3008 LSI 3008 NIC Supermicro AOC-S25G-m2S Supermicro AOC-S25G-m2S Supermicro AOC-S25G-m2S Storage Type Qty. Form Factor Type Qty. Form Factor Type Qty. Form Factor Caching 400GB NVMe 2 2.5\u201d U.2 800GB NVMe 3 2.5\u201d U.2 800GB NVMe 2 2.5\u201d U.2 Capacity 2TB NVMe 6 2.5\u201d U.2 2TB SATA3 HDD 6 2.5\u201d U.2 6TB SAS3 HDD 6 3.5\u201d U.2 4U FatTwin The Supermicro FatTwin represents a revolution in Green Computing and is highly efficient by design; this system supports customers' critical applications while reducing Data Center TCO in order to help preserve the environment, and extends the compute and storage capabilities of Supermicro's existing Twin SuperServer systems to achieve increased performance and power efficiency. Figure 2: Supermicro 4U FatTwin 4-node Server System Supermicro HCI Family Supermicro offers different S2D HCI SKUs for customers.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "54f0563b-9dfa-481d-908c-14f5fc2c1068": {"__data__": {"id_": "54f0563b-9dfa-481d-908c-14f5fc2c1068", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA-MAXIO-Inference.pdf", "publication_date": "July 2020", "referenced_websites": ["www.supermicro.com", "https://github.com/NVIDIA/tensorrt-inference-server/blob/master/docs/examples/model_repository/resnet50_netdef/config.pbtxt"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 MAX IO SERVERS 2 HARDWARE 2 SOFTWARE 2 PERF_CLIENT TESTING PARAMETERS 3 CONCLUSION INFERENCE APPLICATION OPTIMIZED SERVER - MAX IO - A proliferation of AI-enabled services will mark this era of pervasive intelligence. There is an increased demand for services like image and speech recognition, natural language processing, visual search, and personalized recommendations. The growing complexity of networks and increasing storage creates a great demand for system performance, efficiency, and responsiveness that are critical to the computing needs of today and the future. Supermicro\u2019s inference platform offers these capabilities to power the next generation of AI products and services in the cloud. Supermicro\u2019s platform enables AI implementation in the Data Center, at the network\u2019s edge, and in the autonomous machines. By utilizing Supermicro hardware and NVIDIA NGC docker platform, inferencing server can be deployed with a cost-effective and high-performance solution. NVIDIA NGC DOCKER Open Hardware Platforms Figure 1. Supermicro/NVIDIA Inference Solution Inference Application Optimized Server - Supermicro MAX IO 2 MAX IO SERVERS Supermicro MAX IO solutions are resource optimized, cost-effective and ideal for space-constrained applications. Supermicro\u2019s highly dense yet compact server designs provide excellent compute, networking, storage and I/O expansion. Supermicro MAX IO solutions support a range of Intel technologies for a diverse portfolio of use cases. Support for high-performance enterprise-level New 2nd Gen Intel Xeon Scalable processors enables customers to meet the requirements of applications including Industrial Automation (IPC), Medical Imaging, Intelligent Transport, Digital Signage, Digital Security and Surveillance, Network, Storage appliances, Edge Computing and other applications. FEATURES OF MAX IO SERVERS: \u2022 Dual Socket P (LGA 3647) support 2nd Gen Intel Xeon Scalable processors (Cascade Lake/Skylake). \u2022 16 DIMMs; up to 4TB 3DS ECC DDR4-2933MHz RDIMM/LRDIMM, Supports Intel Optane Persistent Memory \u2022 CPU TDP support Up to 205W, 3 UPI up to 10.4 GT/s \u2022 2 PCI-E 3.0 x16 slots 2 PCI-E 3.0 x16 slots (or 4 PCI-E 3.0 x8 by MUX) 4 PCI-E 3.0 x8 slots 1 PCI-E 3.0 x4 (in x8 slot) 1 PCI-E 3.0 x4 M.2 slot \u2022 2x 10GBase-T LAN ports via Intel X550-AT2 \u2022 16 Hot-swap 2.5\u201d SAS/SATA drive bays, 1 slim DVD-ROM drive bay \u2022 1000W High efficiency (96%) Titanium Level Redundant PSU Figure 2. Supermicro SYS-2029P-TXRT Inference Application Optimized Server - Supermicro MAX IO 3 - In order to show Supermicro MAX IO and NVIDIA inferencing servers are a perfect match. We use perf_ client benchmark tool to run some inferencing benchmark upon NVIDIA NGC inferencing server with the following setup. The following data is running based on ResNet-50 model with input image size as 224*224 three channels, more information please refer to reference1. Final result Image per second on Y-axis is calculated by multiplying Inferences/second and batch size. Testing results show that even when MAX IO is populated with up to 8 pieces of T4, inference server can get nearly linear Inferencing scalability on ResNet-50 with different batch sizes including 8, 16 and 32. With 8 T4 populated in MAX IO from slot 0 to slot 7, we have 6 out of 8 T4 running in PCI-E x8 bandwidth. However, inferencing benchmark result on ResNet50 with small to medium batch sizes shows that we can fully utilized T4\u2019s computing power without being capped by PCI-E x8 bandwidths. HARDWARE \u2022 System: Supermicro 2029P-TXRT \u2022 CPU: 2x CLX8270 \u2022 Memory: 12x 32GB 2666MHz \u2022 GPU: 8x Tesla T4 SOFTWARE \u2022 OS: Ubuntu 18.04.3 LTS \u2022 Driver version: 418.87.00 with CUDA 10.1 \u2022 Docker version 19.03.5 \u2022 TRTIS version: 0.10.0 \u2022 TRTIS container version: 19.12 1 Source: PERF_CLIENT TESTING PARAMETERS \u2022 Instance per GPU: 1 \u2022 Batch size: 8, 16, 32 \u2022 Latency: 200 ms \u2022 Measurement window: 5000 msec \u2022 Concurrency: various from 0 to maximum 100 threads, testing result only shows the concurrency number that has the maximum throughput. 2208 4441.6 8960 13260.8 17548.8 4192 9625.6 19814.4 29337.6 39372.8 8396.8 19865.6 41779.2 61644.8 80076.8 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 0 1 2 3 4 5 6 7 8 9 Images/sec GPU # RestNet Model with different batch size bs=8 bs=16 bs=32 Inference Application Optimized Server - Supermicro MAX IO 4 ABOUT SUPER MICRO COMPUTER, INC. Supermicro (NASDAQ: SMCI), the leading innovator in high-performance, high-efficiency server technology is a premier provider of advanced server Building Block Solutions for Data Center, Cloud Computing, Enterprise IT, Hadoop/Big Data, HPC and Embedded Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. No part of this document covered by copyright may be reproduced in any form or by any means \u2014 graphic, electronic, or mechanical, including photo- copying, recording, taping, or storage in an electronic retrieval system \u2014 without prior written permission of the copyright owner. Supermicro, the Supermicro logo, Building Block Solutions, We Keep IT Green, SuperServer, Twin, BigTwin, TwinPro, TwinPro\u00b2, SuperDoctor are", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "70bac528-b446-49a8-8d9a-b14cbf190e68": {"__data__": {"id_": "70bac528-b446-49a8-8d9a-b14cbf190e68", "embedding": null, "metadata": {"file_name": "Solution-Brief_Xilinx.pdf", "publication_date": "June 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Many of the common data center workloads involving machine learning inference, video transcoding, and database search and analytics traditionally rely on auxiliary GPU technology to supplement or increase CPU footprint as an extension. However, these solutions often contribute to increased costs, management complexity, and negative impact on the environment via increased thermals. Supermicro\u2019s solution based on Xilinx Alveo Data Center accelerator cards helps address all these problems while providing up to 90x performance increase over CPUs employed for the same tasks. 1 Solution Description 2 Summary 3 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to- end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 2 Solution Features and Benefits Today\u2019s data center workload requirements are more dynamic and are evolving faster than the traditional refresh cycles of the infrastructure. Having a fixed function GPU and CPU addresses the complexities of algorithms is becoming an unfaltering and challenging task. Supermicro\u2019s flexible Ultra servers and Xilinx UltraScale architecture provide reconfigurable acceleration that scales to changing algorithm optimizations customers have come to expect. This, in turn, has a significant impact in keeping the costs and schedules under control while boosting productivity and performance multi-fold. Many of the workloads commonly encountered in the data center, the database search & analytics, fintech, machine learning, video processing, or HPC, such as genome sequencing, oil & gas, and basic research, require huge compute and efficient storage capabilities. Supermicro systems are ideal for these tasks, with plenty of data storage capacity and flexible rear I/O to support various network cards for data delivery. The Supermicro Xilinx Accelerator Solution is based on the flexible, scalable, and versatile Ultra Platform. Supermicro\u2019s 2U Ultra 2029U series and Supermicro\u2019s 6029U series are flagship enterprise-grade rackmount servers that provide a balance of high-end compute, storage, and expansion all in one system. These systems support dual 2nd Gen Intel Xeon Scalable processors, with up to 24 DIMM slots. The Supermicro 2029U series supports up to 24 of the 2.5\u201d hot-swap drive bays, and the Supermicro 6029U series supports up to 12 of the 3.5\u201d hot- swap drive bays. Both systems contain flexible onboard Ethernet options and up to 8 PCI-E slots for various add-on cards. Other available Ultra 2U systems, such as the SYS-2029U-TN24R4T, supports up to 24 of the 2.5\u201d NVMe drives that can enhance system storage with higher throughput and IOPS while lowering the overall latency. Additionally, Supermicro Ultra 2U\u2019s highly modular design offers a wide range of configurations that fit the varying requirements of the data centers. FPGAs such as the Xilinx Alveo U200 & U250 have shown significant improvement in power consumption and performance in Deep Neural Networks (DNNs) applications, which offer high accuracy for important image classification tasks. The Xilinx Alveo U200 & U250 have the potential to be resource/power-efficient. It can accelerate network performance without making a significant investment in new hardware. By leveraging the Supermicro Ultra 2U 2.5\u201d system, customers can utilize the capacity and performance of 24 drive bays. The last four drive bays are hybrid for future storage upgradeability, configured for NVMe support (with optional parts) for faster data delivery of up to 6X than traditional SATA drives. The expansion support offers a default of 8 PCI-E slots configured to x16 or x8 devices. By replacing the default riser with an RSC-W2-66, Supermicro can take 4 PCI-E x8 lanes and convert them to 2 PCI- E x16 lanes. This allows Supermicro to support Xilinx Alveo U200 or U250 and a Mellanox MCX516A-CCAT (dual-port 100G) network adapter combination. FPGAs are well-known for their power efficiency. With the constant demand of the modern Data Center, Xilinx Alveo U200 & U250 data center accelerator cards help offload critical workloads from CPUs, including applications as machine learning 2U ULTRA SERVER SERIES 3 inference, video transcoding, and database search and analytics. Built on the Xilinx Alveo U200 & U250 16nm UltraScale architecture, Xilinx Alveo U200 & U250 provides up to 90X higher performance than traditional CPUs for key workloads and 3X higher inference throughput and 3X latency advantage over GPU-based solutions. The Xilinx Alveo U200 & U250 is designed to meet the dynamic changes in acceleration requirements and algorithm standards while reducing the overall cost of ownership. The chart below compares a CPU+GPU solution with a CPU + Alveo solution when running an inferencing benchmark. Combined with the Xilinx Alveo U200 or U250, a Supermicro Ultra system accelerates real-time AI inferencing, which provides a higher throughput performance and better power efficiency for AI-based speech systems. Also, a higher throughput system for video analytics pipelines as compared to GPU-based systems. A comparison of different workloads and the performance of the Xilinx Alveo accelerator is shown below. Summary Supermicro Xilinx accelerator solution based on Ultra 2U platform provides the flexibility, scalability, and simplicity to run multiple different data center workloads without extensive outlays into fixed function accelerator supports changing technology, allowing customers to consolidate many additional requirements into a single platform, thus reducing overall TCO. Reduce ML Inference Latency by 3X CPU+GPU CPU+Alveo 0 5 10 15 20 25 30 35 40 45 50 CNN+BLSTM Speech-to-Text Latency (ms) CPU+GPU: Nvidia P4 + Xeon CPU E5-2690 v4 @2.60GHz (56 Cores) CPU+Alveo: Alveo U200 or U250 + Intel Xeon CPU E5-2686 v4 @2.3GHz (8 Cores) Adapt and Accelerate Any Workload AREA PARTNER WORKLOAD ALVEO ACCELERATION VS CPU Database Search and Analytics BlackLynx Unstructured Data Elasticsearch 90X Financial Computing Maxeler Value-at Risk (VAR) Calculation 89X Machine Learning Xilinx Real-Time Machine Learning Inference 20X Video Processing / Transcoding NGCodec HEVC Video Encoding 12X Genomics Falcon Computing Genome Sequencing 10X FEATURES ALVEO U200 Accelerator Card ALVEO U250 Accelerator Cards Peak INT8 TOPs 18.6 33.3 DDR Memory Bandwidth 77GB/s 77GB/s Internal SRAM Bandwidth 31TB/s 38TB/s Look-up Tables (LUTs) 892,000 1,341,000 Thermal Options Passive or Active Passive or Active", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "7802d602-b114-43bc-bc1b-0a7eee91835a": {"__data__": {"id_": "7802d602-b114-43bc-bc1b-0a7eee91835a", "embedding": null, "metadata": {"file_name": "Solution-Brief_Quantum_ActiveScale.pdf", "publication_date": "March 2021", "referenced_websites": ["https://www.supermicro.com/en/products/storage", "www.quantum.com/object-storage", "https://www.supermicro.com/en/products/top-loading-storage"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro ActiveScale Reference Arch. Unstructured data is our customers' most valuable asset, which must be preserved and protected forever. However, relentless data growth and retention trends drive demands for more efficient, resilient, and secure Exabyte-scale storage solutions. These demands continue to pressure IT budgets and administrators. Simultaneously, organizations are looking to unlock the value in their data, which makes the task even more challenging. The correct storage architecture can allow organizations to leverage more of their data without requiring budgets to scale at the same pace and make facilitating data forever realistic. Jointly with our market leading, strategic partners, Supermicro can help organizations easily transition from their legacy storage to Object Storage platforms. Supermicro, in collaboration with Quantum ActiveScale, enables our customers to deploy any targeted size of Data Lake with great flexibility and scalability. Supermicro's fully integrated, pre-tested, tuned, and racked solution, built explicitly for ActiveScale patented Object Storage technologies, can be operational in less than 30 minutes. Other primary use cases include Artificial Intelligence/Machine Learning and High Performance Computing (HPC), where WekaIO* provides the high performance, low latency, and consistent response time of Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. 1 Object Storage Solution Architecture Overview 2 ActiveScale Configuration & Performance 3 ActiveScale Software Overview 5 Supermicro Server Overview 6 Summary 8 2 Supermicro ActiveScale Reference Arch. local NVMe storage ActiveScale stores massive amounts of data with geographically distributed systems in the back end. Another use case is to provide on-premise Data Lake as cache space to a public cloud, delivering up to 10X performance while cutting down the overall cost to the public cloud by over 90% (30% overall). Supermicro can offer our customers the best-in-class and fully qualified storage solution featuring Quantum ActiveScale. Our starter offering consists of 3 4U90 systems with 5PB of raw capacity, which achieved over 17GB/Sec and 22K Obj/Sec overall performance. ActiveScale provides seamless scalability to a multi Exabyte scale with high performance in a very cost effective way. While ActiveScale is HDD S3 Object based, it can be fully integrated with WekaIO running on NVMe front-end for file access to provide leadership performance. Object Storage Solution Architecture Overview Cluster Reference Configuration Explain Quantum ActiveScale Object Storage Architecture provides a system that can maximize storage availability and scale the system with minimal to no impact on the customer experience and performance by implementing a 2-layer architecture combined with advanced next-gen shared nothing storage techniques The Access Layer is responsible for providing a single global namespace across the entire environment. Client applications talk to the Object Storage system through the Access Layer using the S3 protocol. The Access Layer executes client facing functions like authentication, authorization, encryption. It also houses a scalable object metadata database, protected by having multiple copies across the access servers. The Storage Layer is where all object data is stored in a very reliable fashion. While there is only one instance of the access layer in a single system, there might be multiple instances of the storage layer called Columns. A single object is stored in a single column. Dynamic Data Placement allows the system to directly store the objects on available disk and storage nodes, ensuring reliability and availability. No rebalance is required when scaling up the Column. Dynamic Data Repair will provide all drives upon detection of a failed drive, and the missing data can be repaired to any available drive in the system. Figure 1 \u2013 ActiveScale Object Storage Architecture 3 Supermicro ActiveScale Reference Arch. Configuration Together, Supermicro and Quantum ActiveScale provide the high-performance object storage solution with the 4U90 Top Loading Dual Node Storage Server. 4U90 Storage Server provides 90 x3.5\" drive bays supporting 18 TB drives, totaling 1.620 PB per 4U Rack space. Using standard 42U x 1200mm rack and reserving 6U for Top of rack switches, we can easily fit 9 X 4U90 chassis, totaling 14.6 PB per a Data Lake Rack. Type Description Qty System X11 Dual Node 90-bay Storage Server, use SSG-6049SP-7802A-QC001 to order 1 CPU 2nd Generation Intel Xeon Scalable Processors Xeon Silver 4216 Processor, 16C/32T 2.1G 22M 9.6GT 100W 3647 L1 4 Memory 32GB DDR4-2933 2Rx4 LP ECC Registered DIMM 16 Boot Drive Samsung PM983 3.84TB NVMe PCIe Gen3 x4 M.2 SSD 4 Storage Drive WD or HGST 3.5\"18TB SAS 12Gb/s 7200RPM HDD 90 NIC Mellanox ConnectX-4, Standard Low-Profile Dual-port 25G SFP28 4 SAS HBA Supermicro SAS HBA 3616 for 90 Bay system 2 SAS HBA Supermicro SAS HBA 9405-16e 16-port Tri Mode 2 Management SW Supermicro System Management Software Suite Node License 2 Table 1 - System Config Specifics Type Description Qty System 4U 90-bay Top Load JBOD w/ dual expander, using SSG-947HE1C-7803A-QC001 to order 1 Storage Drive WD or HGST 3.5\"18TB SAS 12Gb/s 7200RPM HDD 90 ActiveScale Performance, Proven and Validated by the Joint Lab ActiveScale Performance Setup and Measurements \u2022 EC policy: 13/3 (=10+3 Reed-Solomon) \u2022 90 HDDs per 4U Chassis (45 HDDs per Node) \u2022 Backend Network: 12 x 25Gbps \u2022 Theoretical max S3 PUT performance: 27 GB/s \u2022 Theoretical max S3 GET performance: 37.5 GB/s \u2022 Different object sizes: 64 kiB, 512 kiB, 1 MiB, 4 MiB, 8 MiB, 16 MiB \u2022 Different number of parallel TCP connections: 384 connections, 10000 connections 4 Supermicro ActiveScale Reference Arch. Performance Results \u2013 S3 GET 45 HDDs, 4 x 25 Gbit 45 HDDs, 4 x 25 Gbit 45 HDDs, 4 x 25 Gbit 45 HDDs, 4 x 25 Gbit 45 HDDs, 4 x 25 Gbit 45HDDs, 4 x 25 Gbit Loadgen Loadgen Loadgen Loadgen Loadgen Loadgen 25 Gbit Switch (ActiveScale backend) 25 Gbit Switch (public) Figure 2 - Solution Network Topology 5 Supermicro ActiveScale Reference Arch. Performance Results \u2013 S3 PUT The performance testing on three (3) Supermicro Dual-Node 4U90 storage servers, SSG-6049SP-7802A-QC001 with 18TB Drives, showed impressive results with both PUT and GET operations pushing the system to theoretical drive performance limits. The system achieved 17.4 GB/s READs and 13.0 GB/s WRITES. Random read requests were above 20K Objects/Sec. Much higher performance can be achieved by using more nodes as performance scales linearly. For Smaller configurations, one can start with 3 1Ux12 (or SSG-6119P-7804A-QC001) This benchmark uses 6 1Ux12: 6 Supermicro ActiveScale Reference Arch. Specifications Type Description Qty System X11 Dual Node 12-bay Storage Server, use SSG-6119P-7804A-QC001 to order 1 CPU 2nd Generation Intel Xeon Scalable Processors CLX 4208 2P,8C/16T 2.1G 11M 9.6GT 85W 3647 R1 2 Memory 16GB DDR4-2933 1RX4 LP ECC RDIMM, HF, RoHS 4 Boot Drive Kioxia XG6 256GB NVMe M.2 22x80mm <1DWPD, HF, RoHS 2 Metadata Drive Samsung PM983 960GB NVMe PCIe3x4 V4 TLC 2.5\" 7mm (1.3 DWPD) 2 Storage Drive WD or HGST 3.5\"18TB SAS 12Gb/s 7200RPM HDD 12 NIC AIOM Dual-Port 25GbE SFP28 based on Mellanox CX-4 Lx EN 1 Management SW Supermicro System Management Software Suite Node License 1 System Specification Configurations \u2022 EC policy: 13/4 (=9+4 Reed-Solomon) \u2022 12 HDDs per system \u2022 Service Network: 12 x 25Gbps, Backend Network: 12 x 25Gbps \u2022 S3 PUT performance: 5.2 GB/s \u2022 S3 GET performance: 6.5 GB/s \u2022 Different object sizes: 64 kiB, 512 kiB, 1 MiB, 4 MiB, 8 MiB, 16 MiB \u2022 Different number of parallel TCP connections: 384 connections, 10000 connections Network Topology for Benchmark 7 Supermicro ActiveScale Reference Arch. S3 GET Results S3 PUT Results 8 Supermicro ActiveScale Reference Arch. ActiveScale Software Overview Quantum Corporation, founded in 1980, focuses on creating innovative technology and solutions to help our customers get the most value from their data. Quantum is proud to offer the ActiveScale Object Storage system in its portfolio. ActiveScale Object Storage is an early pioneer in the Object Storage market, emphasizing fully consistent, very low touch, and easy-to- scale object storage solutions. ActiveScale is now wholly owned by Quantum, ActiveScale software is running in a multitude of customer environments from less than a PB to multiples 100s of PBs under management. Software Operating system software ActiveScale OS 6.0 Management interfaces Real-time System Management Console, CLI, RESTful API System analytics ActiveScale CM, a cloud-based storage analytics service Security Data encryption in flight SSL/TLS using AES-256, Data encryption at rest using AES-256 Data protection Advanced Erasure Coding, Dynamic Data Placement, Versioning, Object Locking Data durability Up to 19 nines, Dynamic Data Repair SW/FW upgrades Non-disruptive rolling upgrades Supermicro Server Overview SSG-6049SP-DE1CR90 Object Storage Server 9 Supermicro ActiveScale Reference Arch. SC947HE2C-R2K05JBOD JBOD 10 Supermicro ActiveScale Reference Arch. 6119P-ACR12N4L Value Proposition \u2022 Density: Highest density storage and computing power \u2022 Performance \u2022 Dual node configuration provides double processors and dram performance \u2022 Multiple expanders architecture maximizes drive performance. \u2022 Flexibility \u2022 Capacity and TCO software defined scale-out object storage \u2022 Flexible configurations to match different workloads \u2022 Quality \u2022 The architecture SW+HW is fully redundant (NSPOF) \u2022 Component compatibility verification \u2022 Enterprise serviceability with hot-swappable drives, fans, and power supplies \u2022 Server nodes can be replaced hot without disruption of other nodes in the chassis \u2022 Building Block modular design with the highest drive capacity Supermicro Top Load Storage Design Enhancement \u2022 Design for Easy Field Serviceability \u2022 Passive Mid-plane, Backplane \u2022 No CMA required \u2022 Tool-less access \u2022 Drawer type design \u2022 Twin server nodes can be replaced hot without disruption to other nodes (share nothing) 11 Supermicro ActiveScale Reference Arch. Minimum configuration for ActiveScale Object Storage ActiveScale can also be configured with Supermicro SSG-6119P-7804A-QC001 systems which provide an entry-level configuration for customers who wants to start small. The entry level configuration: 3 X SSG-6119P-7804A-QC001 Server: Total of 648 TB (18 TB HDD) \u2022 Optimized component integration for increased cost-effectiveness and reliability \u2022 Better energy efficiency with optimal thermal design and CRPS power supply (single 12V power source) \u2022 Great serviceability with the patented internal cable arm design \u2022 Tiered storage architecture (2x M.2 -> 4x NVMe/SATA SSD -> 12x 3.5\u201d HDD), optimized for Object Storage applications TCO Savings Implementing our new 4U90 storage servers vs. previous generations can reduce 650-1200 KW/hr. in power consumption (Totaling $2M-$4M saving over three years) and reduce rack counts by 250-500 (totaling $21M-$48M saving over three years). Below are comparisons of current platforms and saving estimates based on future implementation Services Supermicro Global Services organization can support customers who require rack integration/configuration, installation, training, post-deployment hardware/software maintenance. Summary With no slowdown in sight for data growth, IT's imperative remains the same \u2013 find more efficient and effective ways to store and protect the organization's vast store of valuable data. The correct storage architecture must simplify complexity and help organizations take advantage of their data without requiring budgets to scale at the same pace as data growth. It should deliver disk-based access performance from anywhere in the world, protect the data from loss with high durability, scale without limits and be easy to manage. ActiveScale, a new class of storage built on patented object storage technology, addresses these needs. Its architecture supports exabyte solutions and beyond with high data durability and high data integrity that disperse erasure encoded chunks across drives, chassis, and geographies, protecting against data loss and data corruption. The distributed, scale-out design supports high-throughput performance even in a geo-dispersed deployment. ActiveScale provides better resiliency and seamless adoption of new capacity as customers grow their way into the future. With just 3 Supermicro 4U90 Storage Servers, over 17GB/sec can already be achieved. With more nodes, one can quickly achieve 100\u2019s GB/s. With industry leading $/GB, the storage density of 14.5 PB per rack, combined CapEx and OpEx savings, Supermicro and Quantum can deliver a complete rack integrated, tested, ready-to-deploy Activescale object storage solutions to customers immediately, Supermicro presents a best in class, low cost, up to 19 9\u2019s availability, from 5PB on 3 4Ux90 to multi-exabytes with Quantum Activescale which enables our customers to deploy any targeted size of Data Lake with great confidence. Assumption Form Factor Drive Size Racks CoLo Cost Power Consumptio n (KW) Power Costs ($M) Gen1 Storage HW 4U36 6TB 617 $66,636,000 1758 $6.0 Gen2 Storage HW 4U60 8TB 278 $30,024,000 1320 $4.5 Gen 3 (4U90) 4U90 18TB 83 $8,964,000 586 $2.0 1) 1.2EB 2) Co-Lo $3K / month /rack 3) $0.13KW-Hr 4) 3 Years 12 Supermicro ActiveScale Reference Arch.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "eb10622c-22dc-49a9-9016-9e739c33b588": {"__data__": {"id_": "eb10622c-22dc-49a9-9016-9e739c33b588", "embedding": null, "metadata": {"file_name": "Solution-Brief_Qumulo_LS.pdf", "publication_date": "August 2022", "referenced_websites": ["https://www.supermicro.com/en/solutions/qumulo", "www.qumulo.com", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 A + Single AMD EPYC 7003/7002 Series All-Flash NVMe Platform - AS -1114S-WN10RT Life Science and Bioinformatics organizations pursue their research objectives in myriad ways. However, they are all characterized by massive volumes of machine-generated file data pipelined into downstream processes for analysis. The need for efficient, high-performance processing of file-based data is at the heart of innovation and discovery in life sciences. Whether running specialized life science workflows, such as genomic sequencing and analyzing drug discovery, microscopy, 3D imaging, blood analysis, proteomics, and biomedical research, or forecasting and modeling, they are all experiencing an unyielding explosion in need of more storage and faster performance. 1 Supermicro and Qumulo Solution for Life Sciences Market 2 Obtain Real-Time Answers About Data and Storage 2 Maximize Price/Performance and Price/Capacity With Software Designed for All-NVMe 3 Fine Tuned for the Widest Range of Workloads and Files Sizes 3 Conclusion & Resources 3 2 Their challenge is simple: The legacy storage systems they have been using for years cannot keep up with the workflow demands for petabyte-scale and billions of objects. From a minimum of a four-node cluster configurations to a maximum of 100 node cluster configurations, customers can go from 68TB to 11.4PB usable capacity in a single enterprise file storage environment. Supermicro and Qumulo Solution for Life Sciences Market Supermicro\u2019s highly performant and economic All-NVMe platform is powered by Qumulo, a file data platform designed from the ground up for the new era of multi-petabyte data scale on-prem and in the cloud. As a result, customers who need performance and scale in a small footprint at the right price can build an economical yet powerful cluster on any of the three Supermicro configurations. A 30TB node configuration for smaller workloads and edge computing use cases. A 76TB node configuration for midrange capacity and density use cases. Or the highly dense and highly economical 153TB platform for workloads that need the highest performance and scale. From a minimum of four-node cluster configurations to a maximum of a 100 node cluster configurations, customers can go from 68TB to 11.4PB usable capacity in a single enterprise file storage environment. Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. 100GbE Supermicro, Qumulo File Storage Solution Bundle Figure 1 - Life Science Architecture 3 Obtain Real-Time Answers About Data and Storage Qumulo stores tens of billions of files with scalable throughput and is the only product that provides real-time visibility and control for file systems at the petabyte scale. Storage administrators and life sciences researchers can instantly see usage, activity, and throughput at any level of the unified directory structure, no matter how many files are in the file system. Qumulo\u2019s modern scale-out storage allows Life Sciences storage administrators to scale storage infrastructure on-demand. Qumulo enables massive scaling by adding another All-NVMe node; the rebalancing happens automatically. Qumulo also enables customers to deploy Qumulo Core anywhere \u2013 on-premises, on third-party hardware, or in the public cloud. Maximize Price/Performance and Price/Capacity With Software Designed for All-NVMe Qumulo Core\u2019s advanced software extends the advantages that adminstrators can achieve with Supermicro\u2019s All-NVMe platform. Qumulo Core was initially designed with All-NVMe in mind and is continually tuned to improve the performance that organizations can obtain from the Supermicro platform. Fine Tuned for the Widest Range of Workloads and Files Sizes Qumulo Core provides unmatched support for the broadest range of Life Sciences workflows. Whether dealing with transactional or sequential access patterns and small or large file sizes, Qumulo Core supports them within a single file system. In addition, Qumulo Core delivers industry-leading scalability\u2014 from 4 to over 100 nodes in a single cluster and 100 terabytes to over 360 petabytes in a single file system. Conclusion & Resources Supermicro and Qumulo Software-Defined Storage solution bundle is designed for commercial HPC workflows in the Life Sciences industry. Check out our solution page, for more details. Contact us to discuss your organization\u2019s specific requirements. Supermicro All-NVMe Server model AS -1114S-WN10RT Form Factor 1U server Configurations 30TB, 76TB, 153TB per node CPU AMD EPYC 24 core 2.8 Ghz Network Port 4 x 100GbE MGMT Port Base-T (RJ45) Memory 128GB 4 ABOUT QUMULO Qumulo is the breakthrough leader in simplifying data management in its native file form at a massive scale across hybrid-cloud environments. Its high-performance file data platform is designed to store, manage and create workflows and applications with data in its native file form at massive scale on prem and in the public cloud. Qumulo is trusted by Fortune 500 companies, major film and animation studios, and some of the largest research facilities in the world to easily manage the full data lifecycle from ingestion, transformation, publishing and archiving with cost-effective capacity, dynamic scalability, automatic encryption, real-time visibility and an advanced API that enables customers to easily integrate Qumulo into their ecosystem and workflows.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "5573867b-da14-49bc-9224-e17357027d64": {"__data__": {"id_": "5573867b-da14-49bc-9224-e17357027d64", "embedding": null, "metadata": {"file_name": "Solution-Brief_SMCI-INTC-NVIDIA-RedHat-AIEnterprise.pdf", "publication_date": "May 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "AI is a game changer for many businesses. With multitudes of mature, pre-trained AI models, including Generative AI models, businesses can deploy AI to analyze data quickly to identify issues and opportunities, to automate interactions with customers, partners, and suppliers, and to accelerate content creation and product development. Supermicro offers a complete line of time-to-market systems supporting a wide range of NVIDIA GPUs. These run the NVIDIA AI Enterprise software suite, which enables rapid AI development and deployment. Red Hat OpenShift provides a reliable environment to support MLops workflows. Supermicro accelerates AI implementations by delivering systems with OpenShift running on the latest generations of Intel CPUs and NVIDIA AI Enterprise running on NVIDIA GPUs. As a result, customers can quickly take advantage of the game changing AI capabilities. 1 AI Training, Inference, Data Flow and Workflow 2 Supermicro Systems 3 Red Hat OpenShift 3 NVIDIA AI Enterprise Software Suite 3 Enterprise Support Services 3 Management & Security 4 Supermicro Reference Architecture 4 Example Applications 5 Conclusion, References 5 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 2 AI Training AI training for small AI models, such as image and object recognition, can be accomplished using one or several GPU systems. Large language models (LLM) require one or multiple racks of these systems. The number of servers and the amount of time can be reduced using pre- trained models provided by NVIDIA AI Enterprise. Supermicro offers very fast NVMe based storage systems to enable fast GPU- Direct access to data to train the AI models. AI Inference After the AI models are trained, AI inference can be done in the data center or on the edge. The inference servers can automatically deploy Trained AI models using TensorRT and NVIDIA Inference Server, available from NVIDIA AI Enterprise. AI Data Flow and Workflow Comprehensive data flow and workflow can be incorporated as part of the business. Supermicro offers systems to collect data at the edge. Data are streamed to the hybrid data center and consolidated into data lakes. Data are then cleansed and formatted for AI training. After training, the trained AI models can be automatically exported to inference servers. Supermicro offers systems and storage to support different aspects of AI data flow and workflow. 3 Red Hat OpenShift Red Hat OpenShift is an enterprise-ready Kubernetes container platform built for an open hybrid cloud strategy. It provides a consistent application platform to manage hybrid cloud, multi-cloud, and edge deployments. Using GPU Operators and other Operators, Red Hat OpenShift enables easy setup and robust operations running NVIDIA AI Enterprise workloads. NVIDIA AI Enterprise Software Suite The NVIDIA AI Enterprise software suite includes AI tools and frameworks, cloud native deployment, and infrastructure optimization software to enable rapid AI development and deployment. The software suite is offered with the Essentials version to support 100 AI frameworks and many AI deployments, along with premium versions: Riva to support speech AI and custom to support specialized AI deployment. By providing minimal risk and a simple approach to integrating AI into the existing enterprise container environment, NVIDIA AI Enterprise enables an end-to-end software stack approach to start using AI in the enterprise. Enterprise developers can initially run small trials until they feel comfortable expanding to more extensive deployment. At that point, the solution is very scalable to deployment in multiple racks. Enterprise Support Services Using the NVIDIA AI Enterprise software suite, enterprise customers get enterprise-grade support for the entire system, from AI software to the virtualization and system hardware, including NVIDIA data center GPUs and network accelerators optimized in Supermicro systems. As a solutions provider, Supermicro offers and supports the entire Supermicro systems with Red Hat OpenShift and NVIDIA AI Enterprise software. NVIDIA CERTIFIED SERVERS Supermicro servers with NVIDIA GPUs are NVIDIA certified. H100, A100, L40, L4, and other GPUs are supported. Choices of Intel Xeon Scalable processors, system memory up to 8TB, PCIe Gen4 or Gen 5 connectivity, NVMe drives, 400Gbit/s network connectivity, redundant power IPMI/Redfish management, TPM 2.0, hardware Root of Trust security. NVIDIA certifications for the 4th Xeon Scalable systems with H100 are in progress. 4 Management & Security Supermicro systems provide out-of-band and in-band monitoring. Using out-of-band IPMI and Redfish management, the health and operation of each server in the cluster can be managed. The servers also come with optional TPM 2.0 and Root of Trust security features. Supermicro Reference Architecture for NVIDIA AI Enterprise running Red Hat OpenShift Supermicro Reference Architecture for NVIDIA AI Enterprise and Red Hat OpenShift provides a scalable architecture. As a result, enterprise AI developers can quickly develop AI solutions to increase efficiency and enable new services using pre-trained AI models. Supermicro accelerates the deployment of AI containers in the Red Hat OpenShift\u2019s orchestrated container environment with the help of Generative AI to automate tested installation scripts. Enterprise support is available on the Supermicro systems that are NVIDIA-Certified, and Red Hat certified, including the entire software stack. Red Hat OpenShift Master Nodes, SuperCloud Composer Node Edge AI Worker Small AI Worker Medium AI Worker Large AI Worker Server SYS-110P-WTR 1U SYS-221HE-FTNR 2U SYS-221H-TNR 2U SYS-421GE-TNRT 4U SYS-821GE-TNHR 8U Number of Servers 4 1 to 256 1 to 256 1 to 256 1 to 256 (per POD) Server Configuration 1 x Xeon Scalable 4310 (12 core) 64GB 256GB M.2 2 x 1TB SSD Dual 10GbE 2 x Xeon Scalable 5418Y (24 core) 256GB 256GB M.2 2 x 1TB SSD Dual 10GbE 2 x Xeon Scalable 6442Y (24 core) 256GB 256GB M.2 2 x 1TB SSD Dual 25GbE 2 x Xeon Scalable 6430 (32 core) 1024GB 2 x 1TB M.2 2 x 4TB SSD 4 x 200GbE 2 x Xeon Scalable 8468 (48 core) 2048GB 2 x 1TB M.2 2 x 1TB SSD 8 x 400GbE GPU - 1 to 3 x A30, A100, H100 1 to 4 x A30, A100, H100 1 to 8 x A100 or H100 HGX-H100 8-GPU BMC Switches (per 32 worker nodes) - - 2 x SSE-G3648B 2 x SSE-G3648B 2 x SSE-G3648B Data Switches (per 32 worker nodes) - - 2 x SSE-X3648SR 2 x SSE-SN3420-CB2RC or 2 x SSE-SN3700-CS2RC 2 x SSE-SN3700-CS2RC or 2 x SSE-SN3700-VS2RC 5 Example Applications Here are example applications using containerized machine learning infrastructure. Specific customer solutions need to be adjusted to match customer needs. Conclusion Supermicro NVIDIA-Certified Systems support NVIDIA AI Enterprise running on Red Hat OpenShift to enable AI developments and delivery to run small to large AI workloads. The reference architectures with specific small, medium, and large configurations provide a robust framework for customers to start using NVIDIA AI Enterprise, running in a robust orchestrated container environment provided by Red Hat OpenShift. Supermicro offers these as integrated solutions, including systems, software, and support. Please call your Supermicro representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "0e5aaf01-72e1-4bbe-bb36-e581b080f46c": {"__data__": {"id_": "0e5aaf01-72e1-4bbe-bb36-e581b080f46c", "embedding": null, "metadata": {"file_name": "Solution-Brief_SMCI-AMD-NVIDIA-RedHat-AIEnterprise.pdf", "publication_date": "May 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "AI is a game changer for many businesses. With multitudes of mature, pre-trained AI models, including Generative AI models, businesses can deploy AI to analyze data quickly to identify issues and opportunities, to automate interactions with customers, partners, and suppliers, and to accelerate content creation and product development. Supermicro offers a complete line of time-to-market systems supporting a wide range of NVIDIA GPUs. These run the NVIDIA AI Enterprise software suite, which enables rapid AI development and deployment. Red Hat OpenShift provides a reliable environment to support MLops workflows. Supermicro accelerates AI implementations by delivering systems with OpenShift running on the latest generations of AMD CPUs and NVIDIA AI Enterprise running on NVIDIA GPUs. As a result, customers can quickly take advantage of the game changing AI capabilities. 1 AI Training, Inference, Data Flow and Workflow 2 Supermicro Systems 3 Red Hat OpenShift 3 NVIDIA AI Enterprise Software Suite 3 Enterprise Support Services 3 Management & Security 4 Supermicro Reference Architecture 4 Example Applications 5 Conclusion, References 5 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 2 AI Training AI training for small AI models, such as image and object recognition, can be accomplished using one or several GPU systems. Large language models (LLM) require one or multiple racks of these systems. The number of servers and the amount of time can be reduced using pre- trained models provided by NVIDIA AI Enterprise. Supermicro offers very fast NVMe based storage systems to enable fast GPU-Direct access to data to train the AI models. AI Inference After the AI models are trained, AI inference can be done in the data center or on the edge. Trained AI models can be automatically deployed by the inference servers using TensorRT and NVIDIA Inference Server, available from NVIDIA AI Enterprise. AI Data Flow and Workflow Comprehensive data flow and workflow can be incorporated as part of the business. Supermicro offers systems to collect data at the edge. Data are streamed to the hybrid data center and consolidated into data lakes. Data are then cleansed and formatted for AI training. After training, the trained AI models can be automatically exported to inference servers. Supermicro offers systems and storage to support different aspects of AI data flow and workflow. 3 Red Hat OpenShift Red Hat OpenShift is an enterprise-ready Kubernetes container platform built for an open hybrid cloud strategy. It provides a consistent application platform to manage hybrid cloud, multi-cloud, and edge deployments. Using GPU Operators and other Operators, Red Hat OpenShift enables easy setup and robust operations running NVIDIA AI Enterprise workloads. NVIDIA AI Enterprise Software Suite The NVIDIA AI Enterprise software suite includes AI tools and frameworks, cloud native deployment, and infrastructure optimization software to enable rapid AI development and deployment. The software suite is offered with the Essentials version to support 100 AI frameworks and many AI deployments, along with premium versions: Riva to support speech AI and custom to support specialized AI deployment. By providing minimal risk and a simple approach to integrating AI into the existing enterprise container environment, NVIDIA AI Enterprise enables an end-to-end software stack approach to start using AI in the enterprise. Enterprise developers can initially run small trials until they feel comfortable expanding to more extensive deployment. At that point, the solution is very scalable to deployment in multiple racks. Enterprise Support Services Using the NVIDIA AI Enterprise software suite, enterprise customers get enterprise-grade support for the entire system, from AI software to the virtualization and system hardware, including NVIDIA data center GPUs and network accelerators optimized in Supermicro systems. As a solutions provider, Supermicro offers and supports the entire Supermicro systems with Red Hat OpenShift and NVIDIA AI Enterprise software. NVIDIA CERTIFIED SERVERS Supermicro servers with NVIDIA GPUs are NVIDIA certified. H100, A100, L40, L4, and other GPUs are supported. Choices of AMD EPYC processors, system memory up to 8TB, PCIe Gen4 or Gen 5 connectivity, NVMe drives, 400Gbit/s network connectivity, redundant power IPMI/Redfish management, TPM 2.0, hardware Root of Trust security. NVIDIA certifications for the 4th Gen EPYC systems with H100 are in progress. Supermicro servers with NVIDIA GPUs are NVIDIA certified. H100, A100, L40, and other GPUs are supported. Choices of AMD EPYC processors, system memory up to 8TB, PCIe Gen4 or Gen 5 connectivity, NVMe drives, 400Gbit/s network connectivity, redundant power IPMI/Redfish management, TPM 2.0, hardware Root of Trust security. 4 Management & Security Supermicro systems provide out-of-band and in-band monitoring. Using out-of-band IPMI and Redfish management, the health and operation of each server in the cluster can be managed. The servers also come with optional TPM 2.0 and Root of Trust security features. Supermicro Reference Architecture for NVIDIA AI Enterprise running Red Hat OpenShift Supermicro Reference Architecture for NVIDIA AI Enterprise and Red Hat OpenShift provides a scalable architecture. As a result, enterprise AI developers can quickly develop AI solutions to increase efficiency and enable new services using pre-trained AI models. Supermicro accelerates the deployment of AI containers in the Red Hat OpenShift\u2019s orchestrated container environment with the help of Generative AI to automate tested installation scripts. Enterprise support is available on the Supermicro systems that are NVIDIA-Certified, and Red Hat certified, including the entire software stack. Red Hat OpenShift Master Nodes, SuperCloud Composer Node Small AI Worker Medium AI Worker Large AI Worker Server AS -1114CS-TNR 1U AS -2125HS-TNR 2U (w/ 2 server nodes) AS -4125GS-TNRT 4U AS -8125GS-TNHR 8U Number of Servers 4 1 to 256 1 to 256 1 to 256 (per POD) Server Configuration 1 x AMD EPYC 7343 (16 core) 64GB 256GB M.2 2 x1TB SSD Dual 10GbE 2 x AMD EPYC 9254 (24 core) 512GB 256GB M.2 2 x 1TB SSD Dual 25GbE 2 x AMD EPYC 9354 (32 core) 1024GB 2 x 1TB M.2 2 x 4TB SSD 4 x 200GbE 2 x AMD EPYC 9534 (64 core) 2048GB 2 x 1TB M.2 2 x 1TB SSD 8 x 400GbE GPU - 1 to 2 x A30, A100, or H100 1 to 8 x A100 or H100 HGX-H100 8-GPU BMC Switches (per 32 worker nodes) - 2 x SSE-G3648B 2 x SSE-G3648B 2 x SSE-G3648B Data Switches (per 32 worker nodes) - 2 x SSE-X3648SR 2 x SSE-SN3420-CB2RC or 2 x SSE-SN3700-CS2RC 2 x SSE-SN3700-CS2RC or 2 x SSE-SN3700-VS2RC 5 Example Applications Here are example applications using containerized machine learning infrastructure. Specific customer solutions need to be adjusted to match customer needs. Conclusion Supermicro NVIDIA-Certified Systems support NVIDIA AI Enterprise running on Red Hat OpenShift to enable AI developments and delivery to run small to large AI workloads. The reference architectures with specific small, medium, and large configurations provide a robust framework for customers to start using NVIDIA AI Enterprise, running in a robust orchestrated container environment provided by Red Hat OpenShift. Supermicro offers these as integrated solutions, including systems, software, and support. Please call your Supermicro representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a6ef55b5-53db-40c7-9d20-dbec4638d85f": {"__data__": {"id_": "a6ef55b5-53db-40c7-9d20-dbec4638d85f", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA_HGX_A100_VCS.pdf", "publication_date": "April 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "A flexible AI processing environment makes it easy to incorporate AI into IT workflow. Many applications involve small to large AI models and different data batch sizes. Simultaneously, AI product development and IT deployment require a wide range of AI processing capabilities on demand. NVIDIA Virtual Compute Server (vCS) and Red Hat Virtualization running on Supermicro\u2019s systems with NVIDIA HGX A100 provide that flexibility, cost effectiveness, and responsiveness to run AI workloads for developers and deployment. We describe in this paper the capabilities and flexibility of Supermicro\u2019s systems with NVIDIA HGX A100 and NVIDIA vCS combined with Red Hat Enterprise Linux to virtualize NVIDIA A100 GPUs to run independent AI workloads. Multiple developers, some needing a small GPU and some needing multiple GPUs, can share the same HGX systems. The same systems also support AI workloads incorporated into IT applications at the same time. 1 Virtualizing Supermicro Systems with NVIDIA HGX A100 for AI Workloads 2 Red Hat Virtualization 3 NVIDIA vCS and AI Workflow 4 Supermicro NVIDIA-Certified Systems with NVIDIA HGX A100 . 4 NVIDIA Virtual Compute Server and NGC 4 More vCS Choices 5 Example Applications 6 Conclusion, References 6 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. AS -2124GQ-NART SYS-220GQ-TNAR 2 Virtualizing Supermicro Systems with NVIDIA HGX A100 for AI Workloads Depending on the size of the AI model and batch data, an AI developer might need a fraction of a GPU or multiple GPUs. NVIDIA vCS enables easy sharing of the same GPU resources running on the Red Hat Enterprise Linux (RHEL) KVM hypervisor for multiple developers. vCS assigns to each virtual machine (VM) a fraction of a GPU or multiple GPUs connected by NVIDIA NVLink in a Supermicro system with NVIDIA HGX A100. By virtualizing the shared GPU, vCS seamlessly allocates the GPUs based on user needs. This flexibility is easier to manage than managing multiple NVIDIA HGX servers running independent operating systems. Red Hat Virtualization provides system redundancy with auto VM failover and scalability. NVIDIA A100 GPUs in Supermicro systems are the state-of-the-art AI processing engines, with 3rd generation Tensor Cores supporting sparsity acceleration, 6,912 CUDA Cores, and up to 80GB of fast GPU HBM2e memory. Multiple NVIDIA A100 GPUs can be combined into a single large processing unit using NVIDIA GPUDirect Peer-to-Peer over NVLink 3.0. Each NVIDIA A100 could also be partitioned into 2 to 7 Multi-Instance GPUs (MIG), where each MIG behaves as an independent smaller GPU. vCS offers flexibility to support one or more users to run multi-vGPUs as an aggregated large GPU. vCS aggregates the vGPUs using GPUDirect Peer-to-Peer in the server and RDMA GPUDirect across servers. HGX SERVERS USING NVIDIA A100 WITH NVLINK AS -2124GQ-NART, with AMD EPYC CPUs SYS-220GQ-TNAR with Intel Xeon CPUs Supermicro servers with NVIDIA HGX A100 deliver highest-performance A100 GPUs with 600GB/s NVLink PEER-to-PEER connections. Choices of 3rd Gen AMD EPYC or 3rd Gen Intel Xeon Scalable processors, system memory up to 8TB, PCIe Gen4 connectivity, NVMe drives, 200Gbit/s network connectivity, A100 GPUs with either 40GB/80GB memory, redundant power IPMI/Redfish v1.8 monitoring/ management, TPM 2.0, hardware Root of Trust 1.0 security. Glossary vCS Virtual Compute Server vGPU Virtual GPU, used for vCS MIG Multi-Instance GPU, A100 feature Multi-vGPU Aggregation of virtual GPU, vCS deployment with MIG disabled Multi-GPU Aggregation of physical GPU, bare-metal deployment Figure 1. vCS and Red Hat Enterprise Linux running on Supermicro servers with NVIDIA HGX A100, supporting multiple developers, with on-demand GPU for AI 3 In other situations, when users need just fractions of an A100 GPU\u2019s power. vCS can virtualize the GPU into as small as 1/20 of a GPU for users. There are two vCS modes. In Enabled MIG Mode, vCS dedicates 1/7 to the entire GPU to a user. In Disabled MIG Mode, where all the partitions are the same, a user could get a virtual GPU that is 1/20 of an NVIDIA A100 GPU to an aggregation of 16 vGPUs from vCS. Red Hat Virtualization NVIDIA vCS runs on top of a hypervisor on the Supermicro server with NVIDIA HGX A100. The Red Hat Virtualization hypervisor allocates CPU and main memory resources for virtual machines to support each user, while vCS allocates the GPU resources. Each virtual machine can run a Linux OS. Red Hat Enterprise Linux provides a robust, enterprise-class hypervisor, offering virtualization that scales from one to racks of servers. Key features include: \u2022 System scheduler \u2022 Storage and network management \u2022 Hot plug of virtual resources \u2022 User and group based authentication and security \u2022 Red Hat Virtualization Manager \u2022 Red Hat Virtualization hypervisor Supermicro servers with NVIDIA HGX A100 are validated to run Red Hat Enterprise Linux. RHEL supports KVM 8.3, which supports NVIDIA vCS. A100 MIG Mode Enabled A100 MIG Mode Disabled Max partitions 7 10 (A100/40GB) 20 (A100/80GB) Partition Type SPACE-SLICED TIME-SLICED Partition Sizes Different sizes, as long as they add up to 1 GPU All the same size per GPU Largest vGPU One A100 16 vGPU Compute resources Dedicated Shared NVIDIA NVLink Support No Yes Heterogeneous Profiles Yes No Figure 3. vCS supports MIG Mode and disabled MIG Mode, with different functions. Figure 2. Two ways to use Supermicro servers with NVIDIA HGX A100: (left hand side) vCS virtualizes GPU resources into 1/10 of an NVIDIA A100 to all GPUs in one server; (right hand side) aggregating GPUs on multiple servers for very large jobs, using GPUDirect RDMA Peer-to-Peer running on servers with bare-metal OS (instead of vCS). 4 NVIDIA vCS and AI Workflows While NVIDIA vCS virtualizes the GPUs in one Supermicro GPU system, Using Red Hat Virtualization and management tools, multiple Supermicro servers running NVIDIA vCS can be deployed to provide a data center virtualized infrastructure to support scalable AI workflows. Each AI developer can quickly spin up a virtual machine with the GPU resource he/she would need. The developer modifies the AI model, trains it with different data batches, and then tests AI inference. The developer can use one virtual machine or multiple VMs. Multiple developers can do their development independently of each other\u2019s, as NVIDIA vCS would allocate system and GPU resources as needed. When the AI model is trained and incorporated into the end application and ready for deployment, NVIDIA vCS can also be used to operate and scale the AI application one or more virtual machines, with allocated GPU resources to run the AI inference. Multi-Tenancy could also be supported using vCS and the underlying virtualization hypervisor. Furthermore, Kubernetes infrastructure could be added to drive containers running in the vCS virtual machines. The vCS VMs would run as worker nodes in the Kubernetes infrastructure. NVIDIA vCS and Red Hat Virtualization running on Supermicro systems with NVIDIA HGX A100 are very flexible and scalable. Supermicro Systems with NVIDIA HGX A100 and NVIDIA Certification Supermicro systems with NVIDIA HGX A100 4-GPU technologies are NVIDIA-Certified. These systems have passed the NVIDIA certification tests to run as a single server and run multiple servers using 200-gigabit networks, supporting the software containers and AI frameworks from the NVIDIA NGC catalog. NGC Support Services are available to help customers develop and deploy AI and HPC systems running on these Supermicro servers. These Supermicro systems can run bare metal using either Canonical Ubuntu or Red Hat Enterprise Linux as the operating system. The NGC software runs in containers under the Linux OS. Alternatively, these systems can run Red Hat Virtualization and NVIDIA vCS \u2013 this environment allows customers to manage multiple systems to provide Virtual Machines, allocating virtual GPUs, to run the NGC software containers. Figure 4. Virtualized and Bare metal deployment options for NVIDIA-Certified Supermicro systems. 5 For an NVIDIA HGX A100 4-GPU systems, Supermicro offers both Intel and AMD CPUs. For example, a customer may choose Intel CPUs because of application fit, while another might choose AMD CPUs because he wants more CPU cores for AI pre-training data processing. NVIDIA Virtual Compute Server (vCS) and NGC NVIDIA vCS supports NVIDIA NGC. All the containers, pre-trained AI models, Helm Charts, GPU Operators in the NGC Catalog can run inside the virtual GPU setup by the vCS. With NVIDIA certification, NGC Support Services are available for the Supermicro servers with NVIDIA HGX to help customer accelerate their use of the NGC capabilities. NGC Support Services provide problem resolution to customers using NGC containers and AI models running on the Supermicro servers with NVIDIA HGX. More vCS Choices In addition to solutions using Supermicro servers with NVIDIA HGX A100 and Red Hat Virtualization described here, Supermicro also offers other choices to provide NVIDIA vCS capabilities. The CPU choices allow the best fit for AI workloads and cost effectiveness. For considerable AI training, it is best to use HGXsystems, whereas, for small inference jobs, the NVIDIA A10 might be more cost-effective. The server choices allow the best fit into customer IT infrastructure and needs. Supermicro Twin and Ultra servers might be best if there is a strong need for more CPU processing in addition to GPU operations. Choose the hypervisor that fits best into the existing customer virtual environment. Supermicro offers all these choices to enable the best fit for customer needs. Virtualized GPU vCS (compute only) vCS (compute only) vCS for Compute, vWS for 3D graphics acceleration vCS for Compute, vWS for 3D graphics acceleration GPU Choices NVIDIA HGX A100 4 GPU, with 40GB or 80GB NVIDIA A100 / PCIe (choice of 40GB or 80GB) or NVIDIA A30 / PCIe NVIDIA A40 / PCIe or NVIDIA A10 / PCIe T4 / PCIe Server Choices AS -2124GQ-NART AS -4124GO-NART SYS-220GQ-TNAR AS -4124GS-TNR AS -4124GS-TNR AS -4124GS-TNR, Twin servers, Ultra servers Virtualization Hypervisor Choices VMware, Red Hat VMware, Red Hat VMware, Red Hat VMware, Red Hat 6 Example Applications Here are example applications using the virtualized machine learning/HPC infrastructure. Specific customer solutions need to situation need to be adjusted to match customer needs. Virtualized GPU Number of Simultaneous Users (VMs) CPU Cores System Memory Storage NVIDIA A100- GPU GPU System AI/HPC Development \u2013 Small Jobs (Single GPU) Up to 80 (4C) 128 512GB 100TB 4 AS -2124GQ-NART or SYS-220GQ-TNAR Up to 160 (4C) 256 1024GB 200TB 8 2x AS -2124GQ-NART or 2x SYS-220GQ-TNAR AI/HPC Development \u2013 Large Jobs (multiple GPUs) 32 (20C) 64 (AMD) 40 (Intel) 1024GB 400TB 16 4x AS -2124GQ-NART or 4x SYS-220GQ-TNAR 64 (20C) 128 (AMD) 80 (Intel) 1024GB 800TB 32 8x AS -2124GQ-NART or 8x SYS-220GQ-TNAR AI Inference Up to 80 (4C) 128 256GB 10TB 4 AS -2124GQ-NART or SYS-220GQ-TNAR Up to 160 (4C) 256 512GB 20TB 8 2 x AS -2124GQ-NART or 2x SYS-220GQ-TNAR Conclusion Supermicro systems with NVIDIA HGX A100 offer a flexible set of solutions to support NVIDIA vCS and NVIDIA A100 GPUs, enabling AI developments and delivery to run small and large AI models. Using the highest performing NVIDIA A100 GPUs, developers minimize their valuable time to run their AI models, delivering fast and cost effective AI features into new and existing products and services. Supermicro offers these as integrated solutions, including systems, software, and support. Please call your Supermicro representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "ba5ff580-03bd-4850-a91e-44afef00b2b6": {"__data__": {"id_": "ba5ff580-03bd-4850-a91e-44afef00b2b6", "embedding": null, "metadata": {"file_name": "Solution-Brief_RedHat_Open_Hyperconverged.pdf", "publication_date": null, "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Open Hyperconverged Solution Virtualization powered by Red Hat Hyperconverged Infrastructure Supermicro and Red Hat have partnered to develop a best-in-class solution based on industry-leading BigTwin and Ultra SuperServers powered by Red Hat Hyperconverged Infrastructure for Virtualization (RHHI-V). RHHI-V integrates proven Red Hat Virtualization and Red Hat Software- Defined Storage to provide an open-source, centrally-administered, and cost-effective integrated compute and storage in a compact footprint for remote office, data center consolidation and enterprise edge environments. This Supermicro HCI solution leverages the advanced features of our line of SuperServers including resource saving, high availability, high density, and high efficiency, delivering a fully optimized turnkey HCI solution for fast and easy deployment and operation. Solution Features Business Value \u2022 Central management for compute, network, and storage resources via integration with a web- based virtualization manager, including a comprehensive RESTful application programming interface (API) \u2022 Includes robust data reduction capabilities provided by native deduplication and compression capability \u2022 Support for vGPUs and software-defined networking \u2022 Capable of deployment in less than an hour with high availability and persistent, durable storage \u2022 Built in Ansible Automation delivers extensibility, automation and customization engine for ops \u2022 Hardware accelerated performance options such as Intel Optane DC persistent memory, Nvidia GPU accelerators, and 25GbE networking are available for your demanding workloads \u2022 Provides secure virtualization (sVirt) and Security-Enhanced Linux (SELinux) technologies to protect the hypervisor against attacks \u2022 Ability to purchase your RHHI-V and other Red Hat subscriptions directly from Supermicro \u2022 Built with the latest server technologies \u2022 Complete integrated HW and SW infrastructure system \u2022 Validated and optimized \u2022 Centralized virtual resource management \u2022 Highly available and scalable resources \u2022 Automated deployment and ops integration means reduced operations costs \u2022 Advanced security and hardening for HCI means reduced unplanned downtime \u2022 Low CAPEX and TCO \u2022 Global Support SLA options \u2022 Purchase your RHHI-V and other Red Hat subscriptions directly from Supermicro \u2022 Supermicro makes it convenient and easy to purchase RHHI-V and other Red Hat subscriptions directly from Supermicro. Contact Supermicro for details. Flexible and Easy Deployment Options Supermicro Ultra SuperServer and BigTwin server platforms provides a range of footprints for compute, storage, and networking to right-size HCI deployments for your operation management requirements, for example: \u2022 Best performance density per rack unit: The 2U 4-node BigTwin model offers the highest performance density per rack unit and additional power savings owing to shared power and cooling. \u2022 Storage density with granular scaling of nodes: The 2U Ultra offers flexibility, an attractive HCI entry price, and highest number of drives for more storage per server node. Supermicro Open HCI Solutions Supermicro RHHI-V Solution Red Hat Hyperconverged Infrastructure v1.7", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "da99104f-0446-4b42-82b6-9002bfbfc1a8": {"__data__": {"id_": "da99104f-0446-4b42-82b6-9002bfbfc1a8", "embedding": null, "metadata": {"file_name": "Solution-Brief_IS_Wireless.pdf", "publication_date": "October 2022", "referenced_websites": ["https://www.o-ran.org/o-ran-ecosystem)", "https://www.is-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "A Collaboration Between Supermicro and IS-Wireless Delivers Complete ORAN Solution Open RAN is the latest trend in building cellular networks. Open RAN is based on separating software and hardware concept, enabling the use of COTS (Commercial Off The Shelf) servers. Furthermore, it is based on open and standardized interfaces, which grant interoperability. Thus, it enables multiple vendors to provide different parts of hardware and software. This combination of hardware and software allows for lower prices and improving competitiveness, which is crucial for further developing the 5G network. Supermicro servers SYS- 220HE-FTNR and the Super Server SYS-E403-9D-14CN-IPD2 are used for Open RAN deployment. IS-Wireless software is responsible for DU (Distributed Unit) and CU (Central Unit) network functionalities deployed as CNF (Cloud Native Network Functions) on top of a container platform. RedHat provides an open, hybrid container/virtual machine infrastructure with Red Hat OpenShift Container Platform. Traditional Mobile Networks The telecommunications market is undergoing a revolution. It is not only about introducing 5G networks but also about how the mobile networks infrastructure is developed: the move from closed to open systems. According to some estimates, in less than 5 years, most of the new networks will be built in that model. 1 Traditional Mobile Network 1 Moving to Open Systems 2 Solution Overview 3 Why Supermicro 5 About IS-Wireless 5 Supermicro is the leading innovator in high- performance, high-efficiency server and storage technologies and a premier worldwide provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative by providing customers with the most energy-efficient, environmentally friendly solutions available on the market. Supermicro SYS-220HE-FTNR 2 Until recently, the telecommunications market was locked and dominated by just a few global vendors delivering radio networks in a monolithic way - software with dedicated hardware. That is how 2G, 3G, and 4G networks were built. As convenient as it might be, it did come with serious risks. In case of problems with an element from one supplier, it was impossible to replace selected network elements. Due to the lack of interoperability with devices from other suppliers, the entire solution had to be replaced with enormous costs as Radio Access Network is the most expensive part of the mobile network. Not to mention the high pricing in general as a result of virtually no competition on the market. It was clear that changing a model was a matter of time. Also, to build a 5G network offering the quality parameters underlying the 5G standardization, the density of the base stations\u2019 grid should be significantly increased while reducing their power. However, densifying the network in the traditional silo model is impossible, as it will be too expensive. Moving to open systems The Open RAN concept is based on open and standardized interfaces, which grant interoperability. Thus, it enables multiple vendors to provide different parts of hardware and software. Although various network elements come from numerous vendors and are proprietary, they are designed to work together with other vendors\u2019 products. In addition, open RAN is based on a software and hardware separation concept, enabling COTS (Commercial Off The Shelf) servers to be used. This open model allows for significant savings, and on the other hand, it enables much more efficient use of available resources such as locations, computing devices, and frequency bands. The image explains the main differences between traditional RAN, vRAN, and Open RAN. According to Dell\u2019Oro research, Open RAN will account for 15% of the overall 2G-5G RAN market by 2026. They also estimate that the Open RAN sector is supposed to generate $15 billion in revenues between 2020 and 2025 globally. Also, the share of mobile networks built in the open model will grow in the following years. Figure 1 - Source: ABI Research, Revenue forecast comparison for public cellular: traditional RAN and Open RAN Figure 2 - Source: ABI Research. Examples of traditional RAN, vRAN, and Open RAN deployments. 3 Solution Overview The IS-Wireless solution contains software for 4G and 5G RAN (Radio Access Networks): O-RU software (Low PHY), O-DU software (High PHY, MAC, RLC), and O-CU software (PDCP, SDAP, RRC, S1AP, NGAP). The IS-Wireless solution is compliant with the following standards: 3GPP (4G LTE / 5G NR protocol stack and features, integration with EPC/5GC, support standard UE, authentication, ciphering, integrity protection), O- RAN (open interfaces, RAN virtualization, SW/HW separation, COTS HW usage) and ETSI (support NFV concept with VNF/CNF - Virtual/Cloud Native Network Functions). Thanks to the Open RAN approach and virtualization, software-defined RAN functionalities can be deployed on flexible HW: O-RU hardware (from IS-Wireless partners, i.e., Benetel, Cablefree), O-DU hardware (COTS servers, e.g., Supermicro SYS-E403-9D-14CN-IPD2),and O-CU hardware (COTS servers, e.g., Supermicro SYS-220HE-FTNR). Near-RT RIC (RAN Intelligent Controller) is typically deployed on the same server as O-CU. Core and MANO can be installed in the public cloud or also on CU server (private network deployments). Figure 3 - IS-Wireless Open RAN solution architecture overview. IS-Wireless integrated and tested their main product (5G RAN) on Supermicro servers - one unit of SYS-E403-9D-14CN-IPD2 and three units of SYS-220HE-FTNR. The servers have been tested with IS-Wireless 5G RAN software (DU and CU network functionalities) on top of the Red Hat OpenShift platform). Figure 4 - The IS-Wireless solution deployed on Supermicro servers with RedHat operating system and virtualization platform. 4 O-RAN Alliance defines an O-RAN ecosystem with different scenarios for Macro distributed, Macro centralized, RAN sharing / MORAN - distributed, RAN sharing /MORAN - centralized. Due to a disaggregated and virtualized RAN solution, IS-Wireless can test all use cases below in Open RAN scenarios 1,2,3,4,7,8 and 10. Figure 5 - O-RAN ecosystem - example scenarios (Source: 5 Supermicro servers with RedHat OpenShift and IS-Wireless software can be used to test multiple configurations: \u25cf Single-node with both the control plane and worker functions in a smaller footprint. \u25cf Triple-node clusters of combined control plane and worker nodes. \u25cf Remote worker configurations where only the worker nodes are deployed at the edge. IS-Wireless tested interoperability with Supermicro and RedHat in two options: \u25cf Single-node (DU/CU on a single server - typical scenario) \u25cf Triple-node (DU/CU on cluster made from three servers - high-reliability scenario). From an IS-Wireless perspective, it is key that the equipment is future-proof and allows scaling up the network. The company also values the performance of Supermicro servers, short lead time, and attractive commercial conditions. All of this makes Supermicro an ideal partner for the solution. On top of this, the pole-mounted server solution provides additional significant benefits for ORAN deployment with limited floor space. Where COTS hardware working as DU (Distributed Unit) can be installed close to the RU (Radio Unit) to reduce latency for uRRLC (ultra-Reliable and Low Latency Communications) services like V2X (Vehicle-to-Everything). After performing tests, IS-Wireless declares that Supermicro servers are very well suited for 5G mobile networks deployed in the Open RAN model. Why Supermicro \u201cSupermicro offered us Telco optimized 2U SYS-220HE System and Super Server SYS-E403-9D-14CN-IPD2 system. They are designed using the market standard components, making the certification process simple. The hardware architecture is future proof as it\u2019s thermally prepared to support future generations of CPUs. The SYS-220HE System servers offer exceptional versatility and expandability. We can use up to 10 expansion cards, including a wide range of accelerators, two CPUs with up to 270W TDP, and up to 32 DIMMS in a short depth (574mm) chassis. That allows us to use the same server model as a CU or DU, which keeps the total cost of investment low. Serviceability is simplified with a toolless design. The ability to work directly with engineers designing the offered products is also an advantage.\u201d - Robert Cieloch, COO, IS-Wireless About IS-Wireless IS-Wireless develops and delivers 4G and 5G mobile networks, supporting more users with better performance at lower costs by applying cutting-edge technologies. The company is a provider of software and hardware necessary for building 4G and 5G networks in the scope of both RAN and Core. IS-Wireless participates in the Open RAN revolution and expects significant changes in how networks are built and deployed in the coming years. The company has been recognized as one of a few European RAN vendors by leading telco operators, including Deutsche Telekom, Orange, Telecom Italia (TIM), Telef\u00f3nica, and Vodafone, in their report \u201cBUILDING AN OPEN RAN ECOSYSTEM FOR EUROPE.\u201d wireless.com/ Figure 6 - Supermicro IP65 Mounted Server and 2x SYS-220HE-FTNR", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "778adc61-63ec-4676-bde7-8ca9e4e680d4": {"__data__": {"id_": "778adc61-63ec-4676-bde7-8ca9e4e680d4", "embedding": null, "metadata": {"file_name": "Solution-Brief_Highly_Efficient_Redis_on_FatTwin.pdf", "publication_date": "February 2022", "referenced_websites": ["https://redislabs.com/blog/hood-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro X12 FatTwin Server Platform This discusses Redis on Flash (Scaleflux computational storage) on the Supermicro X12 FatTwin Server and the performance and cost benefits that this configuration provides to data center customers. Introduction to Redis on Flash Redis on Flash increases the capacity of a Redis cluster by utilizing high performance Flash memory as a storage tier below main memory (RAM). All keys are stored in RAM along with the hottest values. Cooler values are migrated to Flash. When a value stored in Flash is accessed, it is promoted back into RAM. More details about the internal operation of Redis- of-Flash can be found at redis-enterprise-flash-database-architecture. / Introduction to Redis On Flash 1 The Influence of Flash on Cluster Design 2 CSD 2000 in the U.2 Form Factor 3 Redis on Flash Hardware Configuration and Results 4 Conclusion 17 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 2 The Supermicro X12 FatTwin architecture provides flexibility and system accessibility for unique data center requirements. Unique one-half width nodes provide two nodes per rack unit, allowing for maximum reliability for modularized left and right nodes with redundant power supplies. These highly modular multi-node systems feature a tool-less design, and each node supports dual 3rd Gen Intel Xeon Scalable processors for improved performance. Redis on Flash utilizes RocksDB to manage the values stored in Flash. RocksDB employs a Log-Structured Merge-Tree (LSM-Tree) structure that makes insertions into the database very fast, but reads may require multiple storage access to retrieve a record. RocksDB is therefore ideally suited for write-heavy workloads. This aligns well with Redis on Flash, where frequently accessed data resides in RAM, and less frequently accessed data is tiered into Flash until it expires or is evicted. A typical Redis on Flash system will write frequently to Flash but read only occasionally. The data access pattern strongly influences the performance of a Redis on Flash deployment. A very high temporal locality of reference allows most values to be served from RAM, while random access patterns stress the Flash storage layer more. The higher the Flash to RAM ratio, the more dominant the Flash storage layer becomes to database performance. A practical recommendation is to maintain a 10:1 ratio of Flash to RAM, but the ideal ratio will depend on the workload and the goals of the Redis on Flash deployment. This document introduces a reference design that combines the ScaleFlux CSD 2000 solid-state storage drive and the Supermicro X12 FatTwin platform to deliver a high performance, low TCO platform that is uniquely suited to Redis on Flash deployments. Using a test cluster populated with reference design nodes, the performance under extreme workload corner conditions and real-world access patterns is evaluated to understand how the introduction of a Flash storage layer affects Redis performance. The Influence of Flash on Cluster Design Considerations The Flash storage layer in a Redis on Flash deployment resides on solid-state disks (SSDs). Due to the latency-sensitive demands of a Redis database, data center SSDs are preferable to hard disk drives. Also, the PCI-E interface will be faster than legacy SAS or SATA interfaces to the storage device. Modern datacenter grade SSDs are offered in capacities typically ranging from 2TB to 16TB, with average capacity increasing as Flash density continues to scale. At a 10:1 ratio of Flash to RAM, few SSDs per node are required in a Redis on Flash deployment. For example, a system with 1TB of RAM may deploy 10TB of Flash storage. The small number of SSDs needed for a Redis on Flash deployment leads to several important design considerations: 1. The SSDs must individually offer very high endurance with excellent mixed workload performance since the workload will not be spread out among a large quantity of SSDs. 2. The server platform does not need to provide a large quantity of drive bays, which enables high-density solutions. 3. The increased database capacity concentrates the number of shards per node, favoring the latest generation processors with higher core counts. In addition to addressing these key workload attributes, the capacity saved by transparent data compression can be returned to the host by expanding the logical capacity of the drive. Furthermore, capacity expansion can be performed while the drives are online without losing any existing data. This capability allows more data to be stored per dollar in a Redis on Flash cluster. 3 The following block diagram (Figure 1) shows where the compression and decompression take place within the Flash controller: Figure 1 - CSD 2000 Block Diagram The CSD 2000 is available in add-in card (AIC) and U.2 (2.5\u201d) form factors. Figure 2 shows the CSD 2000 in the U.2 form factor. Figure 2 - CSD 2000 in the U.2 Form Factor CSD 2000 in the U.2 Form Factor With individual Redis on Flash nodes requiring just a handful of SSDs, high-density systems are the ideal choice to maximize data center floor cost. The Supermicro X12 FatTwin provides unique half-width nodes to accommodate two nodes per rack unit. The modular left and right nodes feature redundant power supplies for high reliability. In addition, the nodes implement a tool-less design and are hot swappable for maximum serviceability. 4 Figure 3 - Supermicro X12 FatTwin server Each node supports dual 3rd Gen Intel Xeon Scalable processors that deliver the core counts needed to support densely sharded Redis on Flash databases. Up to 2TB of DRAM are supported per node. Redis on Flash Hardware Configuration Racklive, a leading global data center solutions provider, configured a test cluster combining the unique capabilities of the CSD 2000 and Supermicro X12 FatTwin platform. Racklive selected the Supermicro SYS-F610P2-RTN X12 FatTwin platform with four nodes populated. Each node contains 512GB of RAM, dual Intel(R) Xeon(R) Gold 6330N CPUs (112 total v-cores), and two 3.2TB CSD 2000 SSDs configured in RAID 0 for a total Flash capacity of 6.4TB per node. All nodes are connected via a 10Gbps network. Each node runs Ubuntu 18 (Bionic Beaver) and Redis Enterprise version 6.0.20-69. Three nodes are used as database nodes, with one node reserved as the client node. All benchmarking was performed using Memtier version 1.3.0. The following figure (Figure 4) illustrates the hardware configuration: 5 Figure 4 \u2013 Redis on Flash Hardware Configuration Redis on Flash Software Configuration A Redis on Flash database consisting of 1TB of RAM and 9TB of Flash capacity was configured for testing (10TB total memory limit). The database comprises 108 primary shards and 108 replica shards (216 total shards). For persistence, the fsync every second option (append-only log) was enabled. The append-only log, ephemeral data, and the RocksDB database all target mount points on the CSD 2000 RAID 0 array, which was formatted with an ext4 operating system. Note that the Linux page cache uses any free unused RAM to avoid disk access. Memory that is not used by Redis (or other host processes) will be mainly used to cache data managed by RocksDB. This improves the RAM hit rate for data stored in the Flash tier. Initial Database Population The database was populated with 6 billion records with a value size of 512 bytes. This object size creates a relatively large index that consumes over 60% of the available RAM reserved for Redis. This object size was chosen to place the most stress on the Flash storage layer (i.e., ensure the workload maximizes the random read IO demands on the Flash storage layer). The following Memtier parameters were used to fill the database: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=6000000000 -n allkeys --data-size=512 --ratio=1:0 --key-pattern=P:P --cluster- mode 6 Following the database fill, the memory profile is as follows: \u2022 Used Memory: 5.42 TB \u2022 Values in RAM: 310.86 M (6.56% of Values) \u2022 Values in Flash 4.74 G \u2022 Used RAM: 999.02GB (out of 1000GB) The key pattern set to \u2018P\u2019 equally divides the keyspace among threads and writes keys sequentially per thread. This results in a keyspace without gaps to avoid key misses. Corner Case Analysis Since RAM is both higher throughput and lower latency than the Flash storage tier, the highest performance will be achieved when a workload can be served primarily from RAM. Conversely, a workload that maximizes access to the Flash storage tier will determine the lowest performance. By characterizing 100% read (GET), 100% write (SET), and 70%/30% mixed read/write (GET/SET) workloads with both maximum RAM access and maximum Flash access (corner case analysis), the performance boundary conditions can be determined. GET - Maximum RAM Hit Ratio The RAM hit ratio can be driven to 100% by accessing a span of the keyspace that can fit entirely into memory. Once the main memory cache tier is hot (all accessed values have been promoted into RAM), the read performance that the test cluster can achieve reaches a maximum. This scenario results in approximately 1.5M ops/sec at a steady state at an average latency of 0.26ms (see Figure 5). 7 Figure 5 - GET Performance with Maximum RAM Hit Ratio The above data was collected using the following Memtier parameters: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=100000000 --data-size=512 --ratio=0:1 --key-pattern=P:P --cluster-mode --test- time=300 -x 5 GET - Minimum RAM Hit Ratio The RAM hit ratio can be driven close to zero with a large keyspace by accessing the entire keyspace using the parallel key pattern. This also ensures that no thread promotes a key into the main memory that another thread could subsequently access. At a steady state, this scenario results in approximately 842k ops/sec at an average latency of 0.54ms (see Figure 6). 8 Figure 6 - GET Performance with Minimum RAM Hit Ratio The above data was collected using the following Memtier parameters: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=6000000000 --data-size=512 --ratio=0:1 --key-pattern=P:P --cluster-mode SET \u2013 Maximum Hit Ratio Evictions to Flash can be avoided by accessing a span of the keyspace that can fit entirely into the main memory. Once the main memory cache tier is hot (all values to be updated have been promoted into RAM), the test cluster's write performance reaches a maximum. At a steady state, this scenario results in approximately 1.17M ops/sec at an average latency of 0.32ms (see Figure 7). 9 Figure 7 - SET Performance with Maximum RAM Hit Ratio The above data was collected using the following Memtier parameters: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=150000000 -n allkeys --data-size=512 --ratio=1:0 --key-pattern=P:P --cluster- mode -x 4 SET \u2013 Minimum Hit Ratio With a large keyspace, all SET operations can result in an eviction to Flash. This places the worst-case load on the Flash storage layer. At a steady state, this scenario results in approximately 359k ops/sec at an average latency of 0.88ms (see Figure 8). 10 Figure 8 - SET Performance with Minimum RAM Hit Ratio The 1:1 RAM to Flash access ratio reflects the nature of Redis on Flash, where SET operations are stored in RAM, and an equal number of older values are de-tiered to the Flash storage layer. The above data was collected using the following Memtier parameters: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=6000000000 -n allkeys --data-size=512 --ratio=1:0 --key-pattern=P:P --cluster- mode 70/30 GET/SET \u2013 Maximum Hit Ratio As with the pure GET and SET corner cases, exercising a keyspace that fits within the main memory results in maximum performance. At a steady state, this scenario results in approximately 1.59M ops/sec at an average latency of 0.25ms (see Figure 9). 11 Figure 9 - Mixed GET/SET Performance with Maximum RAM Hit Ratio The above data was collected using the following Memtier parameters: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=150000000 -n allkeys --data-size=512 --ratio=3:7 --key-pattern=P:P --cluster- mode -x 4 70/30 GET/SET \u2013 Minimum Hit Ratio As with the pure GET and SET corner cases, exercising the entire keyspace maximizes the use of the Flash storage layer. At a steady state, this scenario results in approximately 706k ops/sec at an average latency of 0.58ms (see Figure 10). 12 Figure 10 - Mixed GET/SET Performance with Minimum RAM Hit Ratio The above data was collected using the following Memtier parameters: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 64 --key- maximum=150000000 -n allkeys --data-size=512 --ratio=3:7 --key-pattern=P:P --cluster- mode Corner Case Testing Conclusions Flash latency is three orders of magnitude higher than RAM; nonetheless, running the workloads exclusively from Flash achieves 31% of RAM performance for write (SET) and 56% of RAM performance for read (GET). In both cases, the average latency remains below a 1ms threshold. The Flash storage layer provides an appreciable level of performance under worst- case conditions while extending database capacity by nearly 10x. 13 The following table (Table 1) summarizes the performance deltas for each corner test: Corner Case Maximum RAM Hit Ratio Maximum Flash Hit Ratio Flash Performance Delta kops/sec Avg. Latency (ms) kops/sec Avg. Latency (ms) kops/sec Avg. Latency 100% GET 1500 0.26 842 0.54 56% 208% 100% SET 1170 0.32 359 0.88 31% 275% 70/30 G/S 1630 0.25 706 0.58 43% 232% Table 1 - Summary of Corner Case Test Results Summary of Corner Case Test Results While corner case testing establishes the upper and lower bounds of performance, real world access patterns are expected to demonstrate a high degree of temporal locality of reference. As a result, there will be a strong access bias for more recent records available in RAM. The Gaussian key pattern option in Memtier can be used to model such access patterns. For the tests described in this section, the Gaussian access pattern under different standard deviation (\u03c3) values is used to characterize the performance. The following plot (Figure 11) illustrates the standard deviation values that were tested: 14 Figure 11 - Test Access Pattern Distributions The gray box is a visual aid representing the maximum quantity of values stored in RAM. It does not indicate the actual key range that will be present in RAM at any given time. The template for the Memtier commands used to test different standard deviation values is as follows: $ memtier_benchmark -s <Node 1 IP> -p <DB Port> --pipeline=8 -c 1 -t 8 --key- maximum=6000000000 -n allkeys --data-size=512 --ratio=3:7 --key-pattern=G:G --cluster- mode --key-stddev=<Set per Desired Standard Deviation> --distinct-client-seed 15 Figure 12 - Performance vs. RAM Hit Rate Performance remains highly consistent between a hit ratio of approximately 60% and 90%. This remarkably large band accommodates 40% of access, reaching the Flash storage tier with a high latency consistency. As the hit ratio decreases below 60%, the Flash layer becomes saturated. As the hit ratio exceeds 90%, performance becomes increasingly RAM dominated; however, note that while there are gains in the number of operations per second, the average latency is not significantly improved compared to hit ratios down to 60%. A Closer Look at Flash Throughput Figure 13 shows the instantaneous read throughput collected over a three-minute interval at three different sigma levels. 16 Figure 13 - Flash Read Throughput over Time The read workload from Flash is relatively steady. At the lowest RAM hit ratio tested (\u03c3 = 10% of the key range), the read throughput peaks to the maximum limit provided by the RAID0 array (6GiB/s). The write workload to Flash is much more mixed. It consists of persistence data, ephemeral data, and the RocksDB workload. Persistence data is flushed every second and produces a baseline workload. This can be most easily observed in the case where \u03c3 = 0.5 of the key range. On the other hand, the RocksDB workload is characterized by periodic bursts corresponding to table flushing from RAM (see Figure 14). Figure 14 - Flash Write Throughput over Time 17 Flash Endurance Flash devices are rated for a total amount of write activity (or endurance) expressed in either drive writes per day (DWPD) or in total bytes written (TBW). With the write heavy workload of RocksDB, it is essential to characterize the Flash storage layer's performance and its expected life. The following table (Table 2) shows the expected service life as a function of average write throughput and the PBW rating: Averag e MiB/s TBW Rating 10 PBW 15 PBW 20 PBW 30 PBW 35 PBW 40 PBW 100 3.02 Years 4.54 Years 6.05 Years 9.07 Years 10.58 Years 12.10 Years 200 1.51 Years 2.27 Years 3.02 Years 4.54 Years 5.29 Years 6.05 Years 300 1.01 Years 1.51 Years 2.02 Years 3.02 Years 3.53 Years 4.03 Years 400 0.76 Years 1.13 Years 1.51 Years 2.27 Years 2.65 Years 3.02 Years 500 0.60 Years 0.91 Years 1.21 Years 1.81 Years 2.12 Years 2.42 Years Table 2 \u2013 Drive Life vs. Write Throughput Values in green indicate the PBW ratings required to avoid wear-out within a three-year warranty term for a drive. Conclusion Combining the ScaleFlux CSD 2000 with the Supermicro X12 FatTwin platform creates a compelling platform for Redis on Flash deployments. Benchmarking data showed consistent, low-latency performance with RAM hit ratios as low as 60% using just two CSD 2000 devices per node. In addition, the half width architecture of the Supermicro X12 FatTwin platform slashes physical space requirements, while transparent datapath compression featured in the CSD 2000 cuts the storage space requirements \u2013 all while addressing the key workload concerns of a Redis on Flash deployment: write endurance and read performance.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "c20d2fbf-6578-494a-9206-3312ccce89bf": {"__data__": {"id_": "c20d2fbf-6578-494a-9206-3312ccce89bf", "embedding": null, "metadata": {"file_name": "Solution-Brief_VMware_vSAN_BigTwin_AI_Inferencing.pdf", "publication_date": "August 2023", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 SupermicroX13 BigTwin Multi-Node Infrastructure Solutions With the newfound popularity of AI solutions such as ChatGPT, enterprises are more motivated than ever to deploy AI use cases. By tapping into their rich data sources, enterprises seek to deliver deep real-time insights that improve operational efficiencies, lead to better product designs, improve customer satisfaction and employee productivity, and ultimately increase revenue streams. Challenges: Successful AI solutions begin with data and end with insights. Data is growing unchecked in both consumer segments and business segments. Consumers have increasing tools to create and share information, leading to data growth numbers that can hardly be comprehended. Businesses are doing their fair share to add to this mountain of data, hoping it can be leveraged to provide massive value as business intelligence. Even though data is in high supply, while insights can be elusive, that is not deterring enterprises from investing in AI. Worldwide spending on AI is expected to exceed $300 Billion by 2026. (According to IDC\u2019s Worldwide Artificial Intelligence Spending Guide, ). As businesses look to cash in on the promise of AI, they must improve data management or how data is collected, classified, and secured so that decisions and actions can be taken in the organization's best interest. 1 Challenges 2 Value of vSAN & AI 2 Supermicro X13 BigTwin for Efficiency and Performance 2 AI Benchmarks 3 Supermicro BigTwin Systems Details 4 Conclusion 6 References 6 2 The integration of AI and VMware vSAN is in its infancy. Developers and data practitioners are currently exploring how enterprises can use software-defined storage to utilize the valuable data stored in vSAN clusters for AI use cases. With a myriad of applications running in vSAN and the pervasive nature of AI, it's only a matter of time before advancements in vSAN, including greater scalability, improved performance, and better application management, combine with new AI tools and capabilities embedded in applications to offer the insights and innovation enterprises seek. Value of vSAN & AI: VMware vSAN provides a simple path to hyper-converged infrastructure (HCI) Compute Platform \u2022 CPU is useful for inference, fine-tuning models, and training smaller models \u2022 Application architectures deploy multiple instances of the application to scale as needed. \u2022 Multi-threaded processes offer high levels of resource utilization (CPU, network, and memory) Data Platform \u2022 Storage clusters for large amounts of structured and unstructured data \u2022 Backing hardware resources can be scaled as needed Supermicro X13 BigTwin for Efficiency and Performance Investing in the Supermicro X13 BigTwin for Artificial Intelligence (AI) workloads is a strategic decision that can transform a business's operations. With its density, customers get the latest and greatest processing power of multiple nodes working simultaneously or individually to accelerate complex AI tasks like Natural Language Processing (NLP) and Image Classification. With the Supermicro X13 BigTwin, customers are unlocking possibilities to drive businesses to new heights. The flexible options of 2U 4-Node and 2U 2-Node that the Supermicro X13 BigTwin offers enable enterprises to choose the most efficient configuration for their business needs. With its density, AI workloads demand immense computational resources, and the Supermicro X13 BigTwin delivers the computational power needed. By distributing the workloads across nodes, organizations can achieve remarkable speedups, reducing processing times from days to hours. This configuration means quicker insights, faster iterations, and a competitive edge in many industries. With the Supermicro X13 BigTwin power efficiency, by sharing resources in a single chassis, ensures that AI models reach their full potential while maximizing the return on the system investment. As organizations\u2019 AI initiatives expand, teams won\u2019t face the headache of outgrowing their infrastructure, as this has the flexibility and scalability that AI needs. Adding nodes is a seamless process that adapts to an organizations evolving needs. Whether interested in deep learning, neural networks, or big data analysis, Supermicro X13 BigTwin future-proofs operations, allowing teams to tackle even the most demanding AI workloads. Intel Advanced Matrix Extensions (Intel AMX) accelerates AI capabilities on 4 th Gen Intel Xeon Scalable processors, speeding up deep learning training and inferencing without additional hardware. It is ideal for NLP, recommendation systems, and image classification and is supported out of the box in the most popular AI frameworks such as TensorFlow, PyTorch, and OpenVINO Global Spending on AI by 2026 $300+ Billion 3 Supermicro X13 BigTwin Systems Highlights: \u2022 Dual Socket 4th Gen Intel Xeon Scalable Processors Per Node \u2022 Up to 4 Nodes per 2U \u2022 16 DIMM Slots per Node, Up to 4TB DDR5-4800 Memory \u2022 Flexible Storage Options Including ALL Nvme and Hybrid Nvme/SAS3/SATA3 in 2.5\u201d or 3.5\u201d \u2022 Flexible Networking Options from 1GBps to 400 Gbps Innovations \u2022 Supermicro X13 BigTwin flexible design with 2U 2-Node or 2U 4-Node \u2022 Supermicro AIOM \u2013 Most Flexible, Cost-Optimized Server I/O \u2022 Resource Sharing for Best Efficiency and TCO Intel AMX supports two data types, INT8 and BF16, for the matrix multiplication required for AI workloads: \u2022 INT8 is a data type used for inferencing when the precision of FP32, a single-precision floating-point format often used in AI, isn\u2019t needed. Because the INT8 data type is lower precision, more INT8 operations can be processed per compute cycle. \u2022 BF16 is a data type that delivers sufficient accuracy for most training. It can also deliver higher accuracy for inferencing if needed. AI Benchmarks Image Classification \u2013 ResNet50 This benchmark has become a standard benchmark in the deep learning community for evaluating the performance of image classification models. The Supermicro X13 BigTwin is powered by Intel 4th Gen Xeon Scalable Processors with AMX accelerators brings TCO benefits for certain AI workloads. Enterprises can make informed decisions, increase efficiency, and provide innovative solutions for their customers. 4 Figure 1 \u2013 Image Classification Performance Compared to the Previous Generation Natural Language Processing \u2013 BERT-Large This benchmark holds significant importance due to its pivotal role in evaluating and advancing language understanding models. BERT Large is derived from the BERT model capable of handling more complex language tasks and larger datasets. It can help enterprises draw insights for large and various data sources to provide personalized experiences that help increase 2,943 9,385 749 1002 4943 0 2,000 4,000 6,000 8,000 10,000 Intel AVX-512 for FP32 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AVX-512 for FP32 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel AMX for BF16 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel VNNI for INT8 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AMX for INT8 Intel Xeon Gold 6448Y processor 2.1GHz, 32 cores Images/Second/Node Up to 4.9x Faster Image Classification when using a 4th Gen Intel Xeon Scalable Processor with Intel AMX for BF16 4.9x Higher with virtually no accuracy loss vs AVX-512 FP32 3.1x Higher Gen-over-Gen 1.33x Gen-Over-Gen Image Classification on TensorFlow 2.11 Using ResNet50 Batch Size = 128, Multi-Instance (4 cores per Instance) Higher is Better $0.17 $0.06 $0.66 $0.57 $0.12 $0.00 $0.10 $0.20 $0.30 $0.40 $0.50 $0.60 $0.70 Intel AVX-512 for FP32 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AVX-512 for FP32 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel AMX for BF16 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel VNNI for INT8 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AMX for INT8 Intel Xeon Gold 6448Y processor 2.1GHz, 32 cores Cost per 1M images - 1h time frame Image Classification on TensorFlow 2.11 Using ResNet50 Batch Size = 128, Multi-Instance (4 cores per Instance) Cost Reduction 3y CAPEX - Lower is Better Figure 2 \u2013 CAPEX Calculation of ResNet50 Compared to the Previous Generation 13% less Gen-Over-Gen 63% less Gen-Over-Gen 82% less with virtually no accuracy loss 5 user engagement. The Supermicro X13 BigTwin with up to 4-Node density in a 2U form factor is well-suited for running large and complex models with the help of the Intel AMX accelerator. Figure 3 \u2013 Natural Language Processing Performance Compared to Previous Generation Figure 4 \u2013 CAPEX Calculation of BERT-Large Compared to Previous Generations Configurations: BASELINE: Intel Xeon Gold 6348 (ICX Config): 4-node cluster, Each node: 2x Intel Xeon Gold 6348 Processor, 1x Server Board M50CYP2UR, Total Memory 512 GB (16x 32GB DDR4 3200MHz), HyperThreading: Enable, Turbo: Enabled, NUMA noSNC, Intel VMD: Enabled, BIOS: SE5C620.86B.01.01.0008.2305172341(ucode:0xd000390), Storage (boot): 2x 80 GB Intel SSD P1600X, Storage (flat): 9x 3.84 TB Intel SSD DC P5510 Series PCIe NVMe , Network devices: 1x Intel Ethernet E810CQDA2 E810-CQDA2, at 100 GbE RoCE, Network speed: 100 GbE, OS/Software: VMware/vSAN 8.0U1, 21495797, Test by Intel as of 07/04/2023 using Ubuntu Server 22.04 VM (vHW=20, vmxnet3), vSAN ESA \u2013 Optimal default policy (RAID-5), Kernel 5.15, 46 150 21 26 105 0 30 60 90 120 150 Intel AVX-512 for FP32 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AVX-512 for FP32 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel AMX for BF16 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel VNNI for INT8 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AMX for INT8 Intel Xeon Gold 6448Y processor 2.1GHz, 32 cores Samples/Second/Node NLP on TensorFlow 2.11 Using BERT-Large Batch Size = 128, 28x2 and 32x2 Instances Higher is Better $0.19 $0.07 $0.41 $0.38 $0.09 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 Intel AVX-512 for FP32 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AVX-512 for FP32 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel AMX for BF16 Intel Xeon Gold 6448Y processor 2.1 GHz, 32 cores Intel VNNI for INT8 Intel Xeon Gold 6348 processor 2.6GHz, 28 cores Intel AMX for INT8 Intel Xeon Gold 6448Y processor 2.1GHz, 32 cores Cost per 1 sample - 1h time frame NLP on TensorFlow 2.11 Using BERT-Large Batch Size = 128, 28x2 and 32x2 Instances Cost Reduction 3y CAPEX - Lower is Better 1.23x Gen-Over-Gen 4x Higher with virtually no accuracy loss Up to 4x Faster NLP when using a 4th Gen Intel Xeon Scalable Processor with Intel AMX for BF16 3.2x Higher Gen-over-Gen 7% less Gen-Over-Gen 77% less with virtually no accuracy loss 64% less Gen-Over-Gen 6 intel-optimized-tensorflow:2.11.0, ResNet50v1.5, Batch size=128, VM=56vCPU+64GBRAM, Multi instance scenario (4 cores per instance), BERT-Large, SQuAD 1.1, Batch size=128, VM=56vCPU+64GBRAM Intel Xeon Gold 6448Y (4th Gen Config): 4-node, 2x Intel Xeon Gold 6448Y, 4x SYS-221BT-DNTR X13DET-B, Total Memory 1024 GB (16x DDR5 64GB 4800MHz), HyperThreading: Enable, Turbo: Enabled, NUMA noSNC, Intel VMD: Enabled, BIOS: 1.3(ucode:0x2b000461), Storage (flat): 7x 6.4 TB Solidigim P5620 Series PCIe NVMe , Network devices: 1x AOC-S100GC-I2C (Intel E810-CAM2), at 100 GbE RoCE, Network speed: 100 GbE, OS/Software: VMware 8.0U1, 21495797 (vSAN in ESA mode), Test by Intel as of 6/23/2023 using Ubuntu Server 22.04 VM (vHW=20, vmxnet3), vSAN ESA \u2013 Optimal default policy (RAID-5), Kernel 5.15, intel-optimized-tensorflow:2.11.0, ResNet50v1.5, Batch size=128, VM=64vCPU+64GBRAM, Multi instance scenario (4 cores per instance), BERT-Large, SQuAD 1.1, Batch size=128, VM=64vCPU+64GBRAM Conclusion The convergence of AI solutions and enterprise aspirations has propelled the drive toward AI development. The exponential growth of data both in customer and business realms, presents challenges, but enterprises remain with the need for more AI solutions, evidenced by the substantial investments in AI. As the world anticipates AI spending to surpass $300 Billion by 2026, the critical role of effective data management becomes paramount and Supermicro X13 BigTwin powered by 4th Gen Xeon Scalable Processors can bring added value for this AI investments. The integration of AI with Vmware vSAN is still in its early stages, with developers and data practitioners exploring ways to harness the potential of software-defined storage within the vSAN cluster for AI applications. The synergy between vSAN advancements and emerging AI capabilities promises to deliver the required insights and innovation to enlightened enterprises. Vmware vSAN\u2019s role as a pathway to hyper-converged infrastructure cannot be understated. Its compute and data platforms provide the necessary foundation for AI operations, offering scalable and efficient resources for various AI workloads. The Supermicro X13 BigTwin stands out as a strategic investment for AI workloads, providing the processing power and flexibility needed for complex tasks like Natural Language Processing and Image Classification which are used within inferencing, fine- tuning models, and training smaller models. The configuration options of the Supermicro X13 BigTwin, coupled with its power efficiency and scalability, ensure that organizations can meet the demands of expanding AI initiatives without outgrowing their infrastructure.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "6a2ffa8c-b573-4d54-8782-75dcb69af3fd": {"__data__": {"id_": "6a2ffa8c-b573-4d54-8782-75dcb69af3fd", "embedding": null, "metadata": {"file_name": "Solution-Brief_AI-ML_Horovod_SuperBlade.pdf", "publication_date": "April 2022", "referenced_websites": ["https://www.nvidia.com/en-us/data-center/data-center-gpus/qualified-system-catalog/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Extremely large AI and ML workloads can push the boundaries and capabilities of a multi-server platform. Even the most advanced CPUs and GPUs require coordination among multiple independent servers. Combining fast CPUs and GPUs with a fast and efficient networking architecture is critically important for these massive training workloads. A well-designed system scales when needed and is also available for smaller workloads requiring only a single system. This white paper describes how the Supermicro SuperBlade powered by 3rd Gen AMD EPYC processors excels at scaling distributed AI and ML training. Supermicro 8U SuperBlade Overview The Supermicro 8U SuperBlade system hosts up to 20 individual SuperBlade servers in a single 8U enclosure. The GPU- accelerated SBA-4119SG blade provides end-to-end AI/ML/DL solutions from the edge to the data center. This system integrates one 200G HDR InfiniBand switch and two 25G Ethernet switches in a highly scalable HPC environment that processes distributed ML workloads without losing flexibility or performance. This \u201ccloud-in-a-box\u201d configuration is also ideal for AI platforms where the experiment and deployment of ML models can be easily managed and scaled. A Supermicro SuperBlade achieved one of the best overall MLPerf Inference v1.0 performance scores. 1 System Configurations 2 AI/ML Workloads on the SuperBlade 4 SuperBlade AI/ML performance 8 Use Cases 11 Conclusion 11 Supermicro is the leading innovator in high- performance, high-efficiency server and storage technologies and a premier worldwide provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative by providing customers with the most energy-efficient, environmentally friendly solutions available on the market. 2 Horovod is an open-source framework for scaling deep learning training across hundreds of GPUs in parallel. It is a distributed, scalable deep learning training framework based on the ring allreduce algorithm that leverages High Performance Computing (HPC) techniques, such as MPI, Data Parallel, etc., to scale across multiple devices and nodes in both on-premise and cloud deployments efficiently. In addition, it enables running GPU-enabled AI/ML frameworks such as TensorFlow, Keras, PyTorch, and Apache MXNet. This paper describes the testing performed running image classification on eight GPU-enabled Supermicro 8U SuperBlade servers using the ResNet50 benchmark, demonstrating high throughput with distributed workloads across multiple nodes. System Configurations The Supermicro 8U SuperBlade Enclosure (SBE-820H-822) supports both CPU-only and GPU-enabled blades. The tests described in this whitepaper used the following components: Components Part Description QTY SBE-820H-822 8U SuperBlade Enclosure with 8x2200W PSUs 1 Management SuperBlade Chassis Management Module (CMM) 1 Networking 25GbE Switches 2 InfiniBand Switch 40-port 200G HDR InfiniBand Switch 1 Table 1 \u2013 SuperBlade chassis components Supermicro SuperBlade systems are available in both CPU-only (Table 2) and GPU-enabled (Table 3) configurations. Components Part Description QTY SBA-4114S-T2N Supermicro SuperBlade (AMD- powered single-socket) 10 CPU AMD EPYC 7713 64-Core processor 10 Memory 32GB DDR4-3200 2Rx4 ECC REG DIMM 80 Storage (M.2) 2TB M.2 NVMe SSD 20 Storage (U.2) 2TB U.2 NVMe SSD 20 Table 2 \u2013 CPU-only blade components 3 Components Part Description QTY SBA-4119SG Supermicro SuperBlade (AMD-powered single-socket) 8 CPU AMD EPYC 7713 64-core processor 8 Memory 32GB DDR4-3200 2Rx4 ECC REG DIMM 64 Storage 2TB M.2 NVMe SSD 8 GPU NVIDIA A100 PCIe 40GB 8 Table 3 \u2013 GPU-enabled blade components. Networking The density-optimized 8U SuperBlade supports advanced networking options to include 10G, 25G, 100G EDR and 200G HDR InfiniBand switches. In addition, each Supermicro SuperBlade chassis includes networking switches for both internal and external connections, as shown in Figure 1. Figure 1 - Networking component topology CMM 4 Figure 1 illustrates the following components: - 200G HDR InfiniBand Switch: Mainly used for high bandwidth HPC communications between the blades. This switch can also boost performance by fully leveraging Remote Direct Memory Access (RDMA) to bypass the CPU. It also supports NVIDIA GPUDirect using the NVIDIA Ampere architecture, provided that the OFED driver is installed and the Subnet Manager is running on one of the blades. - 2x 25G Ethernet Switches: Primarily used for data traffic or NIC bonding for each blade for redundancy and higher bandwidth. You can also configure the uplinks on the switch modules with different VLANs to reduce routing latency in large data center environments. - CMM Module: Supermicro Chassis Management Module (CMM) is primarily used to access the chassis for initial configuration, monitoring components, and firmware upgrades. Once each blade is configured, you can directly access that blade\u2019s BMC via the CMM from any routable subnets. NVIDIA Certifications The AMD-based GPU blade SBA-4119SG is an NVIDIA-Certified Systems (NCS) 2.3, as shown in Table 4. These certifications demonstrate the flexibility of the Supermicro SuperBlade for AI/ML applications in either the data center or at the edge. System Category GPU Type Certifications Datacenter (compute only) NVIDIA A100, A30 Single node, Multinode, GDS certified with NVIDIA Driver 460.73.01 Datacenter Datacenter (compute and graphics) NVIDIA A40, A10 Table 4 \u2013 NCS 2.3 certifications AI/ML Workloads on the SuperBlade The Message Passing Interface (MPI) is the primary tool for making multiple ML sessions run in parallel by scaling a single-GPU training script across multiple GPUs in a single- or multi-node configuration. The Horovod MPI wrapper provides a straightforward interface for distributing ML workloads across the HPC environment with performance on par with both bare metal systems and Docker containers, as described here. Supermicro performed the benchmark tests described in this whitepaper using the Horovod Docker configuration shown in Table 5. 5 Configuration Items Descriptions System SKU Supermicro SuperBlade SBA-4119SG (8 nodes) # of nodes 8 Chassis 8U System BIOS SMBIOS 3.3.0 CPU 3rd Gen AMD EPYC 7003 Series Processor (7713 64-Cores, 2.0GHz, 225W TDP) GPU NVIDIA A100 PCIe 40GB VBIOS 94.02.5C.00.04 CUDA 11.4 OS Ubuntu 20.04.2 Docker engine 20.10.8 NVIDIA driver 460.73.01 NVIDIA docker 2.6.0 Horovod Docker v0.23.0 Dataset Synthetic Benchmark type Training Table 5 \u2013 Benchmark configuration 6 Figure 2 provides a hardware and software stack graphical depiction of the information listed in Table 5. It consists of the Horovod Stack at the top, followed by SuperBlade hardware configuration at the bottom. Figure 2 \u2013 Hardware and software stack 7 Running Horovod with Docker A prebuilt Horovod Docker image is available from the Docker hub. The Docker file can be customized to fit any specific test environment. Figure 3 summarizes the steps to configure Horovod for the tests described in this whitepaper. Figure 3 \u2013 Horovod configuration summary Here are the steps described below to run Horovod on the eight GPU enabled Supermicro SuperBlade servers: 1. Initiate the Horovod container. docker run -it --network=host --cap-add=IPC_LOCK --device=/dev/infiniband \u2013 gpus all \\ horovod /bin/bash 2. Run the benchmark on a single node inside the Horovod container. horovodrun -np 1 -H localhost:1 \\ python scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\ --model resnet101 \\ --batch_size 64 \\ --variable_update horovod 3. Start the benchmark on two nodes inside the Horovod container. horovodrun -np 2 -H localhost:1,host2:1 \\ python scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\ --model resnet101 \\ --batch_size 64 \\ --variable_update horovod 4. Add hosts as described in steps 1 to 3. 8 SuperBlade AI/ML Benchmark Performance The Multi-node benchmark with TCP tests was performed with Horovod distributing multiple AI/ML workloads with a batch size of 256 FP32 across all eight nodes using image database samples from GoogleNet, ResNet50, ResNet101, and Inception3. Figure 4 uses several popular benchmarks to show how the number of images trained per second scales as blades are added. Figure 4 \u2013 Adding nodes boosts benchmark performance. (Source: internal Supermicro testing) From the above testing, it is evident that adding SuperBlade nodes delivered scale-out performance gains. For example, Figure 4 shows that 2 SuperBlade nodes process 3,622 GoogleNet images/second, and the number scales up to 13,475 GoogleNet images/second on 8 SuperBlade nodes. 0 2,000 4,000 6,000 8,000 10,000 12,000 14,000 16,000 1 2 3 4 5 6 7 8 Images/second Number of SuperBlade Nodes Horovod Multi-node Performance without RDMA Different AI/ML Models batch size 256 FP32 GoogleNet ResNet50 ResNet101 Inception3 9 Optimized Multi-node SuperBlade Benchmark Performance with RDMA The Horovod Docker image also includes a built-in InfiniBand driver that supports the Mellanox Quantum RDMA features. Enabling RDMA in the Horovod Docker container boosts AI/ML training performance by allowing the data path to bypass the CPU and directly access system memory. Figure 5 \u2013 Enabling RDMA boosts ResNet50 performance (Source: internal Supermicro testing) For example, figure 5 above shows how enabling RDMA boosts ResNet50 benchmark performance by up to 30%. Note: Other ML models (e.g., VGG16, ResNet101, and GoogleNet) produce similar benchmark results. 10 Figure 6 shows each of the eight blades with a single GPU connected to the CPU in that blade. Horovod is a data-parallel distributed framework; it divides the whole dataset and copies it to each GPU. Figure 6 \u2013 Eight-blade SuperBlade system architecture One GPU acts as the centralized parameter server that processes and redistributes the training results from different nodes. SuperBlade performs well in HPC environments because of its density and flexibility. The 8U SuperBlade, when fully populated with 20 nodes, is flexible to accommodate both Inferencing and Training simultaneously. For example, two of the 20 nodes can be used for inferencing, and the remaining 18 nodes can be used for Training models. 11 Use Cases Supermicro SuperBlade can improve performance-intensive computing, which is used to process large volumes of data or execute complex instruction sets in the fastest way possible. This is commonly used in artificial intelligence (AI), modeling and simulation, and Big Data and Analytic use cases. The Supermicro GPU-based SuperBlade accelerates solutions across retail, healthcare, financial service, transportation, automotive, media and entertainment, and manufacturing. Having data insights at hand, digital innovators disrupt competitors\u2019 business models aggressively by innovating at a much faster pace. Some of the other areas where SuperBlade can provide benefits are: \u2022 Data driven Enterprise Intelligence and AI everywhere \u2022 Micro-segmented, hyper-personalized online shopping platforms \u2022 GPS-driven ride-sharing companies \u2022 Recommendation-driven streaming channels \u2022 Adaptive learning\u2013based educational tech companies \u2022 Conversational AI-driven work scheduling SuperBlade offers excellent operational efficiency by effectively allowing enterprises to automatically streamline processes, monitor for potential breakdowns, apply fixes and more efficiently facilitate the flow of accurate and actionable data throughout companies. In addition, this process improvement permits enterprises to offload maintenance work to machines so they can spend more time doing what they do best - which is innovating. Conclusion Supermicro SuperBlade powered by 3rd Gen AMD EPYC processors delivers exceptional performance and TCO across multiple HPC and AI/ML workloads. GPU-accelerated SuperBlade servers are ideal for running converged AI/ML and HPC workloads, as evidenced by the excellent Horovod AI/ML workload performance described in this white paper and the ability to scale training across multiple nodes. In addition, Supermicro SuperBlade can accommodate simultaneous non-ML or AI/ML training and inferencing workloads. Supermicro GPU accelerated SuperBlade servers deliver high performance with high density, high throughput, and excellent scalability.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "3af86ea8-8180-4495-8103-fba605e48081": {"__data__": {"id_": "3af86ea8-8180-4495-8103-fba605e48081", "embedding": null, "metadata": {"file_name": "Solution-Brief_SuperCloud_Composer.pdf", "publication_date": "January 2021", "referenced_websites": ["https://www.networkworld.com/article/2959532/startup-says-it-has-solved-server-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "SUPERCLOUD COMPOSER Your Infrastructure Gateway SuperCloud Composer is a composable cloud management platform that provides a unified dashboard to administer software-defined data centers. Supermicro\u2019s cloud infrastructure management software brings speed, agility, and simplicity to IT administration by integrating data center tasks into a single intelligent management solution. Our hybrid approach allows traditional paradigm data centers to continue to support their existing operations while allowing their current workloads to have the flexibility to move to a disaggregated infrastructure model. Our robust composer engine can orchestrate cloud workloads through a streamlined Redfish API. SuperCloud Composer also monitors and manages the broad portfolio of multi-generation Supermicro servers and third-party systems through its data center lifecycle management feature set from a single unified console. 1 Key Benefits 2 Features 3 Hardware and Software Requirements 11 Virtual Machine Appliance 11 Supported Server Platforms 12 SuperCloud Composer License 12 Supermicro is a global leader in high performance, green computing server technology and innovation. We provide our global customers with application-optimized servers and workstations customized with blade, storage, and GPU solutions. Our products offer proven reliability, superior design, and one of the industry\u2019s broadest array of product configurations, to fit all computational needs. 2 Today\u2019s modern data centers face the growing need for operating efficiency through cost reduction in IT spending. Supermicro understands that IT organizations require a management platform to span multiple generations of infrastructure technology. IT managers are faced with the ever-rising cost of technology refresh and scale-out of systems due to Big Data. The Intel Data Center Group estimates resources are underutilized at rates of up to 45 %, and data center operating efficiency is only at 50 %. In addition, PUE costs are increasing, data center real estate square footage prices are on the rise, and manpower hour rates are climbing exponentially. In addition, Patrick Nelson from Network World (Reference 1 ) estimates in-house server capacity to be in the range of 20% to 50% even when you factor in virtualization gains. The traditional IT paradigm resulted in a cumbersome hardware provisioning process, with a fixed ratio of computing, storage, accelerator resources, and a lack of a one-size-fits-all platform capable of monitoring, telemetry, analytics, and intelligent system management. The new SuperCloud Composer embodies Supermicro\u2019s approach to software-defined and composable cloud solutions for future data centers. This provides you some of the key benefits and features of SuperCloud Composer and system requirements and licensing details of the solution. Key Benefits of SuperCloud Composer \u2022 A single-pane-of-glass platform with a streamlined, intuitive management interface \u2022 A standardized Redfish Northbound API Message Bus for easy third-party software platform integration \u2022 A scalable management platform without adding unnecessary complexity \u2022 A unified dashboard that encompasses compute, storage, networking, and rack management \u2022 The ability to monitor and manage all elements of the resource pools in a Composable Disaggregated Infrastructure (CDI) \u2022 Inherently software-defined and automated in support of multi-tiered datacenter-to-edge cloud infrastructure management \u2022 Role-based access control to support modern data center security policies \u2022 Rich analytics, telemetry, and intelligent system lifecycle management \u2022 Parallel multi-system upgrade and configuration capability reducing hardware maintenance downtime 3 Features Intelligent Data Center Management Network Storage Disaggregated Infrastructure Composed Node Administration of Management Appliance Comprehensive system health monitoring and alerting Top-of-rack (TOR) Network Provisioning utilizing streamlined GUI wizards JBOF management Integration support for GigaIOTM PCIe Switch OS deployment in seconds utilizing fast-deploy (Centos, RHEL Ubuntu) Support for SNMP v2 and SNMP v3 Rack management Powerful network configurator wizard that creates network template build plans Storage fabric configurator wizard that creates storage template build plans for NVMe network fabrics JBOF management Repository to store golden images for fast-deploy deployments Change IP address/CIDR of SCC appliance Device discovery and deep discovery Robust network orchestrator that utilizes a REST API gateway to push network configuration build plans to infrastructure fabric Creation of storage integration support, including GigaIO Switch JBOG management Operating provisioning utilizing PXE boot (ESX 6.8, RHEL 7.5, Ubuntu 18.04, 16.04, 14.04, SUSE Enterprise Linux 15.1, and Centos 7) DNS Pod management utilizing POD View Switch sweeper Management support for ISCSI initiators and targets Allocation of GPUs from a resource pool utilizing GigaIO PCIe fabric Software inventory to manage Kickstart and ISO images for PXE deployment NTP BMC access Switch configuration detail Management support for NVMe initiators and targets Allocation of NVMe storage from a resource pool utilizing GigaIO PCIe fabric Support to send logs to a Syslog server iKVM console Interface status and counters RAID management and storage controller monitoring for Broadcom 3008 and 3108 Dynamic fabric topology discovery Streamlined installation configuration wizard that utilizes Ansible Playbooks UID management MAC address table Fabric configuration and reporting BIOS harvesting Zero-touch provisioning Fabric representation persistence & recovery Asset Tagging Analytics of thermal and power for JBOG resource box Physical asset collateral and collection JBOG physical asset collection FRU management Interface status and counters DMI GPU monitoring 4 Dashboard Dashboard is an information management tool to provide aggregated views of POD health, visualized system data analytics, activity event timeline tracking utilizing standardized icon footprints, providing the administrator at a glance awareness of data center operations. Administrators can click on each component within the dashboard to learn more detailed metadata about system status, composed node status, and allocated storage. POD View The Pod View\u2019s rack management solution provides Data Center operatives the flexibility to organize their data center requirements based on common workloads assigned to a rack deployment either at the edge or physical appliances within a Data Center that are miles away. 5 Network SuperCloud Composer (SCC) enforces a network blueprint where it constructs VLANs to partition specific workloads from segmented broadcast domain traffic. SuperCloud Composer utilizes a rich feature called network provisioning. It pushes build plans to data switches either as single-thread or multi- thread operations where Composer updates multiple switches simultaneously by shared or unique build plan templates. Build plan templates for data switches are constructed by a Network Configurator Wizard in JSON format and pushed by a Network Orchestrator engine utilizing industry standardized API calls. During network management operation, SuperCloud Composer also offers a rich, intelligent network agent called switch sweeper to maintain configuration compliance between original build plans constructed by network configurator and operational build plans within switch dynamic memory. 6 Fast OS Deployment and Provisioning During the fast-deploy composition phase, architects execute a composed new node wizard where snapshots of OS images are composed with customized metadata that has been ingested within the OS image. The architect instructs this customized metadata when performing the creation of a user-defined build template. 7 Composed Node and GigaIOTM PCIe Switch Integration SuperCloud Composer delivers a software-defined model, leveraging pools of Composable Disaggregated resources across GigaIO\u2019s PCIe switch fabric for low latency workloads Supermicro\u2019s software framework enables Administrators to deploy collections of fluid resources (GPU, FPGA, and NVMe flash) utilizing an intuitive provisioning wizard within seconds. Each composed system can allocate resources on-demand across a scalable GigaIO FabreX fabric and then return resources back to the pool for other systems. 8 Composable Rack-Scale Infrastructure Integration with GigaIO FabreX TOR Switch to deliver NVMe-oF, DAS performance with NAS sharing, and GPUDirect RDMA to GPU systems or JBOGs. 9 JBOF Management SuperCloud Composer uplifts the JBOF management experience by exposing an intuitive drive map tool giving the end-user visualization of drive level presence. 10 Physical Asset Collateral The compute module is a collection of monitored hosts that have been successfully registered by administrators. It is important to note that monitored hosts cannot perform simple system management tasks unless data center operatives complete drawer configuration functions during POD View execution. SuperCloud Composer provides an inventory of fluid pools of compute to manage physical fabric resources individually without entering the BMC webUI, allowing administrators to drill down and look at the physical attributes of a system. 11 Hardware and Software Requirements Standalone Server SYS-1019P-WTR (SuperServer 1019P-WTR) HA Server Configuration 2 of SYS-1019P-WTR (SuperServer 1019P-WTR) Motherboard Super X11SPW-TF CPU Single Socket P (LGA 3647) (Intel Xeon Scalable Processor) Memory 256GB SSD Drive 2X 1TB SATA set to Raid 1 Operating System Ubuntu 18.04 LTS Browser Chrome, Firefox Virtual Machine Appliance Hypervisor Support Centos, RHEL, VMware ESX Anti-affinity Group virtual machines across different hypervisors CPU Requires one unit of CPU, 16 core count Memory 256GB SSD Drive RAID SAN configuration of 1TB Operating System Ubuntu 18.04 LTS Browser Chrome, Firefox Hypervisor Support Centos, RHEL, VMware ESX 12 Supported Server Platforms (as of September 23rd, 2020) AS -2124BT-HNTR SYS-1019P-WTR SYS-2029U-E1CR4 SYS-6019P-WT SYS-7049GP-TRT AS -2124BT-HTR SYS-1029GP-TR SYS-2029U-E1CR4T SYS-6019P-WTR SYS-F619P2-RC0 MBE-314E-420 SYS-1029GQ-TRT SYS-2029U-E1CR25M SYS-6019U-TN4RT SYS-F619P2-RC1 MBE-628E-822 SYS-1029GQ-TVRT SYS-2029U-E1CRT SYS-6019U-TR4 SYS-F619P2-RT MBE-628L-816 SYS-1029GQ-TXRT SYS-2029U-E1CRTP SYS-6019U-TR4T SYS-F619P2-RTN SBE-414E-422 SYS-1029P-N32R SYS-2029TP-HC1R SYS-6019U-TR25M SYS-F629P3-RC0B SBE-610J-822 SYS-1029P-WTRT SYS-2029TP-HTR SYS-6019U-TRT SYS-F629P3-RC1B SBE-614E-822 SYS-1029U-E1CR4 SYS-2029U-TN24R4T SYS-6019U-TRTP2 SYS-F629P3-RTB SBE-820C-820 SYS-1029U-E1CR4T SYS-2029U-TR4 SYS-6019U-TRTP SYS-F629P3-RTBN SSE-F3548 SYS-1029U-E1CR25M SYS-2029U-TR4T SYS-6029BT-DNC0R SSE-F3548S SYS-1029U-E1CRT SYS-2029U-TR25M SYS-6029BT-HNC0R SSE-F3548SR SYS-1029U-E1CRTP2 SYS-2029U-TRT SYS-6029P-WTR SSE-G3648B SYS-1029U-E1CRTP SYS-2029U-TRTP SYS-6029TP-HC0R SSE-G3648BR SYS-1029U-TN10RT SYS-2029UZ-TN20R25M SYS-6029TP-HTR SSG-136R-N32JBF SYS-1029U-TR4 SYS-4029GP-TRT2 SYS-6029U-E1CR4 SSG-6029P-E1CR12H SYS-1029U-TR4T SYS-4029GP-TRT3 SYS-6029U-E1CR4T SSG-6029P-E1CR12T SYS-1029U-TR25M SYS-4029GP-TRT SYS-6029U-E1CR25M SSG-6029P-E1CR16T SYS-1029U-TRT SYS-4029GP-TVRT SYS-6029U-E1CRT SSG-6049P-E1CR24H SYS-1029U-TRTP2 SYS-5019P-MR SYS-6029U-E1CRTP SSG-6049P-E1CR36H SYS-1029U-TRTP SYS-5019P-MT SYS-6029U-TNR SSG-6049P-E1CR60L+ SYS-1029UZ-TN20R25M SYS-5019P-WT SYS-6029U-TR4 SYS-1019D-16C-FHN13TP SYS-2029BT-HNC0R SYS-5019P-WTR SYS-6029U-TR4T SYS-2029BT-HNTR SYS-5019S-MT SYS-6029U-TR25M SYS-2029BT-HTR SYS-5029P-WTR SYS-6029U-TRT SYS-2029GP-TR SYS-6019P-MT SYS-6029U-TRTP Licensing Requirements for BMC advanced features BMC Data Center Product SKU: SFT-DCMS-Single Note: SuperCloud Composer (SCC) enforces licensing keys for advanced data center BMC licensing and SCC monitor node license. SuperCloud Composer License Type of License Description SCC Appliance License P/N Trial License 90-day trial license with 200 monitored system activation See the hardware requirements above. SFT-SDDC-TRIAL (for SCC software and up to 200 systems managed) Monitor License (per node) Single monitored system license activation See the hardware requirements above. SFT-SDDC-SINGLE (1 license key per system managed by SCC appliance) BMC License DCMS License Monitored system SFT-DCMS-SINGLE (1 license key per system managed by SCC appliance) 13", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "27c208e5-3141-42e0-8bd3-5fd676f49010": {"__data__": {"id_": "27c208e5-3141-42e0-8bd3-5fd676f49010", "embedding": null, "metadata": {"file_name": "Solution-Brief_Blacknut_Cross_Media.pdf", "publication_date": "April 2023", "referenced_websites": ["www.blacknut.com", "https://newzoo.com/resources/blog/the-games-market-in-2022-the-year-in-numbers", "www.radianarc.io.", "https://newzoo.com/resources/blog/how-much-time-do-consumers-spend-on-media-platforms"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro GPU Edge Infrastructure Solution The advance of Cloud Gaming technology has removed all hardware barriers preventing video games from being played by the broadest audience. Dedicated video game consoles or PCs are no longer needed, and the on-screen experience (whether sports, movies, TV shows, or documentaries) can now be expanded upon with an interactive gaming experience at the simple push of a button. In partnership with Supermicro and Radian Arc, Blacknut recently announced the launch of a cross-media entertainment offering bringing together a cloud Gaming-as-a-Service solution, bundled and fully managed game licensing, in-depth content metadata, and a global hybrid cloud solution, all within a comprehensive package: \u2022 Turnkey cloud gaming service (integrable as an App or through an SDK); \u2022 A catalog of 600+ premium games from major publishers and studios working with movie IPs; 1 Cloud Gaming as-a-service and Cross-Media Integration 2 Case Study \u201cCliq - best of alles\u201d 4 Radian Arc GPU Edge Infrastructure Solution Overview 6 Why Supermicro 7 Conclusion 8 References 9 2 \u2022 Expansive Metadata and APIs to quickly cross-integrate with existing media catalogs; \u2022 Hybrid cloud infrastructure with more than 23 local Points Of Presence (POP) across all five continents; This turnkey solution allows media companies to easily integrate cloud gaming within over-the-top (OTT) and subscription video-on-demand (SVOD) platforms to deliver new cross-media experiences to their subscribers. Cloud Gaming-as-a-Service and Cross-Media Integration The impact of technology on cross-media content Cross-media entertainment is not a recent phenomenon; for the past 150 years, technologies like the phonograph, radio broadcasting, cinema, televisions, and personal computers have contributed to the development and extension of original content from one medium to another. Thanks to the democratization of video gaming and the increased sharing of original IPs across industries, playing video gaming is no longer perceived as a marginal form of entertainment, or reserved for a small sub-group of tech fans. In fact, with many gaming IPs having grown to become a ubiquitous part of pop culture, and the creative IPs from video games now seen in the same vein as original novels or movies, the boundaries between target user groups have all been removed. Similar to how past technology breakthroughs shaped the way we collectively interact with content today, cloud gaming is the technological revolution within the cross-media entertainment landscape which will open up gaming content to all existing media platforms. Cross-Media Cloud-Gaming Solution 1. Benefits of adding cloud gaming to existing media platforms Interactive entertainment and Game streaming, in particular, have been identified as \u201cthe next big thing\u201d in revenue growth, Newzoo forecasted that over 30 million paying users spent a combined $2.4 billion on cloud gaming services in 2022,1 with expected revenues to grow to $8.2 billion by 2025. SVOD (Subscription Video On Demand) platforms are investing in movies and TV shows based on gaming IPs in a bid to attract and retain new gaming centric users and, in some cases, even directly publishing games based on popular internal IPs. Gen Z consumers spend an average of just over 12 hours per week on video games2, surpassing TV by approximately half an hour. The only media platform that accounts for higher hours per week is social media. The difference between Gen Z and other consumers in terms of time spent with video games and virtual worlds is not so stark, suggesting that every generation is leaning toward the more immersive platform, especially as more types of entertainment are getting folded in. 1 2 As a global leader in high performance, high efficiency data center technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 3 Catering to gaming and IPs fans, old and new, is a proven strategy to increase time and attention from subscribers and help in justifying ever increasing costs and subscription fees. For content distributors, like ISPs, device manufacturers, OTT services, and Media companies, Cloud Gaming is an opportunity to provide their subscribers with interactive features and access to a whole new media catalog previously locked away behind a hardware wall. By providing additional content verticals to a single content platform, users\u2019 fidelity and time spent within the platform will be increased. For the Gaming Industry and game publishers, this is an opportunity to have a whole new population of gamers discover, or re-discover, games based around an IP or universe they might not have known existed or were unable to previously access because of the prerequisite hardware needed to run them. 2. Driving usage and user engagement with cross media experience. The expansive metadata dataset available through the Blacknut API enables the close integration of game IPs and universes with existing media ecosystems and recommendations algorithms. Linking video games with media leverages the continuous growth in casual gamers with the universe or content they might be fond of. For content distributors, like ISPs, device manufacturers, OTT services, and Media companies, an all-in-one media ecosystem encourages the cross-pollination of users between cloud gaming and traditional media catalogs of relevant shows and movies. Users can switch between forms of entertainment seamlessly without leaving their platform of choice. As cross-media works both ways, video and gaming content can be advertised to subscribers, surfacing content they might be unaware of and incentivizing them to remain within the ecosystem. Figure 1: Illustration of cross-media integration and content suggestion between movies and video-games interface 4 Case Study: \u201cCliq \u2013 best of alles\u201d Cliq is the new flagship streaming service from CLIQ Digital for the German market. About CLIQ Digital Founded in 2005, CLIQ Digital specializes in online advertising and streaming services that are advertised towards specific consumer groups. Starting with the licensing and selling of single-category content services, CLIQ released its first all-in-one streaming service in 2019 and its flagship direct-to-consumer streaming service, with movies and series, music, audiobooks, sports, and cloud gaming in 2022. The company is headquartered in Germany and currently has around 1.8 million paid memberships on numerous streaming services across 30+ countries. Product Vision The ever increasing demand of the last few years has shown that streaming content is here to stay, but a scattered market quickly resulted in a streaming service overload, leaving consumers feeling overwhelmed by the ever-increasing number of content-specific platforms and rising costs. CLIQ Digital believes that streaming content should be accessible to everyone and that simplicity means one service, one price and one login that goes beyond one content category and profiles. To offer an all-in-one cross-media service containing movies and series, music, audiobooks, sports, and games, CLIQ Digital chose Blacknut\u2019s turnkey solution to handle the cloud gaming portion. Figure 2: Cliq\u2019s best of alles offer 5 Technical Implementation Using Blacknut\u2019s APIs, CLIQ Digital incorporates videogames metadata into its CLIQ Tech Hub, where they store, bundle, and curate digital content. Proprietary data-driven marketing and business knowledge are then combined inside the digital content warehouse, which will ultimately drive the streaming service end-user experience through the Radian Arc GPU Edge IaaS platform powered by Supermicro GPU Edge Infrastructure solution. The Cliq Streaming Service allows users to play on a large variety of devices, including Android Mobile and TV, Webapp for iOS, Windows, and MacOS computers, Web Browsers (Chrome, Safari, Firefox), FireOS, and Samsung Tizen. Project Key facts At the end of 2022, CLIQ Digital launched its mass-market all-in-one streaming service for the German market: Cliq. The service offers unlimited access and bundles five different types of streaming content: movies and series, music, sports, audiobooks, and more than 600+ Console quality grade games. The subscription fee for the service is \u20ac6.99 per month with a free trial period of 30 days. The work done in conjunction with Cliq\u2019s technical team positions Radian Arc IaaS and Blacknut GaaS platforms for cross-media integration immediately. Figure 3: Implementation of Blacknut cloud Gaming-as-a-Service within Cliq \u2013 best of alles (Image Courtesy Blacknut) 6 Radian Arc GPU Edge Infrastructure Solution Overview (powered by Supermicro) \u2022 Radian Arc is a provider of cloud gaming technology through proprietary GPU Edge infrastructure deployed to telecommunications, cable networks, and game publishers. \u2022 Radian Arc offers an out-of-the-box white-label solution for telco and cable companies who want to offer cloud gaming services to their customers. \u2022 Radian Arc can deliver cloud gaming in any region of the world when integrating their GPU Edge cloud gaming technology with your network. \u2022 Radian Arc technology stack provides additional monetization and utilization of 5G and cable networks from an active and lucrative audience: gamers. \u2022 Subscription-based cloud gaming services, powered by Radian Arc, can increase retention and revenue of your existing network. \u2022 Radian Arc\u2019s new container based solution offers massive scalability and support for metaverse applications. \u2022 Radian Arc sees cloud gaming as the tip of the spear, leading to more monetization opportunities with applications beyond gaming: AI, IoT, smart home, smart city, and more. Compelling 5G applications No CAPEX investment to have the latest GPU technology and Supermicro servers Marketing solutions to drive revenue from the 5G applications BASED PURPOSE-BUILT, FLEXIBLE AND MASSIVELY-SCALABLE GPU EDGE INFRASTRUCTURE SOLUTION AS-4124GS-TNR Flexible GPU Server with directly attached 6-8 GPUs with dual- root balance architecture, and titanium-grade efficient redundant power supplies, supports double AMD EPYC 7003/7002 Series Processors, and 8TB Registered ECC DDR4 3200MHz SDRAM in 32 DIMMs AS-1114CS-TNR Cloud optimized and scalable Management Server with flexible advanced I/O and storage configuration, supports single AMD EPYC 7002/7003 Series Processor, and 16 DIMMs; up to 4TB 3DS ECC DDR4-3200MHz RDIMM/LRDIMM SSE-x3548S Industry leading feature-rich and cost optimized ToR Switch, 48x 10Gbps Ethernet ports, 6x 100Gbps Ethernet ports, Switching Capacity: 2.1 Tb 7 Why Supermicro Supermicro offers the industry\u2019s broadest portfolio of cloud-optimized game servers to support the highest density of gaming CCU\u2019s (concurrent users), high I/O throughput, and open management. To manage mission-critical game servers in the cloud, the Supermicro CloudDC product line offers the industry's broadest portfolio of servers optimized for ultimate scalability and flexibility with advanced I/O features, innovative tool-less designs, and open architecture. Supermicro\u2019s costoptimized and feature rich line of ToR networking switches stitches everything together effortlessly at the GPU Edge. Supermicro products are assembled and tested at production facilities in the USA. For EMEA and APAC companies, Supermicro builds products at production facilities in the Netherlands and Taiwan. Now, media and entertainment companies worldwide can depend on Total IT-Solution from Supermicro to accelerate their unique workloads and services. \u201cSupermicro\u2019s scalable servers offer the highest density of gaming CCUs, providing Radian Arc with the ideal platform to power our GPU edge technology solutions and deliver unparalleled gaming experiences to our customers,\u201d David Cook, CEO, of Radian Arc. \u201cWe are thrilled to finally announce the general release of our GaaS cross-media solution, which was the fruit of more than two years of behind-the-scenes labour with our clients, content, and infrastructure partners.\u201d Said Olivier Avaro, CEO, Blacknut. \u201cThis is an important milestone for the company, not only for being live with CLIQ Digital, a major media industry player, but also because our partnership with Radian Arc and Supermicro enables us to immediately address a global market, with the ability to scale massively in line with our business requirements.\u201d 8 Conclusion Blacknut\u2019s cloud Gaming-as-a-Service platform combined with Radian Arc\u2019s GPU Edge Infrastructure-as-a-Service platform powered by Supermicro GPU Edge Infrastructure solution offers a flexible turnkey solution to add gaming content easily and quickly to existing platforms. The solution enables common target groups to interact with all the available content they might be interested in without the need to leave the platform or subscribe to third party services. Cloud Gaming Service: Service providers can launch cloud gaming services or activate gaming content with Blacknut and Radian Arc. Games: In addition to a licensed catalog of 600+ AAA to Indie games, Blacknut also provides the following white glove services: \u2022 Onboard games wish lists and help negotiate exclusive agreements with publishers \u2022 Support \u201cBring Your Own Game\u201d (BYOG) and Freemium Game models \u2022 Assist in developing IP-licensed games in partnership with specialized studios like Gameloft, Outright, and others \u2022 Specialized internal Marketing Agency team to support go-to-market plan and manage subscribers' engagement, as well as a complete assets library and editorialized content. Infrastructure: Radian Arc\u2019s proprietary infrastructure is scalable and cost-efficient with the following: \u2022 Integrated with Blacknut\u2019s Public and Private \u2013 Hybrid - Cloud Environment. \u2022 Supermicro purpose-built, flexible, and massively scalable GPU Edge Infrastructure Solution \u2022 Optimized with Netint high-density container-based solution \u2022 Support for Windows, Linux, and Android games \u2022 Optimized to support 5G slicing with Ericsson and Quality on Demand (QoD) APIs The platform is live in 45 countries, with distribution partnerships signed with OTT providers such as CLIQ Digital, and carriers such as STC (Saudi Telecommunication Company) Group, Bridge Alliance, CKH Group, or M1. It is also pre-embedded in set-top boxes and TV ecosystems such as the Samsung Gaming Hub, the LG Gaming Shelf, and Amazon FireTV. 9", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "55a65f6e-2dc0-4476-86aa-b951ccbe6445": {"__data__": {"id_": "55a65f6e-2dc0-4476-86aa-b951ccbe6445", "embedding": null, "metadata": {"file_name": "Solution-Brief_RedHat-OpenShift.pdf", "publication_date": "September 2019", "referenced_websites": ["https://www.supermicro.com/en/solutions/red-hat-openshift"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Red Hat OpenShift Solutions Scalable PaaS cloud infrastructure powered by OpenShift Container Platform BUSINESS VALUES \u2022 Built with the latest compute technologies \u2022 Complete HW and SW stack \u2022 Cloud native, variety of workload support \u2022 Certified and optimized \u2022 Fast, automated deployment \u2022 Global Support options Overview Supermicro and Red Hat have partnered to develop a best-in-class solution based on industry- leading SuperServers, SuperStorage, and Red Hat OpenShift. The solution provides the ability to deploy and manage containers in private or hybrid cloud environments by combining automation with performance and efficiency. Supermicro OpenShift solution utilizes advanced features of SuperServers and SuperStorage such as resource saving, high density, high availability, and high efficiency. It is a fully optimized turnkey solution for fast and easy deployment. Solution Features \u2022 An integrated container application platform (CaaS/PaaS/FaaS) with enterprise-grade Kubernetes and infrastructure management, simplified for on-premise deployment and scale \u2022 Capable of deployment in less than an hour with high availability and persistent storage; automated with Red Hat Ansible, and configured to be horizontally scalable to multiple racks \u2022 Utilizing latest technologies such as Intel Xeon Scalable Processors, NVMe, 25G Ethernet, and resource-saving SuperServer and SuperStorage servers \u2022 Hardware accelerated performance options such as Intel Optane DC persistent memory, Nvidia GPU accelerators, and 100GbE networking are available for demanding workloads \u2022 Native security for container-based applications with role-based access control and security- enhanced enterprise ready Linux RedHat OpenShift Architecture . OpenShift with Gluster OpenShift with Ceph OpenShift Hyperconverged Master node 3* nodes (BigTwin) 3* nodes (BigTwin) 3* nodes (Ultra) Infra node 3* nodes (BigTwin) 3* nodes (BigTwin) 3* nodes (Ultra) App node 6* nodes (BigTwin) 6* nodes (BigTwin) 3* nodes (Ultra) Storage node 3* nodes (1U12Bay) 3* nodes (Simply Double) Share with App Node Compute cores 240 (up to 336 max) 240 (up to 336 max) 96 (up to 168 max) Total Memory 3TB (up to 36TB max) 3TB (up to 36TB max) 1.5TB (up to 18TB max) Total Storage (Raw) 576TB 288TB 144TB Networking 1 x 10G + 2 x 25G Software RHEL 7.5 or Red Hat CoreOS 7.5 / OpenShift 3.11 or 4.1 SKU Name SRS-OPSHFT-GLFS-01 SRS-OPSHFT-CEPH-01 SRS-OPSHFT-HCI-01 Supermicro Red Hat OpenShift Solutions MKT-0001-09/2019 Rev 1.1 RedHat OpenShift Configurations Hardware Features: \u2022 2nd Generation Intel Scalable Processors -Cascade Lake \u2022 NVMe support \u2022 25GE networking \u2022 Large memory footprint \u2022 High availability \u2022 Ceph storage with NVMe Journal [Master / Infra / App] Compute Node [Ceph / Gluster] Storage Node BigTwin Ultra 1U 12 Bay Simple Double CPU 40 cores 32 cores 32 cores 32 cores RAM 512GB 512GB 96GB 96GB Storage 1.92TB 48TB 96TB 192TB NIC 2*10GbT, 4*25GE 2*10GbT, 4*25GE 2*10GbT, 4*25GE 2*10GbT, 4*25GE SKU Name SYS-2029BT-RH-OPSHFT SYS-2029U-RH-OPSHFT SSG-6019P-RH-OPSHFT SSG-6029P-RH-OPSHFT Server Features Management Switches NIC 10 GBase-T (48*10GbT, 4*40GE ) 25 GE (48*25GbT, 6*100GE ) SKU Name SSE-X3348TR SSE-F3548SR Switch Specification Please contact your Supermicro Sales representative or your local authorized reseller", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a8a22770-8aeb-4db7-b6b9-a93c150d8149": {"__data__": {"id_": "a8a22770-8aeb-4db7-b6b9-a93c150d8149", "embedding": null, "metadata": {"file_name": "Solution-Brief_Workstations_and_2U2N.pdf", "publication_date": "March 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 1 WHITE PAPER New technologies are driving the delivery of many new products that interact with people and the environment, whether they are flying vehicles or systems that affect the environmental temperature of airflow. Ansys Fluent and Ansys Mechanical applications running on Supermicro systems enable fast development of these products. Supermicro workstations and servers supporting the AMD Ryzen Threadripper PRO CPU (single socket) run Ansys applications in a shorter time but at two-thirds the power consumption of dual processor systems. As a result, these are ideal solutions for mission-critical Ansys Fluent simulation for enterprises and SMBs alike. This explains the performance and power savings for Ansys software running on a Supermicro workstation and the Supermicro 2U-2Node server. 1 Benefits of Single CPU Systems 2 Performance Results 2 Test Scenarios and Performance Settings 6 Ansys Fluent and Mechanical Software 6 AMD Threadripper PRO CPU 7 Supermicro Workstation 7 Supermicro 2U-2Node Server 8 Conclusion and References 8 2 2 In addition to supporting the high-performance AMD Ryzen Threadripper PRO CPUs, the Supermicro workstation and Supermicro 2U-2Node server also support GPU options to enhance Ansys software operations. Whether for individual users or as scalable data center compute clusters, Supermicro workstations and the Supermicro 2U-2Node server systems provide the performance and energy savings that can address the demands of high-performance Ansys Fluent, Mechanical, and other software in the Ansys offering. Benefits of Single CPU in a System The Supermicro workstation and the Supermicro 2U-2Node system support a single AMD CPU in the system. Since the AMD Ryzen Threadripper PRO delivers up to 64-core in a single CPU, the system performance rivals dual-CPU systems. These systems offer the latest two generations of AMD Ryzen Threadripper PRO processors: 3995WX and 5995WX for 64-core systems. Other AMD CPUs for single-socket systems are also supported. Performance Results Below are the performance results of the Ansys Fluent and Ansys Mechanical benchmarks for two generations of the AMD Ryzen Threadripper PRO CPU running in the Supermicro workstation. For each CPU, the benchmarks were run with 32 active CPU cores (processes) and 64 active CPU cores (processes). The key result is that the 3rd generation 5995WX CPU delivers significantly better performance than the 2nd generation 3995WX. While the CPUs running with 64-cores deliver higher performance compared to when running with 32-cores, the improvement is incremental. For 32-core operations, 5995WX and 3995WX are similar in performance. There are potential software licensing implications of using 32-core CPUs instead of the 64-core CPU. Regardless of running the software with 32-core or 64-core active, it is better to use the 5995X processor as the processor has a larger L3 cache, significantly improving the system's performance running the Ansys software. As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 0 500 1000 Single socket system Dual socket system Power Consumption (CPU + Memory + Disk) 1S vs. 2S (Watts) 3 3 Ansys Fluent benchmarks (version 2021 R2) include the following: \u2022 Pump (2 million cells) \u2022 Aircraft Wing (2 million cells) \u2022 Fluidized Bed (2 million cells) \u2022 ICE (2 million cells) \u2022 Rotor (3 million cells) \u2022 Sedan (4 million cells) \u2022 Oil rig (7 million cells) \u2022 Combustor (12 million cells) \u2022 Aircraft Wing (14 million cells) \u2022 Landing gear (15 million cells) \u2022 LM 6000 (16 million cells) \u2022 Exhaust system (33 million cells) \u2022 Combustor (71 million cells) \u2022 F1_racecar (140 million cells) 7,470 5,217 5,157 5,096 3,733 1,162 711 448 441 278 265 234 43 19 6,817 4,707 4,354 3,663 3,454 849 675 357 325 239 222 198 39 18 7,162 4,088 4,894 4,146 3,532 1,005 694 401 415 269 266 232 43 21 6,275 4,285 3,992 3,131 3,072 811 636 347 330 241 231 191 37 19 - 5,000 CORE SOLVER RATING (HGIHER IS BETTER) ANSYS FLUENT BENCHMARKS ON SINGLE 3995WX/5995WX, RUNNING WITH 32-PROCESS AND 64- PROCESS, WINDOWS OS, ANSYS 2021 R2 5995WX-64 core 5995WX-32 core 3995WX-64 core 3995WX-32 core 4 4 5,577 4,281 3,528 3,119 3,039 748 637 255 325 239 222 186 39 18 3,917 4,271 2,465 2,961 2,696 833 648 20 385 257 252 190 43 17 5,231 4,023 3,136 2,775 2,799 746 549 240 320 239 226 178 37 17 3,837 4,192 2,444 2,860 2,648 826 622 40 373 251 250 187 42 18 - 5,000 CORE SOLVER RATING (HGIHER IS BETTER) ANSYS FLUENT BENCHMARKS ON SINGLE 3995WX/5995WX, RUNNING WITH 32-PROCESS AND 64- PROCESS, WINDOWS OS, ANSYS 2022 R1 5995WX-64 process 5995WX-32 process 3995WX-64 process 3995WX-32 process 5 5 Ansys Mechanical benchmarks include the following: Engine Block V21cg-3 Tractor Rear Axle V21cg-2 Power Supply Module V21cg-1 Gear Box V21ln-1 Semi-Submersible V21sp-2 Peltier Cooling Block V21sp-1 Radial Impeller V21ln-2 CG - 100 million degrees of freedom V21cg-100mdof Speaker V21sp-3 Turbine V21sp-4 BGA V21sp5 SP \u2013 25 million degrees of freedom V21sp-25mdof SP \u2013 8 million degrees of freedom V21sp-8mdof 819 423 401 500 294 327 258 133 28 19 14 6 3 681 455 475 397 271 310 233 128 20 15 13 8 3 780 484 424 475 285 260 272 137 26 16 12 8 3 624 435 459 361 259 229 229 130 21 13 11 7 3 - 500 1,000 CORE SOLVER RATING (HGIHER IS BETTER) ANSYS MECHANICAL BENCHMARKS ON SINGLE 3995WX/5995WX, RUNNING WITH 32-PROCESS AND 64- PROCESS, WINDOWS OS, ANSYS 2021 R2 5995WX-64 core 5995WX-32 core 3995WX-64 core 3995WX-32 core 6 6 Test Scenarios and Performance Settings Ansys Fluent is a general-purpose computational fluid dynamics (CFD) application that models fluid flow, heat, mass transfer, chemical reactions, and more. This study analyzes the performance of Ansys Fluent software as measured by fourteen common benchmark workloads provided by Ansys. These workloads vary in size and complexity, so the aggregate scores offer a representative view of performance for a wide variety of end-user scenarios. Testing was conducted by the performance consulting firm MVConcept. MVConcept ran the benchmarks on the Supermicro systems with the AMD Ryzen Threadripper PRO CPU using multiple permutations of CPU, operating system, software versions, launch modes, and BIOS settings. \u2022 Systems Configurations tested: o The Supermicro workstation and the Supermicro 2U-2Node systems, each with the following configurations \u25aa 3995WX processor with 512GB memory \u25aa 5995WX processor with 512GB memory o While the CPU supports 64-core, some tests were run with 32 cores active (to explore the impact of the available L3 cache), while other tests used all 64 available cores \u2022 Operating system: Windows 10 Professional (x64) Build 19044.1706 (21H2) and CentOS Linux release 8.5.211 \u2022 Ansys Fluent versions: 2020 R1 and 2021 R2 \u2022 Launch mode: Default is the way to launch as explained inside Ansys Doc -r20.1.0 -g 3d -mpi=intel -t36 -i C: /fluent_bench/combustor_12m_36.jou \u2022 Intel MPI Version 2018 Update 3 Build 20180411 \u2022 BIOS settings: For the AMD Ryzen Threadripper PRO: \u25aa NPS (NUMA per socket) equal to 1, 2, or 4 (4 is recommended) \u25aa SMT (Symmetric Multithreading) equal to ON and OFF (OFF is recommended) \u2022 The BIOS settings proved to be especially important for realizing the optimal performance from the AMD Ryzen Threadripper PRO when running the tested applications. NPS (NUMA Per Socket) controls the number of NUMA (Non- uniform Memory Access) nodes, which enables fine-tuning of the transfer speed between specific CPU cores and the closest (fastest) available memory channels. SMT (Symmetric Multithreading) determines whether each physical core can appear to the operating system as two \u201clogical\u201d cores, which can boost performance significantly in applications that perform many smaller or random tasks. However, the tested Ansys applications perform best when each physical core is fully dedicated to the compute-intensive and memory bandwidth intensive simulation workload. Therefore, Supermicro recommends using NPS=4 and SMT=OFF when running Ansys Fluent and Ansys Mechanical on systems with AMD Ryzen Threadripper PRO. Ansys Fluent and Mechanical Software Ansys develops some of the most widely used Multiphysics engineering simulation software solutions for product design, testing, and operation. With the Supermicro systems, designers and engineers can run complex simulations on the desktop earlier in the design process to test and validate design ideas without tying up valuable data center resources. Ansys Fluent is a general-purpose computational fluid dynamics (CFD) application that models fluid flow, heat, mass transfer, chemical reactions, and more. The software runs in individual workstations or in a scalable server cluster. Ansys Mechanical enables you to solve complex structural engineering problems and make better, faster design decisions. With the finite element analysis (FEA) solvers available in the suite, you can customize and automate solutions for your structural mechanics problems and parameterize them to analyze multiple design scenarios. In addition, Ansys Mechanical is a dynamic tool that has a complete range of analysis tools. 7 7 AMD Ryzen Threadripper PRO Processor 64-core AMD Ryzen Threadripper PRO processor (3995WX) specs and 5995WX specs. The 32-core CPUs in this family are also listed here. The 5995WX and 3995WX with bigger cache improve performance, even when running with 32-process Ansys software. CPU 3995WX 3975WX 5995WX 5975WX AMD Ryzen Generation SECOND GEN SECOND GEN THIRD GEN THIRD GEN # CPU cores 64 32 64 32 Base Clock 2.7GHz 3.5GHz 2.7GHz 3.6GHz L3 Cache 256MB 128MB 256MB 128MB Default TDP 280W 280W 280W 280W Memory Support 8 x DDR4-3200 8 x DDR4-3200 8 x DDR4-3200 8 x DDR4-3200 PCIe Generation PCIe 4.0 PCIe 4.0 PCIe 4.0 PCIe 4.0 Supermicro Workstation with the AMD Ryzen Threadripper PRO Processor Supermicro workstation with the AMD Ryzen Threadripper PRO AMD Ryzen Threadripper PRO 5000WX/3000WX Series Processor, up to 64 Cores 8 DIMMs; up to 2TB Registered ECC DDR4 3200-MHz Memory 6 PCI-E 4.0 x16 slots M.2 Interface: 4 PCI-E 4.0 x4, RAID 0, 1, 5 & 10, M.2 Form Factor: 2280, 22110, M.2 Key: M-Key U.2 Interface: 2 U.2 sockets (Software RAID 0,1) 1x 10GBase-T LAN port, 1x 1GbE LAN port (shared with IPMI) 4 fixed internal 3.5\"/2.5\" SATA drive bays, 2 fixed front 2.5\" SATA drive bays, 4 M.2 1 VGA port (dedicated for IPMI) 7.1 HD Audio 2000W Platinum Level Power Supply GPU support and applications. Height 21.06\" (535mm), Width 8.74\" (222mm), Depth 22.56\" (573mm) 8 8 Supermicro 2U-2Node Server with the AMD Ryzen Threadripper PRO Processor Supermicro 2U-2Node server supporting the AMD Ryzen Threadripper PRO Two hot-pluggable systems (nodes) in a 2U form factor. Each node supports the following: Single Threadripper PRO 5000WX/3000WX Series Processor, or Single AMD EPYC 7003/7002 Series Processor (The latest AMD EPYC 7003 Series Processor with AMD 3D V-Cache Technology requires BIOS version 2.3 or newer) Max 2TB Registered ECC DDR4 3200MHz SDRAM in 8 DIMMs Up to 6 PCI-E Gen 4 x16 (4 internal, 2 external) slots, 1 PCI-E 4.0 x8 AIOM slot M.2 Interface: 2 PCI-E 4.0 x4, M.2 Form Factor: 2280, 22110, M.2 Key: M-key Integrated IPMI 2.0 + KVM with dedicated LAN 2 front Hot-swap 2.5\" U.2 NVMe Gen4 drive bays AST2600 BMC 2600W Redundant (1+1) Power Supplies, Titanium Level (96%) GPU support and applications Height 3.47\" (88mm), Width 17.6\" (447mm), Depth 29.9\" (760mm) Conclusion The Supermicro workstation and the Supermicro 2U-2Node servers deliver dual-CPU performance with a single processor, and ISV is certified for multithreaded application environments. The Supermicro 2U-2Node server has two systems in a 2U form factor that enables the customer to use one server to run pre-processing of data before running Ansys software, while the second server would run the Ansys software. With up to 64 cores, 128 PCIe lanes (Gen 4), up to 2TB of memory, and an 8-channel memory architecture, designers and engineers now have access to data center power on their desktops in a compact and economical package. Backed by enterprise-level features for seamless security, manageability, and support; the Supermicro systems are ideal solutions for enterprises and SMBs alike, creating mission critical simulations. Supermicro offers these as integrated solutions, including systems, software, and support. Please call your Supermicro representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "0739bd8d-3315-4197-a08f-7d65853966ab": {"__data__": {"id_": "0739bd8d-3315-4197-a08f-7d65853966ab", "embedding": null, "metadata": {"file_name": "Solution-Brief_RedHat-OpenShift_202102.pdf", "publication_date": "February 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "RED HAT Red Hat is the world\u2019s leading provider of open source enterprise IT solutions. We\u2019re here to help you address change with open principles so that you can navigate today\u2019s need for transformation, and prepare for the future. With engineers connected to open source communities, the freedom of our subscription model, and a broad portfolio of products that\u2019s constantly expanding, Red Hat is here to help you face your business challenges head-on. RAPIDLY DEPLOY HYBRID CLOUD INFRASTRUCTURE The Supermicro Solution for Red Hat OpenShift Container Platform \u2022 Deploy hybrid cloud faster and reduce time to market with Supermicro servers that are tested, certified and optimized to run Red Hat OpenShift Container Platform. Designed for scale-out environments, this solution can easily scale to petabytes of storage and thousands of cores. \u2022 Lower the risk of new technology with proven reference configurations integrated by joint engineering teams that let you start with the right configuration, scaling gracefully as your needs grow. \u2022 Simplify procurement and support with a complete integrated hardware and software stack that delivers cloud-native development and workload support\u2014 all available from Supermicro. Supermicro Solution for Red Hat OpenShift Container Platform The Supermicro Solution for Red Hat OpenShift Container Platform combines the advanced features of SuperServers with Red Hat\u2019s enterprise-grade Kubernetes platform. Red Hat OpenShift Container Platform offers a consistent hybrid cloud foundation for building and scaling containerized applications. It provides a powerful container cluster management and orchestration system, natively integrating Docker and Kubernetes technologies for demanding enterprise applications. Whether creating a solution for a single department or a hyper-converged infrastructure, the Supermicro Solution for Red Had OpenShift Container Platform is consistent and easy to install. It also integrates seamlessly with Red Hat OpenShift Container Storage to provide container- native file, block, and object storage that can move with applications and microservices from on-premises environments to the cloud and back. Supermicro is a global leader in high performance, green computing server technology and innovation. We provide our global customers with application- optimized servers and workstations customized with blade, storage, and GPU solutions. Our products offer proven reliability, superior design, and one of the industry\u2019s broadest arrays of product configurations, to fit all computational needs. Simplify hybrid cloud Supermicro and Red Hat have partnered to develop a best-in-class solution based on industry-leading SuperServers, and Red Hat OpenShift Container Platform. With this innovative solution, organizations can deploy and manage containers in private or hybrid cloud environments, combining automation with performance and efficiency to: OPEN AWARD WINNING PLATFORMS: BIGTWIN MULTI-NODE HYBRID SYSTEM \u2022 Hot-Pluggable 1/2 RU Dual- Socket Nodes in a 2U System \u2022 Double the density for compute and memory performance \u2022 10% Power Savings vs Four 1U Servers, Based on STH Study1 \u2022 Support for NVMe drives and All-flash SSDs with HW RAID ULTRA ALL-FLASH NVME SYSTEMS \u2022 10 NVMe drives in 1U, 24 NVMe drives in 2U \u2022 Offers unrivaled performance, flexibility and serviceability \u2022 Ideal for Enterprise applications and workloads SYS-2029BT-HNR (Rear) SYS-1029U-TN10RT SYS-2029U-TN24R4T Rapidly Deploy Hybrid Cloud Infrastructure 2 * Please check with your Supermicro sales representative and website for compatibility and configuration details. Actual product may vary in appearance due to product configuration. Storage (NVMe) Memory 16 cores 24 cores 32 cores 192 GB 384 GB 768 GB 7.6 TB 15.2 TB 45.6 TB SKU Name Master Node Infra Node Total Memory Compute Cores Total Storage Networking U CP 3x nodes (Ultra 1U) Entry App Node OCS Cores Performance Performance Plus 3x nodes (Ultra 2U) 3x nodes (Co-located) 2 3x nodes (Ultra U) 3x nodes (Ultra 1U) 8x nodes (Ultra 2U) 48 144 256 256 144 48 576 GB 2304 GB 6144 GB 22.8 TB 91.2 TB 364.8 TB 1x 1G + 2x 25G 1x 1G + 4x 25G 2x 1G + 2x 100G SYS-1029 -OPNSHFT SYS-2029BT-OPNSHFT SYS-2029U-OPNSHFT Data Switch 1x SSE-C3632SR 2x SSE-C3632SR 2x SSE-C3632SR SRS-OPNSHFT-01 SRS-OPNSHFT-02 SRS-OPNSHFT-03 Mgmt. Switch 1x SSE-G3648BR 1x SSE-G3648BR 2x SSE-G3648BR 3x nodes (2U 4-Node BigTwin) 3x nodes (2U 4-Node BigTwin) 6x nodes (2U 4-Node BigTwin) U * Contact your Supermicro sales representative or your local authorized reseller", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "8ee35d51-ff3d-45bc-9c78-fa5abfdfce92": {"__data__": {"id_": "8ee35d51-ff3d-45bc-9c78-fa5abfdfce92", "embedding": null, "metadata": {"file_name": "Solution-Brief_NEBS_5G.pdf", "publication_date": "May 2020", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 5G SERVER SOLUTION 3 ULTRA 1U SUPERSERVER APPLICATION 4 ULTRA 1U CARRIER GRADE SUPERSERVER OVERVIEW 5 SPECIFICATIONS CARRIER-GRADE NETWORK EQUIPMENT BUILDING SYSTEMS (NEBS) LEVEL 3 CERTIFIED SERVERS FOR 5G TELECOM SOLUTIONS - Telecommunications is one of the fastest-growing markets as 5G comes into the picture. As a global leader in enterprise computing, storage, networking solution, and green computing technology, Supermicro has optimized its 1U Carrier Grade NEBS Level 3 certified Ultra SuperServers to bring powerful processing capabilities to 5G telecommunication markets. 5G TELECOM SERVER SOLUTION NEBS compliance is a critical requirement for equipment deployment in the telecommunications environment globally. Supermicro\u2019s Carrier Grade Ultra SuperServers will power the next-generation 5G network infrastructure for operators and service providers. The Ultra 1U SuperServers offer NEBS Level-3 compliance running on Intel Xeon Scalable processors known for high performance, stability, and global availability. The 1U rackmount AC and DC servers deliver scalability, safety, and reliability. Supermicro 11th Generation Ultra Carrier Grade SuperServer features: \u2022 Open standard systems: \u2013 Enhanced capabilities based on industry-leading Supermicro products \u2013 Proven compatibility and reliability from standard Supermicro Ultra servers \u2013 Rapidly scalable and easily expandable \u2022 Telecom industry-standard solutions: \u2013 Validated to NEBS Level 3 standards GR-63 Issue 5 and GR-1089 Issue 7 standards \u2013 Enabled for operation in higher environments than traditional data centers \u2013 Designed for extreme conditions such as high humidity, high altitude, earthquakes and dust \u2022 Global regulatory support and availability Carrier-Grade Network Equipment Building Systems (NEBS) Level 3 Certified Servers for 5G Telecom Solution 2 ULTRA 1U SUPERSERVER APPLICATIONS CLOUD DATA CENTERS \u2013 Enterprise-grade computer systems \u2013 High-performance computational systems \u2013 Big data applications TELECOM CENTRAL OFFICE \u2013 NEBS Level 3 certified, both GR-63 and GR-1089 \u2013 Meets high Telecom central office application requirements \u2013 Resistant to humidity, high altitude, earthquakes, and dust \u2013 Highly available, reliable and dependable 5G EDGE COMPUTING \u2013 Flexibility with open hardware designs to support mixed workloads \u2013 Multi-Access Edge Computing (MEC), provides execution resources for applications with networking close to the end users \u2013 Low-latency, high-bandwidth, and high-concurrency device processing and data offload as well as trusted computing and storage from cloud data center 0 seconds 10 Gbps 20 minutes 1% downtime 20 milliseconds 5 miles 2 minutes 3 ounces SPEED 1ms LATENCY 1 0 G b p s Carrier-Grade Network Equipment Building Systems (NEBS) Level 3 Certified Servers for 5G Telecom Solution 3 - ULTRA 1U CARRIER GRADE SUPERSERVER OVERVIEW The Supermicro Ultra 1U Carrier Grade AC/DC SuperServers are designed with two Intel Xeon Scalable processors with up to 24 cores each, supporting 150 watt TDP, and delivers high-performance compute, storage and networking for Edge micro data centers, standard data centers, and telecom central office applications. These new 1U servers support up to 6TB of DDR4 memory in 24 slots and features three PCI-E 3.0 expansion slots for flexible networking as well as storage configurations. The convenient 12 all-hybrid NVMe/SATA/SAS hot-swappable drive bays offer complete storage versatility. A compact 29.1\u201d (739mm) depth and NEBS-3 certification make these systems valuable assets for organizations looking to modernize their data centers, telecom central offices, and Edge infrastructure. These are the first of many Ultra SuperServers that will be NEBS-certified and optimized for 5G and telecom installations. 1029U-TN12RV-NEBS (AC/DC) ULTRA FRONT VIEW 1029U-TN12RV-NEBS (AC) ULTRA REAR I/O VIEW SYS1029U-TN12RV-NEBS-DC REAR I/O VIEW Carrier-Grade Network Equipment Building Systems (NEBS) Level 3 Certified Servers for 5G Telecom Solution 4 1029U-TN12RV-NEBS/1029U-TN12RV-NEBS-DC CARRIER GRADE ULTRA SUPERSERVER SPECIFICATIONS FEATURES TECHNICAL SPECIFICATIONS Processor 2x Intel Xeon Scalable processors up to 24-core, 2.1 GHz, 150W TDP Memory 24 DDR4 DIMM slots supporting RDIMM, speeds up to 2933 MHz, 6TB max 16GB, 32GB, 64GB DIMMs supported Storage Controllers Onboard: Intel C621 chipset SATA 3 (6Gbps) Internal: Broadcom 3108L SAS3 (12Gbps) Drive Bays Up to 12x hot-swap 2.5\u201d NVMe/SATA drive bays (SAS support via HBA/SAS controller) Power Supplies Titanium redundant hot-swap 1600W AC or Gold redundant hot-swap 1300W DC power supplies Dimensions Form Factor: 1U Depth: 29.1\u201d (739 mm) Embedded Management \u2022 Intel Node Manager \u2022 Redfish API \u2022 IPMI 2.0 \u2022 KVM with dedicated LAN \u2022 NMI \u2022 SSM, SPM, SUM \u2022 SuperDoctor 5 Embedded NIC Options AOC-URN4-b2XT-O: 2-port 10GbE RJ45, Broadcom BCM57416 AOC-URN4-m2TS: 2-port 25GbE SFP28, Mellanox CX-4 Lx EN Add-on NIC Options AOC-S25G-M2S-O: low-profile 25G dual port SFP28, based on Mellanox, two SFP28 25Gpbs Ethernet ports AOC-S100G-M2C-O: low-profile adapter card based on Mellanox ConnectX-4 chipset, two QSFP28 100Gpbs Ethernet ports Ports Front ports: USB 2.0 Rear ports: Video, serial, 2 x USB 3.0, IPMI Rack Rail Support Ready Rails, Sliding Rails Environmental Specs (NEBS Level-3) Temperature: Continuous operatingtemperature of -5C to 40C; 96 hour operating excursions from -5C to 55C Humidity: Operating Humidity of 5% to 85% with excursions of 5% to 93%, Altitude: Up to 4000m; Sea Level -60M to 1800M; -61m to 1829m at 40C; from 1829M to 3960m at 30C Seismic: Operational resiliency up to Richter 7.5 seismic event (Zone 4 seismic event) EMI: Immunity up to 8kV/15kV or contact/air Fire resistance: Built with fire-retardant material to contain and extinguish fire if any occurs inside the box Carrier-Grade Network Equipment Building Systems (NEBS) Level 3 Certified Servers for 5G Telecom Solution 5 -", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "8ad73ba0-f779-45e2-a0e2-efb524ef8d0b": {"__data__": {"id_": "8ad73ba0-f779-45e2-a0e2-efb524ef8d0b", "embedding": null, "metadata": {"file_name": "Solution-Brief_X12_GrandTwin_OpenSSL.pdf", "publication_date": "April 2023", "referenced_websites": ["https://www.supermicro.com/en/products/grandtwin", "https://www.intel.com/content/www/us/en/architecture-and-technology/intel-quick-assist-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro\u2019s GrandTwin servers, the latest entry in the hyper- converged product line, provide a modular system architecture in a hyper-converged platform. These servers enable companies to achieve high scalability and speed using the latest CPU, memory, and I/O technologies. In addition, it provides companies with the performance they need and the flexibility to adapt to the requirements of any application. To demonstrate the exceptional capabilities of GrandTwin for cryptographic algorithms, Supermicro and Intel conducted an OpenSSL benchmark test combined with Intel QuickAssist Technology (Intel QAT). This test showed remarkable results, demonstrating significant improvements of up to 33.23 times increase in performance in cryptographic algorithms when Intel QAT was enabled. This feature highlights GrandTwin as a high-performance, cost-effective solution for customers seeking to optimize their computing power while minimizing their footprint. Additionally, the 4th Gen Intel Xeon Scalable processors will feature a built-in Intel QAT accelerator that is expected to outperform servers based on the 3rd Gen Intel Xeon Scalable processors, and Supermicro will conduct a comparative analysis in the future to provide further insights. The Supermicro GrandTwin provides a modular design that can be easily configured to provide complete flexibility within a system. This feature allows the system to be modified to the changing needs of the application and business. With cold aisle serviceability and easy front-node access, GrandTwin offers four hot-swappable nodes in a compact 2U form factor with up to 60 cores in a uniprocessor platform, up to 4TB of memory, and up to 6 NVMe/SATA drives per node. Each node can be configured 1 What is OpenSSL? 2 What is Intel QuickAssist Technology? 2 Testing Environment 2 Test Results: 3 Raw Test Results 4 Significance of Results 4 Summary 5 Contents 1 Solution Overview . Error! Bookmark not defined. Open RAN Error! Bookmark not defined. Key Components Error! Bookmark not defined. Hardware Solution Features . Error! Bookmark not defined. Summary Error! Bookmark not defined. Further Information Error! Bookmark not defined. Supermicro GrandTwin 2 with an AIOM (OCP 3.0) card and different types of I/O modules to give customers the flexibility to customize the system to a specific network requirement. This system is optimized for virtualization, cloud, hosting, content delivery, hyper-scale/hyper-converged, and other general- purpose computing workloads. The latest Supermicro X13 GrandTwin has been enhanced with the latest 4th Gen Intel Xeon Scalable processor, enabling even faster processing speeds that can be optimized for a wide range of workloads. With its built- in acceleration capabilities, this new processor offers an improved performance that can help boost application performance, productivity, and efficiency across various applications. What is OpenSSL? OpenSSL is an open-source software library that implements the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols and provides a full-length general-purpose cryptography library. Therefore, anyone interested in securing the communication between clients and servers may benefit from using OpenSSL to benchmark performance. What is Intel QuickAssist Technology? Intel QuickAssist Technology (Intel QAT) is an acceleration engine that significantly increases the performance and efficiency of standard platform solutions in the cloud, networking, big data, and storage by providing a framework for accelerators supporting software and hardware offload of popular cryptography, hash public key and compression/decompression algorithms. As a result, applications utilizing Intel QAT will see significantly reduced CPU utilization and greatly increased performance for encryption, secure client tunnels, and/or secure storage compression. Intel Quick Assist Technology has been expanded to provide software-based acceleration of cryptographic operations through instructions in the Intel Advanced Vector Extensions 512 (Intel AVX-512) family. This software-based acceleration has been incorporated into the Intel QAT Engine for OpenSSL. This dynamically loadable module uses the OpenSSL framework, allowing administrators to add this capability to OpenSSL without having to rebuild or replace their existing OpenSSL libraries. When combined, Intel QuickAssist Technology and OpenSSL work together to provide fast and more secure encryption and decryption performance. Supermicro and Intel ran OpenSSL Speed performance testing on a Supermicro X12 GrandTwin system showing performance gains when Intel QuickAssist Technology software engine is enabled. These results demonstrate that organizations can benefit from increased performance and enhanced security for their encryption and decryption operations when Intel\u2019s technology is used on a highly versatile Supermicro platform. Testing Environment In the Supermicro\u2019s test lab, engineers ran an OpenSSL Speed test on the Supermicro SYS-210GT-HNTF GrandTwin system. The platform used an Intel Xeon Scalable 6312U processor running at 2.4 GHz, 512GB DDR4 memory, 480GB SSD, and Ubuntu 20.04 LTS operating system. In addition, both Hyper-Threading and Turbo Boost were enabled. 3 Test Results: Supermicro achieved significant performance gains in the tests by enabling the Intel QuickAssist Technology engine. Improvements up to 33.23x were observed compared to our baseline across all the tests. The most substantial performance gains were observed in more secure algorithms, which tend to be more compute intensive. The increased performance of these algorithms over less secure ones can be quite significant. For example, our baseline, non- QAT test for ECDSA p384 (384 bit) achieved 1,253.4 signs/sec. However, when we enabled the Intel QAT software engine, the performance increased drastically, achieving 41,649.7 signs/sec, which is 33.23x more than the baseline. Similarly, ECDH p384 baseline achieved 1,317 ops/sec, then 17,752.6 ops/sec with Intel QAT software engine enabled, a 13.48x performance improvement over the baseline test. Overall, the Intel Quick Assist Technology is highly effective in handling cryptographic workloads and delivering impressive performance gains, as summarized in the plots below: 3433.4 559.6 252.5 9541.1 1843.1 1151.8 0 2000 4000 6000 8000 10000 12000 RSA 2048 RSA 3072 RSA 4096 sign/sec RSA Algorithm Baseline Intel QAT Engine for OpenSSL 20326 1317 70321.7 17752.6 0 10000 20000 30000 40000 50000 60000 70000 80000 ECDH p256 ECDH p384 ops/sec ECDH Algorithm Baseline Intel QAT Engine for OpenSSL 4 Raw Test Results Significance of Results OpenSSL is an open-source and widely used cryptography library that provides cryptographic functions for various applications such as web servers, VPNs, and software encryption. Getting good results for OpenSSL and then combining OpenSSL with Intel QAT for even better results is critical to ensure the reliability and security of these applications in Supermicro GrandTwin. Cryptographic libraries like OpenSSL are used by millions of websites worldwide, and a good performance can significantly impact the user experience. Therefore, these benchmark results assure users and industries that their data is protected solidly and efficiently. 47101.9 1253.4 117277.9 41649.7 0 20000 40000 60000 80000 100000 120000 140000 ECDSA p256 ECDSA p384 signs/sec ECDSA Algorithm Baseline Intel QAT Engine for OpenSSL 6488301.57 5602071.89 13558233.99 11280160.09 0 2000000 4000000 6000000 8000000 10000000 12000000 14000000 16000000 AES-128-GCM AES-256-GCM kB/sec AES Algorithm Baseline Intel QAT Engine for OpenSSL 5 Intel Quick Assist Technology is an accelerator engine that improves the performance of cryptographic algorithms. Enabling this accelerator to OpenSSL and improving the benchmark results give us insights into the speed and efficiency these cryptographic algorithms can reach in a real-world application with a reliable GrandTwin system. For example, Intel QAT can help improve the performance of digital signature generation and verification, which is widely used in the financial industry. As the market evolves with new technologies and the volume of data and transactions grows, security and data protection must keep up with the increasing demand. Security and data protection are essential for everyone, especially industries that need to protect sensitive data and information from the outside world. For Supermicro, providing the latest, most secure environments is very important. Significant benchmark results can be important for various markets to show cryptographic functions' reliability, security, and performance. Some of these markets include: 1. Finance: Cryptography is critical for this market to secure financial transactions and sensitive data such as bank accounts, credit card numbers, and personal information. 2. Healthcare: This market relies on cryptography to protect patient\u2019s personal information and records. 3. Government: This market uses cryptography to secure classified data and other intelligence gatherings. 4. E-commerce: The increasing number of users makes cryptography critical for this market to secure transactions, credit card numbers, and other personal information from users. Summary Security is an extremely important consideration in today\u2019s world. Intel Quick Assist Technology can significantly increase the number of encrypted connections in choosing more secure cryptography algorithms. When used with the Supermicro GrandTwin, significant performance gains are achieved, resulting in decreased processing time with no additional cost to the end user. Our reliable GrandTwin platform provides an efficient foundation for real-world applications that demand high-speed cryptographic functions. When combined with OpenSSL and Intel QAT, the results are remarkable. We have achieved significant improvements in the performance of widely used cryptographic algorithms. Supermicro\u2019s GrandTwin, combined with Intel Quick Assist Technology, provides the efficiency that applications heavily rely on, even as user demands and data encryption and decryption keep increasing. The resulting boost in speed and security means businesses and organizations can confidently manage large-scale data processing and financial transactions, knowing that reliable cryptographic solutions protect their data. Users of both 3rd and 4th Gen Intel Xeon Scalable processors can take advantage of this power. The newest improvements and higher performance gains are expected on the X13 GrandTwin platforms featuring 4th Gen Intel Xeon Scalable processors with Intel QAT built-in acceleration. This combination provides a powerful, low-cost solution to the most secure cryptography environments. 6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "3f505baa-3275-4888-b5b5-f750beb86a44": {"__data__": {"id_": "3f505baa-3275-4888-b5b5-f750beb86a44", "embedding": null, "metadata": {"file_name": "Solution-Brief_Quantum_ActiveScale_X12.pdf", "publication_date": "December 2023", "referenced_websites": ["https://www.supermicro.com/en/products/storage", "www.quantum.com/object-storage", "https://www.supermicro.com/en/products/top-loading-storage"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro ActiveScale Reference Arch. 1 1 Object Storage Solution Architecture Overview 2 ActiveScale Configuration & Performance 3 ActiveScale Software Overview 5 Supermicro Server Overview 6 Summary 8 Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology, is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \"We Keep IT Green\" initiative and provides customers with the most energy-efficient, environmentally- friendly solutions available on the market. Unstructured data is our customers' most valuable asset, which must be preserved and protected forever. However, relentless data growth and retention trends drive demands for more efficient, resilient, and secure Exabyte-scale storage solutions. These demands continue to pressure IT budgets and administrators. Simultaneously, organizations are looking to unlock the value of their data, making the task even more challenging. The correct storage architecture can allow organizations to leverage more of their data without requiring budgets to scale at the same pace and make facilitating data forever realistic. Jointly with our market leading, strategic partners, Supermicro can help organizations easily transition from their legacy storage to object storage platforms. Supermicro, in collaboration with Quantum, enables our customers to deploy any targeted size of storage infrastructure with great flexibility and scalability. Supermicro's fully integrated, pre-tested, tuned, and racked solution integrates fully with ActiveScale patented object storage software technologies. Supermicro ActiveScale Reference Arch. 2 Supermicro can offer our customers the best-in-class and fully qualified storage solution featuring Quantum ActiveScale. Our starter offering consists of 3 4U90 systems with 5PB of raw capacity, which achieved over 17GB/Sec data transfer bandwidth and 22K Obj/Sec overall performance. ActiveScale provides seamless scalability to a multi-Exabyte scale with high performance in a very cost-effective way. Unstructured Data Management Build your own S3-compatible storage cloud or data lake with ActiveScale and Supermicro to simply scale and protect massive data sets from various digital sources. HPC, AI, and ML ActiveScale is fully integrated with the Weka file system. The Weka file system is a flash-optimized, scale-out file system that runs across a cluster of NVME-based Supermicro servers for leadership performance of HPC, artificial intelligence, and machine learning workloads. Weka provides high performance, low latency, and consistent response time using local NVMe storage. The Weka file system can use ActiveScale object storage (based on Supermicro servers) as a secondary storage resource to store massive amounts of information at lower cost. Data Archiving and Long-Term Retention Curate, consolidate and maintain cold data assets online with ActiveScale for low cost, easy access, and long-term protection. ActiveScale supports a disk-based data storage tier for fast access to active data and a cold, tape-based data storage tier for lower cost storage, protection, and online access to massive data. Object Storage Solution Architecture Overview Figure 1 \u2013 ActiveScale Object Storage Architecture Cluster Reference Configuration Explained Quantum ActiveScale Object Storage Software Architecture provides a software environment that can maximize storage availability and scale the system with minimal to no impact on the customer experience and performance. ActiveScale software provides a scale-out architecture that allows the environment to grow and expand by adding additional Supermicro servers. The ActiveScale software resident on each server in the cluster cooperates with all other instances of software for a seamless, single system environment and single global namespace. The software is composed of an Access Layer and a Storage Layer. The Access Layer coordinates a single global namespace across the entire environment. Client applications talk to the Object Storage system through using the S3 protocol. The Access Layer executes client facing functions like authentication, authorization, and encryption. It also houses a scalable object metadata database, protected by having multiple copies distributed across each server in the cluster. Metadata includes attributes and policies attached to objects or buckets, internal ACCESS LAYER Metadata Storage: NVME Flash DATA LAYER Cold Data Storage: LTO Tape ( optional ) Active Data Storage: HDD ActiveScale Independent Software Layers Scale Access Layer for Performance & Object Count For Capacity, Scale Each Storage Class Independently Depending on Need Supermicro ActiveScale Reference Arch. 3 data, custom object metadata added by users or applications, and other information critical to the system's operation. Metadata operations performance is critical to overall system performance, more so than the performance of the bulk storage. The ActiveScale software stores object metadata on blazing fast NVMe Flash storage within the Supermicro servers to ensure the lowest latency and highest performance. The Storage Layer processes object data and reliably stores this data on hard disk drives (HDDs) within the Supermicro servers (or optionally on tape media resources within a Quantum Scalar tape library). HDDs have a reasonable cost per TB and perform very well when aggregated together into arrays and accessed with many parallel streams. ActiveScale Dynamic Data Placement distributes data for any one object across HDDs across the multiple servers in the cluster, ensuring reliability and availability. Active and Cold Storage Classes. With the industry's only integrated class of storage designed for cold data, ActiveScale reduces your overall cost of storing and protecting massive data sets. ActiveScale Cold Storage class provides for simple, quick recovery of your cold data sets stored on Quantum tape library-based resources into your active working group for continuing analysis and reuse. ActiveScale software provides unlimited scalability of active and cold data at consistent levels of availability and performance at scale without rebalancing. Configuration Supermicro and Quantum ActiveScale provide a high-performance object storage solution with the Supermicro 4U90 Top Loading Dual Node Storage Server. The Supermicro 4U90 Storage Server provides 90 3.5\" drive bays supporting 22 TB drives, totaling 1.620 PB per 4U Rack Units. Using a standard 42U x 1200mm rack and reserving 6U for Top of Rack switches, it easily fits 9 Supermicro Top-Loading 4U90 chassis per rack, totaling 14.6PB per Data Lake Rack. Type Description Qty System Supermicro X12 Dual Node Twin 90-bay Storage Server, use SSG-640SP-DE1CR90 to order 1 CPU 3rd Gen Intel Xeon Scalable processors ICX 4314 2P 16C/32T 2.4G 24M 10.4GT 135W 4189 M1 or ICX 4316 2P 20C/40T 2.3G 30M 10.4GT 150W 4189 M1 4 Memory 32GB DDR4-3200 2Rx4 LP ECC RDIMM,HF,RoHS 16 Boot Drive Samsung PM9A3 3.8TB NVMePCIeGen4 V6 M.2 22x110M(1DWPD),HF 4 Storage Drive Seagate 3.5\", 22TB,7.2K RPM, SAS3 12Gb/s,512MB, 512e/4kn or Seagate 3.5\", 18TB, 512e/4Kn (EvansBP) 90 NIC Std LP 2-port 25G SFP28, Mellanox ConnectX-4 L LX EN 4 SAS HBA Supermicro SAS HBA 3616 for 90 Bay system 2 Management SW Supermicro System Management Software Suite Node License 2 Table 1 - System Config Specifics Type Description Qty System Supermicro Top-Loading 4U 90-bay JBOD w/ dual expander, using CSE-947HE2C- R2K05JBOD to Order 1 Storage Drive WD or HGST 3.5\"18TB SAS 12Gb/s 7200RPM HDD 90 Supermicro ActiveScale Reference Arch. 4 ActiveScale Performance, Proven and Validated by the Joint Lab ActiveScale Performance Setup and Measurements \u2022 Erasure Coding (EC) policy: (18,5) (=13+5 Reed-Solomon) \u2022 90 HDDs per 4U Chassis (45 HDDs per Node) \u2022 Backend Network: 12 x 25 Gbps \u2022 Different object sizes: 64 kiB, 512 kiB, 1 MiB, 4 MiB, 8 MiB, 16 MiB \u2022 Different number of parallel TCP connections: 384 connections, 1000 connections Figure 2 - Solution Network Topology Performance Results 1-GEO 100% GET (1200 Connections) Supermicro SSG-640SP-DE1CR90 (3x4U chassis, 6-nodes, 270 HDD\u2019s) The performance graph below presents performance for GET OBJECT performance for a range of Object Sizes. Performance is expressed in terms of total number of Objects per Second and total throughput in Megabytes per Second. Loadgen Loadgen 25 Gbit Switch (ActiveScale backend) 25 Gbit Switch Loadgen Loadgen Loadgen Loadgen 45 HDDs, 4 x 25 45 HDDs, 4 x 25 45HDDs, 4 x 25 45 HDDs, 4 x 25 45 HDDs, 4 x 25 45 HDDs, 4 x 25 Supermicro ActiveScale Reference Arch. 5 1-GEO 100% PUT (1200 Connections) Supermicro SSG-640SP-DE1CR90 (3x4U chassis, 6-nodes, 270 HDD\u2019s) The performance graph below presents performance for PUT OBJECT performance for a range of Object Sizes. Performance is expressed in terms of total number of Objects per Second and total throughput in Megabytes per Second. The performance testing on three (3) Supermicro Dual-Node 4U90 storage servers, SSG-640SP-DE1CR90 with 18TB Drives, showed impressive results with both PUT and GET operations. The system achieved 17.4 GB/s READs and 13.0 GB/s WRITES. Random read requests were above 20K Objects/Sec. Much higher performance can be achieved by using more nodes as performance scales linearly. Supermicro ActiveScale Reference Arch. 6 ActiveScale Software Overview Quantum Corporation focuses on creating innovative technology and solutions to help our customers get the most value from their data. Quantum is proud to offer the ActiveScale Object Storage system in its portfolio. ActiveScale Object Storage is an early pioneer in the Object Storage market, emphasizing fully consistent, very low touch, and easy-to-scale object storage solutions. ActiveScale software runs in many customer environments, from less than a PB to multiple 100s of PBs under management. Software Operating system software ActiveScale OS 6.5 Management interfaces Real-time System Management Console, CLI, RESTful API System analytics Cloud Based Monitoring, Prometheus, Email, SNMP, Syslog Security Data encryption in flight SSL/TLS using AES-256, Data encryption at rest using AES-256 Data protection Advanced Erasure Coding, Dynamic Data Placement, Versioning, Object Locking, Geospreading Data durability Up to 19 nines, Dynamic Data Repair, Wide Stripe Storage Tiers and Classes Metadata: NVME, Active: HDD, Cold: Tape SW/FW upgrades Non-disruptive rolling upgrades nd d o e ss, e o e ss, ) e o d on o n o e e s s o D ess D e es e e e e e e o H d e o s e on e s on n n on o s e e o es e o n e o on 2 Supermicro ActiveScale Reference Arch. 7 Supermicro Server Overview Supermicro SSG-640SP-DE1CR90 Object Storageserver asdf Supermicro ActiveScale Reference Arch. 8 Value Proposition \u2022 Density: Highest density storage and computing power \u2022 Performance \u2022 Dual node configuration provides dual processors and DRAM performance \u2022 Multiple expanders architecture maximizes drive performance. \u2022 Flexibility \u2022 Capacity and TCO optimized software-defined scale-out object storage \u2022 Flexible configurations to match different workloads \u2022 Quality \u2022 The architecture SW+HW is fully redundant (No Single Point of Failure) \u2022 Component compatibility verification \u2022 Enterprise serviceability with hot-swappable drives, fans, and power supplies \u2022 Server nodes can be replaced hot without disruption of other nodes in the chassis. \u2022 Building Block modular design with the highest drive capacity Supermicro Top Loading Storage Design Enhancement \u2022 Design for Easy Field Serviceability \u2022 Passive Mid-plane, Backplane \u2022 No Contiguous Memory Allocator required \u2022 Tool-less access \u2022 Drawer type design \u2022 Twin server nodes can be hot swapped without disruption to other nodes (share nothing) Services Supermicro\u2019s Global Services can support customers requiring rack integration/configuration, installation, training, and post- deployment hardware/software maintenance. Summary With no slowdown in sight for data growth, it is imperative to find more efficient and effective ways to store and protect the organization's vast store of valuable data. The correct storage architecture must simplify complexity and help organizations take advantage of their data without requiring budgets to scale at the same pace as data growth. It should deliver disk-based access performance from anywhere in the world, protect the data from loss with high durability, scale without limits, and be easy to manage. ActiveScale, a new class of storage built on patented object storage technology, addresses these needs. Its architecture supports exabyte solutions and beyond with high data durability and high data integrity that disperse erasure encoded chunks across drives, chassis, and geographies, protecting against data loss and data corruption. The distributed scale-out design supports high-throughput performance even in a geo-dispersed deployment. ActiveScale provides better resiliency and seamless adoption of new capacity as customers grow into the future. With just 3 Supermicro 4U90 Storage Servers, over 17GB/sec of I/O bandwidth can already be achieved. With more nodes, the solution can quickly achieve 100's GB/s of aggregate data transfer bandwidth. With industry leading $/GB, the storage capacity of 14.5 PB per rack, and combined CapEx and OpEx savings, Supermicro and Quantum have proven a complete integrated rack, tested, ready-to-deploy Activescale object storage solutions to customers immediately. Supermicro presents a best-in-class, cost effective, highly available object storage platform from 5PB on 3 4Ux90 to multiple exabytes with Quantum Activescale which enables customers to deploy any target Data Lake size with great confidence.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "f8d459fb-fe26-4e2e-bf64-404f782c4e0a": {"__data__": {"id_": "f8d459fb-fe26-4e2e-bf64-404f782c4e0a", "embedding": null, "metadata": {"file_name": "Solution-Brief_VMware_vSAN_BigTwin_HCI.pdf", "publication_date": "August 2023", "referenced_websites": ["https://www.supermicro.com/products/system/2u/2029/SYS-2029BT-HNC0R.cfm", "www.supermicro.com", "https://www.supermicro.com/en/products/system/bigtwin/2u/sys-221bt-dntr"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 SupermicroX13 BigTwin Multi-Node Infrastructure Solutions Over the years, hyper-converged infrastructure (HCI) has emerged as a reliable solution for its simplified management, scalability, cost efficiency, and high-performance capabilities. In HCI environments, technologies like vSAN have proven to be critical as the underlying storage technology due to their seamless integration and ability to provide storage to multiple servers simultaneously. However, like any evolving technology, vSAN has faced several challenges. Addressing data growth and scalability has become essential for applications to meet the demands of the rapidly expanding market while maintaining top-notch performance and reducing latency for improved serviceability. In this context, Supermicros\u2019 X13 BigTwin system introduces innovation with the new 4th Gen Intel Xeon Scalable Processors bringing new accelerators and more powerful cores. These cutting-edge components seamlessly integrate into the vSAN environment to elevate its capabilities. Business Challenges 1 Business Challenges 2 Value of vSAN & AI 2 Supermicro X13 BigTwin for Efficiency and Performance 2 AI Benchmarks 3 Supermicro BigTwin Systems Details 4 Conclusion 6 References 6 2 Business Critical Applications (BCAs) are software applications vital to a company's core operations and success. Running business-critical applications requires on-demand scalability, improved performance, optimal efficiency, and simplified management. Hyperconverged infrastructure (HCI) platform helps boost data center efficiency by delivering developer-ready infrastructure, scaling without compromise, simplifying operations, and expanding file services. vSAN offers policy-based management to eliminate or automate highly manual storage processes, and it increases agility by enabling administrators to prioritize SLAs of mission-critical workloads on the fly. Organizations can configure multiple RAID levels for performance or capacity savings and non-disruptively scale out or scale up to size business-critical applications at each expansion interval. Solution Overview Supermicro\u2019s objective is to deliver a high-performance system optimized for VMware vSAN. The Supermicro X13 BigTwin, powered by 4th Gen Intel Xeon Scalable Processors, offers exceptional capabilities thanks to Intel DSA (Data Streaming Accelerator) technology, which optimizes streaming data movement and transformation operations, improving computing and storage efficiency for daily operations. As data becomes increasingly valuable as a critical corporate asset, accelerated data protection for NVMe/TCP becomes essential to improve efficiency for data storage applications by offloading CPU in storage solutions. To demonstrate this, Supermicro has selected the Supermicro X13 BigTwin SYS-221BT-DNTR and the Supermicro X11 BigTwin SYS-2029BT-HNC0R. The chosen configuration for SYS-221BT-DNTR is targeted for a vSAN-ESA-AF-6 ready node with a minimum storage capacity of 40TB per node. This configuration was carefully selected as the sweet spot between performance and cost to have a better total cost of ownership over prior generations. By leveraging the Supermicro X13 BigTwin, the solution was able to optimize the resources available within the vSAN environment. HCIBench played a crucial role in benchmarking and validating the performance capabilities of the Hyper- converged infrastructure deployment, ensuring that it exceeded the anticipated workload demands. This solution highlights the successful integration of Supermicro X13 BigTwin, vSAN software-defined storage capabilities, and the solution\u2019s ability to handle demanding workloads efficiently and reliably. Supermicro X13 BigTwin System When you look into the requirements of vSAN ESA environments, it becomes evident that computing power and storage density are needed for this kind of environment. The Supermicro X13 BigTwin, with its modular design, emerges as an ideal solution that aligns the most with these essential vSAN ESA requirements. With its flexible and dense design, the Supermicro X13 BigTwin ensures enterprises will have easy integration into their existing Hyper-Converged Infrastructure (HCI) environments. As the organizations' requirements expand and transform, the Supermicro X13 BigTwin can effortlessly accommodate these changes, making scalability a smooth and worry-free experience and allowing you to integrate new technologies seamlessly without interruptions. In our Proof of Concept, Supermicro proud to spotlight the 2U 2-Node configuration, which optimally balances storage capacity and cost-effectiveness performance. The target configuration was a vSAN-ESA-AF-6 ready node with 40TB of storage capacity per node. This result was achieved by populating 7 out of 12 drive bays in the front. This configuration demonstrates the best minimum configuration for ESA-AF-6 for the best performance per dollar. However, if it is still needed to scale the infrastructure, the Supermicro X13 BigTwin 2U 2-Node can potentially be a high-density vSAN-ready node with 12x drives per node and 3x PCI-E Gen5 slots for networking. The Supermicro X13 BigTwin empowers organizations with the flexibility to accommodate any configuration in their existing HCI infrastructure. As a high-density vSAN-ready node, the Supermicro X13 BigTwin\u2019s 2U 2-Node configuration supports any workload with the most demanding storage and networking requirements. Whether you are pursuing to enhance your storage capacity, network connectivity, or overall performance, the Supermicro X13 BigTwin is an ideal solution with efficiency and adaptability for vSAN ESA environments. 3 Solution Lab Architecture Test Configuration SYS-221BT-DNTR Type SMC PN Description Node QTY System Qty System SYS-221BT-DNTR X13DET-B, CSE-217BD2-R2K22P, SCC- P12N12SGH-B2 2 CPU P4X-SPR6448Y- SRMGN-MCC SPR 6448Y 2P 32C 2.1G225W(24/2.6/225,16/2.9/205)60M BI(1000) 7yr---P4X-SPR6448Y-SRMGN-MCC 2 8 MEMORY MEM-DR564L-CL01- ER48 64GB DDR5 4800 ECC REG---MEM-DR564L- CL01-ER48 16 64 AOC STORAGE SCC-A2NM2241G3- B1 2x Gen3 Marvell2241 NVMe M.2 RAID with 1x PCIEx16 Gen5 S 1 4 Drive HDS-MMN- MTFDKBA400TFS1BC Micron 7450 MAX 400GB NVMe PCIe 4.0 3D TLC M.2 22x80 mm, 3DWPD---HDS- MMN-MTFDKBA400TFS1BC 2 8 Drive HDS-IUN0- SSDPF2KE064T1 D7-P5620 6.4TB NVMe PCIe 4.0 X4 3D TLC U.2 15mm 3DWPD---HDS-IUN0- SSDPF2KE064T1 7 28 AOC Network AOC-S100GC-I2C-P Standard PCIe 4.0x16 dual port 100GbE w/QSFP28 2 8 Accessory SKT-1424L-001B-FXC SOCKET E E1B CARRIER LGA 4677 W/SHIM SP MCC , DG1.0 , RoHS 2 8 4 SYS-2029BT-HNCOR Type SMC PN Description Node QTY System Qty System SYS-2029BT-HNC0R BigTwin 2U 4-Node, 6x2.5 NVMe/SAS 1 CPU P4X-CLX6230N- SRFPR Intel Xeon Gold 6230N 4/2P 20/(6+14)C/40/(12+28)T 2.3/(2.7+2.1)G 27.5M 1 2 8 MEMORY MEM-DR432L-CL01- ER29 32GB DDR4 1.2V 2933 ECC REG--- MEM-DR432L-CL01-ER29 12 48 AOC Storage AOC-SMG2-2TM2 2xSATA M.2 RAID adapter for Big Twin,HF,RoHS 1 4 Drive (boot) HDS-IMT0- SCKKB240G8-NI22 Intel D3 S4510 240GB M.2 SATA 6Gb/s 3D TLC 22x80mm 1DWPD 2 8 Drive (caching) HDS-IAN1- SSDPED1K375GAX Intel3D XPointDC P4800X 375G PCIe3.0HHHL AIC30DWPD FW435 2 8 Drive (capacity) HDS-I2T0- SSDSC2KB038T8 Intel S4510 3.84TB, SATA 6Gb/s, 3D, TLC 2.5\" 1DWPD, HF,RoHS---HDS-I2T0- SSDSC2KB038T8 4 16 AOC NETWORK AOC-STGS-I2T-O 2x 10GbE RJ45 Intel X550-AT2, Gen3 x4 LP -- AOC-STGS-I2T-O 2 8 HCIBench Performance Results \u2013 Throughput and Latency HCIBench is a performance testing tool for Hyper-Converged Infrastructure (HCI) environments t ensure optimal functionality and resource utilization. This benchmark simulates real workloads scenarios that test the system and configuration performance. Supermicro compared the performance between Supermicro X13 BigTwin with 4th Gen Intel Xeon Scalable Processors and the Supermicro X11 BigTwin with 2nd Gen Intel Xeon Scalable Processors. The Supermicro X13 BigTwin achieved 4.7x higher throughput with almost 2.5 million IOPS and 87.8% lower latency in the HCIBench test. These incredible results reflect how the Supermicro X13 BigTwin can be the critical player for modern HCI environments that want to deliver optimal user experience, effectively handle any workload, and ensure high availability. 5 0 500000 1000000 1500000 2000000 2500000 Intel Xeon Gold 6230N Processor Intel Xeon Gold 6448Y Processor IOPS HCIBench Throughput Higher is Better 8K Block Size 70% Reads 100% Random 16K Block Size 70% Reads 80% Random 32K Block Size 50% Reads 50% Random 4.7x 1.0 0.0 2.0 4.0 6.0 8.0 10.0 Intel Xeon Gold 6230N Processor Intel Xeon Gold 6448Y Processor Latency (ms) HCIBench Latency Lower is Better 8K Block Size 70% Reads 100% Random 16K Block Size 70% Reads 80% Random 32K Block Size 50% Reads 50% Random 1.0 8.2 6 CAPEX Analysis \u2013 Performance Per Dollar Its remarkable cost reduction signifies an important advancement in optimizing resource utilization, driving unparallel efficiency, and reducing the total cost of ownership. Enterprises can channel their financial resources toward strategic growth initiatives and innovations by substantially decreasing the capital expenditure required for hardware, software, and infrastructure components. Conclusion The Supermicro X13 BigTwin with 4th Gen Intel Xeon Scalable Processors is an advanced hardware solution that offers numerous advantages when deployed in vSAN environments. The Supermicro X13 BigTwin is available in two highly flexible form factors: 2U 2 Node and 2U 4 Node. This design offers customers unparallel options for achieving the perfect balance between flexibility and density in their environments. Whether the goal is to maximize the number of compute nodes within a limited space or achieve optimal node count within a specific rack, the Supermicro X13 BigTwin provides the ideal solution. This level of customization ensures that organizations can tailor their infrastructure to meet their precise requirements, empowering them to efficiently utilize resources while maintaining the desired level of scalability.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "1b48f32f-cc7f-44b7-9f23-3ebdacc23912": {"__data__": {"id_": "1b48f32f-cc7f-44b7-9f23-3ebdacc23912", "embedding": null, "metadata": {"file_name": "Solution-Brief_High_Performance_Redis.pdf", "publication_date": "July 2022", "referenced_websites": ["https://www.intel.com/content/www/us/en/products/docs/memory-", "https://github.com/RedisLabs/memtier_benchmark", "https://www.supermicro.com/en/solutions/redis", "https://community.intel.com/t5/Blogs/Thought-Leadership/Big-Ideas/Validating-Redis-Enterprise-Operator-"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "As the market demands more bandwidth and real-time online services, the challenge to support new technology such as 5G, IoT, and real-time applications has dramatically changed data center infrastructure requirements. Cloud IaaS (Infrastructure-as-a-Service) providers constantly optimize caching services to reduce the \u201cLast Mile\u201d latency at strategically located Edge Data Centers. Real-time applications are prevalent in various markets, especially in advertising, media & entertainment, online gaming, e-commerce, mobile apps, healthcare, higher education, and government. Supermicro has partnered with Intel, Red Hat, and Redis to create a high-availability cache cluster in a compact 2U 4-Node system for easy deployment and scalability with hybrid cloud capabilities. With its award-winning multi- node design, in-memory performance, low-latency NVMe storage, and redundant Titanium level power supplies, one Supermicro X12 BigTwin system can reliably deploy and support real-time applications with the power of Red Hat OpenShift and Redis Enterprise. The solution was inspired by the growing demand for cloud-native applications that stream static and dynamic content, including rich media. These applications must be optimized for viewing on mobile devices, AR/VR glasses, televisions, and web browsers on tablets and laptops of all shapes & sizes. 1 Solution Overview 1 Value Proposition 2 Sub-millisecond Response 3 Easy Button for Hybrid Cloud 4 Baseline Configurations 6 Performance Metrics 8 Performance Monitoring 9 Summary of Redis Performance 1 0 Conclusion 1 1 2 High-Performance Redis Cluster on Supermicro X12 BigTwin Solution Overview Red Hat OpenShift is an Enterprise-ready, hybrid-cloud Kubernetes platform built to run and scale container-based applications to provide a consistent platform for managing hybrid cloud, multi-cloud, and edge deployments. Redis is an in-memory data structure store used as a database cache and message broker. It is an ideal database for highly interactive, scalable, low- latency geo-distributed apps. To reduce CAPEX & OPEX, as well as accelerate time to value for Enterprise DevOps teams, Supermicro has introduced the REC-Optane Series, based on popular X12 SuperServers, powered by 3rd Gen Intel Xeon Scalable Processors & Intel Optane PMem 200 Series, as an integrated solution with Red Hat OpenShift & Redis Enterprise. Value Proposition With Supermicro\u2019s high-density BigTwin system, Redis was benchmarked across a 3-node cluster to highlight the power of the REC-Optane product series. The top 3 design decisions to deploy a Supermicro X12 BigTwin as a Redis cluster are as follows: 1) Easy to reliably deploy hybrid cloud infrastructure on bare-metal servers o Red Hat OpenShift makes it easy to manage hybrid cloud infrastructure with an Enterprise-Ready Kubernetes platform o Red Hat OpenShift Data Foundation provides persistent storage for hybrid cloud and multi-cloud container deployments o The Supermicro X12 BigTwin is a 2U 4-Node system, allowing Cloud IaaS Providers to simplify the logistics of hardware deployments at strategic Edge Data Centers o The HW RAID 1 NVMe Switch on each node allows administrators to automate the configuration of redundant boot drives for Red Hat OpenShift with Redfish APIs, enabling zero-touch provisioning Figure 1 \u2013 Zero-Touch Provisioning 2) Performance per Dollar o Optimal value of K8s on bare-metal (using a max core count of OpenShift subscription of 64C per node) o Double the memory capacity with Intel OptaneTM PMem 200 Series compared to DRAM-only configurations o Power-efficiency of the Supermicro X12 BigTwin (Optimized OPEX with multi-node design, shared power & cooling) Supermicro , the leading innovator in high-performance, high- efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. 3 High-Performance Redis Cluster on Supermicro X12 BigTwin 3) Seamless support for real-time applications with Redis Enterprise Operator o Easily configure a high-availability cache cluster with Redis Enterprise Operator to support real-time applications o Stay up to date with the latest Redis features through the Red Hat Operator Framework o Run once, run anywhere with Kubernetes-native applications Figure 2 \u2013 OpenShift Container Platform Support: Run Once, Run Anywhere Sub-millisecond Response with Reduced Cost from Edge to Cloud Supermicro\u2019s patented Twin Architecture is the foundation for the most energy-efficient and advanced server platforms in HPC, Data Center, Cloud Computing, and Enterprise IT applications. This high-performance, high-density system features optimum airflow for energy-efficient cooling and easy maintenance with hot-swappable nodes and redundant PSUs. The Red Hat OpenShift cluster is deployed on the Supermicro BigTwin 2U 4-Node chassis containing 3rd Gen Intel Xeon Scalable Processors. The Supermicro X12 BigTwin, SYS-220BT-HNTR supports up to 4TB of memory per node with Intel Optane Memory. Based on Supermicro customer surveys, 512GB of DRAM per node is a popular memory capacity to support static and dynamic web content. Still, more memory is needed to support rich media. 1TB per node would be ideal, but it is cost-prohibitive due to the high costs of 128GB RDIMM-3200 modules. For the same price of 512GB of DRAM, system memory may be doubled with Intel Optane PMem on the Supermicro X12 BigTwin, as shown in Table 1 below. By using Intel OptaneTM PMem 200 Series, the Supermicro X12 BigTwin can potentially double the memory bandwidth without significant degradation in latency compared to a DRAM-only setup. This will examine the relative P99 latency of Intel Optane PMem vs. DRAM and ensure a typical SLA of 1ms can be met. Based on the benchmarks results, Cloud IaaS Providers may consider using Intel Optane PMem to deploy enlarged high- availability cache clusters with fewer servers. With the Supermicro X12 BigTwin, lowering the cost of larger memory 4 High-Performance Redis Cluster on Supermicro X12 BigTwin capacities becomes much more practical, especially with its shared power, cooling, and storage backplane to save snapshots periodically of the Redis database. In addition, this allows for hardware consolidation of in-memory caching and All-Flash NVMe storage platforms \u2013 resulting in lower server count and product mix to simplify deployments and lower TCO. SYS-220BT-HNTR Description Qty Function DevOps-in-a-Box Based on X12 BigTwin 2U 4-Node 1 Redis Enterprise Cluster: Optane-REC-BT Intel Processor ICX 8352V 36C @ 2.1G, 195W 8 2 CPUs per Controller + Worker Nodes Memory 32GB DDR4-2933 RDIMM 32 256GB per Node (64 RDIMMs for Baseline) Persistent Memory 128GB Intel OptaneTM PMem 200 Series 32 1028GB in Memory Mode per Node Bare-Metal Network 100GbE 2-port QSFP28 PCI-E 4.0 LP Card 4 Bare-Metal Network Interfaces Provisioning Network 10GbE 2-port RJ-45 PCI-E 3.0 AIOM 4 Isolated Provisioning Network Interfaces Optional Boot Controller M.2 NVMe HW RAID Controller 4 HW RAID Protection for OpenShift Boot Devices 1TB M.2 NVMe PCI-E 3.0 Devices 8 Redundant Boot Devices Storage 3.84TB U.2 PCI-E 4.0 Drives 8 Local Storage Kubernetes SW Red Hat OpenShift Container Platform 3 Hybrid Cloud, Platform-as-a-Service Persistent Storage SW Red Hat OpenShift Data Foundation 3 Software-Defined Storage for Containers Optional Bastion SW Red Hat Enterprise Linux 1 Bastion Host: Deployment & Management Table 1 \u2013 Red Hat OpenShift Compact Cluster Specifications Figure 3 \u2013 Supermicro OpenShift Compact Cluster Hit the Easy Button for Hybrid Cloud Infrastructure Deployment & DevOps Management Key benefits in deploying and managing these clusters: 1) Streamline the deployment of a hybrid cloud infrastructure with Red Hat OpenShift for enhancing DevOps One Bastion node within the enclosure may be used as a host for deploying and managing the Red Hat OpenShift cluster, allowing for zero-touch provisioning without needing an external system for deploying the 3-node compacter cluster. The Bastion node is optional but offers powerful orchestration support with Ansible playbooks. 2) OpenShift has built-in CI/CD support for cloud-native applications. Many mobile applications require high- availability caching services. The cache cluster size and location of a CDN PoP (Points-of-Presence) or Edge Data 5 High-Performance Redis Cluster on Supermicro X12 BigTwin Center can significantly impact a mobile application\u2019s response. Therefore, it is critical for app developers and cloud architects to monitor and manage the performance of these applications early in the development cycle through UAT (User Acceptance Testing), as well as production environments (core, regional, and/or edge data centers) with different SLAs (service-level agreements). Popular CDN edge servers typically respond to queries in less than 30ms. Figure 4 \u2013 Continuous Integration & Deployment with Supermicro Compact Cluster 3) The Redis Enterprise Operator was deployed across three nodes to support a high-availability cache cluster. Supermicro has run several performance tests with the following setup. Figure 5 below shows the Kubernetes Abstractions and how a Job with Pod and ConfigMap can be used to run the memtier_benchmark1 across the Redis Enterprise Cluster deployed by the Redis Enterprise Operator. Figure 5 \u2013 Kubernetes Abstractions Baseline and PMem Use Cases Configurations 6 High-Performance Redis Cluster on Supermicro X12 BigTwin The tables below provide details for the hardware and software configurations used to benchmark. The objective was to show that the DRAM performance would be similar to the Intel OptaneTM PMem performance but double the cluster's memory capacity. As a result, the parameters can significantly impact throughput and latency. Those details are included below for repeatability and transparency. Configuration 1 \u2013 Baseline (DRAM-only) 1TB Dataset Configuration 2 \u2013 Memory Mode (DRAM + Intel Optane PMem) Same Dataset Size used in Baseline Configuration 3 \u2013 Memory Mode (DRAM + Intel Optane PMem) 2x Dataset Size Total Memory (per node) 16 x 32GB DRAM = 512GB [1.5TB across 3 nodes] 8 x 32GB DRAM + 8 x 128GB PMem = 1 TB in Memory Mode [3 TB across 3 nodes] 8 x 32 GB DRAM + 8 x 128 GB PMem = 1 TB in Memory Mode [3 TB across 3 nodes] Dataset size 1TB (500GB master shards + 500GB replica shards) with replication across 3 nodes 1TB (500GB master shards + 500GB replica shards) with replication across 3 nodes 2.1TB (1.05TB master shards + 1.05TB replica shards) with replication across 3 nodes Table 2 \u2013 Baseline (DRAM) and Optimal (Optane) Memory Configuration Software Component Version OpenShift Container Platform 4.8.27 Redis Enterprise Operator 6.2.10-4 Table 3 \u2013 Red Hat OpenShift Software Versions 7 High-Performance Redis Cluster on Supermicro X12 BigTwin Before starting the tests, Supermicro worked closely with Intel to define the parameters used in the synthetic benchmark to simulate containerized application workloads. Component Parameter Value Redis Enterprise Operator Version 6.2.10-4 Deployment 3 Nodes Redis Enterprise Cluster Memory & CPU Resource Allocation redisEnterpriseNodeResources: limits: cpu: 64 memory: 450Gi shards_placement: sparse redis_version: 6.2 proxy: mode: dynamic scale_threshold: 50 threads: 3 max_threads: 36 Redis Enterprise Database Proxy Policy & Shards Count proxy_policy: all-master-shards oss_cluster: true memorySize: 1050GB replication: true shardCount: 56 \u2192 112 with replication memtier_benchmark Version 1.3.0 (edge) Threads 6 Clients 5 Pipelines 4 Ratio SET:GET 1:4 Test Time 3 x 600sec = 15min Requests 3 000 000 000 Object Size 100b Table 4 \u2013 Redis Enterprise and Benchmark Tool Configuration 8 High-Performance Redis Cluster on Supermicro X12 BigTwin Performance Metrics - Results with DRAM and Intel Optane Persistent Memory The following sections provide the results of synthetic benchmark performance for the 3-node Redis cluster. Several tests were conducted with different configurations and parameters (see Figure 6 below for details). Three configurations were tested, one test with DRAM-only as a baseline, and two tests were run with Intel OptaneTM PMem to measure the impact in latency with different datasets. Memory Mode is the default configuration for the Intel OptaneTM PMem modules. Synthetic workloads were generated using the memtier_benchmark. Figure 6 \u2013 Performance of DRAM vs. PMem Figure 7 \u2013 P99 latency of DRAM vs. PMem 1167032 1135246 1071621 0 200000 400000 600000 800000 1000000 1200000 Configuration 1 Baseline (DRAM-Only) Configuration 2 DRAM + Intel OptaneTM PMem Configuration 3 DRAM + Intel OptaneTM PMem (with 2x bigger dataset) Throughput (ops/sec) 0.94 0.96 0.99 0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80 0.90 1.00 Configuration 1 Baseline (DRAM-Only) Configuration 2 DRAM + Intel OptaneTM PMem Configuration 3 DRAM + Intel OptaneTM PMem (with 2x bigger dataset) P99 Latency (ms - LIB) SLA of P99 at 1 ms 9 High-Performance Redis Cluster on Supermicro X12 BigTwin Performance Monitoring DevOps teams may want to monitor infrastructure and/or application performance to ensure applications are meeting SLAs. Grafana is a very popular open-source monitoring tool used to build interactive dashboards configurable to suit a DevOps team's needs. Grafana may be customized further to monitor application performance to gain a deep understanding of user patterns and integrated microservices. These dashboards are critical for CSPs with CDN PoPs to help make more intelligent decisions to manage resources, configure load balancers, and even identify DDoS threats. Figure 8 shows a snapshot of the Grafana dashboard, customized to monitor the performance of the 3-node Redis cluster simply, in response to various synthetic benchmarks outlined above in Table 2. This dashboard was focused on monitoring throughput (ops/sec), latency (ns), total keys, and memory usage. This custom Grafana dashboard is modeled from the default view of the Redis telemetry service, shown in Figure 9. Figure 8 \u2013 Redis Telemetry on Grafana dashboard 10 High-Performance Redis Cluster on Supermicro X12 BigTwin Figure 9 \u2013 Redis Telemetry (from REC UI \u2013 5min scope) Summary of Redis Performance Below is a Redis performance summary for the three different tested configurations. The total throughput and latency of the Intel OptaneTM PMem configurations were close to the performance of the DRAM-only configuration. This result is remarkable as the configuration has twice the amount of memory across the 3-node cluster with PMem, operating in Memory Mode. In addition, configurations 1 and 2 used the same dataset size of 1TB, which had a delta in P99 latency of 2.1%, with a 2x bigger dataset of 2.1TB, the P99 latency delta of 5.3% against the baseline configuration. Traffic generation and benchmarking tool: memtier_benchmark Core Metrics Total throughput (ops/sec) P99 latency (ms) Average latency (ms) Configuration 1 \u2013 Baseline (DRAM only) 1,167,032 0.94 0.30 Configuration 2 \u2013 DRAM + Intel Optane PMem 1,135,246 0.96 0.31 Configuration 3 \u2013 DRAM + Intel Optane PMem (2x bigger dataset) 1,071,621 0.99 0.33 Redis with PMem in MM vs. Baseline 97.3% 102.1% 103.3% Redis with PMem in MM (2x bigger dataset) vs. Baseline 91.8% 105.3% 110.0% Table 5 \u2013 Redis Performance Summary: DRAM baseline and PMem Test Results 11 High-Performance Redis Cluster on Supermicro X12 BigTwin Conclusion In partnership with Intel, Red Hat, and Redis, Supermicro offers a performance-optimized hybrid cloud building block to scale-out Redis Enterprise with Red Hat OpenShift, running on a Supermicro 2U 4-Node BigTwin (SYS-220BT-HNTR). Building scalable caching infrastructure has never been easier, thanks to the Operator Framework, which Supermicro has proven with the Redis Enterprise Operator, certified by Red Hat, as a Kubernetes-native application. With 3rd Gen Intel Xeon Scalable Processors, 8352V CPUs, DDR4-2933, plus Intel OptaneTM PMem 200 Series in Memory Mode across 3 nodes, the solution delivers game-changing performance with double the memory capacity for the same cost of a typical DRAM- only configuration. The DRAM-only and PMem configurations achieved over 1 million ops/sec with P99 latency below 1ms. Additionally, the PMem configuration processed twice the amount of data than the DRAM-only configuration while staying within a typical SLA of 1ms P99 latency. With a balanced memory topology across two CPUs and support for 64+ cores per node, the Supermicro BigTwin offers tremendous performance per dollar. The solution maximizes the value of OpenShift, as each bare-metal subscription supports up to 64 cores or 2 sockets per node. In addition, the Supermicro BigTwin supports up to 6 NVMe PCI-E 4.0 drives per node, providing low-latency persistent storage for the Redis database. With Red Hat OpenShift Data Foundation, data can be replicated or striped across the local 3-node cluster or with external S3 object storage services via the Multi- Cloud Object Storage Gateway. Scaling resources and predicting application performance at the edge are challenging, requiring a sophisticated cache- tiering solution to optimize OPEX. Now, these challenges can be addressed with this solution. With Red Hat OpenShift, doubling the memory capacity per node becomes exceptionally valuable in the context of a microservices architecture. The Kubernetes Engine simplifies resource management by elastically allocating resources to support a wide variety of applications leveraging Redis. This unlocks the true potential of PMem in a 2U 4-Node system, supporting twice the amount of memory capacity of a typical 1U server. Supermicro, Server Building Block Solutions, and We Keep IT Green are", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "79c6edd1-bb7d-4129-aa86-54d41a0d655b": {"__data__": {"id_": "79c6edd1-bb7d-4129-aa86-54d41a0d655b", "embedding": null, "metadata": {"file_name": "Solution-Brief_WekaIO_Aplus_EPYC-7003.pdf", "publication_date": "March 2021", "referenced_websites": ["https://www.supermicro.com/en/products/rackmount", "https://www.weka.io/how-it-works/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro WEKAIO Reference Architecture SERVERS EXCEL AS A WEKAIO REFERENCE ARCHITECTURE The Next Generation Storage Solution with 3rd Gen AMD EPYC 7003 Processors Unstructured data is a customer's most valuable asset, which must be preserved and protected forever. However, relentless data growth and retention trends drive demands for more efficient, resilient, and secure Exabyte-scale storage solutions. These demands continue to pressure IT budgets and administrators. Simultaneously, organizations are looking to unlock the value in their data, which makes the task even more challenging. The correct storage architecture can allow organizations to leverage more of their data and make facilitating 'data forever' a realistic prospect. Jointly with our market-leading, strategic partners, Supermicro can easily transition from legacy storage to next-generation storage platforms. 1 Weka Solution Architecture Overview 2 Configuration 3 Weka Performance Overview 4 Supermicro Server Overview 5 Case Study: Biomedical and Life Science 5 Summary 6 Additional Resources 6 2 Supermicro WEKAIO Reference Architecture WekaIOwas founded on the idea that current storage solutions have forced IT organizations to choose complex solutions to address their highest storage need at the expense of other desirable capabilities. The three dominant architectures are block, file, and object, each servicing a different need: speed, shareability, and scalability in that order. In today's \"data-as-a-service\" market, organizations need a flexible infrastructure that addresses the many business needs within a single framework. The design philosophy behind the Weka file system \u2013 WekaFS - was to create a single storage architecture that runs on-premises or in the public cloud with the performance of all-flash arrays, the simplicity and feature set of network-attached storage (NAS), and the scalability and economics of object storage. WekaIO Solution Architecture Overview WekaIO\u2019s file system (WekaFS) is a fully distributed, parallel file system that was written entirely from scratch to deliver the highest performance file and object services by leveraging NVMe flash as its primary storage for persistent data across a wide range of applications. WekaFS will also, and transparent to the application layer, seamlessly expand the filesystem namespace to include an extended layer built on any S3 compliant object storage system. There is no need for a particular data migration software or complex scripts; all data resides in a single global namespace for easy access and management while maintaining the best performance. The intuitive graphical user interface allows a single administrator to quickly and easily manage hundreds of petabytes of data without any specialized storage training. Leveraging existing technologies in new ways and augmenting them with engineering innovations, Weka's software delivers a more powerful and more straightforward solution that would have traditionally required several disparate storage systems. Figure 1 - Weka File System Structure Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. 3 Supermicro WEKAIO Reference Architecture The resulting software solution provides high performance for all workloads (big and small files, reads and writes, random, sequential, and metadata heavy). Furthermore, it is designed to run on a server infrastructure that does not rely on any specialized hardware-assist. As future hardware innovations come to market, WekaFS is well-positioned to leverage emerging technologies for the continued delivery of best cost and performance. The system can be expanded online to handle more demanding performance or store more capacity with no service interruption. Configuration \u2022 Our WekaIO reference configuration offers the lowest cost, most flexible, outstanding performance on a single processor platform leveraging AMD EPYC processors with 128 lanes of PCIe Gen4 that supports up to 20 PCIe Gen 4 NVME storage devices, greater than 256 GB of memory, with 24 cores per CPU. \u2022 The reference system provides raw capacity of up to 6.5 PB/rack or 306 TB/server using 15.3 TB NVME PCIe Gen 4 (21x20x15.3=6.5 PB per 42U Rack) \u2022 High-performance PCIe4 Kioxia NVME drives with measured performance of 6.9 GB/s vs. 3.3 GB/s and 1.6 MIOPs vs. 800 KIOPs for PCIe 3 drives. \u2022 One of the key advantages of this platform is the online upgrade of additional capacity without adding IO/switches/network port/or nodes by inserting NVMe drives to empty slots within the cluster systems. This allows users to simply install additional drives for extra capacity, turn on the software, and the systems are being configured automatically.Users can also easily scale out the number of storage cluster hoststo improve performance and capacity as needed. An example of a validated cluster solution using AS -2114S-WN24RT single-node servers: Type Description Per System 6 System config System AS -2114S-WN24RT AMD WIO 2U/24 NVMe A+ Rack Server 1 6 CPU 3rd Gen AMD EPYC 74F3 24C/48T 3.2G 256M 240W 1 6 Memory 32GB DDR4-3200 2Rx4 ECC Registered DIMM 8 48 Boot Drive Micron 2300 2TB NVMe PCIe Gen4 M.2 SSD 1 6 Storage Drive Kioxia CM6 7.68TB NVMe PCIe Gen4 2.5\" U.2 SSD 20 120 NIC Mellanox ConnectX-6, Low-Profile Dual-port VPI HDR 200GbE, QSFP56, PCIe Gen4 2 12 Table 1 - 6 System Config Specifics 4 Supermicro WEKAIO Reference Architecture Figure 2 - Cluster Network Topology WekaIO Performance Overview Using FIO IO generators on 12 AMD clients, massive performance of 217 GB/s (36GB/s per node) was measured on just 6-nodes of Supermicro WIO platform with 3rd Gen AMD EPYC 74F3 processor, 2x200 Gb/s CX6 IO, 20 Kioxia PCIe4 NVME, and WekaIO (10.x.x). Figure 3 - Weka Performance Overview 5 Supermicro WEKAIO Reference Architecture Supermicro Server Overview AS -2114S-WN24RT Note: additional PCIe4 slots can be exchanged for 4 NVME connect (2 max) Case Study: Biomedical and Life Sciences Research The data center infrastructure team's key focus at biomedical research centers is supporting high-performance computing (HPC) for general bioinformatics work. One very common workflow is Next-Gen Sequencing (NGS) analysis using the GATK pipeline for sequence alignment and variant calling. However, the HPC cluster has also to support numerous research jobs running simultaneously with unique toolsets. The data center infrastructure team's challenge is to architect a system for scientists with growing informatics needs for their research: more compute, more storage, faster storage, and \"bigger\" data. The team typically manages the data from high throughput lab instruments, such as NGS and Electron Microscopy. (EM) They support mixed workloads that can vary greatly, ranging from jobs with a few very large files (100s GB), to jobs with many very large files, to jobs with thousands of tiny (< 1MB) files, and jobs doing lots of meta operations. Existing storage architectures based on decades-old technologies used to meet the needs of capacity and were never a significant bottleneck to productivity when software stacks were not well developed. But with the increase in workload size, complexity, and throughput and the maturing of analysis workflows (highly-tuned CPUs and the emergence of GPUs), the legacy storage system can no longer keep pace with the growing performance demands. For the \"hot\" active data tier, researchers demand faster storage to handle mixed workloads and a cost-efficient object storage back-end solution to manage larger capacity. The ideal storage solution would: \u2022 Provide better throughput to remove the storage I/O bottleneck and speed data access to the applications \u2022 Enable concurrent research jobs \u2022 Tier seamlessly to object storage archive SERVER AS -2114S- WN24RT Figure 4 - 2U UP Single Node Server 6 Supermicro WEKAIO Reference Architecture \u2022 Be cost-efficient \u2022 Future-ready the data center that has begun exploring and using GPUs to accelerate compute By implementing the WekaIO solution, researchers have achieved better throughput and run more research jobs concurrently without negatively impacting other jobs or workloads. In addition, the turn-around time is better because the jobs finish faster and the results get to the scientist quicker, which accelerates the next stage of their research. The research workflows are greatly simplified because using Weka eliminates the complexity of staging data in and out of a compute node's local SSD. Research outcomes are no longer limited by how much data can be stored on a compute node's local SSD, and with WekaFS acting as a front-end, they have faster and easier access to their object archive tier, ensuring the applications have access to all the data. Ultimately, researchers now have so much performance and expandable capacity available to all nodes that nobody has to think about storage any longer, enabling a greater focus on outcomes of their research. For one customer, they had the following results: \u2022 Faster Time to Answer: research jobs were reduced 10X; one job was reduced from 70 days to 7 days; another typical analysis workflow was reduced from 12 hours to 2 hours. \u2022 Multiple Concurrent Projects: researchers supported 3x the number of simultaneous new research initiatives, all while having faster turn-around time and job completion times. This gets results to researchers faster. \u2022 Cost-Efficiency: The object tiering feature of Weka doubled the scratch space's available capacity for a lower overall storage cost. Alternative solutions based on All-flash combined with object storage for additional capacity were found to be 1.9-2.4X the price of Weka per usable TB. And while other SATA-based hybrid solutions being considered were slightly less $/TB, the massive performance improvement and time-to-value delivered by Weka offset the slight difference in acquisition cost. By comparing $/IOP or $/RW throughput, the Weka solution came out 8-10X ahead of both the all-flash and hybrid solutions. Summary Dramatic improvements in computational power and exascale needs for storage in today's digital mediums have meant that typical file systems traditionally used to address complex workloads are often impractical or inadequate to the task. WekaIO combined with Supermicro servers provides a stunning performance, protection, and data management story for Deep Learning, High-Performance Compute, and high-throughput low-latency storage workloads. WekaIO removes your computational storage bottlenecks by leveraging the power of NVMe and task-optimized servers with software designed for performance, scalability, and flexibility. The combination of Supermicro with the WekaIO application solution provides customers with solutions that can leverage our collective building-block architecture design to provide for the most cost-optimized capital expenditure while maximizing operational efficiencies. With Supermicro's professional services, the Supermicro Rack Integration can fully integrate, pre- tested, tuned, racked, and be operational in less than 30 minutes after receiving.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "224b4963-9d84-4a2c-a93c-ebb1eeff4609": {"__data__": {"id_": "224b4963-9d84-4a2c-a93c-ebb1eeff4609", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA_Power_on_AI.pdf", "publication_date": "March 2020", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 CUTTING EDGE AI 3 VALIDATED NVIDIA GPU CLOUD (NGC) SERVERS 3 FULL SUPPORT POWER-ON AI Supermicro NGC-Ready Systems - AI is helping to solve some of the world\u2019s most complex problems. Solving these enormous challenges require the computation of large amounts of data and highly optimized AI models running at scale. NVIDIA GPU Cloud (NGC) is the GPU-accelerated software hub for optimized AI and HPC. Supermicro\u2019s NGC-Ready systems make it easy and efficient to run large workloads with a complete end-to-end NVIDIA Tensor Core GPU-accelerated hardware and software stack: \u2022 Immediate AI software development and deployment when the systems are powered on. Operating System, CUDA, CUDA-X, NVIDIA drivers, container infrastructure are preloaded. Full support is available. \u2022 Access to the latest, cutting-edge deep learning AI models. Using pre-trained models, new AI systems can be constructed quickly with additional training. \u2022 The NGC containers run anywhere, whether they are on the Supermicro systems in the data center, in edge micro datacenters, on edge servers, and in the cloud if Cloud Bursting is needed. Kubernetes can orchestrate the containers in an extended set of systems to scale the processing for large enterprises. Power-on AI 2 CUTTING-EDGE AI The Supermicro NGC-Ready Systems run any of the NGC software, which is updated monthly with the latest deep learning models across multiple frameworks, including Tensorflow, PyTorch, MXNet. The models come pre-trained, allowing for faster training on new data. Some example models are available as shown in figure 2. NGC support service option removes road blocks in the development VALIDATED NGC-READY SYSTEMS \u2022 Performance-Validated: \u201cOut-of- the-box\u201d systems accelerate time to solution \u2022 Purpose Built for AI: Choose the right systems for the appropriate AI workload \u2022 Enterprise-Grade Support: Resolve issues during deployment to ensure minimal disruption Figure 2. NGC Ready Systems hardware and software offering. MACHINE LEARNING TOOLS RAPIDS, DIGITS, TensorRT Tensorflow PyTorch RECOMMENDATION ENGINE VAE, NCF, BERT NCF OBJECT RECOGNITION SSD Mask R-CNN IMAGE RECOGNITION ResNet50 VIDEO PROCESSING DeepStream TEXT, TRANSLATION BERT, GNMTv2 SPEECH NeMO ASR, Jasper MEDICAL CLARA V-Net, Unet Figure 2. Example NGC AI models and frameworks available from ngc.nvidia.com. CUDA-X NVIDIA DOCKER WITH GPU PASS THRU OPERATING SYSTEM CERTIFIED SYSTEMS Power-On AI 3 - Figure 3. Supermicro NGC Ready Systems. Processor, memory, disk, network could be adjusted to reflect customer needs. Please consult with your Supermicro representative to build larger systems. FULL SUPPORT The NGC-Ready Systems can be configured to come with pre-installed operating systems and NGC support software. Full support for the hardware system, the Red Hat or Ubuntu operating system, and the NGC software is available. VALIDATED NVIDIA GPU CLOUD (NGC) SERVERS SYSTEM CONFIGURATION LOCATION SYS-5019D-FN8TP with NVIDIA T4 GPU Xeon-D, Up to 512GB memory, 1 x PCIe x8 slot for GPU, 1 to 4 internal drives. 9.8\u201d depth Edge SYS-1019D-FHN13TP with NVIDIA T4 GPUs Xeon-D, max 512GB memory 2x PCI-E 3.0 x16 slots for GPU and I/O, 2 SATA, 15\u201d depth Edge SYS-1019P-FHN2T with NVIDIA T4 GPUs Single Xeon Scalable Gen 2, max 1.5TB memory 2x PCI-E 3.0 x16 slots for GPU, 2 SATA, 15\u201d depth Edge SYS-1019P-WTR with NVIDIA T4 GPUs Single Xeon Scalable Gen 2, max 1.5TB memory 2x PCI-E 3.0 x16 slots for GPU, 1 PCI-E 3.0 x8 for I/O, 10 SAS/SATA or 2 NVMe Edge SYS-2029GP-TR with NVIDIA V100, T4 GPUs Dual Xeon Scalable Gen 2, max 4TB memory 6x PCI-E 3.0 x16 slots for GPU and I/O, 8 SAS/SATA or 2 NVMe Edge SYS-5039MD18-H8TNR with NVIDIA T4 GPUs 8 Modules in 3U. Each Module has Xeon-D, max 512GB memory 1 PCIe x16 slot for GPU and I/O, 2 SATA with optional NVMe, 23\u201d depth Micro Data Center, Data Center SYS-1029U-TRT with NVIDIA T4 GPUs Dual Xeon Scalable Gen 2, max 6TB memory 2x PCI-E 3.0 x16 slots for GPU, 2 PCI-E 3.0 x8 for I/O, 10 SAS/SATA or 2 NVMe Micro Data Center, Data Center SYS-2029GP-TR with NVIDIA V100 GPUs Dual Xeon Scalable Gen 2, max 4TB memory 6 PCIe x16 slots for GPU and I/O, 8 SAS/SATA or 2 NVMe Micro Data Center, Data Center SYS-4029GP-TRT2 with NVIDIA V100 GPUs Dual Xeon Scalable Gen 2, max 6TB memory 11x PCI-E 3.0 x16 slots for GPU and I/O, 16 SAS/SATA or 8 NVMe Data Center SYS-4029GP-TVRT with NVIDIA V100 SXM2 GPUs Dual Xeon Scalable Gen 2, max 3TB memory 6x PCI-E 3.0 x16 slots for I/O, Single Root, 8 SAS/SATA/NVMe Data Center Power-on AI 4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "831992ef-9760-407f-9817-e87de86e9e70": {"__data__": {"id_": "831992ef-9760-407f-9817-e87de86e9e70", "embedding": null, "metadata": {"file_name": "Solution-Brief_RedHat_Ceph.pdf", "publication_date": "February 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "RED HAT Red Hat is the world\u2019s leading provider of open source enterprise IT solutions. We\u2019re here to help you address change with open principles so that you can navigate today\u2019s need for transformation, and prepare for the future. With engineers connected to open source communities, the freedom of our subscription model, and a broad portfolio of products that\u2019s constantly expanding, Red Hat is here to help you face your business challenges head-on. DEPLOY MASSIVELY SCALABLE SOFTWARE- DEFINED STORAGE The Supermicro Solution for Red Hat Ceph Storage Exploit new opportunities from your data Data is a powerful differentiator. The ability to extract value from your data can make a critical difference. Whether building a data lake for analytics (AI/ML) workloads, serving digital media, or providing capacity for archive or backup, you need flexible software-defined storage solutions that can be deployed rapidly and scaled or changed on demand to meet business needs. Supermicro and Red Hat have partnered to develop a best-in-class solution based on industry-leading SuperServers, SuperStorage, and Red Hat Ceph Storage to support a wide range of performance and capacity requirements. Red Hat Ceph Storage clusters can also serve Red Hat OpenShift clusters through Red Hat OpenShift Container Storage external mode. Supporting a full complement of object, block, and file access methods, Red Hat Ceph Storage provides a robust and compelling software-defined data storage solution that can support your data, no matter the format or origin. As a self-healing, self-managing platform with no single point of failure, Red Hat Ceph Storage significantly lowers the cost of storing enterprise data and helps companies manage exponential data growth in an automated fashion, offering: \u2022 Scalability and data protection, with capacity that scales to store hundreds of petabytes and billions of objects, with default replication. \u2022 Simplicity, with dramatically easier installation, operation, monitoring, and capacity management for greater flexibility and control. \u2022 Security, with client-side object-level encryption and sophisticated authentication features. As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. Deploy Massively Scalable Software-Defined Storage 2 * Please check with your Supermicro sales representative and website for compatibility and configuration details. Actual product may vary in appearance due to product configuration. High Performance Key Applications Base Server SKU Usable Capacity1 Form Factor CPU Memory Network Cache Device (optional) Drive (OS) Minimum cluster size Optimal starter cluster Content repository, object storage SSG-6049P-E1CR45L SSG-6049P-DE1CR90 360TB per node 4U 45x 3.5-inch bays Dual-node 4U 90x 3.5-inch bays Intel Xeon Scalable 384GB (up to 3TB) 4x 25Gb SFP28, 2x 10Gbe Up to 4x U.2 NVMe (45 bay) 2x 240GB 4x nodes 10x nodes Media delivery and streaming SSG-6029P-E1CR24L 176TB per node 2U 24x 3.5-inch bays (22x if deploying with optional NVMe cache) Intel Xeon Scalable 192GB (up to 3TB) 4x 25Gb SFP28, 2x 10Gbe Up to 2x U.2 NVMe (in 3.5-inch bays) 2x 240GB 4x nodes 10x nodes Flexible block, file and object storage for OpenStack SSG-6019P-ACR12L+ 88TB per node 1U 12x 3.5-inch bays and up to 4x 7mm U2NVMe for cache Intel Xeon Scalable 192GB (up to 3TB) 2x 10Gbe Up to 4x 7mm NVMe 2x 240GB 4x nodes 10x nodes Persistent storage SYS-1029P-N32R SSG-1029P-NEL32R 163TB per node 1U 32x NVMe bays Intel Xeon Scalable 384GB (up to 3TB) 4x 100Gb QSFP, 2x 10Gbe Not applicable 2x 240GB 4x nodes 10x nodes Medium Capacity Small Capacity Large Capacity High Performance Small Capacity Medium Capacity Large Capacity 1. Usable capacity based on 12TB drive capacity and 4+2EC data protection. Actual usable capacity may be different. Working together, Supermicro and Red Hat offer proven, validated solutions and reference architectures across multiple Red Hat software platforms, including Red Hat Ceph Storage. With these integrations, organizations can focus on their applications, knowing that careful engineering and testing has removed much of the time and risk and time required to deploy modern hybrid cloud infrastructure. The Supermcro Solution for Red Hat Ceph Storage also offers: \u2022 Installation and system burn-in for rack and cluster configurations, turn-key shipment with customer-provided IP address ranges and node naming, and burn-in and erasure for secure site deployments. \u2022 24/7 Onsite service from next business day to four-hour break-fix response service level agreement (SLA), toll-free number and VIP website, Technical Account Manger as a single point of contact, and a local parts depot stocked to help ensure SLAs. Supermicro solutions for Red Hat Ceph Storage use cases . Supermicro, the Supermicro logo, Building Block Solutions, We Keep IT Green, SuperServer, Twin, BigTwin, TwinPro, TwinPro\u00b2, SuperDoctor are", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a4731e2d-3b3b-46af-b230-4d6b49f903b7": {"__data__": {"id_": "a4731e2d-3b3b-46af-b230-4d6b49f903b7", "embedding": null, "metadata": {"file_name": "Solution_Brief_MicroAI.pdf", "publication_date": "August 2023", "referenced_websites": ["www.micro.ai.", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Traditionally, manufacturing maintenance strategies have relied on two main approaches: scheduled and reactive maintenance. For several decades these approaches were sufficient to maintain average levels of overall equipment efficiency (OEE); however, this is no longer the case, as costly limitations often accompany these approaches. On one end, equipment would either be over or under-maintained when relying on scheduled maintenance. While on the other end, reactive maintenance significantly increases the chance of unplanned downtime and safety risks. Both scenarios result in the inefficient use of resources while negatively impacting overall operational efficiency. To overcome these costly limitations, the industry has started shifting towards a predictive maintenance approach, which leverages artificial intelligence (AI) and machine learning (ML) algorithms to optimize OEE. The goal is to utilize real-time data and performance indicators to proactively identify potential 1 Challenges of AI Application Deployment in Manufacturing 2 Supermicro & MicroAI Solution 2 Next Generation Factory Management & Process Optimization 4 6 Conclusion 6 Further Information 7 2 equipment failures and prioritize maintenance activities to optimize resource allocation. Although AI and ML-based predictive maintenance technologies show great promise, it is not always easy to implement as they require certain prerequisites. Challenges of AI Application Deployment in Manufacturing Deploying AI-based predictive maintenance in this industry presents specific challenges that must be overcome to ensure successful implementation. Some of these include: \u2022 Limited Historical Data: AI models typically rely on substantial amounts of historical data for training. Usually, a subject matter expert and data scientist would be needed to analyze and develop an algorithm to train the AI model based on available historical data. \u2022 Data Complexity & Interpretability: In some cases, critical machine information may not have been captured in the past due to equipment or process changes, making it difficult to establish reliable patterns for accurate predictions. \u2022 Real-time Processing & Latency: Significant computational power and time are likely required, which can introduce latency that can impact other performances. \u2022 Complex System Integration: Manufacturing operations have a complex ecosystem of interconnected systems. This will require careful planning and implementation to ensure compatibility and seamless data exchanges between new applications and existing infrastructure. \u2022 Appropriate Edge Hardware Requirements: Edge devices with sufficient processing power to execute AI workloads while being robust in design to withstand rugged environments. Although these challenges prove to be burdensome, AI based predictive maintenance can provide many benefits in manufacturing. Supermicro & MicroAI Solution Realizing these challenges, Supermicro has partnered with MicroAI to develop a turnkey plug & play AI and ML factory platform. This Digital Factory combines Supermicro\u2019s ultra-reliable Intelligent Edge Systems with MicroAI\u2019s innovative technology to enable an AI based predictive solution that can be trained within a few days without needing preexisting historical data or data scientists. Features: Machine-Centric Intelligence Embedding and training AI and ML algorithms directly onto the MCU or MPU of the manufacturing device or machine. Customizes AI algorithms based on the asset's specific operational and/or environmental parameters to provide breakthrough predictive insights into maintenance requirements. Self-Learning AI and ML algorithms learn the standard behavior patterns of the asset under various operational conditions. This self- learning occurs without human intervention requirements and provides performance baselines based on actual performance vs. static specifications. Predictive Analytics Real-time, asset-specific performance data is automatically collected and analyzed to produce predictive maintenance intelligence based on current and projected asset health and performance. Maintenance is performed when needed eliminating unnecessary machine downtimes and reducing maintenance costs. 3 Catastrophic Failure Prevention Local, real-time, predictive analytics that detect and alert the possibility of device or machine failure. Intelligent, automated workflows provide rapid alerts to ensure prompt response and fault mitigation to extend asset lifespans and improve factory floor safety. Robust and Reliable Hardware Built to withstand harsh environments while still delivering high compute performance capabilities. Fanless design offers reduced energy consumption and ultra reliability. Deployment Architecture The deployment architecture consists of multiple components working together to ensure seamless data acquisition, analysis, and actionable insights. Overview: 1. Supermicro Edge Device: At the heart of the architecture, these edge devices are deployed throughout the manufacturing facility to capture sensor data from various machinery and equipment to perform real-time data processing, AI model inference, and local analytics. 2. Data Acquisition and Integration: This layer ensures seamless integration of all sensors with the edge devices. It utilizes communication protocols such as Modbus, OPC-UA, or MQTT to capture data from these sources. The acquired data is then preprocessed, filtered, and integrated to ensure compatibility and consistency. 3. Analytics Engine: Responsible for processing and analyzing sensor data collected by edge devices. It includes the AI models specifically trained for factory use cases, such as anomaly detection, fault prediction, and performance optimization. These 4 models are compact and optimized for edge computing, allowing real-time analysis directly on edge devices without relying heavily on cloud connectivity. 4. Central Management System: Allows administrators to monitor the health and performance of the edge devices, track analytics results, and configure the system settings in a user-friendly dashboard. 5. Connectivity & Communication: This includes wired and wireless connectivity options or industrial protocols like MQTT or OPC-UA. Supermicro SYS-E100-12T Series Specification: Next Generation Factory Management & Process Optimization Features: 5 Asset Monitoring & Self-Reporting: Enables real-time monitoring capabilities through collecting and analyzing sensor data. It continuously tracks asset conditions such as temperature, vibration, pressure, and other performance metrics to identify anomalies or deviations from normal operating parameters. OEE Analysis: Provides the ability to develop real-time AI/ML based insight into OEE performance of any manufacturing line and shift. The ability to view which equipment is performing below the expected rate immediately allows operations to make informed decisions. Cycle Time Analysis: This can predict the number of jobs that will be completed throughout a cycle. Displays a full line view that shows the occurrence of starved or blocked conditions and predicts the root cause of these conditions. This will allow management to see which assets or operators are underperforming. Performance Monitoring: AI/ML based Machine Health Scores are generated for each asset by ingesting control systems and sensor data. It\u2019s configured to optimize the days to the next maintenance based on the current performance and health of the machine. It will also generate alarms based on the events happening to the device or environment. Causality Analysis & Feedback Loop: Identifies root causes of problems or inefficiencies and establishes a feedback loop by providing insights into the causal relationships between variables. It will then facilitate the integration of these actions into the operational processes to continuously monitor and adjust performance. Key Benefits: Density Package Selection Increased Equipment Uptime Improved Operational Efficiency Cost Savings Efficient Resource Utilization Better Privacy & Security Enhanced Equipment Reliability Easy Integration Provides Real-time Analytics 6 Supermicro Servers Small: SYS-E50-9AP Medium: SYS-E100-12T-E Large: SYS-E302-12D-8C SYS-110P-FRN2T Conclusion AI driven predictive solutions have provided clear advantages for manufacturers, especially those that do not rely on the need for historical data. Supermicro and MicroAI\u2019s partnership creates a robust and comprehensive predictive maintenance solution combining AI, Edge Computing, and robust hardware. This powerful combination enables real-time anomaly detection, proactive maintenance, scalability, and security, ultimately optimizing OEE, reducing cost, and ensuring uninterrupted production in industrial manufacturing environments. By implementing Supermicro & MicroAI Digital Factory Platform, manufacturers unlock their manufacturing processes' full potential while maintaining their advantage in the dynamic manufacturing landscape. 7 Further Information Supermicro 5G, Edge, IoT, & Embedded Brochure 2023 Supermicro Fanless Edge Systems Supermicro Compact Edge Systems Supermicro 1U Edge Systems MicroAI Predictive Manufacturing MicroAI Digital Factory MicroAI Digital Intelligent Manufacturing WhitePaper MICRO.AI MicroAI is the pioneer in edge-native artificial intelligence (AI) and machine learning (ML). The company\u2019s mission is to automate the management of machines, enable them to self-monitor and self-report, and provide the most accurate information on machine health. The company\u2019s software is deployed within edge appliances aggregating data from multiple machines, as well as embedded on microcontrollers (MCUs) and microprocessors (MPUs) within an individual machine themselves. MicroAI\u2019s software is used by manufacturing and industrial processing companies, original equipment manufacturers, and asset owners to predict failures, identify security issues, and improve life-cycle management and overall equipment effectiveness (OEE).", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "1ef4cb95-5db0-4a7a-a63b-e61054fcfaae": {"__data__": {"id_": "1ef4cb95-5db0-4a7a-a63b-e61054fcfaae", "embedding": null, "metadata": {"file_name": "Solution-Brief_Reliant_Edge.pdf", "publication_date": "October 2023", "referenced_websites": ["www.supermicro.com/iot-edge", "www.reliant.io"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Deploying Next Generation Initiatives at the Edge 1 Acumera Reliant Edge Platform 2 Acumera Reliant Edge Platform continued 3 Supermicro Servers for Retail Edge 4 Conclusion 5 Supermicro is a global leader in high performance, green computing server technology and innovation. We provide our global customers with application-optimized servers and workstations customized with blade, storage, and GPU solutions. Our products offer proven reliability, superior design, and one of the industry\u2019s broadest array of product configurations, to fit all computational needs. ACUMERA Acumera is a leading provider of an edge computing software platform for hospitality and retail. Acumera\u2019s Reliant platform centralizes, automates, and controls application and content delivery, management, and security on-premise, in stores and restaurants. A natural extension of the cloud, edge computing reduces latency, supports continuous operations, and can accelerate digital transformation. The Acumera Reliant platform is a ready-to-deploy, proven solution with embedded tools to support large scale distributed environments through virtualization, containerization, centralized management, and comprehensive monitoring and security. Acumera converges new and legacy applications into an integrated and scalable system that is hardware agnostic. Acumera\u2019s clients represent leading retailers and restaurants. Edge computing refers to computing done in close proximity to users instead of relying entirely on the cloud. For businesses like retail, hospitality, and convenience stores, this often represents their stores, restaurants, and branches. Consumer-engaging businesses are increasingly seeking digital transformation, and edge computing is where new innovation meets the needs of connected consumers in these distributed environments. Today, every business, employee, and consumer is connected by technology, which has driven businesses to create more services and immersive experiences that require large amounts of data processing in real-time. As a result, the retail and hospitality industries must deliver the kind of innovation these connected consumers expect, such as mobile shopping/ordering, video streaming capabilities, interactive content, artificial intelligence, machine learning, and other new, exciting technology we now have at our fingertips. Edge computing allows the cloud and physical world to integrate, providing this next-generation, digital-ready infrastructure to support speed to market, delivering digital and immersive experiences in your stores, restaurants, and branches. Not surprisingly, Gartner predicts that 75% of data is expected to be created outside of central data centers (the Edge) by 2025. 2 Deploying Next Generation Initiatives at the Edge The Acumera Reliant Platform The Acumera Reliant Platform is a fully built-out, hardened platform for the retail, hospitality, and convenience store industries that includes robust capabilities for virtualization, containerization, monitoring, security for sensitive data, and centralized controls. This product provides a scalable infrastructure for supporting both legacy and next-generation applications, along with IoT devices across thousands of geographically dispersed locations. Figure 1: Acumera\u2019s Reliant Platform Benefits The Acumera Reliant Platform provides six core foundational components: 1. Application Hosting - (both containerization and whole OS virtualization) 2. Centralized Management \u2013 cloud-based web UI and REST-ful API enabled control 3. Orchestration \u2013 manage major or micro configurations across one, a set, or all sites, applications, and target endpoints under management 4. Monitoring \u2013 a comprehensive toolset for application and system availability, resources, services, and configurable thresholds for disk, CPU, RAM, port/service checks 5. Data Collection \u2013 centralized aggregation point within store/restaurant location for local log streams across all deployed hardware types, applications, and endpoints 6. Security - Endpoint security with managed threat protection, intrusion detection, and vulnerability management 3 Deploying Next Generation Initiatives at the Edge Acumera provides the Edge Platform solution directly to end operators and large-scale franchise organizations. The Acumera Reliant Platform is both cloud agnostic and supports x86 on-premise hardware related to end-customer deployment. The Acumera Reliant Platform management plane runs in client data centers, at 3rd colocation providers, and at major public cloud providers such as AWS, Google, and Microsoft Azure. Platform as a Service (\u201cPaaS\u201d) \u2013 where the Acumera Reliant Platform Edge solution is bundled with x86 physical edge capable hardware from an appropriate provider based on requirements with complete managed services, including encompassing account management/client services and level 1/2 break-fix support from a 24x7x365 US-based customer service center, core Acumera Reliant Platform release/updates, and patches. Software as a Service (\u201cSaaS\u201d) \u2013 software only where the prospect reuses existing x86 physical hardware or where Acumera facilitates hardware selection based on requirements. For SaaS delivery, the operator or franchise operator usually provides level 1/2 support, however, the Acumera Reliant platform can also supplement potential operators' support resources through a separate statement of work. Additionally, Acumera Reliant provides core level 3 product releases, bug fixes, and scheduled maintenance releases. Edge Management Plane Regarding the overall Edge Management plane, the customer can leverage Acumera\u2019s existing PCI DSS validated environment within AWS within a dedicated VPC or run those servers within their data center or authorized 3rd party hosting provider. Connectivity between the Acumera Reliant Edge Platform running on physical hardware can be established through a software- based TLS/SSL VPN originating from the Edge Appliance directly to a Reliant managed aggregation point within either Acumera\u2019s AWS VPC, the specific Customer\u2019s DC, or an authorized 3rd party. Alternatively, the Customer may elect to leverage existing dedicated connectivity through their existing providers through MPLS or an alternate VPN solution such as IPSEC. User authentication is based on username and password with multi-factor authentication into the central UI, which controls the Edge appliances, underlying hosted applications, and endpoints. Authentication between Cloud or Client DC management plane servers and the Acumera Reliant Edge Platform instances occurs through Acumera generated and managed certificates as part of Acumera\u2019s infrastructure. 4 Deploying Next Generation Initiatives at the Edge Convenience and Retail Stores Retail Edge Appliances are moving toward higher performance and greater expansion capabilities. This drive for increased performance is due to the industry\u2019s outlook on new technologies such as AI, particularly inferencing at the Edge. Industry leading brands are taking a strong position on deploying AI capability for immediate use and strategically deploying technology assets that will allow simple upgrades, such as adding GPUs when the application requirements evolve. A perfect example of this strategy is the recent deployment of a large Mid-West Convenience Store brand that installed Supermicro\u2019s SYS-E403-12P-FN2T into roughly 2,500 locations. This system can accommodate multiple GPUs, aligning with the brands' plans to bring AI capabilities to their locations. Based on Xeon Scalable processors, the E403, running the Acumera Reliant Platform has future proofed its technology deployment, saving considerable upfront costs while at the same time allowing for a later cost effective refresh using the already installed technology platform. E403-12P-FN2T Quick Serve Restaurants In the world of Quick Serve Restaurants, technology deployments present some unique challenges that Supermicro addresses with their Server Class Fanless systems, such as the SYS-E302-12D series. Bringing server performance into kitchen environments allows QSR brands to deploy technology in areas where a device relying on fans to keep cool would require a significant degree of maintenance and would likely experience an unacceptable level of failures due to particulates in the air being drawn into the system. The E302 platform is ideal for these locations to install technology that can handleall their application demands. Together, Supermicro and Acumera have deployed thousands of systems into this environment. SERVERS FOR RETAIL EDGE Supermicro supplies a range of servers optimized for Edge computing, with the processing power needed for applications and services required for retail and hospitality businesses. Edge SuperServers also support local data storage and coprocessors for Edge AI inferencing and visual computing. E302-12D-4C/8C The Supermicro E302-12D is a high performance fanless system that brings the power of the Intel Xeon D processor into kitchen environments where particulates and humidity wreak havoc on electronics. SYS-510D-4C/8C/10C-FN6P The 5019A-FTN4 is a low-power short-depth server that is ideal for the typical retail and hospitality environment while offering the cost/performance the market demands. SYS-E200-12D-4C/8C/10C w/Dual System Tray Redundancy is a critical requirement for retailers, where downtime can result in lost sales. Supermicro\u2019s small form factor systems are the ideal solution to maintain retail uptime. 5 Deploying Next Generation Initiatives at the Edge Acumera Reliant & Supermicro Partnership The Acumera Reliant platform utilizes off-the-shelf physical hardware directly from ISO certified vendors owned and managed facilities such as Supermicro. Reliant leverages Supermicro\u2019s ISO certification, including physical security controls, procedures, and processes, including order placement, procurement, staging, integration, and shipment. All physical hardware built for Acumera end-customers as part of a Platform-As-A-Service (PAAS) is shipped directly to Acumera\u2019s facility for the secure application of Edge system image, required quality assurance (QA) testing, and shipment. Conclusion Retail and Hospitality are increasingly enhancing customer experiences, efficiency, and profitability by expanding their Cloud- to-Edge compute capabilities. Technologies and services provided by both Acumera and Supermicro deliver the right scalable architecture to enhance a greater amount of next-generation technology and capabilities at the Edge. The combined solution offers significant efficiency through consolidated operations and central management, orchestration, and virtualized applications in a hardened and fault- tolerant system, enabling greater options for the store while providing AI and computer/machine vision applications, IoT, and immersive digital experiences at the Edge \u2013 inside the four walls of stores and restaurants. Scalability, reliability, and the enhanced management services from Acumera and Supermicro create a robust architecture to build upon and deliver faster digital transformation to meet today\u2019s retail, hospitality, and convenience store requirements.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "2798ba4b-2db7-453e-b440-5f82e4844120": {"__data__": {"id_": "2798ba4b-2db7-453e-b440-5f82e4844120", "embedding": null, "metadata": {"file_name": "Solution_Brief_Nodeweaver_and_Supermicro.pdf", "publication_date": "July 2023", "referenced_websites": ["https://nodeweaver.eu", "https://www.supermicro.com/en/products/system/iot/1u/sys-110p-frn2t", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 NodeWeaver is a software-defined \u201cnano-cloud\u201d platform that simplifies infrastructure and applications' deployment, management, and orchestration at the distributed edge. It installs on the bare metal of any x86_64 hardware. It enables the deployment of resilient and scalable compute clusters capable of running multiple applications, whether they run as VMs, containers, K8s, and/or real- time. Servers running NodeWeaver automatically combine at each edge location to form highly available compute clusters, delivering a cloud-native experience with reliable and scalable compute and storage for applications. NodeWeaver executes workloads on as few as one or two or scales up to N number of servers, providing reliability and high availability without reengineering the application. Thanks to the integrated remote management and monitoring service, the customer can update and control all the deployments, even with ephemeral internet connectivity. The autonomous management system eliminates the cost of downtime related to software or hardware failures. NodeWeaver\u2019s real-time mode allows even latency-critical workloads to run alongside traditional applications, removing the need for specialized hardware. The solution is optimized for virtualization, cloud, hosting, content delivery, hyper-scale/hyper- converged, and other general-purpose computing workloads. What types of workloads are deployed at the Edge? With advancements in artificial intelligence, deep learning, and machine learning technologies, companies are unlocking the value of data at the edge to improve insights and enable real-time responses and decision making. This leads to an explosion of 1 What types of workloads are deployed at the Edge? 1 Complete Edge Cloud Platform Provides a Zero- Touch Deployable, Autonomously Managed, and Hardware Agnostic Solution 3 Major Cruise Line Deploys Supermicro servers and NodeWeaver software 4 Benefits of the Supermicro/NodeWeaver Solution: 6 Summary 6 For More Information 6 2 the number of devices at the edge, which generate massive amounts of data that are too large to transfer to the cloud. Sending data to the cloud for processing can mean increased latency, processing and storage costs, and security risk in transferring sensitive information through the entire network. Additionally, local compute resources are essential in situations requiring near real-time data processing and response. Most solutions that include inferencing need to be updated frequently (or at least more frequently than traditional applications) because of changing environments, advances in state-of-the-art, and models that no longer perform the way they did when first deployed (model drift). This requirement drives the need to be able to remotely deploy, manage and monitor edge solutions that include an inferencing component. Another unique aspect of these inferencing workloads is that they often run on heterogeneous computing platforms (GPUs, NPUs, FPGAs, and ASICs), and the infrastructure needs to be able to orchestrate, monitor and monitor these different computing devices. In addition, a significant use case for Edge Computing is called Secure Access Service Edge (SASE). SASE is a architectural model that combines network and security-as-a-service functions together and delivers them as a single service. Conceptually, SASE extends networking and security capabilities beyond where they\u2019re typically available. This allows remote workers (or guests on ships at sea, for example) to take advantage of firewall as a service (FWaaS), secure web gateway (SWG), zero-trust network access (ZTNA), and a variety of threat detection functions. SASE solves several problems that traditional network security solutions face, such as: \u2022 High latency and poor performance due to backhauling traffic through centralized data centers or VPNs \u2022 Increased complexity and cost of managing multiple point solutions for different security functions \u2022 Lack of visibility and control over traffic and devices \u2022 Inability to scale and adapt to changing business needs and threats Additional SASE benefits include: \u2022 Improving user experience and productivity by reducing latency and enhancing performance \u2022 Simplifying network and security management by consolidating multiple functions into a single platform \u2022 Enhancing security posture by applying consistent policies and protection across all users, devices, applications, and locations \u2022 Reducing operational costs by eliminating the need for hardware appliances, VPNs, and MPLS circuits \u2022 Increasing agility and scalability by enabling rapid deployment and adaptation to changing business requirements and threats SASE deployment architecture consists of a global network of SASE points of presence (PoPs). The SASE PoPs provide network optimization, routing, encryption, and security services, such as firewall, secure web gateway, zero trust network access, identity and access management, and security broker. Traditionally, these network and security functions were deployed as separate, dedicated hardware devices for each service, however today, these network services are run as Virtualized Network Functions (VNFs) A typical enterprise might have dozens, hundreds or thousands of geographically distributed locations running SASE services \u2013 all critical to operations. Businesses must maintain maximum efficiency and resiliency for these services to optimize operations, 3 reduce downtime, and drive greater profit margins. Running as single, standalone appliances, these \u201ctraditional\u201d platforms lack redundancy or the ability to scale as requirements grow. Consequently, when there is a failure, disruptions occur, resulting in downtime and disruptions to processes, slowing down business and increasing the cost of ownership. Additionally, the inflexibility of an appliance-based approach presents numerous operational challenges related to upgrading, scaling, and future proofing systems, so having an autonomous, easy-to-deploy-and-manage platform which enables the delivery of these applications in an efficient, scalable, and highly available manner is crucial to success. Complete Edge Cloud Platform Provides a Zero-Touch Deployable, Autonomously Managed, and Hardware Agnostic Solution NodeWeaver is an edge operating platform optimized for running any type of application (VMs, containers, K8s, realtime) on the distributed edge and manageable at mass scale. It is a fully integrated system that includes multiple hypervisors, software-defined storage, software-defined networking, orchestration, provisioning, monitoring, remote access, high availability, and remediation, all in a small footprint. In addition to delivering cloud-native functionality at the edge, NodeWeaver addresses the challenges of deploying, operating, and managing infrastructure and applications at the distributed edge. \u2022 Zero Touch Deployment: NodeWeaver provides an integrated, secure, and patent-pending zero-touch configuration system called DNSOps, which combines the power and ubiquity of DNS with a USB key pre-downloaded installer that brings any hardware from zero to a fully operating private edge cloud in minutes without requiring customization or user intervention. It enables the deployment of autonomously run compute clusters capable of running multiple virtual Figure1:Edge Operating Platform 4 machines and container-based workloads reliably and cost-effectively. One or more servers running NodeWeaver automatically combine at each edge location, delivering a cloud-native experience with reliable and scalable compute and storage for applications. \u2022 Autonomous Operation: NodeWeaver\u2019s Autonomic Engine empowers edge nodes to handle issues and task execution without user intervention, even when connectivity is limited or non-existent. All the features of a cloud are available out of the box: high availability, load balancing, storage replication, software-defined networks, scripting, and API access. Businesses can significantly lower costs by reducing the need for IT expertise or physical intervention. \u2022 Simplified Scalability: NodeWeaver adapts itself to the available hardware, so it is possible to create clusters with heterogeneous hardware without needing to adapt or configure anything. Live swapping means you can replace a faulty system with any available system: no need to be restricted to identical hardware forever. Users can mix hardware within a cluster of nodes or even replace a specific node with new hardware, and the system automatically recognizes the processor, memory, and storage and optimizes/rebalances the cluster to meet the needs of the applications. The extremely lightweight footprint of the NodeWeaver platform \u2013 requiring only one physical core and 1 GB of memory - means that you can select the optimal hardware for your use case without wasting resources. Major Cruise Line Deploys Supermicro servers and NodeWeaver software One of the world\u2019s largest cruise lines uses Supermicro servers and NodeWeaver as the foundational platform for a global distributed edge infrastructure solution across all ship and shore-based operations to support a SASE (Secure Access Service Edge) rollout across their enterprise. The customer needed to have virtualized network functionality globally across all of its ships and in land based locations. Challenge The customer used the legacy approach of deploying standalone physical appliances to deliver network functionality such as firewalls, load balancers, access/management, and WAN optimization. These physical appliances are: \u2022 Expensive \u2013 the proprietary nature of purpose-built hardware adds significant cost. \u2022 Don\u2019t scale \u2013 additional capacity or compute power requires replacing with a new appliance. \u2022 Consume rackspace and power, and require cooling \u2022 Inflexible \u2013 proprietary appliances only do one thing. \u2022 Represent a single point of failure \u2013 if there is a hardware failure, services go down until another hardware appliance can be shipped. Or, the customer has to purchase 2x of each appliance for redundancy. Solution Nearly all modern network functions can be run as virtual instances (VMs and/or containers). By virtualizing multiple network functions and consolidating them onto a single platform, the customer was able to achieve several significant benefits: \u2022 Efficiency \u2013 no longer must run multiple standalone appliances, each occupying space, consuming power, and generating heat. \u2022 Resiliency \u2013 by running as a highly available, two node cluster, the VNFs will automatically restart on the surviving node in the event of a hardware failure. Given that these ships are at sea for days or weeks at a time, resiliency is critical as replacement parts aren\u2019t readily available. \u2022 Scalability \u2013 additional nodes can be added, one at a time, as they grow and add additional services \u2022 Flexibility \u2013 clusters can be comprised of heterogeneous hardware, so they don\u2019t have to worry about maintaining a spares pool of different servers over time. 5 \u2022 Management \u2013 Deploying, managing, and operating many geographically distributed locations at scale requires capabilities such as zero-touch deployment, autonomous operation, self-healing, self-optimization, remote management, and monitoring. While the initial use is focused on VNFs, this is a universal service delivery platform that acts as the foundation for delivering many other high-value services in the future across their entire global footprint. A vital example of this is Artificial Intelligence (AI). AI is being used today by companies of all sizes across all industries, and these applications are based on the collection and analysis of vast amounts of data from various IoT devices, such as video cameras and sensors. To take advantage of the actionable insights these AI applications can deliver, appropriate compute infrastructure must be in place to store and analyze this data. With Supermicro and NodeWeaver, the customer has a future-proof platform to run any application and incorporate any type of specialized processor, such as GPUs. The critical criteria for this project were the ability to create flexible, scalable, and highly available nano-clouds at the edge, which autonomically addresses failures, and the ability to easily manage hundreds of distributed locations worldwide with minimal human intervention. After evaluating other solutions in the market - Supermicro server PN: SYS-110P-FRN2T, which integrates compute, storage, and networking on a commodity platform, was selected. Supermicro and NodeWeaver were selected due to their simplicity, flexibility, reliability, and time to value. An Example of Edge Products: Supermicro SYS-111E-FDWTR Supermicro has the most extensive edge portfolio in the industry. An example of a core edge platform is the SYS-111E-FDWTR, one of the most powerful systems in its form factor. This compact system supports the latest 4th Gen Intel Xeon Scalable processors (up to 32 cores - 205Wor 350W with Fan Upgrade) and can support up to 2TB in DDR5 memory. This 1U short depth system measures in at 16.9\" (D) x 17.2\" (W) x 1.7\" (H), weighing in roughly over 15 lbs. This IoT system has front I/O network options for you to use the onboard 2 10GbE LAN ports with options of adding three additional front I/O add-on cards supporting 2 X PCIe 5.0 full height full length and 1X PCIe 5.0 HHHL. Key applications for this server include multi-access edge computing, flex-RAN, Open-RAN vBBU, artificial intelligence (AI) on edge, and machine learning. 6 Benefits of the Supermicro/NodeWeaver Solution: \u2022 Zero touch deployment capability enables customers to deploy the full environment with all applications and network settings without requiring skilled personnel. This is highly important given that these are being deployed on ships and other land-based locations worldwide. \u2022 Utilizes the latest technology with 4th Gen Intel Xeon Scalable processors (up to 32 cores - 185W) and can support up to 2TB in DDR5 memory with onboard 2 X 10GbE BaseT ports for network connectivity. \u2022 Network services are resilient to failure since they are virtualized on this platform. \u2022 Highly resilient 2-node clusters that run multiple VMs can replace multiple dedicated appliances at customer sites and provides a scalable platform on which other high-value services can be delivered in the future. \u2022 Front I/O makes it easy to deploy. \u2022 Redundant 800W AC Power Supplies with Power-on mode for AC power recovery help to keep the platform running without disruption. \u2022 The server supports the creation of nano-clouds at the edge, providing redundancy and continued service without disruption. Summary In today\u2019s world, processing large amounts of data at the edge is critical in supporting application demands at the edge. Processing data closer to where it is being generated decreases latency, increases processing speed, and improves results for real-time applications. Supermicro\u2019s building block solutions enable us to provide you with a wide selection of products to satisfy your requirement, delivering the best solution fully optimized with low latency and high availability. Simplicity, flexibility, reliability, and time to value from Supermicro and NodeWeaver provide a great Edge Cloud Platform to meet today\u2019s challenges and requirements at the Edge.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "0a196c04-5a8d-4221-9604-3a4ea6a223e8": {"__data__": {"id_": "0a196c04-5a8d-4221-9604-3a4ea6a223e8", "embedding": null, "metadata": {"file_name": "Solution-Brief_Media_Processing_Delivery.pdf", "publication_date": "December 2022", "referenced_websites": ["https://www.supermicro.com/en/products/rackmount", "https://www.supermicro.com/en/accelerators/intel", "https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/data-center-gpu/flex-series/overview.html"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 The global health crisis of COVID-19 has played a significant role in driving the surge in video streaming, and this trend seems set to persist. Today, video is responsible for more than 80% of all internet traffic worldwide. As the demand for this online video content continues to grow, so does the need for reliable and efficient transcoding and streaming infrastructure. In addition, consumers are getting accustomed to viewing broadcast-quality videos using a wide variety of devices with high resolutions. As a result, service providers must find new ways to optimize their existing solutions and ease the total cost of ownership; while meeting consumers' demands for more sophisticated content. With Supermicro systems equipped with Intel Data Center GPU Flex Series, providers can efficiently fit and scale to more subscribers with a smaller data center footprint, thereby reducing equipment and facility costs\u2014without compromising quality. 1 The Importance of Transcoding in Video Streaming 2 Media Delivery Architecture and Workflow 2 The Challenges of Media Delivery 3 Supermicro Solutions for Media Processing and Delivery . 4 Extensible IT Portfolio with Supermicro Systems 4 Advanced Accelerators: Intel Data Center GPU Flex Series 5 Open Standards Architecture 6 Optimized Platform with Supermicro and Intel 6 Conclusion 8 2 The Importance of Transcoding in Video Streaming Over the past few years, streaming quality has skyrocketed across industries due to the ongoing pandemic, increased accessibility to high-end video, and better bandwidth for Over-the-Top (OTT) and Video-on-Demand (VOD) delivery. Further, organizations increasingly use video to disseminate information internally and externally, relying on live-streaming media for webinars and company meetings. Cloud Gaming is another fast-growing segment in the video streaming domains, presenting service providers and game publishers with new business opportunities and rapid technological changes. As technology becomes more accessible, new streaming content providers, both large and small, are emerging. Media or video content, either on-demand streaming or live streaming, needs to be adjusted based on the device characteristics of viewers. The original video must be encoded or compressed to reduce the size of Raw video files. Also, to match the viewers' devices, the stream must be decoded or converted to a supported resolution, frame rate, video codec, and network bandwidth. This process is referred to as video transcoding, which minimizes bandwidth and delivery infrastructure usage. Video transcoding is a core technique for streaming because it affects the streaming service for both the service provider and the users. The video service provider must decide how to transcode video content into multiple representations and store them, which further increases the operational cost of the service provider. Since video transcoding is computation-intensive and consumes considerable resources, it will significantly affect the service provider's operating cost. Media Delivery Architecture and Workflow To provide viewers with high-quality video content in real-time so much goes on behind the scenes. Media processing and delivery comprise three essential processes: video capture, video transcoding, and streaming delivery. Video content is initially captured and stored with a particular format, spatial resolution, frame rate, and bit rate. Then, the video is uploaded to streaming servers. Next, a streaming server must transcode the original video based on the client's network bandwidth, device resolution, frame rate, and video codec. Finally, video streams are distributed via CDNs server to end devices. Figure 1 - Video Transcoding Workflow Figure 2 \u2013 Media Delivery Architecture and Workflow 3 The Challenges of Media Delivery Rapid technological and network advances are improving content delivery but, at the same time, drastically increasing the streaming throughput. Therefore, a modern streaming solution infrastructure must be flexible and scalable. Determining the proper hardware to architect the media delivery workflow can take time and effort. Cloud service providers need to consider an extensible and easy-to-manage IT platform ecosystem, covering from the cloud to the edge. The challenge of delivering video is aggravated by the users demanding access to their video streams anywhere, on any device. Videos must be transcoded effectively and efficiently to provide the desired user experience. Codecs are essential in delivering the best video quality while ensuring a smooth playback experience. Accordingly, a video streaming infrastructure requires leveraging the most advanced and new codecs, such as AV1, VP9, and HEVC. New codecs allow service providers to deliver the same video quality with a smaller bitrate. However, these codecs are more compute-intensive than H264. With hundreds of millions of videos being uploaded by users every day, it would be prohibitively expensive for service providers to use CPU-only transcoding for all AV1 and HEVC videos. So, compute costs must be added as another dimension of an optimized and cost-effective solution. New hardware and technologies are demanded to support new streaming requirements. In addition to the above challenges, HEVC and h264 codecs include many patent-protected video compression techniques. Organizations must license the patents from their creator or representative to use these codecs. However, we're talking about several thousand patents from just a few dozen companies. Consequently, codec royalty payments are pricey and difficult to understand. Key Challenges in Media Delivery Solutions Total Cost of Ownership \u2022 Hard-and-fast hardware platforms; are expensive to manage and scale. \u2022 Hardware accelerators with high power consumption, low transcoding density, and high bit rate demands. \u2022 Siloed environments and high royalty fees. User Experience \u2022 High latency \u2022 Network and data congestion \u2022 Poor video quality 4 Supermicro Solutions for Media Processing and Delivery Partnering with Intel, Supermicro offers qualified platforms to get service providers ready to tackle the Media Processing and Delivery challenges. \u2022 An extensible IT portfolio offering fitting platforms for the cloud and the edge. \u2022 Latest accelerator support, offering advanced codecs and technologies. \u2022 Open standard architecture with standard industry frameworks and libraries. Extensible IT Portfolio with Supermicro Systems Deciding whether a streaming media workflow should use cloud servers, edge servers, or a mix of both comes down to several factors. Encoding and transcoding can span across the streaming platform depending on specific workloads. For example, while the processing of live streaming for social networks can operate acceptably from the cloud, more latency-sensitive and high- performance workloads, such as game streaming (cloud gaming), should be placed at the edge. Figure 3 \u2013 Media Solution Platform Stack Figure 4 - Supermicro Systems for Media Processing and Delivery 5 With an extensible IT portfolio, Supermicro offers a choice of systems to build an optimized streaming platform. The systems provide a tradeoff between the maximum number of accelerators, rack density, and cost-effectiveness. Systems like the SYS- 530MT-H8TNR, provide essential performance, low power consumption, and balanced workload density for the cloud. While systems equipped with the Intel Xeon Scalable Processors, such as the SYS-420GP-TNR and the SYS-220BT-HNTR, offer high performance and additional compute resources for critical workloads and optimized application acceleration. In addition to having flexible, scalable, and power-efficient designed systems, Supermicro offers reliable and manageable systems. Featuring redundant power and cooling systems, Supermicro systems have proven reliability. Remote management, IPMI support, and Redfish 1.8 are standard, and the systems also support TPM 2.0 and Root-of-trust security. Advanced Accelerators: Intel Data Center GPU Flex Series The development of GPUs in the last few years has progressed from specialized graphics chips to general-purpose computing devices. GPUs offer higher efficiency for parallelizable operations, allowing for higher compute per dollar compared to CPUs. This power consumption challenge is also faced by video streaming solutions. The new Intel Data Center GPU Flex Series performs high- performance and high-quality transcoding. The GPU instances deliver higher throughput, meaning a lower cost per video. In addition, it is possible to process the latency-sensitive workload faster and provide a better customer experience. This accelerator has exciting new media features\u2014royalty-free AV1 Hardware Encoding support and an advanced software bitrate controller to boost hardware encoding quality. The Flex Series comes in two flavors: The Flex Series 140 and the Flex Series 170. These GPUs have four classes of video accelerator engines, ensuring typical transcode operations can facilitate pipeline execution to minimize latency. Multiple accelerator units allow the concurrent execution of various frames to maximize throughput. Intel has significantly innovated to develop these two data center GPU accelerators to provide the best operations and performance for Cloud Gaming and Virtual Desktop Infrastructure. Also, the AV1 codec has been demonstrated to provide lower bandwidth requirements to transmit higher quality streaming graphics. Being royalty-free versus HVEC codecs, the use of Intel Data Center GPUs significantly reduces costs for media delivery providers. Figure 5 - Intel(R) Data Center GPU Flex Series Specs 6 Open Standards Architecture Intel's discrete graphics accelerators are well integrated into open-source media frameworks such as FFmpeg and Intel's oneAPI Video Processing Library (oneVPL). These popular frameworks allow both complex pipeline support and extreme customization of accelerator control. In addition, to make these tools even more accessible to Linux developers, Intel provides build scripts in Docker on the latest Linux kernels. Media transcoding performance is optimized across integrated and discrete GPUs with Intel oneVPL. In addition to video processing and delivery, oneVPL provides encoding, decoding, and streaming APIs for applications, including broadcasting, streaming, video-on-demand, and cloud gaming. CDNs and other delivery providers continue to struggle with high delivery costs, despite the decreasing cost of large- scale data storage. Improved compression helps the media processing and delivery providers reduce operating costs. AV1, a next-generation codec, is built into the Flex Series GPUs, bringing the highest quality real-time video, scalable to any modern device at any bandwidth. AV1 is a royalty-free codec that delivers commercial or non-commercial user- generated content with a low computational footprint optimized for internet streaming. In addition, the streaming quality is not compromised, and the cost per stream is reduced by 30% with no degradation in compression. AVC, HEVC, and VP9 codecs are also supported along with AV1. It is possible to access these codecs using standard frameworks such as FFmpeg or Gstreamer, or with oneVPL, which allows access to more controls and parameters. With these encoders, providers can adjust TCO-related parameters based on performance/quality presets. Optimized Platform with Supermicro and Intel To meet subscriber demands for more sophisticated content, media processing and delivery providers must optimize their TCO. Supermicro and the Intel Flex Series GPU support that purpose by increasing the density of streams supported per server without compromising quality. Supermicro is first-to-market with solutions for Intel Data Center GPU Flex Series, so early testing for workload has been possible. Following Intel's guidelines, video streams with 1080p and 4K resolutions were benchmarked using FFmpeg. Further, using optimized Intel presets for video transcoding, H.264, HEVC, and AV1 codecs were tested. 7 As a result, a single Intel Flex Series 140 GPU can support as many as eight simultaneous 4Kp60 or 36 1080p60 streams per card. The accelerator provides this exceptional performance while keeping its power below 70 watts. The partnership between Supermicro and Intel allows for a range of configurations. For example, populating SYS-the 420GP-TNR systems with ten cards, 80 4Kp60 or 360 1080p60 streams can be delivered. More configurations are available for different Supermicro systems, giving service providers the right choice and allowing them to reduce their data center footprints and expenses associated with equipment and facilities. Figure 7 - Intel Flex Series GPU Transcoding Performance Figure 6 - Streaming density for various Supermicro systems with the Intel(R) Flex Series GPUs 8 Conclusion Supermicro and the Intel Flex Series GPUs let providers serve more subscribers with a smaller data center footprint, reducing the costs associated with equipment and facilities. In addition, reducing the high performance per watt reduces the total cost of ownership (TCO). Please contact your Supermicro sales representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "130b32a3-5d81-4922-85f8-7a619cb8aa6c": {"__data__": {"id_": "130b32a3-5d81-4922-85f8-7a619cb8aa6c", "embedding": null, "metadata": {"file_name": "Solution-Brief_MemX.pdf", "publication_date": "June 2017", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Advanced In-Memory Computing using Supermicro MemX Solution What is In-Memory Computing With the explosion of data gathering we are seeing today, organizations need to find new ways of collecting, sorting, and analyzing this data in order to make real time business decision. Having a large amount of data at your disposal is only one part of the equation. Being able to use the data is the other part. Traditional storage systems can no longer keep up with the demand of real-time analytics, so Big Data System Administrators have turned to large scale-up systems populated with massive amounts of DRAM. Benefits of IMC By turning to in-memory computing, businesses can quickly discover patterns, analyze massive data volumes, and perform business intelligence operations in real time. In-Memory Computing is used in diverse industries such as financial services, telecommunications, healthcare and life sciences, government, energy, transportation, among many others. Some of the benefits to in-memory computing include: \u2022 Mitigating Errors and Avoiding Future Failures Real-time data analytics allows businesses to quickly react to, or avoid future operating problems. Doing so protects business continuity and keeps customers satisfied. \u2022 Advanced Business Intelligence Staying ahead of the competition is key. Using in-memory computing for BI applications allows businesses to become dynamic, and transform their strategies on the fly. \u2022 Fraud Detection Security is paramount. Cyber-attacks lead to financial losses and business down-time. Real-time security systems expose these threats and allow them to be mitigated instantly. Advanced In-Memory Computing using Supermicro MemX By replacing large monolithic servers with Supermicro\u2019s high- performance NVMe solutions, system administrators can now us NVMe Solid State Drives in place of expensive DRAM and slow external SAN or NAS storage. This greatly reduces initial acquisition costs by up to 85%, while reducing operational costs and providing added scale-out flexibility over competing DRAM In-Memory Computing solutions. With Supermicro\u2019s MemX Solution, end users can increase their internal storage up to 10x and system memory up to 2x. This allows for greater server consolidation, making Supermicro MemX the most flexible, scalable IMC solution on the market. System Memory (GB) Internal Storage (GB) Supermicro MemX HD Enterprise Scale-up System Solution Cost 90% Acquisition Cost Reduction ENTERPRISE SCALE-UP SYSTEM MEMX MEMX HD MEMX ENTERPRISE Up to 12x Storage Increase Up to 2x Memory Increase ENTERPRISE SCALE-UP SYSTEM MEMX MEMX HD MEMX ENTERPRISE 01_MemX-Solution-Brief_170104_Rev07 Specifications subject to change without notice. All other brands and names are the property of their respective owners. Reference Architecture MEMX CLOUD (PER NODE) SYS-2028BT-HNR+ MEMX HD SYS-1028U-TN10RT+ MEMX SYS-2028U-TN24R4T+ MEMX ENTERPRISE SSG-2028R-NR48N Processors E5-2683 v4 E5-2683 v4 E5-2683 v4 E5-2699 v4 Total Cores 32 cores @ 2.1GHz 32 cores @ 2.1GHz 32 cores @ 2.1GHz 44 cores @ 2.2GHz Total System Memory (GB)* 3,328 / 11,776 3,328 / 11,776 3,328 / 11,776 6,656 / 11,776 Total SSD Storage Size (GB) 1,920 9,600 / 38,400 60,800 / 145,920 137,600 / 330,240 SSD Storage Model 2 x 10GBase-T ports (SIOM) 2 x 10GBase-T ports 2 x 10GBase-T ports 2 x 10GBase-T ports MemX White Paper", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "81d4b2c2-ab24-450d-9f63-018ead99033f": {"__data__": {"id_": "81d4b2c2-ab24-450d-9f63-018ead99033f", "embedding": null, "metadata": {"file_name": "Solution-Brief_Atempo.pdf", "publication_date": "February 2023", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Solution Overview Unstructured data growth is accelerating at an ever-increasing pace, with petascale file sets becoming commonplace. To store these large file sets, companies have typically used heterogeneous storage platforms from multiple vendors\u2014cloud, NAS, distributed, or parallel file systems\u2014which contributes to data sprawl and adds management complexity. As a result, many organizations are turning to next-generation software-defined storage platforms to consolidate into a single namespace and simplify management. However, migrating unstructured file data between these disparate storage platforms is complex and risky. Solutions such as rsync or Robocopy are not scalable, require many time-consuming checks, and can lead to data loss. Organizations require a cost-effective migration solution that can quickly and reliability move hundreds of millions or billions of files from existing storage to these next-gen platforms. Atempo\u2019s Miria, built on Supermicro SuperServers, offers a high-performance, scalable, multi-platform solution for migrating petabytes of unstructured file data with millions/billions of folders and files. Solution Features Miria is an open solution for multi-storage sources (cloud, object storage, NAS & Scale-out NAS, storages, and shared or parallel filesystems) with a wide range of target storages: disk, object, optical disk, tape, and/or cloud. It provides migration, archive, and disaster recovery capabilities for organizations of all sizes. Solution Overview 1 Solution Features 1 Solution Architecture 2 Use Cases 3 Networking Options 4 Supermicro Miria Ready Server Platforms 5 Conclusion and Summary 5 Further Information 5 1 Solution Overview . Error! Bookmark not defined. Solution Features Error! Bookmark not defined. Solution Architecture Error! Bookmark not defined. Use Cases Error! Bookmark not defined. Networking Options Error! Bookmark not defined. Supermicro Miria Ready Server Platforms Error! Bookmark not defined. Conclusion and Summary Error! Bookmark not defined. 2 Key Benefits \u2022 Multi-Storage Platforms: Object, Cloud, SAN/NAS, distributed and parallel filesystems \u2022 Multi-Storage Protocols: NFS, SMB/ CIFS, PFS, S3, and more \u2022 Scalable: Adjust performance by simply adding or removing a Data Mover \u2022 Incremental and automatic file migration between heterogeneous architectures \u2022 Minimum impact on production and a fast cutover to the new storage \u2022 Automatic integrity checks on all migrated files \u2022 Simple and user-friendly web interface to supervise the migration process \u2022 Evolutive solution: New storage can be backed up using the same solution if necessary Migration Usages \u2022 Local to Cloud: Migrate data from local storage to the cloud. \u2022 Cloud to Cloud: Migrate data from provider A to provider B to change to a new cloud provider or move data from public to private cloud. \u2022 Cloud to Local or back to on-prem: Migrate data from cloud storage to local storage, a \u201creverse cloud\u201d migration. \u2022 Local to Local: Migration between different storage technologies or different vendors, for instance, from Lustre to GPFS or from GPFS to Lustre, from NAS to GPFS, etc. Solution Architecture The infrastructure for Miria is designed to be scalable, flexible, and efficient. Miria\u2019s infrastructure is composed of the following software components: \u2022 Miria Server \u2022 Miria Data Movers Miria Server The Miria Server hosts a central repository to monitor the complete Miria infrastructure and to provide reporting and statistical information. This catalog stores all file information and all relevant configuration details, such as backup workflows and associated backup policies, data mover pools, and associated target pools. The primary role of the Miria Server is to maintain a centralized catalog based on a relational database. Data Mover The role of a data-mover is to simultaneously read data from a source storage and write data to the target storage at the maximum speed. 3 Figure 1 - Miria Architecture Use Cases The Supermicro and Atempo solution can be used in many industries, and the type of servers needed depends on the volume and type of data. Figure 2 - Miria Use Cases 4 Supermicro Configurations The following configurations are provided for the Miria Server: Figure 3 - Supermicro Miria Server Configurations The following configurations are provided for the Data Mover: *See Networking Options below Figure 4 - Supermicro Data Mover Configurations Networking Options The design includes all core components to support migration over a dedicated 100GbE QSFP28 network with the addition of a 10GbE SFP+ management network. Flexibilities to accommodate a specific customer use case comes from the number of available PCIe slots in the selected server. For example, optional I/O cards for SAS, Ethernet, or Fiber Channel connectivity require a free PCIe slot in the server being considered. Additional Ethernet card options can be substituted to replace the 100GbE networking provided. 5 Supermicro Miria Ready Server Platforms SYS-510P-WTR SYS-110P-WTR SYS-120C-TR Single Socket P+ (LGA-4189) 3rd Gen Intel Xeon Scalable processors. Up to 270W TDP. Single Socket P+ (LGA-4189) 3rd Gen Intel Xeon Scalable processors. Up to 270W TDP. Dual sockets P+ (LGA-4189) 3rd Gen Intel Xeon Scalable processors. Up to 270W TDP. 8 DIMMs; Supports 3DS DDR4-3200: RDIMM/LRDIMM/Intel DCPMM 8 DIMMs; Supports 3DS DDR4-3200: RDIMM/LRDIMM/Intel DCPMM 16 DIMMs up to 6TB 3DS ECC DDR4-3200: LRDIMM/RDIMM/Intel DCPMM 2 PCIe 4.0 x16 (FHFL) slots 1 PCIe 4.0 x16 (LP) slot 2 PCIe 4.0 x16 (FHFL) slots 1 PCIe 4.0 x16 (LP) slot 2 PCIe 4.0 x16 (FHHL) slots 2 PCIe 4.0 x16 AIOM (OCP 3.0) 2 PCIe 3.0 x2 NVMe M.2 Intel Ethernet Controller X550 2x 10GbE RJ45 Intel Ethernet Controller X550 2x 10GbE RJ45 Networking via Slim AIOM 4x hot-swap 3.5'' Hybrid SATA3/NVMe drive bays, SAS3 with additional SAS controller card; Onboard 1x NVMe/SATA M.2 10x hot-swap 2.5'' SATA3 drive bays with 4 hybrid NVME/SATA drive bays, SAS3 with additional SAS controller card; Onboard 1x NVMe/SATA M.2 8x 2.5\" hot-swap SATA/SAS drive bays Redundant Platinum 500W Power Supply Redundant Platinum 750W Power Supply Redundant Platinum 800W/860W Power Supply Conclusion and Summary Supermicro is a high-performance server and storage solution provider, while Atempo is a software company specializing in data migration and management. Together, these two companies can help an organization meet its data migration needs by providing hardware and software solutions that are optimized for the task. Supermicro's high-performance servers and storage systems can be used to quickly and efficiently move large amounts of data, while Atempo's data migration and management software can be used to ensure that the data is adequately protected and managed during the migration process. By combining the strengths of these two companies, an organization can ensure that its data migration needs are met in a reliable and efficient manner. Further Information", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "5cee4769-2d41-458a-a0d1-9c9cca9fb36d": {"__data__": {"id_": "5cee4769-2d41-458a-a0d1-9c9cca9fb36d", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA_AI_Training.pdf", "publication_date": "March 2020", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 CUTTING EDGE AI 3 VALIDATED NVIDIA GPU CLOUD (NGC) SERVERS 3 FULL SUPPORT SCALING AI TRAINING WITH DESIGNED NVIDIA GPU SYSTEMS Supermicro NGC-Ready Systems - Time to market is key to success for today\u2019s AI development. By using Supermicro designed NVIDIA GPU systems that have all the latest AI stack installed and supported, data scientists and AI developers can start testing and training their AI models for product development and research. New AI models, such as BERT, GPT-2, or R-CNN require the compute power of multiple GPUs to solve them. Strong scale-up nodes can be built by using NVIDIA NVLink and NVSwitch interconnect technology within a single server, and GPUDirect RDMA across servers. Supermicro offers a set of scalable multi-GPU systems using the fastest NVLink/NVSwitch GPU interconnects supporting 4, 8, and 16-GPU, and high speed Mellanox interconnect between servers. The more GPUs that are aggregated, the shorter the AI training time. Other times, each GPU can be shared by multiple data scientists and developers. Scaling from fractional GPU use to aggregating thousands of GPUs, NVIDIA GPU Cloud (NGC) is the most cost effective way to get these multi-GPU systems ready for AI development. Power-on AI 2 AI READY NVIDIA GPU CLOUD CONTAINERS NGC is the hub for GPU-optimized software that contains quality assured, enterprise-grade containers for AI and HPC applications, pre-trained models, model scripts, helm charts and industry SDKs. This allows data scientists, developers and IT managers to access, build, and deploy apps across various platforms, from on-premise to cloud to edge. The software can be pre-installed on the systems to enable the following: \u2022 Latest optimized and secure AI models, many of which are pre-trained \u2022 Containers run anywhere, supports CI/CD infrastructure \u2022 Full 24x7 support Figure 2. GPU scaling for more CUDA cores and bigger GPU memory. 12,800GB 2,560GB 256GB 32GB 16GB 4GB 640 2,560 5,120 40,960 409,600 2,048,000 1/8 1/2 1 V100 8 80 4,000 NUMBER OF V100 GPU CORES GPU MEMORY SYS-1029GP SYS-4029GP 10x SYS-4029GP 50x SYS-4029GP vComputeServer NVLINK GPU-Direct RDMA Power-On AI 3 - For AI models and data batches that require more CUDA cores and GPU memory than that available from the largest 16-GPU system, GPUDirect RDMA and NCCL are used to scale the GPU cores and memory over 100Gigabit InfiniBand or Ethernet fabrics. NGC software makes deployment of multiple GPU systems easy. Tens or hundreds of these systems can be aggregated to run the biggest AI models and data batches. Combined with high performance NVMe-fabric storage and networking, these systems build complex AI systems with ease and speed. SXM-GPU SYSTEMS CONFIGURATION WITH ADDITIONAL OPTIONS SYS-1029GP-TVRT With 4 NVIDIA V100 SXM2 GPUs 300GB/s NVIDIA NVLink GPUDirect RDMA support Aggregate 20,480 CUDA cores, 128GB GPU memory 1U Rackmountable, 35.2\u201d depth Dual 2nd Gen Intel Xeon Scalable Processors Max 3TB ECC memory 4 PCI-E 3.0 x16 slots for I/O 2 SAS/SATA drives 2000W (1+1) Redundant Titanium Level power IPMI, Redfish SYS-4029GP-TVRT With 8 NVIDIA V100 SXM2 GPUs 300GB/s NVIDIA NVLink GPUDirect RDMA support Aggregate 40,960 CUDA cores, 256GB GPU memory 4U Rackmountable, 31.7\u201d depth Dual 2nd Gen Intel Xeon Scalable Processors Max 6TB ECC memory 6 PCI-E 3.0 x16 slots for I/O 16 SAS/SATA (optional 8 NVMe) drives 2200W (2+2) Redundant Titanium Level power IPMI, Redfish SYS-9029GP-TNVRT With 16 NVIDIA V100 SXM3 GPUs 300GB/s NVIDIA NVLink and NVSwitch fabric GPUDirect RDMA support Aggregate 81,920 CUDA cores, 512GB GPU memory 10U Rackmountable, 27.75\u201d depth Dual 2nd Gen Intel Xeon Scalable Processors Max 3TB ECC memory 16 PCI-E 3.0 x16 slots for I/O 2 SAS/SATA drives 3000W (5+1) Redundant Titanium Level power IPMI, Redfish HIGHEST PERFORMANCE MULTI-GPU SYSTEMS Supermicro offers a scalable set of multi GPU systems with NVIDIA V100 GPUs interconnected with NVIDIA NVLink and NVSwitch. These systems offer an increasing number of aggregate CUDA cores and GPU memory for scaling larger AI models and batch data. SYS-1029GP-TVRT SYS-4029GP-TVRT SYS-9029GP-TNVRT Power-on AI 4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "afb5cd69-8cb0-43e2-82f0-6dbe7b30d3d4": {"__data__": {"id_": "afb5cd69-8cb0-43e2-82f0-6dbe7b30d3d4", "embedding": null, "metadata": {"file_name": "Solution-Brief_Rack_Scale_AI.pdf", "publication_date": "June 2023", "referenced_websites": ["https://www.supermicro.com/en/support/resources/cpu-4th-gen-intel-", "www.supermicro.com/liquid-cooling)", "https://www.supermicro.com/en/solutions/rack-integration", "https://www.supermicro.com/en/products/gpu"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Turbocharge AI infrastructures with Supermicro\u2019s rack-scale complete plug-and-play AI solutions powered by Supermicro SYS- 821GE-TNHR or the AS -8125GS-TNHR GPU Servers. These application-optimized servers are ideal for medium to very large AI training scenarios and contain dual AMD or Intel CPUs and eight high- performance NVIDIA GPUs. This purpose-built highest density turnkey rack scale solution is extremely scalable and customizable to meet any scale of Deep Learning workload demands. Leveraging NVIDIA\u2019s cutting-edge NVIDIA H100 SXM GPUs and harnessing the power of Supermicro\u2019s supreme building blocks, these rack-scale AI solutions deliver unprecedented Deep Learning performance. Solution Highlights Supreme AI Cluster for Exascale Computing The Supermicro Rack Scale AI Solution is powered by Supermicro GPU servers - the highest density and compact computation powerhouse. The cluster utilizes the latest NVIDIA HGX H100 GPUs to deliver incomparable performance. The design features 32 GPUs in the Base Package (Scalable Unit-SU), scaling up to 128 GPUs per POD (4 racks of servers) and 256 GPUs per SuperPOD (8 racks of servers). 1 1 Solution Highlights 1 Use Cases 3 Customer Benefits 4 Representative Performance Benchmarks 6 Supermicro Liquid Cooling Solution 8 Supermicro Advantages with Scale AI Solutions Plug and Play 10 Further Information 10 Appendix 11 Contents 1 Solution Overview . Error! Bookmark not defined. Open RAN Error! Bookmark not defined. Key Components Error! Bookmark not defined. Hardware Solution Features . Error! Bookmark not defined. Summary Error! Bookmark not defined. 2 Scalable Design achieving unprecedented peak performance Supermicro Rack Scale AI Solution is designed to provide outstanding scalability for faster and easier future deployments. Starting with the Base Package (Scalable Unit-SU) delivering 1.1 PetaFlops, the cluster is seamlessly scalable to reach close to 4.5 Peta Flops (FP64) per POD and up to 8.7 Peta Flops (FP64) per SuperPOD. In addition, Supermicro offers to deploy Rack Scale AI Solutions with 1 to 4 nodes as a proof of concept (POC). It provides flexibility to quickly scale to hundreds of servers via SuperPODs to meet workload demands. Most Advanced Processors & Networking The clusters feature the latest and state-of-the-art CPUs (both 4th Gen Intel Xeon Platinum Processors or AMD EPYC 9004 Processors), achieving an unprecedented number of cores. Furthermore, each cluster is powered by NDR InfiniBand, allowing virtually unlimited scalability for large data aggregation through the network. Along with three terabytes per second (TB/s) of memory bandwidth per GPU and scalability with NVLink (900 GB/sec) and NVSwitch (up to 256 GPU connections)\u2014further enhancing system performance under heavy Deep Learning workloads. Customizable Highest Quality Storage Options Depending on the scale and end application requirements, Supermicro\u2019s AI Solution offers additional Storage Solutions that are seamlessly integrated and completely tested with the compute cluster. Utilizing Supermicro\u2019s application-optimized, high performance storage blocks, along with storage software integration (parallel filing systems like WekaIO, BeeGFS, etc.), Supermicros AI solutions are complete offerings \u2013 capable of meeting any scale of DL workloads. Flexible and Superior Cooling Options With the rising number of TDPs for both CPUs and GPUs, large-scale AI clusters will soon demand superior cooling technologies compared to air cooling. Supermicro Rack Scale AI Solution offers air and liquid cooling options, which include Direct To Chip, Rear Door Heat Exchangers, and Immersion Cooling. Powered by Supermicro\u2019s high- quality liquid cooling components, Supermicro\u2019s AI solution provides dramatic savings in PUE and OPEX. In addition, the building blocks for this solution can be either air cooled or liquid cooled. Figure 1- Liquid Cooled or Air Cooled Supermicro 8U Servers with NVIDIA H100 GPUs 3 Use Cases Supermicro\u2019s rack-scale AI solutions are designed to remove AI infrastructure obstacles and bottlenecks, accelerating Deep Learning (DL) performance to the max. Primary Use Case \u2013 Large Scale Distributed DL Training Deep Learning Training requires high-efficiency parallelism and extreme node-to-node bandwidth to deliver faster training times. Supermicro\u2019s rack-scale design facilitates training massive neural network models with millions of training instances and billions of parameters - in the most optimized and cost-efficient manner. While the Base Package (SU) is a great starting point for training DL models, the PODs and SuperPODs (and beyond) ensure to shorten enterprise level DL training times to a minimum. Secondary Use Cases \u2013 DL Inference & Hyperparameter Search In addition to parallel computing, production Inferencing requires deploying models at scale and high availability. Supermicro\u2019s GPU servers include (N+N) power redundancy, capable of delivering seamless inferencing performance. Regarding Hyperparameter search, where parallel computation matters but node-to-node bandwidth is not critical, Supermicro\u2019s customizable networking options make these solutions an excellent fit for this application. Supermicro\u2019s versatile array of end-application and delivery focused total AI solutions offer great flexibility to choose from the latest and greatest compute platforms. Both ML training and inferencing serving applications can scale from a single rack to a SuperPOD. Generative AI (such as GPT models) and Large Language Models are examples of applications that can take advantage of the scalability of this solution. 4 The Supermicro Scalable Rack Scale AI Solutions are based on a single rack as a building block, referred to as a Scalable Unit, which can then be expanded to four or eight racks. SU/Base Package SRS-42UGPU-AI-SU1 POD SRS-42UGPU-AI-SU2 SuperPOD SRS-42UGPU-AI-SU3 GPU Server (8U 8GPU) 4x SYS-821GE-TNHR / 4x AS -8125GS-TNHR 16x SYS-821GE-TNHR / 16x AS -8125GS-TNHR 32x SYS-821GE-TNHR / 32x AS -8125GS-TNHR Total CPUs 8x Intel Xeon Platinum 8480+ Processors or 8x AMD EPYC 9004 Processors 32x Intel Xeon Platinum 8480+ Processors or 16x AMD EPYC 9004 Processors 64x Intel Xeon Platinum 8480+ Processors or 64x AMD EPYC 9004 Processors Total GPUs 32x NVIDIA HGX H100 SXM5 128x NVIDIA HGX H100 SXM5 256x NVIDIA HGX H100 SXM5 Rack 1x 42U (Optional 48U) 4x 42U (Optional 48U) 8x 42U (Optional 48U) Memory 32TB DDR5 (X13) 24TB DDR5 (H13) 128TB DDR5 (X13) 96TB DDR5 (H13) 256TB DDR5 (X13) 192TB DDR5 (X13) Estimated Total Power Per Rack Max 45 kW Max 180 kW Max 360 kW Networking 1x 400G 64-port NDR IB: SSE- MQM9700-NS2F 1x 400G 64-port NDR IB: SSE- MQM9700-NS2F 3x 400G 64-port NDR IB: SSE- MQM9700-NS2F 1x SMC 100G Eth Switch (Storage) 1x SMC 100G Eth Switch (Storage) 1x SMC 100G Eth Switch (Storage) 1x SMC 1G/25G MGT Switch 1x SMC 1G/25G MGT Switch 2x SMC 1G/25G MGT Switch Customer Benefits Rapid Deployment Rack scale solutions can lower the deployment time of an average IT system from 3 months down to 2 weeks. We attribute this to the fact that our rack assembly team stocks an inventory of parts and can start assembly of a rack cabinet of systems immediately upon receiving an order. Rather than customers waiting and stock-piling many components until everything arrives, Supermicro can begin assembly quickly and ship the final product to customers in a single box. Supermicro Plug and Play (PnP) solution can save money and accelerate the time-to-market approach for timely deployment. 5 Industry Standard Components Supermicro builds the entire Rack Scale solution. That means we audit all hardware components, including 3rd party components, to give confidence that a completely tested and standardized total solution. Evaluating factors such as processing power, memory capacity, network connectivity options, storage capacity, and reliability ensures that the selected hardware meets the specific needs of the rack integration project. It\u2019s all guaranteed to work right after delivery. Energy Efficiency Supermicro can adapt our rack solutions to whatever power configuration our customers have. The manufacturing facility supports 208, 230, 415, or 480VAC. Single or Three Phase, and the facility is 48VDC-ready. Most importantly, though, the rack scale solutions are energy efficient. Supermicro significantly reduces energy consumption through more efficient power supplies in our products, liquid cooling capabilities, and even immersion cooling. Supermicro considers factors such as power consumption, heat dissipation, cooling capacity, and available space for IT solutions. For example, determining proper ventilation requires assessing components' heat output and airflow patterns and implementing appropriate cooling mechanisms to prevent overheating and ensure efficient cooling throughout the rack. Liquid and immersion cooling significantly reduce the energy required to cool IT equipment. Because liquid creates much better thermal transfer than air, the cost to our customers to cool a rack cabinet of IT equipment can be a tenth of what an air- cooled system might require. Supermicro\u2019s liquid cooled racks are optimized for high coolant temperatures offering unmatched efficiency. The solution can sustain a 100% server uptime with the new Supermicro Coolant Distribution Unit, which integrates redundant and hot swappable pump modules and Power supplies. The integrated software suite lets customers control the entire system from a single interface. This solution also comes with best-in-class after-sales services dispensed by our local experts. Lower Carbon Footprint Along with lower energy consumption comes lower carbon emissions. A hallmark of Supermicro is the desire to deliver green products to our customers, and Supermicro has done that repeatedly over the past several years. By reducing power consumption with Supermicro liquid cooling and immersion cooling capabilities, customers can better meet their reduced carbon footprint goals. Scalable A large value proposition of our rack scale systems is our ability to scale-up and scale-out with our customers\u2019 expanding IT needs. Because Supermicro uses a building-block approach to our rack solutions, the manufacturing facility can easily add new systems as our customers\u2019 requirements grow. The components work together seamlessly and can be added cumulatively. Testing/Validation Expertise Supermicro has developed its own unique quality assurance testing processes that will thoroughly validate the operational effectiveness of the entire integrated rack solution (pre-shipment). As a result, customers are delivered an entire solution, thoroughly tested as a working unit at the rack or multi-rack level. 6 Representative Performance Benchmarks X13-H100 GPU Super Server: Training Performance - ResNet-50 v1.5 for MXNet (Config 1) Performance Unit: Images/ sec (Higher is better) \u2013 # of GPUs SYS-821GE-TNHR Ref NVIDIA DGX A100 1 6385 3411 4 25022 13443 8 49433 26674 H13-H100 GPU Super Server: Training Performance - ResNet-50 v1.5 for MXNet (Config 2) Performance Unit: Images/ sec (Higher is better) # of GPUs AS-8125GS-TNHR Ref NVIDIA DGX A100 1 6393 3411 4 24705 13443 8 49057 26674 H13-H100 GPU Super Server: TensorRT BERT Large Inference Performance (Higher is Better) Data Type Batch Size Sequence Length AS-8125GS-TNHR Ref A100 SXM4 80GB Ref H100 SXM5 80GB INT8 128 128 9743 4887 9622 INT8 8 128 5056 2679 5024 INT8 128 384 2826 1412 2819 INT8 8 384 2047 1071 2016 Building Block Server: GPU Super Server SYS-821GE-TNHR 7 Overview 8U Dual Socket (4th Gen Intel Xeon Scalable Processors), up to 8 SXM5 GPUs CPU 2x 4th Gen Intel Xeon Scalable Processors Memory (additional memory available) 32 DIMM slots Up to 8TB: 32x 256 GB DRAM Graphics 8x HGX H100 SXM5 GPUs (80GB, 700W TDP) Storage (additional storage available) 8x 2.5\u201d SATA 8x 2.5\u201d NVMe U.2 Via PCIe Switches Additional 8x 2.5\u201d NVMe U.2 Via PCIe Switches (option) 2x NVMe M.2 Power 3+3 Redundant 6x 3000W Titanium Level Efficiency Power Supplies *These are max Turbo frequencies Building Block Server: GPU Super Server AS -8125GS-TNHR Overview 8U Dual Socket (4th Gen AMD EPYC), up to 8 SXM5 GPUs CPU 2x 4th Gen AMD EPYC Processors Memory (additional memory available) 24 DIMM slots Up to 6TB ECC DDR5-4800 RDIMM Graphics 8x HGX H100 SXM5 GPUs (80GB, 700W TDP) Storage (additional storage available) 8x 2.5\u201d SATA 8x 2.5\u201d NVMe U.2 Via PCIe Switches Additional 8x 2.5\u201d NVMe U.2 Via PCIe Switches (option) 2x NVMe M.2 Power 3+3 Redundant 6x 3000W Titanium Level Efficiency Power Supplies 8 Building Block Switch: NDR 400G IB SSE-MQM9700-NS2F Overview 64-ports NDR, 32 x NDR 400Gb/s OSFP ports, managed, power-to-connector (P2C) airflow (forward) Max Throughput 51.2 Tb/s Power Typical power with passive cables (ATIS): 747W Max power with active cables: 1,703W Supermicro Liquid Cooling Solution A critical component of an advanced AI solution is a liquid cooling system that works at the rack level, which can decrease the PUE of a data center. The Supermicro Liquid Cooled Solution consists of several components, all available from Supermicro. ( The main components of an effective liquid cooling solution include: \u2022 CDU \u2013 Cooling Distribution Unit: The Supermicro CDU is at the heart of the system. The Supermicro CDU is designed to ensure that high-performing servers' entire racks perform as expected. This CDU is designed with dual redundant and hot-swappable coolant pumps and power supplies. Figure 1 - Supermicro CDU \u2022 Cold Plates: To cool the hot CPU and GPU chips, the heat must be removed from the packages. This is accomplished by applying a device to the top of the chip, through which the liquid will flow and carry away the heat. The cool liquid is passed over the CPU or GPU, warming up as the liquid traverses the chip, removing the heat. 9 Figure 2 - Supermicro Cold Plates in Parallel \u2022 CDM \u2013 Cooling Distribution Manifold: The purpose of the CDM is to deliver cold liquid from the CDU to each server and send the hot liquid back to the CDU. CDMs can take a number of different forms. Below is a horizontal CDM that serves two servers, one above the CDM and one below. Figure 3 - Horizontal CDM \u2022 Leak Proof Connectors When working with a liquid cooled system, it is essential to ensure that liquid does not come in contact with electronic surfaces that it is not supposed to. Leak-proof connectors allow for maintenance, with the possibility of leakage. Figure 4 - Leak Proof Connectors 10 \u2022 Optimal Hoses With the Supermicro Rack Scale Liquid Cooling solution, hose lengths are optimized for the server that is being liquid cooled and the position of the server within the rack. Figure 5 - Supermicro BigTwin(R) with Liquid Cooling Cold Plates and Hoses Supermicro Advantages with Scale AI Solutions Plug and Play One-Stop-Shop: From initial cluster design (extreme optimization for end user DL applications), assembly and configuration, testing and validation, delivery and deployment, all the way up to support and service \u2013 Supermicro is the ultimate one-stop- shop for AI infrastructure building. Supermicro\u2019s comprehensive AI packages are entirely tested and validated at rack scale. Extensive testing includes L10 (system level tests), L11 (cluster level tests), and L12 (application level optimization and benchmarking). Further Information", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a3da80fd-11ac-4dde-a56c-b435bb634a1e": {"__data__": {"id_": "a3da80fd-11ac-4dde-a56c-b435bb634a1e", "embedding": null, "metadata": {"file_name": "Solution-Brief_Qumulo_MnE.pdf", "publication_date": "August 2022", "referenced_websites": ["https://www.supermicro.com/en/solutions/qumulo", "www.qumulo.com", "www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 A+ Single AMD EPYC 7003/7002 Series All-Flash NVMe Platform - AS -1114S-WN10RT Supermicro\u2019s Qumulo file storage solution bundle provides a modern infrastructure for data-driven media and entertainment organizations and meets the needs of today\u2019s in-house and remote creative teams for post-production, animation and visual effects, games production, broadcast, and corporate video production. Qumulo\u2019s file system provides reliable, high-performance data access to speed creativity and collaboration, as well as robust management, storage, and protection for petabyte levels of HD, 4K, and 8K content across on-prem and public cloud environments. In addition, Qumulo\u2019s file system is designed to provide support and visibility for billions of files, with easy scalability to enable rapid growth and expansion. 1 Performance to Speed Workflows 2 Harness the Power of the Cloud When Needed 2 Enhance Collaboration and Optimize Workflows 3 Simple Scalability and Enterprise-Level Protection 3 Built-In, Real-Time Operational Analytics for Control 4 Customer Support - Today and Into The Future 4 Conclusion 4 2 Performance to Speed Workflows Media organizations can utilize Supermicro\u2019s All-NVMe platforms that provide low latency and ultra-fast performance to accelerate collaboration, creativity, management, and delivery. In addition, Qumulo\u2019s file data platform provides fast data access and powers rendering on-prem or in cloud environments, together with cost- efficient content storage, in one solution - no complex tiering required. Harness the Power of the Cloud When Needed By leveraging Amazon Web Services (AWS) or Google Cloud, if needed, Qumulo enables media and entertainment organizations to quickly and easily burst to compute power to the cloud to create render farms on demand to support rendering and production processes. In addition, studios can spin up complete cloud production environments on-prem with Qumulo providing multi-location production teams with access to the applications and content they need to collaborate more effectively and meet project deadlines faster. This flexibility eliminates the barriers and complexities of legacy storage, enabling media organizations to address today\u2019s rapidly changing production pipeline requirements quickly and easily. Supermicro , the leading innovator in high- performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. available on the market. 3 Enhance Collaboration and Optimize Workflows Qumulo\u2019s file data platform, used by leading media and entertainment organizations, integrates seamlessly with existing applications. Qumulo\u2019s file system creates a single pool of storage that supports SMB and NFS file protocols. Artists, editors, and producers, including those working remotely, can easily access all content, create and edit content, and render from the same volume. Supermicro\u2019s All-NVMe high-performant, economical platform in a sleek 1U form factor, combined with Qumulo\u2019s file data platform, lets you securely store, dynamically scale, and easily manage petabyte-scale file data. In addition, with Qumulo\u2019s advanced API, media and entertainment organizations can automate and optimize applications to further enhance workflows. Simple Scalability and Enterprise-Level Protection Managing rapid growth demands is easy with Qumulo. With its modular architecture, media and entertainment organizations can use Qumulo\u2019s file data platform to expand capacity and support billions of files and petabyte- levels of data, on-prem or in the cloud, without disruption or downtime. Qumulo provides built-in enterprise-level data protection using erasure coding, local and remote snapshots, and continuous replication to ensure that data is preserved for the long term and always available. SOLUTION BENEFITS \u2022 Accelerate performance, collaboration, and productivity to speed media workflows \u2022 Fast, reliable user responsiveness to all media applications \u2022 Cloud-native software enables creative teams to work anywhere in the world \u2022 Burst cloud compute power for rendering, if needed \u2022 Create a studio in the cloud for cloud-based editorial collaboration \u2022 Simple scalability to support petabyte-scale capacities for billions of large and small files \u2022 API-first design for simple application integration to automate workflows \u2022 Built-in enterprise-level content security and protection \u2022 Optimize creative environments, simplify resource management and reduce costs with real-time analytics \u2022 Be delighted with Qumulo\u2019s unique approach to customer success \u2022 High performance with Supermicro\u2019s All-NVMe platform 4 Built-In, Real-Time Operational Analytics for Control Qumulo provides built-in, real-time operational analytics that provides visibility to the entire creative environment, including workstations, storage usage, throughput, latency, and more, to enable administrators to optimize the environment to support maximum productivity to quickly and easily manage issues and help plan for future requirements. Customer Support That Will Delight You Today and Into The Future Supermicro and Qumulo file storage solution is available through a simple subscription model that covers everything, including upgrades, new features, and support to help make costs transparent. Qumulo\u2019s award-winning customer success team provides instant access to a dedicated storage expert via communication tools such as Slack. This ability ensures your teams have the support you need right away to keep the creativity flowing. Conclusion Supermicro and Qumulo file storage solution takes advantage of AMD All-Flash NVMe Platform and Qumulo Core File management system, accelerates performance and productivity to your media workload, and makes data management cycle easy. Supermicro All-NVMe Server model AS -1114S-WN10RT Form Factor 1U server Configurations 30TB, 76TB, 153TB per node CPU AMD EPYC 24 core 2.8 GHz Network Port 4 x 100GbE MGMT Port Base-T (RJ45) Memory 128GB 5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "2e3efce5-201c-4c06-9360-26192e01a3ce": {"__data__": {"id_": "2e3efce5-201c-4c06-9360-26192e01a3ce", "embedding": null, "metadata": {"file_name": "Solution-Brief_VDI.pdf", "publication_date": "June 2020", "referenced_websites": ["https://www.supermicro.com/en/solutions/nvidia-vgpu", "https://www.nvidia.com/en-us/data-center/resources/vgpu-", "www.supermicro.com", "https://www.nvidia.com/en-us/data-center/virtual-solutions/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 \u2019S VIRTUAL DESKTOP (GRID vPC) SOLUTIONS 3 \u2019S VIRTUAL WORKSTATION (QUADRO vDWS) SOLUTIONS 3 IS HERE TO HELP! 4 FOR MORE INFORMATION \u2019S VIRTUAL DESKTOP INFRASTRUCTURE (VDI) SOLUTIONS FOR THE MODERN ERA - Enablement of remote workers due to the globalization of the modern workforce has become a differentiating factor of advanced and progressive companies. With the many rapid changes in our environment, support for a myriad of remote workers extends beyond office workers, but also the creative and design professionals, engineers, and whomever may need workstation-class systems and GPU resources. Supermicro has proven and scalable solutions to support performance-critical workloads and disaggregated collaboration for remote workforces. Supermicro\u2019s Virtual Desktop Infrastructure (VDI) Solutions for the Modern Era 2 \u2019S VIRTUAL DESKTOP (GRID vPC) SOLUTIONS For many all-purpose use cases for office functions, the virtual desktop or NVIDIA GRID vPC solution is an ideal option. Focusing on the density of the infrastructure, along with cost and performance for the user experience, Supermicro has multiple options. Working with VDI using NVIDIA virtual GPU (vGPU) supports many programs, including Windows 10, requiring graphics acceleration that, without a GPU for data offload, overwhelms the CPU, degrading the user experience and virtual machine (VM) responsiveness. Supermicro\u2019s vGPU Virtual Desktop solution allows for up to 33% better density with better overall user experience compared to VDI infrastructure with CPU only solution. Supermicro\u2019s solution includes several different options to fit your needs. WHY THE \u201cBEST\u201d CONFIGURATION IS BETTER \u2022 Available higher GPU and CPU and power resources to make sure that all workloads are supported \u2022 2B GRID vPC profile recommended for higher resolution and/or multiple monitors \u2022 More networking options with options for SIOM \u2022 Upgradable to Quadro vDWS software solution with high powered Quadro RTX GPUs with support for Ray Tracing GOOD Lowest cost per user BETTER Universal GPU high utilization BEST (1B) Highest GPU performance GRID vPC @1B BEST (2B) Highest Density GRID vPC @ 2B SERVER SYS-2029U-E1CRT (2U) SYS-2029GP-TR (2U) SUPPORT USER 64 CCU 96 CCU NVIDIA GRID SW GRID vPC \u2013 1B (1GB FB) GRID vPC \u2013 1B (1GB FB) GRID vPC \u2013 2B (2GB FB) NVIDIA GPU 2x NVIDIA M10 4x NVIDIA T4 4x Quadro RTX 6000-P 4x Quadro RTX 8000-P CPU Slower and Lower Core Count CPU 6240R 24C @ 2.4 GHZ Faster and Higher Core Count CPU 6248R 24C @ 3.0 GHZ SYSTEM MEMORY Recommend 384-512 GB ~6-8 GB/CCU Recommend 768 GB ~8 GB/CCU Supermicro\u2019s Virtual Desktop Infrastructure (VDI) Solutions for the Modern Era 3 - \u2019S VIRTUAL WORKSTATION (QUADRO vDWS) SOLUTIONS Supermicro has a long history of designing and manufacturing high powered GPU servers. These GPU servers, combined with NVIDIA\u2019S Quadro Virtual Data Center Workstation (Quadro vDWS) software solution, enables a remote virtual machine to have similar performance as a bare metal workstation with GPU. The Quadro vDWS software solution allows a user to dynamically allocate resources (from 1Q profile to combining up to 4 GPUs in 1 VM). This capability can minimize functionality differences between the bare metal workstation and the VM. Below are configurations for a professional design or engineering user using NVIDIA\u2019s datacenter level Quadro GPUs, the Quadro RTX 6000 passive and Quadro RTX 8000 passive GPUs. We built a solution using frame buffer sizes of the more commonly found, lower performance Quadro RTX 4000 and Quadro RTX 5000. For better performance, a higher FB/vGPU profile can be selected, which allocates more GPU resources among fewer users. IS HERE TO HELP! For any and all your Virtualization needs and use cases, Supermicro has a solution for you. We understand the challenges that everyone is facing and are here to help. Please feel free to contact your Supermicro Representative to learn more. 2U VS 4U \u2022 2U is an easier point of entry. Less connected GPUs and less available resources \u2022 4U is a fully capable and populated solution with greatest available resources for the VMs. 2U Solution 4U Solution SERVER SYS-2029GP-TR SYS-4029GP-TRT SUPPORT USER 15 CCU 24 CCU NVIDIA GRID SW Quadro vDWS \u2013 8Q (8GB FB) Quadro vDWS \u2013 16Q (16GB FB) Quadro vDWS \u2013 8Q (8GB FB) Quadro vDWS \u2013 16Q (16GB FB) NVIDIA GPU 5x Quadro RTX 6000-P 5x Quadro RTX 8000-P 8x Quadro RTX 6000-P 8x Quadro RTX 8000-P CPU Can use lower core CPU because less VMs 6226R 16C @ 2.9 GHz Need higher core CPU because more VMs 6248R 24C @ 3.0 GHZ SYSTEM MEMORY Recommend 960 GB ~64GB/CCU Recommend 1536 GB ~64GB/CCU BENEFITS OF QUADRO RTX 8000 OVER QUADRO RTX 6000 \u2022 Double Frame Buffer in Quadro RTX 8000 \u2022 Able to have higher frame buffer profile at same density (for bigger models and datasets) Supermicro\u2019s Virtual Desktop Infrastructure (VDI) Solutions for the Modern Era 4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "8451bc53-62da-424e-a184-9a5840cd7f6f": {"__data__": {"id_": "8451bc53-62da-424e-a184-9a5840cd7f6f", "embedding": null, "metadata": {"file_name": "Solution-Brief_NVIDIA_HPC_AI.pdf", "publication_date": "December 2020", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Unlocking Business Insights 1 The New Wave of HPC and AI 2 Success Built on Unparalleled Computing 2 World-Class Solutions for HPC and AI 3 Conclusion 4 Supermicro , the leading innovator in high-performance, high- efficiency server and storage technology, is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy- efficient, environmentally-friendly solutions available on the market. UNLEASH THE FUTURE OF INNOVATION WITH HPC & AI Transforming businesses with a new class of Supermicro and NVIDIA high-performance solutions Data is the driving force for success in the global marketplace. Data volumes are erupting in size and complexity as organizations work to collect, analyze, and derive intelligence from a growing number of sources and devices. These workloads are critical to powering applications that translate insight into business value. High-performance computing (HPC) and artificial intelligence (AI) are changing the way businesses operate, allowing them to use their data to extract deeper insights, enhance processes, and realize better outcomes. However, executing these tasks is a major concern for today\u2019s organizations. Data analytics, HPC, AI, machine learning, and deep learning workloads require massive levels of power and flexibility, which rapidly exceed the capacity of traditional infrastructure. In order to succeed, businesses must invest in a new breed of technology that can deliver revolutionary performance and breakneck speeds. Cutting-edge solutions from Supermicro and NVIDIA are enabling customers to transform and capitalize on HPC and AI innovation. Unlocking Business Insights The rise of HPC and AI is triggering a fundamental shift in numerous industries. Businesses utilize these capabilities to drive improvements across their operations by boosting productivity and efficiency, as well as accelerating insights to solve their most significant challenges. HPC and AI are the foundation for a variety of applications such as modeling and simulation, genome sequencing, real-time and predictive analytics, autonomous driving, and climate monitoring. 2 As HPC and AI become increasingly intertwined, businesses will continue to leverage their data in new ways. Legacy infrastructure is the biggest roadblock to data- intensive applications. To overcome this pain point, businesses adopt the latest technological advances to satisfy escalating demands on compute. Innovation is crucial to unlocking future insights, and the ideal solutions will equip businesses with extreme capacity, agility, and flexibility to optimize any workload. The New Wave of HPC and AI As industries recognize the need for advanced technologies to support widespread HPC and AI usage, the next generation of accelerated computing has emerged, offering unprecedented performance. Purpose- built solutions for HPC and AI are redefining the modern enterprise. Backed by the massively parallel processing power of GPUs, businesses can enhance how they work, collaborate, and solve problems: \u2022 Faster Data Movement \u2013 Greater bandwidth to move massive volumes of data. \u2022 Workload Optimization \u2013 Adapt quickly as workloads grow in size, scope, and complexity. \u2022 Performance at Scale \u2013 High throughput and low latency to ensure peak levels of efficiency. \u2022 Technology Standardization \u2013 Centralized frameworks to simplify IT and increase cost savings. As the requirements for HPC and AI continue to evolve, Supermicro is committed to helping businesses transform their operating environments. Our accelerated computing solutions provide the right balance of density and speed to manage diverse workloads while reducing time-to-insight. These groundbreaking platforms leverage the third generation NVIDIA Tensor Core GPUs to enable maximum acceleration at every scale, so customers can harness the full potential of HPC and AI. Success Built on Unparalleled Computing Supermicro has extended its leadership in the GPU server market, with the broadest portfolio of high-performance technologies to keep pace with the increasing demand of HPC and AI applications. From practical and efficient clusters to accelerated computing, our comprehensive offerings empower businesses to build the ideal solution for their needs. At Supermicro, we deliver significant value with an extensive lineup of highly configurable and sustainable technologies, featuring fundamental building blocks that help customers succeed. Supermicro is the foremost developer of new solutions, guaranteeing that customers will benefit competitively from the latest technologies and capabilities through our first-to-market advantage. Supermicro solutions are produced in the U.S., and with total control of manufacturing, we prioritize customer requirements and accelerate time-to-market. Our customers benefit from customizable solutions that accommodate any budget. In conjunction with Supermicro\u2019s Green IT innovation, our solutions dramatically extend sustainability for unbeatable price performance. Supermicro offers the best energy efficiency on the market to fuel HPC and AI platforms of all sizes. Our architectures optimize power consumption, cooling, shared resources, and refresh cycles to ensure top performance per dollar. Liquid cooling options combined with Titanium Level power supplies offer an efficiency rating of 96% and reduce TCO by as much as 40%\u201350%. Now, businesses can operate with confidence, leveraging solutions designed for high configurability, reliability, and flexibility to fit their needs. By integrating compute power, NVIDIA GPUs, optimal storage, and networking options, our robust platforms can reach extremely high rack density with minimal facility footprint. Customers can implement tight configurations with unparalleled I/O capacity to maintain operational consistency for HPC and AI. This infrastructure makes it easy for businesses to carry out today\u2019s workloads and adapt for tomorrow\u2019s challenges, regardless of their requirements. 3 World-Class Solutions for HPC and AI Supermicro\u2019s portfolio enables next-generation performance in any operating environment. We are committed to developing total computing innovations that are customer-centric, providing a one-stop-shop where they can select and deploy a turnkey platform. Now, Supermicro offers an array of GPU accelerated computing solutions to help customers meet and exceed even the most daunting challenges of HPC and AI. Supermicro\u2019s adaptable, fastest-to-market servers powered by unmatched NVIDIA A100 Tensor Core GPUs allow businesses to tackle diverse tasks with ease\u2014from running AI inference on developed models, to HPC, to AI training requests. Fully integrated solutions deliver a significant performance boost across Supermicro\u2019s extensive of 1U, 2U, 4U, and 10U multi-GPU servers, providing leading compute capacity and agility for data analytics, HPC, AI, machine learning, and deep learning. Servers with NVIDIA A100 power applications from edge to cloud, creating the world\u2019s most powerful accelerated platforms for AI featured in the Supermicro NVIDIA HGX A100 8-GPU Platform and Supermicro NVIDIA HGX A100 4- GPU Platform. Additionally, our newly unveiled NVIDIA A100 PCI-E form factor offers high versatility across multiple configurations, including the Supermicro NVIDIA A100 PCI-E AMD Platform, Supermicro NVIDIA A100 Ultra AMD Platform, and Supermicro NVIDIA A100 Blade AMD Platform to expedite data-heavy workloads. Our offerings utilize NVIDIA Mellanox end-to-end Ethernet and InfiniBand interconnected solutions to run complex workloads with outstanding levels of speed and functionality in data centers and the cloud. NVIDIA Mellanox network technologies are the best choice to connect the world\u2019s top HPC and AI accelerated computing platforms. The addition of NVIDIA NVLink and NVIDIA NVSwitch enhances interconnection consistency by providing higher bandwidth, more links, and improved scalability for multi-GPU server configurations to ensure seamless communication between components in addition to the fastest data speed, lowest latency, and resiliency. 2U w/ NVIDIA HGX A100 4-GPU 4U w/ NVIDIA HGX A100 8-GPU 4U w/ 8x NVIDIA A100 PCI-E Conclusion The expansion of HPC and AI poses new and rising challenges for today\u2019s businesses. Savvy organizations 4 are empowering their operating environments with GPU accelerated computing to tap into their data and extract game-changing insights. Supermicro and NVIDIA are preparing our customers for success, offering the right technologies to make the leap. We prioritize the advancement of HPC and AI by continually testing, validating, and integrating advanced hardware featuring optimized software components to support a rising number of use cases. Backed by an extensive partner ecosystem, Supermicro\u2019s unrivaled computing solutions are expertly engineered to achieve faster intelligence, superior outcomes, and proven sustainability for ongoing innovation. This is your time to transform. Visit Supermicro online to learn how you can harness the full power HPC and AI. 2U Ultra w/ 2x NVIDIA A100 GPU 8U 20 Node Blade System", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "a4da9962-551f-4335-b4e5-dfd95ed28a1a": {"__data__": {"id_": "a4da9962-551f-4335-b4e5-dfd95ed28a1a", "embedding": null, "metadata": {"file_name": "Solution-Brief_Supermicro-RSD.pdf", "publication_date": "May 2018", "referenced_websites": ["https://www.supermicro.com/CaseStudies/CaseStudy_Fortune100.pdf", "www.supermicro.com", "www.supermicro.com/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "- 2 BENEFITS OF RSD 3 RSD SOFTWARE COMPONENTS 4 RSD HARDWARE REQUIREMENTS 5 ILLUSTRATION OF RACK SCALE DESIGN CONFIGURATION RACK SCALE DESIGN ( RSD) A Rack-Scale Total Solution Built on Open Standards Supermicro RSD, a rack-scale total solution, empowers cloud service providers, telecoms, and Fortune 500 companies to build their own agile, efficient, software-defined data centers. Built on industry standard Redfish APIs and open source Rack Scale Design software framework from Intel, Supermicro RSD runs on Supermicro server/storage/switch hardware offerings and maximizes utilization through disaggregating compute, network and storage resources distributed within a rack or across multiple racks. Supermicro Rack Scale Design (Supermicro RSD) 2 BENEFITS OF RSD Supermicro RSD offers data center operators the following benefits: 1. Open REST API based Management Provides Interoperability and Scalability in Cloud Scale Infrastructure In today\u2019s large data center environments with tens of thousands of servers distributed in hundreds of racks, traditional 1-to-1 server management using IPMI is inadequate to meet the extensive provisioning and management requirements. Designed with the whole rack as the new management unit in mind, Supermicro RSD leverages an open RESTful API called Redfish that is designed to support composable infrastructure to provide functionality beyond what can be achieved with IPMI. Redfish API provides secure hardware management at rack scale and enables interoperability among potential RSD offerings from different vendors. Acting as a south-bound API for the underlying hardware and a north-bound API for plugging into existing application environments such as OpenStack, Redfish API is the glue of RSD framework. It allows large data center operators to deploy RSD compliant solutions without worrying about vendor lock-in, a critical factor in large scale data center deployments. 2. Resource Pooling and just-in-time Allocation Maximize Utilization of Compute, Network and Storage Resources Similar to server virtualization or container technology that enables resource sharing for VMs and containers on physical hardware, Supermicro RSD supports pooling of compute, storage and network resources and just-in-time allocation to maximize the utilization of those resources. For example, to optimize the infrastructure for a Hadoop workload, customers may want to dynamically compose a node consisting of computing resources from one physical server node and connect it with a networked storage resource that contains the data. Users provision, manage and power-on the composed node as if it were one physical node. When the task is complete, simply delete the composed node to return the resource to the pools for other workloads. 3. Future-Proof Investment with Existing and New Disaggregated Hardware Unlike other RSD offerings, Supermicro RSD does not require purpose-built new hardware. In fact, Supermicro RSD solution supports the new Intel Xeon Scalable Processors based X11 generation and all existing X10 generation server and storage systems, as well as Supermicro networking products. It protects investments that customers have already made in Supermicro. Furthermore, Supermicro MicroBlade offers future-proof, disaggregated hardware that allows customers to independently refresh compute module (CPU+memory) while keeping the remaining server investment intact resulting in substantial savings and flexibility. * * Top Supermicro RSD Features 1. Open REST API based Management Provides Interoperability and Scalability in Cloud Scale Infrastructure 2. Resource Pooling and just-in-time Allocation Maximize Utilization of Compute, Network and Storage Resources 3. Future-Proof Investment with Existing and New Disaggregated Hardware Other Supermicro RSD Features \u2022 Deep discovery including location ID of compute, storage and network building blocks in the rack \u2022 Cooling and Power Management in the rack \u2022 Asset Information, hardware monitoring and provisioning of the application-ready building block Supermicro Rack Scale Design (Supermicro RSD) 3 - RSD SOFTWARE COMPONENTS Supermicro RSD includes the following software components: \u2022 Pod Manager (PodM): A pod is a collection of physical racks. Pod Manager sits at the top of the logical software hierarchy and uses Redfish API to communicate with the racks that make up the pod. It manages and aggregates the hardware resources within multiple racks in the Pod by polling respective PSMEs and RMMs \u2022 Rack Management Module (RMM): RMM manages power and thermal resources within a rack by polling rack hardware and reports this information to PodM through Redfish API. \u2022 Pooled System Management Engine (PSME): PSME acts as the drawer or chassis manager. PSME communicates with each BMC controller in the drawer/chassis and reports aggregated information such as telemetry and asset information through Redfish API to PodM. \u2022 Web UI: A browser based graphical user interface that simplifies the management of RSD To streamline Supermicro RSD deployments, all required management software components are packaged into a 1U management appliance with each software component running in its own container. Alternatively, for customers who prefer to deploy RSD software on their own compute node, Supermicro will provide a software only RSD package. Supermicro Rack Scale Design (Supermicro RSD) 4 RSD HARDWARE REQUIREMENTS Since Supermicro RSD runs on all existing X10 and the new X11 generation server and storage systems supporting Intel Xeon Scalable processors, and networking hardware, customers have the total flexibility to build optimized Supermicro RSD racks that best serve their needs. A minimum Supermicro RSD rack includes the following hardware components: \u2022 A 1U management appliance SKU: SYS-5019S-TN4-SRSMGT and the RSD related software SKU: SFT-SMCI-SRSDM. A second management appliance can be ordered as a standby for high-availability applications. \u2022 One Supermicro 1G management switches for connecting the BMC controllers* \u2022 One Supermicro data switch* \u2022 Select your compute nodes from Supermicro\u2019s broad X10 and the new Intel Xeon Scalable processors based X11 generation server portfolio. Popular server choices include but are not limited to TwinPro, BigTwin, FatTwin and MicroBlade. \u2022 Select your storage nodes from Supermicro\u2019s storage portfolio. Popular choices include 2U Ultra with 24 NVMe as hot storage, 2U SSG with 24 SAS HDDs as warm storage and 60 bay or 90 bay JBODs as cold storage. HOW DO I BUY RSD AND WHAT SKUS TO ORDER? There are two paths to take when ordering Supermicro RSD. For customers who want to manage their existing Supermicro X10 and X11 generation server, storage and networking products with RSD, the required net new products are: 1. SYS-5019S-TN4-SRSMGT for the RSD hardware, and 2. SFT-SMCI-SRSDM for the RSD software. For customer who want a software only RSD package, then order SFT-SMCI-SRSDM for the RSD software only. Other components can be ordered on an as needed basis. For * Switches from other vendors need certification before adding to Supermicro RSD rack Figure 1. 1U Supermicro RSD Management Appliance (SYS-5019S-TN4-SRSMGT) FOR MORE INFORMATION Please visit solutions/SRSD.cfm New with Supermicro RSD 2.1 release, up to 12 application hosts can dynamically share the disaggregated NVMe pooled storage (SSG-136R-N32JBF as shown above). With just 1U of rack space, Supermicro resource-saving NVMe storage supports up to 32 hot-swap 2.5\u201d NVMe SSDs for petabyte-scale high performance and high density NVMe storage. Supermicro Rack Scale Design (Supermicro RSD) 5 - customers who want to order the new Intel Xeon Scalable processors supported X11 generation server and storage products, please follow the list of hardware components outlined in the previous section to configure the hardware that best meets your application needs. Supermicro Rack Scale Design (Supermicro RSD) 6 ILLUSTRATION OF RACK SCALE DESIGN CONFIGURATION GPU Optimized Simply Double Storage 60/45 Bay High Capacity Storage Ultra Datacenter Optimized Systems FatTwin TwinPro MicroBlade/SuperBlade NVMe Storage Enclosures BigTwin Supermicro Rack Scale Design (Supermicro RSD) 7 - NOTES No part of this document covered by copyright may be reproduced in any form or by any means \u2014 graphic, electronic, or mechanical, including photocopying, recording, taping, or storage in an electronic retrieval system \u2014 without prior written permission of the copyright owner. Supermicro, the Supermicro logo, Building Block Solutions, We Keep IT Green, SuperServer, Twin, BigTwin, TwinPro, TwinPro\u00b2, SuperDoctor are", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "e882fed3-6a2c-4748-9a78-b0ce4248839a": {"__data__": {"id_": "e882fed3-6a2c-4748-9a78-b0ce4248839a", "embedding": null, "metadata": {"file_name": "Solution-Brief_Liquid_Cooling_AI_Dev_Platform_NVIDIA.pdf", "publication_date": "March 2023", "referenced_websites": ["https://www.supermicro.com/en/products/system/gpu/tower/sys-751ge-tnrt-nv1", "https://www.supermicro.com/en/products/gpu", "https://www.nvidia.com/en-us/data-center/products/ai-enterprise/", "https://www.youtube.com/watch?v=aSxomAgD8s4"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 1 SYS-751GE-TNRT-NV1 AI is quickly becoming a mainstream technology used in a wide variety of industries. While the current view is that servers that excel at AI training must reside in a controlled environment in a data center, this new and innovative Supermicro Liquid Cooled AI development system with powerful CPUs and GPUs allows a much larger set of data scientists, engineers, and business analysts to make better decisions while reducing OPEX costs. Supermicro is advancing the state of AI by offering an AI server with state-of-the-art CPUs and GPUs with liquid cooling innovations that reduce power consumption and decibel levels. In addition, with the additional purchase of the optional NVIDIA AI Enterprise software and services, the SYS-751GE-TRT-NV1 is a complete solution aimed at the AI development professional. With the purchase of an optional subscription to NVIDIA AI Enterprise software, this unique system is ready to go, allowing developers and users to become productive in less time than ever before. 1 AI and HPC Use Cases 2 AI Development and Execution Locations 2 NVIDIA AI Enterprise Development Platform Summary . 3 AI Development System Hardware Components 4 Liquid Cooled AI Development System Details 5 AI Development Systems Liquid Cooling Components 7 Supermicro AI Product Lines 8 Summary and More Information 9 2 2 AI and HPC Use Cases AI is being developed and used in a wide range of industries and workloads, including (but not limited to): Figure 1 - AI and HPC Use Cases AI Development and Execution Where Developers and Users Live AI is becoming widespread, and developers require local systems with complete software and hardware control to create or execute new applications. The SYS-751GE-TNRT-NV1is a solution containing the necessary hardware for AI development and subsequent execution of applications with the optional purchase of NVAIE software. Locality: Many of these domains and use cases require very low latency for interactive use. With the ability to quickly move this system with the combination of fast CPUs with multiple CPUs and a graphics accelerator, latencies are kept to a minimum. They do not involve relatively slow networking from an information worker's office. Although the hardware could be installed in a data center, the latencies to the users' screen would involve the transmission of graphics data over the network (VDI), which would not allow the combination of AI algorithms and display applications to work together. Locating the development system where the human is situated increases productivity for AI-based applications that require fast response times with minimal latencies. Noise: The Liquid Cooled AI development platform reduces noise significantly. Compared to a data center, work areas are expected to have reduced noise, with the SYS-751GE-TNRT-NV1 AI development platform putting out about 30 dB when idle, 40dB when running at a 50% CPU load, and 50dB at a 100% load. The key is to utilize a self-contained liquid cooling system, where the CPUs and GPUs are all liquid cooled. Mobility: Unlike a server in a data center, the SYS-751GE-TNRT-NV1 can move from one office to another. When a department's need changes, a powerful AI computing system can be easily redeployed with a simple connection to the network. If the AI development server needs to be placed in a centralized computing facility, the system can be easily mounted in a data center rack. This system is designed to be located in an office, cubicle, or at home due to noise levels of about 30dB and standard office electrical power requirements. 3 3 NVIDIA AI Enterprise Development Platform Summary NVIDIA AI Enterprise is a complete set of AI software that allows developers and organizations to become more productive faster. In addition, this included software enables organizations to increase operational efficiency. With a full stack of AI software, including AI solution workflows, frameworks, and pre-trained models, the NVIDIA AI Enterprise software suite is a critical software component for AI developers and users. NVIDIA AI Enterprise is available on NVIDIA NGC, and this system, has the option to purchase the NVIDIA AI Enterprise subscription, at an additional cost, that provides access to an extensive library of full-stack software, including AI workflows, frameworks, and over 50+ NVIDIA pre-trained models, so organizations can develop once and run anywhere. \u2022 Leverage fully integrated, optimized, certified, and supported software from NVIDIA for AI workloads. \u2022 Run NVIDIA AI frameworks and tools optimized for GPU acceleration, reducing deployment time and ensuring reliable performance. \u2022 Deploy anywhere \u2013 including on popular data center platforms from VMware and Red Hat, mainstream NVIDIA-Certified Systems configured with or without GPUs, and GPU-accelerated instances in the public cloud. \u2022 Leverage the jointly certified NVIDIA and Red Hat solutions to deploy and manage AI workloads in containers or VMs with optimized software. \u2022 Scale out to multiple nodes, enabling even the largest deep-learning training models to run on the VMware vSphere. Previously, scaling with bare metal performance in a fully virtualized environment was limited to a single node, limiting the complexity and size of AI workloads that could be supported. \u2022 Run AI workloads at near bare-metal performance with new optimizations for GPU acceleration on vSphere, including support for the latest Ampere architecture, including the NVIDIA A100. Additionally, technologies like GPUDirect Communications can now be supported on vSphere. This ability provides communication between GPU memory and storage across a cluster for improved performance. 4 4 Figure 2 - NVIDIA AI Enterprise Software Stack (Image Courtesy of NVIDIA) AI Development System Hardware Components The Supermicro SYS-751GE-TNRT-NV1 is a complete solution that contains a number of powerful technologies that have been selected for the ultimate user experience: \u2022 CPUs: Dual 4th Gen Intel Xeon Gold 6444Y, 16C/32T, running at a base clock rate of 3.6 GHz, with an all-turbo boost clock of 4.0 GHz. Intel Xeon CPU Max Series is also available. \u2022 GPUs: 4x NVIDIA A100-LC 80GB PCIe GPUs (Liquid Cooled) \u2022 GPU Interconnect: 2x NVIDIA NVLINK Bridge \u2022 Memory: 512GB DDR5-4800MHz memory \u2022 Storage: 6x Micron 1.9TB NVMe SSDs, o Two configured for RAID1 for the Operating System o Four for data storage. \u2022 Graphics: NVIDIA Quadro RTX A4000 \u2022 NVIDIA Mellanox Conenct-X6 25Gb SFP28 5 5 Liquid Cooled AI Development System Details A tightly packed system with two CPUs and four high-end GPUs creates a cooling problem that would be difficult to solve with typical server-level fans. The Supermicro SYS-751GE-TNRT-NV1 system is a self-contained liquid cooled system that rarely needs maintenance. Figure 3 - NVIDIA Liquid Cooled A100 The figure below highlights the CPUs, Memory, PCIe Slots, Radiator, and Drive cage. 6 6 Figure 4 - Side view of Liquid Cooled System Below is the front view of the system. Figure 5 - Front View of Liquid Cooled System Figure 6 - Rear View of Liquid Cooled System 7 7 The open, side view of the SYS-751GE-TNRT-NV1 Figure 7 - Open Side View of Liquid Cooled System AI Development Systems Liquid Cooling Components A liquid cooled deskside system will typically not have access to the building infrastructure for the required process of cooling the liquid. Therefore, a self-contained system must be implemented within the server itself. The components that are needed include: Cold Plates \u2013 these devices transfer the heat from the top of the hot CPU to the liquid. The liquid exits the cold plate warmer than when it entered. Cold plates can be set up to work in parallel. Pumps \u2013 the liquid must be moved around in the system, from the reservoir to the cold plates to the radiator and back to the reservoir. Hoses \u2013 Proper hose length and diameter are critical to the efficiency of a liquid-cooled development system. Radiator \u2013 the heat from the CPUs and GPUs must be removed from the liquid. The simplest way to do this is using a simple radiator, where the warm liquid enters at the top of the radiator, and room temperature air is circulated over the liquid, reducing the temperature of the liquid as it exits the device. Reservoir \u2013 The liquid cooling reservoir in the system stores extra coolant should it be needed. Coolant \u2013 The Supermicro Liquid Cooling AI Development system contains a coolant developed to transport more heat from the CPUs and GPUs than other types of liquid. Liquid Flow 8 8 The flow of the coolant in the Supermicro AI Development system is critical to the proper functioning of the overall system and takes the following path: Figure 8 - Liquid Flow Path Through the Liquid Cooled System Supermicro Liquid Cooling AI Development System Fluid Flow Figure 9 - Internal Liquid Flow Path Supermicro AI Product Lines Supermicro designs and delivers a wide range of servers with GPUs for AI and HPC acceleration. The Supermicro AI Development System is ideal for developing applications at a 4 GPU scale, and Supermicro designs and manufactures a wide range of GPU servers for deployment. When an application is ready for deployment, rack scale solutions are required. With servers containing up to 8 GPUs, and when networked together, the performance may be achieved multiple times in the deployment phase. 9 9 The Supermicro AI Product Line consists of servers in 1U, 2U, 4U, 6U, and 8U form factors. Using a range of GPUs from leading suppliers and with either PCIe, SXM, or OAM fabrics, up to 10 GPUs can be fitted into a single server. Summary The Supermicro SYS-751GE-TNRT-NV1 is an AI development and execution powerhouse. This system, located in an office or home environment, gives users over 2 Petaflops of AI performance. Built with the latest 4th Gen Intel Xeon Scalable processors and high-performance NVIDIA GPUs, this super quiet AI Development system provides data scientists, analytics engineers, and others the performance needed to use AI for any workload. In addition, with liquid cooling, the system allows for high performance CPUs and GPUs to be utilized without the typically associated noise levels.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "7838aa35-8a52-4d3d-b905-889caf14918e": {"__data__": {"id_": "7838aa35-8a52-4d3d-b905-889caf14918e", "embedding": null, "metadata": {"file_name": "Solution-Brief_SMC-AMD-Oracle-7002-vs-7003.pdf", "publication_date": "November 2021", "referenced_websites": ["https://github.com/TPC-Council/HammerDB/releases.", "https://www.hammerdb.com/docs/ch03s02.html.", "https://www.amd.com/en/technologies/infinity-guard.", "https://yum.oracle.com/oracle-linux-isos.html", "https://yum.oracle.com/ISOS/OracleLinux/OL8/u3/x86_64/OracleLinux-R8-U3-x86_64-dvd.iso"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro has closely partnered with AMD since becoming one of the first server vendors to bring 1st Gen AMD EPYC processors with \u201cZen\u201d microarchitecture to market in our H11 platforms in 2017. In 2019, Supermicro launched its first family of H12 generation AMD processor-powered Supermicro A+ servers with 2nd Gen AMD EPYC processors to deliver a new level of integration and superior performance for modern datacenters. Today, the new 3rd Gen AMD EPYC Processors in the new Supermicro A+ servers deliver up to 19% more instructions per clock than the previous generation1. 3rd Gen AMD EPYC processors have up to 64 \u201cZen 3\u201d cores per CPU, introduce new levels of per-core cache memory, and offer PCIe 4.0 connectivity bandwidth. They also include AMD Infinity Guard2, which offers Secure Encrypted Virtualization-Secure Nested Paging (SEV-SNP) to help enhance security in 1 AMD EPYC Overview 2 AMD EPYC 74F3 Processors Deliver Superior Performance 3 Conclusion 12 APPENDIX A \u2013 Oracle Linux & Configuration 13 APPENDIX B \u2013 Oracle Database 19c Configuration 15 Supermicro , the leading innovator in high- performance, high-efficiency server, and storage technology is a premier global provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally friendly solutions available on the market. 2 virtualized environments. SEV-SNP expands on the SEV features found in earlier EPYC processors by adding memory integrity capabilities that can help prevent hypervisor-based attacks by creating an isolated execution environment for each virtual machine. AMD EPYC 7003 Series Processors Deliver Flexibility, Performance, and Security Features Overview AMD EPYC 7003 Series Processors retain the proven Multi-Chip Module (MCM) Chiplet Architecture of prior successful AMD EPYC server-class processors with further improvements and upgraded \u201cZen 3\u201d compute cores. A. \u201cZen 3\u201d Core Microarchitectural Overview AMD EPYC 7003 Series Processors are built with new 7nm \u201cZen 3\u201d compute cores that provide an Instructions per Cycle (IPC) uplift over previous \u201cZen\u201d generations. Each core supports Simultaneous Multi-threading (SMT) that allows running two simultaneous threads per core when enabled. Every core includes both an optimized 32 KB L1 cache and a private 512 KB Unified (Instruction/Data) L2 cache. B. Core Complex (CCX) and Core Complex Die (CCD) Up to eight \u201cZen 3\u201d compute units share an L3 cache of up to 32 MB in a grouping referred to as a Core Complex (CCX). Enabling SMT on a core means that a CCX may support up to 16 concurrent hardware threads, up to 4 MB of L2 cache, and up to 32 MB L3 cache, which is shareable across all cores within the CCX. AMD EPYC 7003 Series Processors contain a single CCX called a Core Complex Die (CCD) on a single die. See Figure 2. C. I/O Die (Infinity Fabric technology) Each CCD connects to memory, I/O, and each other through the I/O Die (IOD) via a dedicated high-speed or Global Memory Interconnect (GMI) link. The IOD also contains memory channels, PCIe Gen4 lanes, and Infinity Fabric Figure 2: AMD EPYC 7003 I/O Die Figure 1 - AMD EPYC 7003 processor 3 links. All dies (or chiplets) interconnect with each other via AMD\u2019s Infinity Fabric Technology. The fabric clock (FCLK) can now run up to 1600 MHz and thus be coupled with DDR4-3200 Memory DIMMs that are also running at 1600 MHz (MEMCLK) to further reduce memory latency. NUMA Topology AMD EPYC 7003 Series Processors use a Non-Uniform Memory Access (NUMA) micro-architecture. Users can optimize this NUMA topology for their specific operating environment and workload by adjusting the BIOS NUMA Nodes Per Socket (NPS) setting. New Software- Visible Features The new \u201cZen 3\u201d core in AMD EPYC 7003 Series Processors includes new and improved Instruction Set Architecture (ISA) features, such as: \u2022 ShadowStack CET (control-flow enforcement) technology. \u2022 AVX2: VAES & VPCLMULQDQ w/256-bit support \u2022 Broadcast TLB invalidation (INVLPGB & TLBSYNC Instructions) \u2022 Fast short rep moves \u2022 Predictive Store Forward Disable \u2022 Secure Encrypted Virtualization-Secure Nested Paging (SEV-SNP) \u2022 Process control ID \u2022 Memory protection keys for users The emerging boom in the number of IoT devices is driving a critical need for faster IoT gateway data analytics. Supermicro offers an industry-leading portfolio of AMD EPYC based servers via our Server Building Block Solutions that empower customers to build application-optimized solutions across a wide range of possible configurations from single-socket mainstream and WIO servers to high-end Ultra server systems and multi-node systems, including BigTwin and TwinPro servers. AMD EPYC 74F3 Processors Deliver Superior Performance on Transactional Processing Workloads with Oracle Database 19c Supermicro AS -1014S-WTRT Server This benchmark ran Oracle Database 19c on a high density single-socket Supermicro AS -1014S-WTRT server powered by AMD EPYC 7F72 and AMD EPYC 74F3 processors, as shown in Table 1. The high core density of AMD EPYC processors makes the Supermicro AS-1014S-WTRT an ideal, compact (1U, 25.6\u201d 4 deep), and cost-effective solution for database processing and enterprise application workloads. Customers may choose AMD EPYC 8, 16, 24, 32, and 64 core, and P variant CPU SKUs that offer unique pricing benefits compared to dual-socket-capable AMD CPUs. The benchmarking process selected a single-socket system because it offers a unique and robust value proposition capable of predictable workload performance scaling and because 3rd Gen AMD EPYC cores can consolidate workloads that previously required dual- or multi-socket systems into a single-socket scale-up server. Server Form Factor System Memory Drive Bays Network Controllers AS-1014S- WTRT 1U Rackmount 8 x DDR4 slots up to 3200MHZ 4 x hot swap 3.5\u201d or 2.5\u201d SATA3 or NVMe drives Dual Broadcom 10G Base -TLAN ports Table 1: Benchmarks CPU Model Specifics Image 1 - AS -1014S-WTRT 5 AMD EPYC 74F3 Processors Boost Scaling Efficiency by 54% Oracle Database delivers leading-edge innovations in relational database management systems (RDBMS) for on-premises, cloud, and hybrid workloads with exceptional performance and ease of use. AMD EPYC 74F3 processor-based systems deliver high performance for Online Transaction Processing (OLTP) with Oracle Database 19c. Table 2 shows the feature differences between the 3rd Gen EPYC 74F3 and 2nd Gen EPYC 7F72 CPUs. CPU Series Base Frequency Boost4 Frequency (up to)* Core Processors Memory Channels Maximum Memory/Socket(DDR4- 3200GHz) PCIe Gen4 Lanes / System AMD EPYC 74F3 3rd Gen 7003 3.2 GHz 4.0 GHz 24 8 4 TB 128 AMD EPYC 7F72 2nd Gen 7002 3.2 GHz 3.7 GHz 24 8 4 TB 128 Table 2: Feature Comparison Between 2nd and 3rd Gen AMD EPYC CPUs Benchmarking with Oracle Database 19c and AMD EPYC 74F3 Processors Supermicro engineers tested the relative performance3 of the 3rd Gen AMD EPYC 74F3 processor versus the 2nd Gen AMD EPYC 7F72 processor and obtained the results shown in Figure 3. Figure 3. The relative performance of the 3rd Gen AMD EPYC 74F3 processor vs. the 2nd Gen AMD EPYC 7F72 processor 1.00 1.54 0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 1.80 AMD EPYC 7F72 24 Core AMD EPYC 74F3 24 Core Database Performance OLTP Performance Gain (derived from TPC-C) AMD EPYC 7F72 24 Core AMD EPYC 74F3 24 Core 6 Benchmarking with Oracle Database 19c Both of the CPUs shown in Table 2 above are optimized for higher frequencies and excel at single- threaded workloads that prefer limited core counts. The OLTP workloads used for this benchmark are derived from the TPC-C Benchmark; they model an order fulfillment system where the database receives requests for data, adds new data, and makes multiple changes to that data from a large number of users. The results show increased transaction throughput from the 3rd Gen AMD EPYC 74F3 processor compared to the 2nd Gen AMD EPYC processor. Customers can right-size compute power to their application needs, thereby helping lower the total cost of ownership (TCO). The OLTP workload is derived from the TPC-C Benchmark, and as such, is not comparable to published TPC-C Benchmark results, as the OLTP workload results do not comply with the TPC-C Benchmark. System Configuration and Setup The hardware configuration for these benchmarks consisted of: \u2022 One Supermicro AS -1014S-WTRT server is equipped with a 24-core 3rd Gen AMD EPYC 74F3 CPU (see Table 2, above) and 512GB RAM. \u2022 One Supermicro AS -1014S-WTRT server is equipped with a 24-core 2nd GEN AMD EPYC 7F72 CPU (see Table 2, above) and 512GB RAM. \u2022 One Supermicro SSE-C3632SR 40GB data switch. 7 \u2022 One Supermicro SSC-X3349T 10GB management switch. \u2022 One Supermicro 2024US-TRT server for the benchmarking/Hammer DB. Supermicro system architects executed these benchmarks using the industry standard HammerDB Benchmark Tool. Both systems used an identical HammerDB 3.2 configuration to execute the benchmarks under similar conditions to obtain similar results. Please see the Appendix for basic HammerDB configuration, benchmark database schema, and execution scripts. An Oracle Restart instance was installed and configured. An Oracle Restart instance is the most basic form of Oracle Real Application Clusters (RAC) with only one system with Oracle Grid Infrastructure and Oracle ASM file system. \u2022 Oracle Restart instance \u2022 Oracle Grid Infrastructure, release 19.3.0.0.0 \u2022 Oracle Database Enterprise Edition, release 19.3.0.0.0 \u2022 Oracle ASM File System \u2022 Oracle Linux 8.3 (5.4.17-2102.201.3.el8uek.x86_64) \u2022 4 Datacenter Class 1.8 TB U2 PCI NVME SSD Disks (2 for Data + 2 Redo Logs) 8 Firmware/BIOS configuration The test configuration was designed for maximum memory channel and interleaving efficiency on all 8 DIMMs, as shown in Figure 1: Firmware / Bios configuration. NUMA Nodes Per Socket: NPS1 (because this is a single-socket system) . 9 SMT Control: Auto (enabled), which allows AMD Simultaneous Multithreading to optimize resource utilization by executing multiple independent execution threads per CPU core. 10 Determinism Slider: Performance (to boost performance while also increasing power consumption) 11 Memory Interleaving: Auto (all DIMM slots must be populated) 12 The following screenshot shows the memory slots Competitive TCO TCO is a crucial consideration when architecting a database solution. Oracle Processor Licensing is available for Oracle Database Enterprise Edition and is calculated by multiplying each processor's total number of cores by the appropriate licensing factor in the Oracle Processor Core Factor Table. Oracle also charges an additional support fee. This license model allows customers to reduce license costs by selecting low-core CPUs with high frequencies, such as the AMD EPYC 74F3. Oracle Database Standard Edition licensing uses a per-socket license model that requires an individual license for each socket. A processor is counted as equivalent to a socket; however, in the case of multi- chip modules, each chip in the multi-chip module is counted as one occupied socket. The single-socket Supermicro AS-1014S-WTRT is, therefore, an ideal cost-optimized solution for small to mid-size Oracle Database deployments. Conclusion The single-socket Supermicro AS-1014S-WTRT is an ideal cost-optimized solution for small to mid-size Oracle Database deployments. Figure 3 illustrates the increased generational performance between 2nd Gen and 3rd Gen AMD EPYC processors, which directly results from the improved frequency, IPC, and larger 32MB L3 cache available to any single core found in the 3rd Gen AMD EPYC Series processors. Supermicro observed this generational performance improvement by comparing the 3rd Gen AMD EPYC 74F3 CPU to the 2nd Gen AMD EPYC 7F72 CPU. As a result, we believe that 3rd Gen AMD EPYC 74F3 13 processors show exceptional per-core and per-node performance across all load levels and offer compelling single-socket and dual-socket solutions to customers. APPENDIX A \u2013 Oracle Linux & Configuration Oracle Linux Installation & Configuration Benchmark system OS version: Oracle Linux 8.3 Kernel version at the time the benchmarks were run: 5.4.17-2102.201.3.el8uek.x86_64 The benchmarks used the \u201cFull\u201d ISO image from the Oracle Linux Installation Media webpage located at: The Oracle Linux OS configuration was prepared by installing the \u201coracle-database-preinstall-19c\u201d package, which checks and configures the required OS packages/parameters as needed. The installation was completed per the recommendations made by this tool. Please see the OS parameter changes made to \u201c/etc/sysctl.conf\u201d in the commands excerpt. The Oracle ASM filesystem was selected for use with Oracle RAC standalone system (Oracle Restart instance), and the ASMLib driver was therefore installed and configured. ASM disks were on SSDs with single partitions. ORAchk is a tool that checks many different Oracle software components. Scheduling regular ORAchk runs can help the database administrator see changes in the Oracle RAC configuration. We installed ORAchk to make a final check of the OS configuration, per Autonomous Health Framework (AHF) - Including TFA and ORAchk/EXAchk (Doc ID 2550798.1) (valid Oracle Support account required). Per the ORACHK results: \u2022 Set Linux Disk I/O Scheduler to Deadline. \u2022 Set baLinux Transparent HugePages to Disable. Configuring HugePages for SGA is especially important for buffer cache performance. Set this to an appropriate value in proportion to your RAM, as described in APPENDIX B - Oracle Database 19c Configuration. The System Global Area (SGA) is a group of shared memory structures called SGA components that contain data and control information for one Oracle Database. All server and background processes share the SGA. 14 OS parameters for Oracle Setup (/etc/sysctl.conf) [root@master2 ~]# cat /etc/sysctl.conf # sysctl settings are defined through files in # /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/. # Vendors settings live in /usr/lib/sysctl.d/. # To override a whole file, create a new file with the same in # /etc/sysctl.d/ and put new settings there. To override # only specific settings, add a file with a lexically later # name in /etc/sysctl.d/ and put new settings there. # For more information, see sysctl.conf(5) and sysctl.d(5). # oracle-database-preinstall-19c setting for fs.file-max is 6815744 fs.file-max = 6815744 # oracle-database-preinstall-19c setting for kernel.sem is '250 32000 100 128' kernel.sem = 250 32000 100 128 # oracle-database-preinstall-19c setting for kernel.shmmni is 4096 kernel.shmmni = 4096 # oracle-database-preinstall-19c setting for kernel.shmall is 1073741824 on x86_64 kernel.shmall = 1073741824 # oracle-database-preinstall-19c setting for kernel.shmmax is 4398046511104 on x86_64 kernel.shmmax = 4398046511104 # oracle-database-preinstall-19c setting for kernel.panic_on_oops is 1 per Orabug 19212317 kernel.panic_on_oops = 1 # oracle-database-preinstall-19c setting for net.core.rmem_default is 262144 net.core.rmem_default = 262144 # oracle-database-preinstall-19c setting for net.core.rmem_max is 4194304 net.core.rmem_max = 4194304 # oracle-database-preinstall-19c setting for net.core.wmem_default is 262144 net.core.wmem_default = 262144 # oracle-database-preinstall-19c setting for net.core.wmem_max is 1048576 net.core.wmem_max = 1048576 # oracle-database-preinstall-19c setting for net.ipv4.conf.all.rp_filter is 2 net.ipv4.conf.all.rp_filter = 2 # oracle-database-preinstall-19c setting for net.ipv4.conf.default.rp_filter is 2 net.ipv4.conf.default.rp_filter = 2 # oracle-database-preinstall-19c setting for fs.aio-max-nr is 1048576 fs.aio-max-nr = 1048576 # oracle-database-preinstall-19c setting for net.ipv4.ip_local_port_range is 9000 65500 net.ipv4.ip_local_port_range = 9000 65500 vm.nr_hugepages=225280 15 APPENDIX B - Oracle Database 19c Configuration The Oracle Init.ora parameters used to run this benchmark with 512 GB memory were set as follows: MILATPCC.__data_transfer_cache_size=0 MILATPCC.__db_cache_size=280G MILATPCC.__large_pool_size=2684M MILATPCC.__pga_aggregate_target=60G MILATPCC.__sga_target=380G MILATPCC.__shared_io_pool_size=0 MILATPCC.__shared_pool_size=50G MILATPCC.__strams_pool_size=0 MILATPCC.__unified_pga_pool_size=0 MILATPCC.__inmemory_ext_roarea=0 MILATPCC.__inmemory_ext_rwarea=0 MILATPCC.__java_pool_size=1G *.audit_file_dest='/u01/app/oracle/admin/MILATPCC/adump' *.audit_trail='db' *.compatible='19.0.0' *.control_files='+DATAZ/MILATPCC/CONTROLFILE/Current.258.1073386059','+REDOZ/MILANTPCC/CONTROLFILE/Current.258.1073386059' *.db_block_size=8192 *.db_create_file_dest='+DATA' *.db_recovery_file_dest='+REDO' *.db_recovery_file_dest_size=8256m *.db_domain='supermicro.com' *.db_name='MILATPCC' *.diagnostic_dest='/u01/app/oracle' *.dispatchers='(PROTOCOL=TCP) (SERVICE=MILATPCCXDB)' *.processes=2048 *.remote_login_passwordfile='EXCLUSIVE' *.open_cursors=300 *.undo_tablespace='UNDOTBS1' *.nls_language='AMERICAN' *.nls_territory='AMERICA' *.undo_retention=10 *.undo_management='AUTO' *._undo_autotune=false *.log_buffer=1G *._rollback_segment_count=5000 *.parallel_min_servers=0 *.parallel_max_servers=0 *.parallel_servers_target=1792 *.db_writer_processes=8 *.sga_target=160G *.pga_aggregate_target=110G *.db_16k_cache_size=0G *.disk_asynch_io=TRUE *.inmemory_size=48g *.lock_sga=TRUE *.result_cache_max_size=32G *.db_block_checking='FALSE' *.db_block_checksum='FALSE' *.DB_CACHE_ADVICE='ON' *.db_file_multiblock_read_count=16 *.dml_locks=16384 *.fast_start_mttr_target=0 *.filesystemio_options='setall' *.transactions_per_rollback_segment=1 *.log_checkpoint_interval=262144 *.log_checkpoint_timeout=900 *.log_checkpoints_to_alert=TRUE *.plsql_code_type='NATIVE' *.plsql_optimize_level=2 *.query_rewrite_enabled='FALSE' *.replication_dependency_tracking=FALSE *.statistics_level='TYPICAL' *.timed_statistics='TRUE' *.trace_enabled='FALSE' *.use_large_pages='AUTO_ONLY' 16 HammerDB Installation and Configuration Successful TNSping to the database system is required before testing HammerDB. Finish installing and configuring the Oracle client before installing HammerDB. These benchmarks used HammerDV v3.1, which can be found at Be sure to create a separate user called \u201chammerdb1\u201d to run the HammerDB client. Step 1: Preparing the Benchmark Database Tablespace Creation: Use the database file destination values. SQL> show parameter file_dest NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ db_create_file_dest string +DATA db_recovery_file_dest string +REDO Step 2: Create the benchmark database using the following SQL scripts: CREATE BIGFILE TABLESPACE TPCC_800 DATAFILE SIZE 300G AUTOEXTEND ON NEXT 10G BLOCKSIZE 8K EXTENT MANAGEMENT LOCAL AUTOALLOCATE SEGMENT SPACE MANAGEMENT AUTO; CREATE BIGFILE TABLESPACE TPCC_800_OL DATAFILE SIZE 500G AUTOEXTEND ON NEXT 10G BLOCKSIZE 8K EXTENT MANAGEMENT LOCAL AUTOALLOCATE SEGMENT SPACE MANAGEMENT AUTO; Step 3: Create a temporary tablespace with a minimum file size of 30G: Create Temporary Tablespace TPCCTEMP TEMPFILE '+DATAZ' size 30G Autoextend On Next 10M Maxsize Unlimited Extent Management Local Uniform Size 10M; Step 4: Create Users and Grants Create User tpcc800 Identified by tpcc800 default Tablespace Tocc_800 Temporary Tablespace TPCCTEMP; Create Temporary Tablespace TPCCTEMP TEMPFILE '+DATAZ' size 30G Autoextend on next 10M Maxsize Unlimited Extent Management Local Uniform Size 10M; 17 grant create session to tpcc800; grant connect,resource to tpcc800; grant dba to tpcc800; GRANT CONNECT, RESOURCE, DBA to tpcc800; GRANT UNLIMITED TABLESPACE TO tpcc800; Step 5: Create the database schema using the HammerDB client. The HammerDB CLI commands allow you to create the schema by logging in to the HammerDB client, changing to the HammerDB directory, and then executing the hammerdbcli command: cd /hammerdb1/HammerDB-3.l ./hammerdbc1 Execute the following commands to set the run parameters: dbset db ora dbset bm TPC-C diset connection system_password Amarit27 diset connection instance MILATPCC diset tpcc tpcc_user tpcc800 diset tpcc tpcc_pass tpcc800 diset tpcc tpcc_def_temp TPCCTEMP diset tpcc count_ware 256 diset tpcc num_vu 20 diset tpcc tpcc_def_tab tpcc_800 diset tpcc tpcc_ol_tab tpcc_800_ol diset tpcc partition true diset tpcc hash_clusters true print dict Execute the following command to create the schema and load benchmark data into the database: buildschema 18 Prepare the system for running new benchmarks by destroying virtual users after building the schema and after every benchmark run: We used the following script to change the count_ware (Number of warehouses) and num_vu (Number of virtual users) to 0: dbset db ora diset tpcc ora_driver timed dbset bm TPC-C print bm diset connection system_password Amarit27 diset connection instance milatpcc diset tpcc count_ware 256 diset tpcc tpcc_def_tab tpcc_800 diset tpcc tpcc_ol_tab tpcc_800_ol diset tpcc checkpoint true diset tpcc rampup 3 diset tpcc duration 10 loadscript vuset vu 300 vuset showoutput 1 vuset logtotemp 1 vuset unique 1 vucreate print dict print vuconf print script vurun Footnotes 1. Based on AMD internal testing as of 02/1/2021, average performance improvement at ISO- frequency on an AMD EPYC 72F3 (8C/8T, 3.7GHz) compared to an AMD EPYC 7F32 (8C/8T, 3.7GHz), per-core, single thread, using a select set of workloads including SPECrate2017_int_base, SPECrate2017_fp_base, and representative server workloads. SPEC and SPECrate are registered", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "bb03a8d6-aa47-46cf-b290-7e21eb758ceb": {"__data__": {"id_": "bb03a8d6-aa47-46cf-b290-7e21eb758ceb", "embedding": null, "metadata": {"file_name": "Solution-Brief_OVX.pdf", "publication_date": "March 2023", "referenced_websites": ["https://www.supermicro.com/en/accelerators/nvidia/omniverse", "https://www.supermicro.com/en/products/gpu"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro is introducing a rack-scale implementation of NVIDIA Omniverse Enterprise powered by the Supermicro SYS-420GP-TNR GPU servers. The Supermicro solution is an NVIDIA-Certified OVX System purpose-built to power and operate large-scale digital twins for Omniverse Enterprise. This purpose-built turnkey solution features the best-in-class architecture to deliver the cutting-edge performance needed for data-intensive applications and real-time collaboration using NVIDIA Omniverse. Designed for Operating Large-Scale Digital Twins and Running Simulations With 256x NVIDIA L40 GPUs and 200 Gbps networking in a scalable 32-node SuperPOD, Supermicro OVX Rack solutions deliver unparallel performance to operate digital twins and run large simulations effortlessly. \u2022 Designed and explicitly architected to meet the computing demands for digital twins and application-intensive workloads \u2022 Validated solution enables data-center scale and reliability for real-time collaboration and high-fidelity simulations 1 Designed for Operating Large-Scale Digital Twins and Running Simulations 1 Scalable Performance and Flexible Deployment Options 2 Deploy In Days, Not Weeks 2 Reasons To Deploy Supermicro Rack Scale OVX Solutions 2 Conclusion and Summary 4 1 1 Designed for Operating Large-Scale Digital Twins and Running Simulations 1 Scalable Performance and Flexible Deployment Options 2 Deploy In Days, Not Weeks 2 Reasons To Deploy Supermicro Rack Scale OVX Solutions 2 Conclusion and Summary 4 2 Scalable Performance and Flexible Deployment Options Deploy Supermicro Rack Scale Solutions of NVIDIA Omniverse Enterprise with 1 to 4 nodes as a proof of concept and quickly scale to hundreds of servers via SuperPODs to meet workload demands. \u2022 Multi-rack plug-and-play design. Easily grow the cluster as an organization's workloads increase. \u2022 SYS-420GP-TNR provides the best-in-class performance and flexible computing architecture with dual 3rd Gen Intel Xeon Scalable processors and NVIDIA GPUs. \u2022 High-performance networking enables high bandwidth and low latency for workloads simultaneously utilizing multiple systems. Deploy In Days, Not Weeks Fully tested and validated design at the cluster level so customers can have Omniverse Enterprise operational in days. As a result, engineers, designers, artists, and scientists can focus on fewer system implementation complexities and more technological breakthroughs. \u2022 Optimized rack layout and topology for power and cooling \u2022 Validated and tuned OVX architecture that is designed for stability and future scalability Reasons To Deploy Supermicro Rack Scale OVX Solutions \u2022 Complete NVIDIA Omniverse Enterprise software stack included \u2013 makes it easy to get started with the NVIDIA Omniverse platform. \u2022 Enabled by NVIDIA RTX and high-speed networking technologies \u2013 Enables fast responses for optimal collaboration. \u2022 End-to-end thoroughly tested and integrated \u2013 Racks are plug-and-play design; Supermicro assembles and extensively tests the entire configuration prior to shipping to the customer. \u2022 Purpose built for performance and acceleration \u2013 Selected components ensure optimal performance using the latest CPUs and GPUs. \u2022 Highly scalable and easy to deploy from four-server clusters to multiple pods to handle the largest workloads. \u2022 Four configurations are available, from single to multiple racks, to begin building metaverse applications, run large- scale simulations, and operate digital twins. 3 Supermicro OVX Solutions Small Medium Large (Pod) SuperPOD Appliance SRS-48UOVX-SMAL-01 SRS-48UOVX-MED-01 SRS-48UOVX-POD-01 SRS-48UOVX-SPOD-01 OVX Nodes 4x SYS-420GP-TNR 8x SYS-420GP-TNR 16x SYS-420GP-TNR 32x SYS-420GP-TNR Nucleus Servers 1x SYS-120U-TNR 2x SYS-120U-TNR Rack 1x 48U (Optional 42U) 2x 48U (Optional 42U) 3x 48U (Optional 42U) 6x 48U (Optional 42U) Total CPUs 8x Intel Xeon Platinum 8362 16x Intel Xeon Platinum 8362 32x Intel Xeon Platinum 8362 64x Intel Xeon Platinum 8362 Total GPUs 32x NVIDIA L40 64x NVIDIA L40 128x NVIDIA L40 256x NVIDIA L40 Total System Memory 4TB 8TB 16TB 32TB Networking 6x 200Gbps 32-port NVIDIA SN3700 Ethernet Switches 8x 200Gbps 32-port NVIDIA SN3700 Ethernet Switches 8x 200Gbps 64-port NVIDIA SN6400 Ethernet Switches 1x 1Gbps 48-port NVIDIA SN2201 Ethernet Switch Total Storage 60.8TB NVMe (Raw) 121.6TB NVMe (Raw) 243.2TB NVMe (Raw) 486.4TB NVMe (Raw) Estimated Power 18.61kW 34.10kW 66.64kW 133.21kW Software NVIDIA Omniverse Enterprise Starter Pack Subscription (1, 3, 4, and 5 yr. options) 4 SYS-420GP-TNR OVX Specifications Overview4U Dual Processor (3rd Gen Intel Xeon), Dual-Root GPU System, up to 10 PCIe GPUs CPU 2x Intel Xeon Platinum 8362 CPUs (32C/64T, 2.8GHz, 265W TDP) Memory (additional memory available) 1TB DDR4 (16x 64GB DIMMS) Graphics 8x NVIDIA L40 GPUs (48GB, 300W TDP) Networking 3x NVIDIA ConnectX-7 200Gbps NICs Storage (additional storage available) 15.2TB NVMe (2x 7.6TB U.2) 1.92TB NVMe (2x 960GB M.2, Boot) Estimated Power 3,874W (3.87kW) Conclusion and Summary NVIDIA Omniverse Enterprise revolutionizes design collaboration, simulation, and operation of digital twins. Globally dispersed teams can accelerate their workflows with one-click interoperability between leading software tools and seamlessly collaborate in a shared virtual world running from the data center. Supermicro\u2019s rack-scale OVX solution for Omniverse enables the development and operations of factory digital twins, harmonizes the flow of design data across the enterprise, and accelerates visualization for in-vehicle experiences, car configurators, and virtual showrooms. Omniverse is driving digital transformation and innovation through the following: \u2022 A Cutting-edge solution to help your business to beat the competition \u2022 Seamless high-speed global connectivity allows for design and collaboration at scale \u2022 Increase productivity and faster time to market \u2022 Resource-saving and lower overhead costs 5 Digital Transformation Through Omniverse", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "35c93b62-474d-44ca-8ac7-42ebc0440be5": {"__data__": {"id_": "35c93b62-474d-44ca-8ac7-42ebc0440be5", "embedding": null, "metadata": {"file_name": "Solution_Brief_Right_sizing_3D_Design_Resources_With_NVIDIA_Omniverse_Enterprise.pdf", "publication_date": "March 2022", "referenced_websites": ["https://www.supermicro.com/en/products/nvidia-omniverse"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Reshaping 3D Design for Scalability 2 Engineered Solutions for 3D Design Teams 3 Three Deployment Configuration Examples 4 Bringing In the Right Skills 5 RIGHT-SIZING 3D DESIGN RESOURCES WITH NVIDIA OMNIVERSE ENTERPRISE Supermicro workstations and servers power workloads for small, large, on-premises or remote teams 3D design environments provide powerful visualization and simulation capability for many industries. Projects in media production, oil and gas exploration, medical imaging, electronic design automation (EDA) and mechanical computer-aided design and engineering (CAD/CAE) need advanced image rendering for design and analysis. For teams in these and other industries, NVIDIA is transforming real-time collaboration around 3D designs with NVIDIA Omniverse Enterprise. It provides photorealistic 3D rendering and simulation in a workflow maximizing rendering iterations, streamlining review cycles, and enabling work from anywhere, on-premises or remote. Supermicro is innovating solutions for Omniverse Enterprise deployments on a range of workstation and server hardware, right-sizing 3D design resources for each team. Three deployment configuration examples show a 6-user single workstation combining all needed capability, a pooled GPU 78- user rack-level deployment, and a new jointly developed OVX reference platform handling 64 heavy users or 256 light users in a rack-level solution with Ethernet or InfiniBand connectivity. As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. 2022 Copyright Super Micro Computer, inc. . 2 Reshaping 3D Design for Scalability 3D design acceleration began in the \"box-on-desk\" deployment model, with applications running on a workstation. Scaling a design team meant adding a designer and investing in another 3D graphics workstation for them. Workflows kicked off rendering jobs over lunch or at the end-of-day for overnight runs, followed by changes and more rendering. This 1:1 coupling between designer and workstation has limited scalability and made remote work difficult. NVIDIA Omniverse Enterprise changes the 3D design scalability and remote work equation. It enables collaboration for creative teams on enterprise 3D visualization projects like never before. This new technology reduces costs and waste by enabling a simultaneous workflow, maximizes creativity by allowing new iterations without opportunity cost, and accelerates time to production by eliminating import-export workflows. Highlights of the Omniverse architecture: \u2022 Rendering builds on advanced NVIDIA RTX accelerated real-time ray-tracing technology and adds dynamic allocation of graphics processing unit (GPU) cores, even from separate machines, for rendering jobs. \u2022 Collaborative scene composition is enabled by Pixar's Universal Scene Description (USD), an extensible, open- source file framework that allows the interchange of 3D assets. \u2022 NVIDIA Omniverse Nucleus database and collaboration engine manage data such as geometry, lights, materials, textures, and more for defining a virtual \"world\" in and around a design, including its environment. \u2022 NVIDIA Omniverse Connect allows 3rd party client applications access to the Nucleus database using publish- subscribe messaging, letting many designers author live changes that everyone connected sees in real-time. \u2022 NVIDIA Omniverse Kit is a toolkit for lightweight plugins building applications and microservices. \u2022 NVIDIA Omniverse Create enables world-building, using advanced USD workflows such as layers, variants, instancing, animation caches, and more. \u2022 NVIDIA Omniverse View lets non-technical users review 3D content interactively in full, photorealistic fidelity. Using Supermicro hardware platforms, 3D design teams can select a hardware topology and mix and match configurations for an Omniverse Enterprise solution best fitting their needs. For example, \"creators\" can tap into the full capability needed for design, while \"reviewers\" can run on lighter hardware platforms at a reduced software licensing cost. In addition, deployments are open to various workstations, deskside, and rack-scale servers right-sized for teams, projects, and workloads. Figure 1 - NVIDIA Omniverse Software Stack - Image Courtesy of NVIDIA 2022 Copyright Super Micro Computer, inc. . 3 Engineered Solutions for 3D Design Teams Supermicro's server technology is proven through years of deployments in enterprise, data center, cloud computing, 5G telecom infrastructure, high-performance computing (HPC), edge computing, and other IT applications. US-based engineering and manufacturing teams provide innovative features, and ISO 9001-certified quality customers expect. These teams design and produce Supermicro motherboards, power supplies, enclosures and racks, and other components, increasing supply chain control. The firmware allows unlocked peripheral integration at the factory or by customers. Supermicro selects the right technology for delivering better price/performance with improved energy efficiency through its partnerships. A key enabler for 3D design is NVIDIA's graphics processing unit (GPU) technology. Supermicro currently offers over 60 workstation and server configurations with installed NVIDIA graphics cards such as the NVIDIA RTX A6000 or NVIDIA A40. With the debut of NVIDIA Omniverse Enterprise, Supermicro is fine-tuning new workstation and server configurations matching hardware allocation to user performance profiles, maximizing resource usage. Flexing GPU muscle for a variety of workloads Supermicro excels at creating denser NVIDIA RTX GPU-based configurations targeting light to heavy Omniverse Enterprise workloads. The combination of cutting-edge AMD or Intel chipsets, fast PCI Express slots, Supermicro-designed high efficiency 80 Plus Titanium power supplies, and thermally simulated system cooling designs enable multi-GPU workstations and servers. In addition, high-speed Ethernet switching and IPMI 2.0 remote management help connect and manage deployments. Some possible use cases for various Supermicro hardware configurations: \u2022 A 1:1 model, with a single GPU in an entry-level workstation for each designer, still works for light 3D design workloads \u2022 Small 3D design teams can render on-demand using a more powerful workstation with several GPU cards installed \u2022 Multi-location teams can use one medium-sized server with multiple GPU cards, connecting remotely over Ethernet \u2022 A heavy media entertainment workload can deploy a rack-scale solution with up to 64 pooled GPUs from several servers Expertise for Omniverse Enterprise deployments Omniverse Enterprise is rapidly growing and being adopted quickly by customers as a new and exciting solution. NVIDIA featured Omniverse Enterprise during its CES 2022 presentation. Supermicro, as an NVIDIA ecosystem partner, keeps pace with new GPU applications, including artificial intelligence (AI) and on-demand 3D rendering. Initial deployments of the use cases above built vital Supermicro expertise with Omniverse Enterprise, and Supermicro can help deploy more solutions now. A typical Omniverse Enterprise engagement with Supermicro looks like this: \u2022 A Supermicro solution architect interviews customer teams about roles, workloads, and deployment options \u2022 Supermicro technology enablement teams look at specific requirements and configurations for workstations/servers \u2022 Supermicro product teams install Omniverse Enterprise at the factory and launch clients on the customer's premises During these engagements, the goal is always to provide efficient compute power where a team needs it for their workflow. For example, a solution architect can help size a platform for a Nucleus database and its Large File Transfer (LFT) technology, allocating disk storage and memory-based cache. Another example includes a rack-mount Ethernet switch for remote connections \u2013 each remote 4K display needs at least 1Gbit of Ethernet bandwidth to run at 60fps without latency. Supermicro is the first solution provider to partner with NVIDIA on an OVX reference platform for low user count and high- intensity use cases. No other hardware vendor has yet deployed Omniverse Enterprise in rack-scale, high user counts solutions. Offering a wide variety of options, Supermicro can address more scenarios for Omniverse Enterprise deployments with results customers can count on \u2013 like three described next. 2022 Copyright Super Micro Computer, inc. . 4 Three Deployment Configuration Examples For small teams of up to six users, one Supermicro A+ SuperWorkstation hosts a Nucleus server, an NVIDIA RTX Virtual Workstation (vWS), and VMware virtualization software. A 64-core AMD RYZEN Threadripper Pro 3995WX processor handles threading in this configuration. Virtualization storage comes from 4x mirrored, striped 3.84TB m.2 SSDs, while 2x 7.68TB U.2 SSDs provide a Nucleus file store. Two NVIDIA RTX A6000 GPUs handle rendering. Dual-port 25GbE handles virtual connections for remote users. Resource allocation creates a dedicated workspace for each user on the workstation, plus threads and storage for the Nucleus server and the vWS licensing server. NVIDIA Omniverse Enterprise Nucleus Server VM: 32 vCPU threads, 52GB DRAM, 6TB Gen4 NVMe mirror NVIDIA RTX vWS license server VM: 4 vCPU threads, 8GB DRAM, 20GB SSD 6x User VM, each with: 10 vCPU threads, 32GB DRAM, 16GB vGPUs frame buffer, 960GB Gen4 NVMe Image 1 - AS -5014A-TT Workstation For a flexible GPU pool handling up to 78 users, a Supermicro rack-scale solution includes a standalone Nucleus server, 13 rendering servers, and a 100GbE switch. The Omniverse Enterprise Nucleus Server is a 1114S-WN10RT, running an AMD EPYC 73F3 with 16 cores at 3.5GHz and 128GB DDR4-3200 DRAM. Storage is 6x 3.84TB U.3 SSDs. Two dual-port 100GbE connections feed the Ethernet switch for smooth database access. Thirteen 2U-2 node user servers are either 2114GT-DNR (Intel Xeon W-3365 with 32 cores at 2.7GHz) or 210GP-DNR (AMD RYZEN Threadripper Pro 3975WX with 32 cores at 3.5GHz), each with 256GB DDR4-3200 DRAM, two 1.92TB U.3 SSDs, and two NVIDIA A40 GPUs. Dual-port 25GbE handles virtual connections. Resource allocation creates a dedicated workspace for each user. 78x User VM, each with 16 vCPU threads, 80GB DRAM, 16GB vGPU frame buffer, 960GB SSD Developed jointly with NVIDIA, the SYS-420GP-TNR OVX reference platform targets heavy rendering or simulation requirements with GPU passthrough capability. A 4U server houses eight NVIDIA A40 GPUs, each dedicated to a user or virtualized for multiple users. Processing is two Intel Xeon SP 8362 with 32 cores at 2.8GHz, backed by 1TB of DDR4 ECC DRAM. Storage is two 960GB NVMe boot drives and two 7368TB NVMe storage drives. In addition, two Mellanox ConnectX-6 VPI cards provide Ethernet/InfiniBand connectivity at up to 200 GB/sec. Eight Supermicro SYS-420GP-TNR servers can be combined with a 220U-TNR standalone Nucleus server and an Ethernet/InfiniBand switch in a rack-scale solution for mixed resource deployments. In a heavy usage scenario, each user gets a full NVIDIA A40 GPU for a total of 64 users per rack. The NVIDIA A40 GPUs can be virtualized with allocated CPU threads and storage for up to 256 users in a rack for medium and light resource usage. Image 2 \u2013 13 x 2U-2Node Servers Image 3 - 8 x SYS-420GP-TNR 2022 Copyright Super Micro Computer, inc. . 5 Bringing In the Right Skills NVIDIA Omniverse Enterprise breaks out of the 1:1 model where a 3D design workstation dedicated to every single user was the only option. It relieves the hassle of planning workflows around scheduled rendering iterations. Instead, it enables on-demand rendering from workstations or servers available to all users in real-time. It also allows teams to staff and scale with flexibility. Teams can grab design and project talent with the right skills based anywhere with high-speed internet access. Supermicro is a natural fit as a solution provider for Omniverse Enterprise deployments. With an in-depth understanding of architecting deployments from small teams to large media entertainment projects, Supermicro can match a team's use case to right-sized solutions saving energy and reducing the total cost of ownership. These solutions continue to evolve, as seen in a new, jointly developed reference platform: \"Supermicro's success in Omniverse Enterprise deployments ranging from small design teams to large, geographically distributed project teams caught our attention,\" says Bob Pette, Vice President, Professional Visualization at NVIDIA. \"We created the NVIDIA OVX SYS-420GP-TNR reference platform working together for a proven configuration that ships quickly, getting customers up and running on Omniverse Enterprise faster.\" The range of solutions Supermicro brings to 3D design and simulation teams \u2013 workstations, servers, and rack-scale \u2013 is formidable. It comes from years of experience supplying IT applications. With access to advanced parts from NVIDIA, AMD, Intel, and many other providers, plus in-house design capability for motherboards, power supplies, enclosures, and more, Supermicro can draw configurations together with the quality, deliverability, and performance needed. Teams turning to Omniverse Enterprise should focus on revolutionizing their 3D content creation and simulation pipelines. Having wrong-sized hardware can get in the way of success. Worry-free projects start with a call to Supermicro, tapping into Omniverse Enterprise capability and deployment expertise no other solution provider offers.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "7fdfc929-1269-4177-abe0-493230887159": {"__data__": {"id_": "7fdfc929-1269-4177-abe0-493230887159", "embedding": null, "metadata": {"file_name": "Solution-Brief_Zededa.pdf", "publication_date": null, "referenced_websites": ["https://www.supermicro.com/", "www.supermicro.com", "www.zededa.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Deploying Cloud-managed Gateways, Simply and Securely More than one trillion edge devices are projected to be deployed by 2035 and organizations are now facing the challenges of how to manage and utilize the ever- increasing amounts of data generated by these devices. As a result, most industries are undergoing a shift in how they think about data management at the edge. This is further underscored by Gartner analysts who estimate that by 2022, more than half of all enterprise data will be processed outside of the datacenter. Enterprises understand that more compute technology will need to be deployed closer to the edge data sources to reduce latency in processing this remote data. This shift to edge computing will heavily rely on the deployment of devices such as IoT gateways and industrial PCs. The scale and complexity of this rapidly expanding edge ecosystem calls for innovative management tools for deploying and maintaining these systems. 1 2 The Challenges 2 The Solution Cloud-Managed Gateways Streamline Deployment Powerful Tools for Remote Management Industrial App Store Simplifies Future Service Deployment Your Managed Devices Are Safe and Secure 4 Supermicro Gateways and Servers Available as Managed Solutions 5 Application Use Cases Hyperlocal, High-density Video Environment\u2014Content Distribution Smart Workspaces\u2014 Personalization Gateway Smart City Application Platform Fully Automated Solar Farm (Local Point of Presence) 7 Key Benefits of Supermicro Managed Edge Solutions Powered by Zededa 7 Summary Figure 1. Supermicro\u2019s edge computing devices teamed with Zededa\u2019s Edge Services Platform allow IT to simply and securely remote-manage all edge computing networks Deploying Cloud-managed Gateways, Simply and Securely 2 The Challenges To successfully build and run a reliable and efficient edge computing infrastructure, organizations need solutions to several new problems: \u2022 Deploying remote devices at any scale normally requires skilled technical resources already onsite or service contracts with regional organizations that can put support personnel where needed and for the duration of the installation. \u2022 Once deployed and properly configured, an organization must develop the means to manage diverse devices distributed across a wide geographical area. This requires either a robust remote management plan or dedicated onsite personnel to ensure full and continued functionality of the devices. \u2022 Deployment plans must take into consideration not only the functionality of the devices as they are deployed today but also how to manage upgrades and enhancements into the future. \u2022 Devices that will likely exist outside of traditional perimeter-based security must adopt technologies such as the zero-trust model in the perimeter-less environment. \u2022 Processing data at remote locations requires multiple means of connectivity to reduce latency and provide a fail-safe for potential service interruptions. The Solution Cloud-Managed Gateways Streamline Deployment Organizations can streamline and simplify the deployment of edge hardware across their entire landscape with Supermicro\u2019s cloud-managed gateways and edge computing devices. Our high-performance, rugged devices enable organizations to move processing power out of the datacenter and closer to their edge. New devices arrive equipped with the Zededa\u2019s Edge Services Platform (ESP) installed, allowing IT to remotely manage all initial and ongoing hardware orchestration. Zededa\u2019s Edge Services Platform offers 100% cloud-managed automation, visibility, and protection of edge applications and the hardware it runs on. It provides an automated, hardware agnostic, and secure operating model for mass-deployed edge devices and applications\u2014eliminating manual configuration processes, requirements for on-site expertise, and any need for manual updates of software. To get started, simply plug the new device into the network, power it on, and log into the Edge Services Platform console from any web browser. Technical expertise is not required at the deployment site. Powerful Tools for Remote Management Once devices are successfully installed in their remote locations, they can easily be managed from any browser through the cloud interface. The management tools offer Deploying Cloud-managed Gateways Challenges \u2022 Large number of different devices with wide geographical distribution \u2022 Onboarding and ongoing management of remote devices \u2022 Hardware security in a perimeter-less world \u2022 Disparate types of edge hardware result in management silos \u2022 Latency complicates real time information/response Benefits of Supermicro Managed Solutions \u2022 Central visibility and management over all edge hardware \u2022 Hardware integrity and security ensured with zero-trust model \u2022 Zero-touch device provisioning \u2022 Configure and manage applications at scale \u2022 Agility and scalability with 100% cloud-based model Deploying Cloud-managed Gateways, Simply and Securely 3 complete visibility into device and application health, while also enabling automated and secure over-the-air software updates to any one device or to millions of devices at the same time. Built-in, one-click disaster recovery of applications provides unprecedented control, visibility, and service reliability for deployments of any size. Industrial App Store Simplifies Future Service Deployment Industrial computing has witnessed a technological leap with the emergence of IoT and the ubiquitous connectivity of edge computing, making it possible for devices with long, multi-year lifecycles to act as a platform for deploying new, revenue enhancing applications. Supermicro edge devices with ZEDEDA\u2019s Edge Services Platform provide a secure method of deploying new industrial applications on existing equipment. Adding new service capabilities is now as simple as adding an app to your smartphone. Your Managed Devices Are Safe and Secure Each device is equipped with TPM/TEE, ensuring hardware root of trust as the starting point of your security measures. All devices are factory configured with a trusted root CA certificate and there are no usernames or passwords within the device software to be discovered by anyone with malicious intent. Figure 2. Zededa software interface controls provide one-click deployment of edge services and applications across your entire landscape. Application configuration and updates are all managed through the central control pane. SYS-E50-9AP-WIFI SYS-E100-9S-E SYS-E300-8D SYS-5018D-FN8T CPU Memory Capacity Memory Type DIMM Sizes Memory Voltage 7th Generation Intel Core i5-7300U Processor Single Socket FCBGA 1356 System-on-Chip CPU TDP support 15W Up to 32GB Unbufered non-ECC SO-DIMM, DDR4-2133MHz, in 2 DIMM slots Intel processor D-1518, 2.2GHz; CPU TDP support 35W FCBGA 1667: 4 Cores, 8 Threads / 6MB 4x DDR4 DIMM sockets Supports up to 128GB DDR4 ECC RDIMM Supports up to 64GB DDR4 ECC/non-ECC UDIMM Intel Xeon processor D-1518 2.2GHz; CPU TDP support 35W FCBGA 1667: 4 Cores, 8 Threads / 6MB 32GB, 16GB, 8GB, 4GB Network Controllers SATA Single LAN with Intel I210IT Single LAN with Intel PHY I219LM SoC controller for SATA3 (6Gbps) SATA3 (6Gbps) SATA3.0 SoC controller for SATA3 (6Gbps) Storage Module LAN Video 1x VGA 1x COM (1 header) TPM 1x TPM 2.0 onboard TPM 2.0 header 1x TPM 2.0 onboard USB 2x USB 3.0 1x 2.5\" fxed drive bay with bracket (when AOC area is not occupied) 1x 3.5\" or 4x 2.5\" drive bays with bracket 2x USB 3.0 Others 1x DIO via DB9 Com Port IoT Gateways ZEDEDA SFT-ZE-ZEDEDGE1EAP1YR SFT-ZE-ZEDEDGE1EAP1YR Operating Temperature 0\u00b0C ~ 50\u00b0C (32\u00b0F ~ 122\u00b0F) 0\u00b0C to 40\u00b0C (32\u00b0F to 104\u00b0F) 0\u00b0C to 40\u00b0C (32\u00b0F to 104\u00b0F) Audio TPM 2.0 header ALC 888S HD Audio Software Operating Environment Processor/Cache Input/Output On-board Devices System Memory Dual 10G SFP+ from D-1500 SoC Quad 1GbE with Intel I350-AM4 Dual 1GbE with Intel I210 Intel Atom processor E3940 Single socket FCBGA 1296 9.5W, 4C Up to 8GB Unbufered non-ECC SO-DIMM DDR3L-1866MHz, in 1 DIMM socket 4x DDR4 DIMM sockets Supports up to 128GB DDR4 ECC RDIMM Supports up to 64GB DDR4 ECC/non-ECC UDIMM 8GB, 4GB, 2GB 16GB, 8GB, 4GB 32GB, 16GB, 8GB, 4GB DDR3L up to 1866MHz DDR4 up to 2133MHz 1.2 V 1.35 V 1.2 V 2133/1866/1600MHz ECC DR4 ECC RDIMM and ECC/Non-ECC UDIMM Dual LAN with Intel Ethernet Controller I210-IT 2x RJ45 Gigabit Ethernet LAN 2x RJ45 Gigabit Ethernet LAN 2x 10G SFP+ 6x RJ45 Gigabit Ethernet LAN 1x RJ45 Dedicated IPM LAN 2x HDMI 1x DP (Display Port) 1x HDMI 1x VGA 1x COM (1 header) 2x USB 3.0 2x USB 2.0 1x USB 3.1 (Type C) 2x USB 3.0 4x USB 2.0 1x SuperDOM (Disk on Module) power connector 1x SATA DOM (Disk on Module) power connector 2x COM (RS-232/422/485) 1x DP (Display Port) 1x HDMI 1x 2.5\" 7mm SATA SSD 1x M.2 B-Key 2242/3042 for SATA SSD 1x M.2 B-Key 2280 (2242 with standof) SFT-ZE-ZEDEDGE1EAP1YR SFT-ZE-ZEDEDGE1EAP1YR 0\u00b0C to 50\u00b0C (32\u00b0F to 122\u00b0F) -20\u00b0C to 50\u00b0C (-4\u00b0F to 122\u00b0F) Without Wif 1x HD Audio header (Mic-in/Line-Out) (option) N/A N/A 2133/1866/1600MHz ECC DDR4 ECC RDIMM and ECC/Non-ECC UDIMM 1.2 V Dual 10G SFP+ from D-1500 SoC Quad 1GbE with Intel I350-AM4 Dual 1GbE with Intel I210 2x 10G SFP+ LAN 6x 1GbE LAN 1x Dedicated IPMI LAN Dual Band Wireless and Bluetooth 4.2 GATEWAYS AND SERVERS AVAILABLE AS MANAGED SOLUTIONS Deploying Cloud-managed Gateways, Simply and Securely 5 Application Use Cases Fully Automated Smart Factory Smart Workspaces\u2014 Personalization Gateway \u2022 Easily integrate and share ICS information along with new sensor data with IT/OT \u2022 Secure App-to-App communi- cation via overlay network \u2022 Real-time data-enabling collaboration \u2022 Central control, automation and autonomous edge operations \u2022 Locally distributed \u2022 Identity-based experience regardless of location \u2022 Instant access control and authentication \u2022 Facial recognition authenticates identity \u2022 Corporate security policies automatically deployed on data \u2022 Reduce remote office expenses Headquarters Edge Gateway Per Desk Deploying Cloud-managed Gateways, Simply and Securely 6 Edge (Virtualized + Networked) Application Use Cases (continued) Smart City Application Platform Fully Automated Solar Farm (Local Point of Presence) \u2022 Hardware agnostic \u2022 Secure app-to-app communication without delay \u2022 Local application logic, real-time action \u2022 Locally survivable of services \u2022 Highly distributed \u2022 Hardware agnostic \u2022 Secure app-to-app communication via overlay network \u2022 Local application logic, real-time action \u2022 Locally survivable of services for extremely remote locations \u2022 Locally distributed Per Segment Gateway Topaz Solar Park (9M Modules) Hindupar Solar Park (195 Acres) Per Street Lamp Gateway Operations Center POP @ Local to Solar Farm SYS-5018D-FN8T PV PCU Monitoring Video Security RT IR Video Analytic RT Env Analytic Legacy PLC E100-9S-E E100-9S-E E100-9S-E Z Hypervisor Z Hypervisor Z Hypervisor Deploying Cloud-managed Gateways, Simply and Securely 7 For More Information \u2022 Optimized SuperServer Solutions products/embedded/embedded_ server.cfm \u2022 Internet of Things Gateway Solutions products/system/Compact/ \u2022 Embedded / IoT Solutions products/embedded/ \u2022 SuperServer E50-9AP-WIFI products/system/Box_PC/SYS- E50-9AP-Wifi.cfm \u2022 SuperServer E100-9S-E products/system/Box_PC/SYS- E100-9S-E.cfm \u2022 SuperServer E300-8D products/system/Mini-ITX/SYS- E300-8D.cfm \u2022 SuperServer 5018D-FN8T products/system/1U/5018/SYS- 5018D-FN8T.cfm Summary Deploying managed and secure Gateways has never been easier. With Supermicro Edge Devices and Zededa\u2019s Edge Services Platform, businesses can move their deployment plans forward with confidence, knowing that their devices are secure and the path to remote management of those devices will be as easy as the deployment. Key Benefits of Supermicro Managed Edge Solutions Powered by Zededa \u2022 Single pane of glass across all edge hardware: Deploy, manage and monitor all hardware through the same console\u2014any hardware, any software, at any time. \u2022 Zero-touch provisioning: Connect the wired or wireless Ethernet, power on the device, and it will automatically connect to the cloud and receive the relevant configuration details. Device initialization requires no IT expertise or pre- installation configuration. \u2022 Superior security designed for the edge: Zero-trust model ensures device integrity in environments where hardware, software, and users cannot always be verified or trusted. Comprehensive security capabilities provide the same comparably high level of control and scrutiny required in traditional datacenters. \u2022 Services ecosystem: One-click deployment of edge services and applications across your entire landscape. Application configuration and updates are all managed through the central control pane, streamlining common tasks and reducing administrative overhead. \u2022 100% cloud-based delivery: All the benefits of the cloud, right at the edge. On-demand scale and Anything-as-a-Service delivery make it easy to enable new functionality as needed, and agile development provides continuous and predictable improvements.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "7f95ba51-808f-4376-b6c6-031f7f5cea7f": {"__data__": {"id_": "7f95ba51-808f-4376-b6c6-031f7f5cea7f", "embedding": null, "metadata": {"file_name": "Solution-Brief_Intelligent_Retail_Edge.pdf", "publication_date": "May 2020", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 CHALLENGES FACING TODAY\u2019S RETAIL 3 THE INTELLIGENT RETAIL EDGE DIFFERENCE 4 NETWORK SECURITY & OPTIMIZATION FOR THE RETAIL EDGE 4 CRITICALITY & SCALE OF DISTRIBUTED RETAIL EDGE 5 THE ADVANTAGE INTELLIGENT RETAIL EDGE - Technology disruption in the Retail industry and the rise of e-commerce continues to put tremendous pressure on brick-and-mortar retailers. In the past, technology at the store level was primarily focused on improving store operations with backend systems such as inventory management and supply chain, PoS, and security/loss prevention. However, there is an opportunity for retailers to combine their physical presence with innovative technologies to create unique and valuable experiences for their customers. Organizations that will adopt technologies such as artificial intelligence, machine learning, virtual and augmented reality, analytics, and digital signage will be able to deliver immersive experiences, better services, and greater efficiencies for consumers. The foundation of these new capabilities is a technology platform that is flexible to adapt to new applications, simple to deploy and manage, autonomous at any scale, optimized and cost-compatible with the retail edge. Supermicro\u2019s Intelligent Retail Edge is the next-generation platform that enables retailers to simplify and automate the delivery and management of applications, data, networking, and infrastructure across their distributed locations in a flexible, reliable and secure manner. Supermicro Intelligent Retail Edge 2 Figure 1. The Supermicro Retail Edge stack consists of 4 key layers: (1) Hardware Infrastructure layer (2) Management and Orchestration layer (3) Application layer, and (4) Secure Networking layer CHALLENGES FACING TODAY\u2019S RETAIL In order to capitalize on the potential of new technologies to transform the store experience, retailers will need to significantly upgrade their in-store computing power to run new applications. Due to bandwidth and latency constraints, as well as the need to be able to act on information in near real- time, it is not possible to leverage centralized and distant cloud computing systems. New sensors and video systems generate more data than can effectively and economically be sent over the network, and Artificial Intelligence (AI) requires more processing power than current in-store systems provide. Running workloads at the edge requires different economics, architecture, and philosophy versus the cloud or core datacenter. Cloud and datacenter leverage technologies designed to manage thousands of nodes and containers within the same physical environment. The Edge requires a solution which is designed for its unique distributed computing requirements - where instead of dealing with a few very large clusters, Edge Computing is built on small clusters that are right-sized and right priced to fit the new generation of retail applications. This is a fundamentally different architectural challenge. Hardware Layer Accelerators Management and Virtualization Software-Defined Storage Software-Defined Network Orchestration Alerting/Monitoring XML-RPC APIs Self-Remediation GitOps - remote deployment and hardware provisioning Remote Management Device & Platform Update User Workloads Legacy Machine Virtualization Lightweight Virtualization Embedded, Zero Trust Security, Software-Defined Networking Small Edge Scalable Edge Core & Data Center Application Layer (IoT, AI/DL) Networking AI/DL Applications Legacy VMs Windows, Linux Containers Micro-Services IoT Applications Private Programmable Policy Engine Edge/IoT HSM Integrations Private/Public Cloud Integrations Optimized Internet Performance Device Pass-Through Virtualization Integrations with Supermicro Infrastructure Integrations with Enterprise, Clouds, MSP Supermicro Intelligent Retail Edge 3 - THE INTELLIGENT RETAIL EDGE DIFFERENCE Supermicro\u2019s Intelligent Retail Edge platform developed in collaboration with NodeWeaver and NetFoundry, is a complete edge computing platform which provides a reliable, flexible, and secure infrastructure solution for retailers, restaurants, hotels and others. \u2022 Low-touch fleet installation: Initial site configuration and application customization and startup can be performed by a technician without IT skills. Ship, connect to the network, and power on to start the self-configuration process. \u2022 Lightweight: Specifically developed for smaller environments, the Intelligent Retail Edge platform achieves feature and function parity with datacenter-grade hyperconverged infrastructure (HCI) solutions in a much smaller compute footprint, making it ideal for in- store deployment. \u2022 Hardware agnostic: Heterogeneous clusters are fully supported, even across different CPU generations and families. It is an extensible platform that is neutral to applications and autonomous at any scale, and designed to run any application, anywhere, non-stop and continually self-optimized with no human interaction. This modular approach allows for hardware to be phased-in incrementally, and enables customers to achieve operational and supply chain flexibility and cost savings. \u2022 Reliability and scalability: The solution delivers highly available server clusters, allowing servers to be clustered together over the Ethernet network to form \u201cnano-clouds\u201d. Applications are automatically load-balanced across all servers in the cluster, all storage is automatically replicated to different systems in the cluster, and virtual machines restart automatically in the event of a server outage. The criticality of these local applications increases the need for high-reliability of these in-store systems. \u2022 Application support: Support for both current and future applications that may require specialized hardware accelerators such as GPU, TPU and VPU. Existing PoS applications can be virtualized to extend longevity and increase availability. Virtual machines (VMs), containers, and/or serverless applications are all supported and NodeWeaver Marketplaces supports automated custom application configuration and deployment. \u2022 Maintenance features: New components (hard drives, network connections) and systems are automatically detected, added and load-leveled, and clusters can be seamlessly composed of different servers \u2013 even different chip families \u2013 to support optimal expansion and non-disruptive hardware refreshes. There is no need to stock identical systems for spares, simply replace failed systems with the latest available hardware. Automatic, non-disruptive firmware updates ensure secure non-stop operation with no system administrator involvement. \u2022 Management features: Most management tasks are fully autonomous. Applications are autonomically optimized across available resources. Create application service stacks to automatically start and elastically scale related in-store applications. Choice of management interfaces: local or remote web-based GUI, or programmatic via the API. \u2022 Cost appropriate: Dramatic lly reduces cost of ownership by simplifying operations and reducing the need for IT expertise or human intervention. Figure 2. Supermicro Intelligent Edge Server E300-9D-4CN8TP Figure 4. Supermicro Intelligent Edge Server E100-9W-H Supermicro Intelligent Retail Edge 4 NETWORK SECURITY & OPTIMIZATION FOR THE RETAIL EDGE Secure, high performance, global networks are key when dealing with hundreds or thousands of geographically distributed sites. Customer and PoS data must be secured and protected at all costs both in the physical retail location as well as when transmitted across the network to transaction processors and to head office/retail corporate data centers. Omni-channel retailing requires networking to securely connect their sites to private data centers, regional branches, public clouds and SaaS providers. Not to mention a myriad of real time 3rd-party transaction processing systems. In addition, reliable, high performance networking is a foundational requirement for successfully operating latency-sensitive edge compute applications such as Artificial Intelligence (AI) powered voice recognition and video inferencing. Network performance is critical for data throughput originating in intensive edge applications such as computer vision and Augmented Reality (AR) applications. Legacy VPN and MPLS solutions can\u2019t deal with the complexities and configuration-intensive aspects of this new reality. Supermicro\u2019s Intelligent Retail Edge platform provides simple, easy to deploy Network-as-a-Service (NaaS) connectivity between globally distributed sites. When powered by NetFoundry NaaS services, the platform can securely and reliably manage global software defined networks (SDN) with the performance of private networks. The resultant networking delivers exceptional performance, Zero Trust security, agility and simplicity. \u2022 Performance - NetFoundry\u2019s dynamic routing across internet fabric minimizes latency and loss providing the performance and reliability of private networks that enhances application delivery globally making employees, partners, and suppliers more productive with a better user experience. \u2022 Zero Trust \u2013 NetFoundry\u2019s Zero Trust security implementations are helping organizations to proactively protect their applications, data and infrastructure from all threats. \u2022 Agility \u2013 NetFoundry\u2019s cloud-based network orchestration tools deliver the agility of global networks delivered as-a-service to meet need of today\u2019s digital retail businesses \u2022 Simplicity - Eliminate high cost dedicated VPN circuits with easy to manage application- driven software-defined-networks CRITICALITY & SCALE OF DISTRIBUTED RETAIL EDGE Critical local Edge compute (low latency, data compliance, & efficiency) combined with a cloud or multi-cloud back-ends is the norm, not the exception with distributed edge. Supermicro, NodeWeaver and NetFoundry offer agile, simple, and performant mesh networks connecting edge and cloud for optimal workload processing. Management is simplified using a single pane of glass, efficiency and error-resistance is maximized with zero-touch deployment, and orchestration and change control is simplified through APIs and integration with common DevOps tools. Figure 3. Supermicro Intelligent Edge Server 1019D-16C-FHN13TP Supermicro Intelligent Retail Edge 5 - THE ADVANTAGE Supermicro provides the building block platforms for Retail Edge computing solutions. Enabling an infrastructure focused on next generation applications from customer premises, to network edge to data center enables customer a broad option-based hardware structure. In addition, Supermicro has a broad ecosystem of software infrastructure providers that can provide best in class performance hardware to software infrastructure layers. Partners such as, NodeWeaver and Intel provide the common architecture for customer to implement edge computing solutions. One of the missions of Supermicro Edge Hardware is to make the latest server technologies accessible to the market as soon as possible, so that our customers can roll out their services in a timely manner on the latest generation of hardware. These systems provide flexible I/O to the backend network infrastructure, and enable the maximum system memory capacity. Supermicro Intelligent Retail Edge 6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "4741b0ea-13ba-4c77-bcbc-945a0c57cf03": {"__data__": {"id_": "4741b0ea-13ba-4c77-bcbc-945a0c57cf03", "embedding": null, "metadata": {"file_name": "Solution-Brief_Supermicro_Neutroon.pdf", "publication_date": "August 2023", "referenced_websites": ["www.supermicro.com", "https://www.neutroon.com/#platform", "https://www.supermicro.com/en/products/system/iot/1u/sys-110d-20c-fran8tp", "https://www.supermicro.com/en/products/system/iot/2u/sys-211se-31d", "www.neutroon.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Supermicro Telecoms Edge Infrastructure Solutions The combination of Supermicro's pioneering edge computing solutions with Neutroon's robust Private 5G/LTE network cloud platform enables enterprises to excel in the age of data-driven connectivity. While Supermicro\u2019s edge servers are tailored to optimize energy consumption and enhance scalability, resilience, and efficiency, Neutroon\u2019s Cloud Platform, an open- API, multi-site, multi-tenant, multi-vendor orchestration solution, unifies advanced connectivity (Private 5G, Wi-Fi 6) and edge computing for enterprise IT customers that simplifies the connectivity of IoT devices to business-critical apps. Neutroon\u2019s Private Network Solution Neutroon aims to enable businesses to understand and embrace the power of private networks and edge computing by providing innovative connectivity between IoT devices and apps in the most efficient, reliable, and affordable way. The platform provides a single, easy-to-use, and cost-effective management solution for all your private networks independently from the location, the extension, the heterogeneity of technologies and vendors, or the complexity of the deployment. We can boost productivity and lower TCOs by reducing CapEx thanks to the disaggregated nature of the solution that enables the optimization of HW/SW vendor/technology and reduces OpEx due to the simplification of the O&M of the network. 1 Neutroon\u2019s Private Network Solution 1 Supermicro\u2019s Edge Computing Solutions 2 Neutroon Architecture 3 How is Edge Computing Related to Private Networks 3 Conclusion/Summary 4 References 4 2 The solution transforms pure connectivity into smart connectivity through the Neutroon Hyperslicing and an integrated marketplace of edge apps that can be easily deployed on systems like the Supermicro SYS-211SE-31A 2U 3Node short depth server. This system was chosen due to its flexibility. It can be used in the core, edge, or RAN. A customer could start with a single node populated for Private 5G, then add edge workloads on additional sled-based nodes. Rack space at the edge is optimized with three nodes in 2U. The SYS-211SE is a short depth chassis for edge located cabinets with all front access I/O and extended operating temperature range, often required at the edge. Supermicro\u2019s Edge Computing Solution Supermicro SYS-211SE-31A For smaller scale Private 5G/LTE networks, the Supermicro SYS-110D Compact 1U system based on Intel\u2019s Ice Lake D platform was selected. This system offers 20 CPU cores and a wide range of integrated on-board network connectivity in a compact short depth 1U chassis at a competitive price point, making it ideal for smaller networks. Supermicro SYS-110D-20C-FRAN8TP Figure 2 - Supermicro Edge Server - Intel(R) Xeon Processor D-2796NT Embedded System Key Features: \u2022 Single Socket E (LGA-4677) 4th Gen Intel Xeon Scalable processor (per node) \u2022 8 DIMMs; Up to 2TB 3DS ECC DDR5-4800: RDIMM/LRDIMM (per node) \u2022 2 PCIe Gen5 x16 FHHL slot and 1 PCIe Gen5 x16 HHHL slot (per node) \u2022 2 NVMe M.2 2280/22110 (per node) \u2022 430mm deep (fits in 600mm cabinet) \u2022 Carrier grade NEBS level 3 compliance Figure 1 - Supermicro Edge System \u2013 2U 3 Node Front Access Short Depth Server Key Features: \u2022 Intel Xeon Processor D-2796NT \u2022 Up to 512GB LRDIMM \u2022 2x Internal 2.5\" drive bays (2x PCIe 4.0 NVMe x8 SlimSAS and 1x OCuLink options) \u2022 4x GbE, 2x 25G SFP28 and 2x 10G Base- T \u2022 1x M.2 M-Key 2242/2280 (SATA/PCIe 3.0 x4) \u2022 Redundant 800 W PSU 3 Neutroon Architecture How is edge computing related to private networks? Increased resilience The private network becomes more robust to disruptions by distributing computing power and tasks among multiple edge devices. In case of a problem when an edge device is facing an error, the workload may be smoothly transferred to another edge device, maintaining continued operations and minimizing network downtime. Edge computing's redundancy gives an extra layer of stability to Private 5G/LTE networks, increasing system availability. Enhanced scalability and flexibility Supermicro\u2019s advanced edge computing capabilities enable effective scalability of the private network managed through the Neutroon Cloud Platform when the number of connected RAN devices increases. Enterprises may quickly deploy more edge devices to manage the increasing computing load, assuring maximum performance and responsiveness. Additionally, Supermicro allows for greater flexibility in deploying new edge applications to serve multiple use cases of the clients, as edge devices may process data locally without requiring significant modifications to the cloud-based architecture. These new use cases can be tested thanks to the unification of edge computing and private 5G/LTE since unparalleled flexibility is achieved by minimizing connectivity firewalls and bottlenecks. Improved data privacy and security In the case of Private 5G/LTE networks, Supermicro\u2019s edge computing solutions optimize data privacy and security. By maintaining data processing and storage at the network edge, sensitive information is positioned inside a localized enterprise environment, diminishing the risk of data breaches during its transmission to the cloud and allowing businesses to gain more control over their data while maintaining compliance with privacy requirements. Edge computing enables Mobile Private 4 Network Operators (MPNOs) to adopt more complex security measures tailored to their needs, improving data protection and network integrity. Bandwidth optimization Edge computing boosts bandwidth usage in Private 5G/LTE networks as the data is processed locally at the network edge. Only necessary and compressed data is sent to the cloud, minimizing the amount of data that travels through the network. This turn- key advantage reduces network congestion and increases overall network performance. Conclusion/Summary Supermicro and Neutroon together are creating an easy-to-use solution to combine Private 5G and Wi-Fi 6 connectivity with an edge computing platform. The winning combination of the Neutroon NaaS Cloud Platform running on Supermicros' highly flexible range of telecoms edge systems allows customers to scale their network deployment while efficiently optimizing CapEx and OpEx.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "55d824ff-7eb0-4779-9946-75be2ef326ff": {"__data__": {"id_": "55d824ff-7eb0-4779-9946-75be2ef326ff", "embedding": null, "metadata": {"file_name": "Solution-Brief_SMCI_NVIDIA_AI_Enterprise.pdf", "publication_date": "November 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 1 Enterprises are increasingly using AI in their IT workflows. AI techniques have proven to be very effective in identifying patterns, finding defects in manufacturing, recognizing objects and images, generating effective recommendations, and many other functions. By incorporating these new AI techniques, enterprises can significantly improve their operational efficiency, grow their top lines, and optimize their bottom lines. There are several challenges to incorporating these new technologies, including identifying the AI frameworks and tools, optimized systems, and implementing IT management software from development to deployment. NVIDIA AI Enterprise, an end- to-end cloud-native suite of AI and analytics software, addresses these challenges. NVIDIA AI Enterprise brings AI to existing VMware vSphere infrastructure that many enterprises use. Developers and IT administrators can incorporate AI training and inference in small steps. With included AI and data science tools and frameworks, enterprises can start with small investments and grow that capability over time. In addition, enterprises can deploy NVIDIA AI Enterprise software optimized and certified by NVIDIA to run on VMware vSphere with Supermicro NVIDIA- Certified Systems. The servers are also VMware certified to support GPUs. 1 Artificial Intelligence Applicable Across Industries 2 Incorporating Artificial Intelligence into Enterprise Applications 2 Enterprise Challenges to Adopting AI 3 Easing into AI, Leveraging Existing Virtual Infrastructure 3 NVIDIA AI Enterprise Software Suite 4 AI Software Stack 5 Enterprise Support 6 Virtualized GPU Options 6 Mixing CPU Cores and GPU Cores 7 Supermicro NVIDIA-Certified Systems, also VMware Certified 7 Conclusion and References 8 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. SYS-220U-TNR SYS-120U-TNR AS -4124GS-TNR SYS-220GP-TNR SYS-120GQ -TNRT SYS-220GQ-TNAR/+ AS -2124GQ-NART/+ 2P / 1 GPU 2P / 2 GPU 2P / 4 GPU 2P / 8 GPU SYS-740GP-TNRT 2 2 As a leader in Green Computing, Supermicro is offering multiple choice of energy efficient server options, so customers can best optimize on power, cooling, space, and cost to fit their infrastructure while bringing AI to their enterprise. Artificial Intelligence Applicable Across Industries Since the advancement of GPUs to accelerate deep neural network processing and the fast-paced evolution of the technology in the last few years, deep learning artificial intelligence has evolved into multiple techniques used across every industry. The techniques include image and object recognition, text and speech understanding, finding correlations and anomalies in data. Here are some examples in select industries: \u2022 In Finance, text and speech understanding can be applied to news and information to extract potential trading signals. \u2022 In Healthcare, image processing is applied to find diseases in MRI, X-Ray, or other medical imaging techniques. \u2022 In Retail, image processing can be used to build automated customer purchases in automated stores. \u2022 In Manufacturing, object recognition can be applied to identify components and to find manufacturing defects. The applications are pervasive, and most industries are beginning to take advantage of these artificial intelligence capabilities. Incorporating Artificial Intelligence into Enterprise Applications Within an industry, a corporation or enterprise can apply artificial intelligence in the various functions within the organization, for example: \u2022 Marketing and sales departments use collaborative filtering to make cross product selling to customers. \u2022 Human resources departments use text processing to identify talents. \u2022 Manufacturing and services departments use computer vision techniques to identify defects in parts and components. Each department within the enterprise can take advantage of AI techniques to make jobs more efficient and more cost effective, producing more reliable and accurate results. Multiple departments can share the compute resources to maximize results and minimize infrastructure costs by leveraging virtualized data centers and NVIDIA AI Enterprise. 3 3 Enterprise Challenges to Adopting AI For many enterprises, there could be significant challenges to adopting artificial intelligence. Since the recent AI advancements are mostly new and fast changing, enterprises have to find the people and know-how with domain- specific understanding to successfully integrate AI into their existing applications. With NVIDIA AI Enterprise running on Supermicro NVIDIA-Certified Systems, enterprises can overcome these challenges to start integrating AI into enterprise workflows. Supermicro NVIDIA- Certified Systems and NVIDIA AI Enterprise software together minimize risks because the entire solution is pretested through NVIDIA\u2019s rigorous certification process. In addition, the certified solutions assure performance and deployment scaling as the systems and software are designed to provide high performance and can be scaled using server clusters. Supermicro servers are designed for high performance and cluster scaling, with built-in PCI-Express Gen-4 I/O to support high bandwidth, low latency networking devices such as the NVIDIA ConnectX-6 and ConnectX-7, fast storage such as the latest Gen4 NVMe disks, as well as the NVIDIA GPUs. As a result, data scientists and developers can get the most productivity using the Supermicro systems to run their AI development and deployment. Easing into Artificial Intelligence, Leveraging Existing Virtual Infrastructure With VMware vSphere, NVIDIA AI Enterprise makes it easy to start AI development in small steps for enterprises that have virtualized their IT infrastructure. An enterprise can start with a single server with a single GPU to run NVIDIA AI Enterprise. This AI Enterprise system operates as a member in the VMware vSphere environment. vCenter Server manages the AI Enterprise server as another member of the infrastructure, immediately enabling AI workloads for the enterprise. Depending on the size of the AI model and batch data, an AI developer may need a fraction of a GPU or full utilization of a GPU. This approach minimizes risk and maximizes the opportunity to create AI value. Over time, as the enterprise begins to realize the potential of AI enabled applications, the IT department in the enterprise can add servers running NVIDIA AI Enterprise to scale the applications. Challenges Solutions Additional Assistance People Data scientists Best-in-class AI frameworks and tools included in the NVIDIA AI Enterprise suite Knowhow AI and domain knowledge NVIDIA AI Enterprise Support Services Consistent Tools Containers with consistent and tested tools & libraries Regular updates & support Performance NVIDIA Ampere-based GPUs and networking solutions Supermicro NVIDIA-Certified Systems Risk NVIDIA AI Enterprise on existing VMware infrastructure Supermicro NVIDIA-Certified Systems Scaling Deployment VMware scaling and future Kubernetes support Supermicro NVIDIA-Certified Systems, networking 4 4 NVIDIA AI Enterprise Software Suite NVIDIA AI Enterprise is a software suite that runs in the VMware vSphere environment running on Supermicro NVIDIA-Certified Systems. The software suite includes AI tools and frameworks, cloud native deployment, and infrastructure optimization software to enable rapid AI development and deployment in VMware infrastructures. NVIDIA AI Enterprise is optimized, certified, and supported on VMware to achieve near bare-metal performance with virtualization of AI workloads on NVIDIA-Certified Systems, of which Supermicro offers a wide myriad of optimal choices. By making it a low risk and simple approach to integrate AI into the existing enterprise virtualization environment, NVIDIA AI Enterprise enables an end-to-end software stack approach to start using AI in the enterprise. Enterprise developers can initially run small trials until they feel comfortable expanding to more extensive deployment. At that point, the solution is very scalable to deployment in multiple racks. The design of NVIDIA AI Enterprise targets two personas: \u2022 Data scientists and developers who use and incorporate AI, and \u2022 IT administrators who need to ensure operational uptime of the systems NVIDIA AI Enterprise provides the AI and data science tools and frameworks, which data scientists and developers need for their AI applications. By using Supermicro NVIDIA-Certified Systems, the IT administrators get assurance of reliable systems with high performance. These Supermicro systems are also VMware certified to support GPUs. Using VMware, the IT administrators are familiar with their existing infrastructure. 5 5 AI Software Stack The NVIDIA AI Enterprise software suite offers the best-in-class tools and frameworks that AI practitioners and data scientists need, from data preparation (NVIDIA RAPIDS), training neural networks (TensorFlow and PyTorch), inference (NVIDIA TensorRT), to scaling inference operations (NVIDIA Triton Inference Server.) The deployment can start on one or more GPUs within a server. As the datasets grow, multi-node scaling can level up for many organizations. Optimized for VMware vSphere environments, the suite delivers near bare-metal performance across multiple nodes, streamlining the production of new AI applications and services. Supermicro NVIDIA-Certified Systems 6 6 Enterprise Support Using the NVIDIA AI Enterprise software suite, enterprise customers get enterprise-grade support for the entire system, from AI software to the virtualization and system hardware, including NVIDIA data center GPUs and network accelerators, all tested and optimized in the Supermicro systems. As a one-stop shop, Supermicro offers the entire system, with VMware and NVIDIA AI Enterprise with support. Virtualized GPU Options NVIDIA AI Enterprise provides multiple virtualized GPU options. By picking the appropriate vGPU profile, each CPU in the system can be partitioned into virtual machines accordingly. For the NVIDIA A30 Tensor Core GPUs and NVIDIA A100 Tensor Core GPUs, there is the choice of using Multi-Instance GPU (MIG) partitioning, which provides hardware isolation for each hardware partition relative to other partitions in a single A30 or A100 GPU. Alternatively, the GPUs can be partitioned as time-slices using NVIDIA vGPU included in the NVIDIA AI Enterprise suite, which would allow users to invoke their use by sharing the GPUs with the VMware hypervisor allocating the GPU slices for use as needed by users in their respective virtual machines. With the NVIDIA A40 GPUs, customers can also use the GPUs for virtualized graphics applications. One popular use of the NVIDIA A40 is to deploy them for virtual desktop applications during the day, where users can run high-end 3D graphics applications in the centralized infrastructure. Then at night, while users no longer use the systems, the NVIDIA A40 GPU systems can be automatically NVIDIA A100 MIG Mode Enabled NVIDIA A100 MIG Mode Disabled NVIDIA A30 MIG Mode Enabled NVIDIA A30 MIG Mode Disabled NVIDIA A40 (no MIG) Max partitions 7 10 (A100/40GB) 20 (A100/80GB) 4 6 (A30/24GB) 32 (*VDI) (A40/48GB) Partition Type SPACE- SLICED TIME-SLICED SPACE- SLICED TIME-SLICED TIME-SLICED Partition Sizes Different sizes, as long as they add up to 1 GPU All the same size per GPU Different sizes, as long as they add up to 1 GPU All the same size per GPU All the same size per GPU Largest vGPU One A100 One A100 One A30 One A30 One A40 Compute resources Dedicated Shared Dedicated Shared Shared Virtualized 3D Graphics Support No No No No Yes NVIDIA NVLink Support No Yes (SXM4) No No (PCIe only) No (PCIe only) Heterogeneous Profiles Yes No Yes No No 7 7 redeployed to run AI workloads, such as AI training or inference. Customers have a wide range of choices to optimize the use of GPUs. Mixing CPU Cores and GPU Cores NVIDIA AI Enterprise offers flexibility in how to partition GPU resources among the virtual machines. For example, some applications may need more CPU cores to do work, while GPU cores run compute-intensive operations, such as matrix multiplications for AI. The table shows some examples of the choices that can be made for different applications. The Supermicro systems provide wide options of CPU cores that could be matched to the system with the maximum number of supported GPUs. Supermicro NVIDIA-Certified Systems, also VMware Certified Supermicro offers a wide range of systems that are NVIDIA-Certified to support PCI-E Gen 4 based NVIDIA A30, A40, and A100, as well as the NVIDIA HGX-A100 4-GPU systems. Choosing from these optimized Supermicro systems, customers can select the systems that provide the best performance while optimizing their energy usage and data center cooling. Supermicro systems range from 1U to 4U support, supporting 1 to 8 GPU, depending on needs. NVIDIA network accelerators, e.g., NVIDIA ConnectX-7 SmartNIC are also supported. ConnectX-7 and NVIDIA Blue-Field DPUs (Data Processing Units) provide fast, low-latency network connectivity to the Supermicro systems. As a result, enterprises can select the most appropriate systems with needed power, cooling, and GPU support. AI Use Case in a VM Examples CPU Cores GPU Cores / GPU Memory GPU Type Data Scientist AI Development 1 \u2013 8 1 / 10 GPU to full GPU 1 / 20 GPU to full GPU A100 (40GB) A100 (80GB) AI Training / Inference using pre- trained model 1 \u2013 8 1 / 7 GPU (MIG) to full GPU A100 (40GB) A100 (80GB) Data Scientist AI Development 1 \u2013 8 1 / 6 GPU to full GPU A30 AI / Inference Training using pre- trained model 1 \u2013 8 1 / 4 GPU (MIG) to full GPU A30 Mixed Workloads (Virtual Desktop by Day, Compute at Night) 1 \u2013 8 1 / 32 GPU to full GPU A40 Supermicro Server Rack Height Depth Max GPU GPU Type Network Acceleration Disks Dual CPU SYS-120U-TNR/+ 1U 29.1\u201d 1 NVIDIA A100, A30, A40 CX6/7, BF2-DPU 12 3rd Gen Intel Xeon Scalable SYS-220U-TNR/+ 2U 28.2\u201d 2 NVIDIA A100, A30, A40 CX6/7, BF2-DPU 24 3rd Gen Intel Xeon Scalable SYS-120GQ-TNRT/+ 1U 35.2\u201d 4 NVIDIA A100, A30, A40 CX6/7, BF2-DPU 2 3rd Gen Intel Xeon Scalable SYS-220GP-TNR/+ 2U 30.18\u201d 4 NVIDIA A100, A30, A40 CX6/7, BF2-DPU 10 3rd Gen Intel Xeon Scalable AS -2124GQ-NART/+ 2U 32.7\u201d 4 NVIDIA HGX A100-4GPU CX6/7, BF2-DPU 4 3rd Gen AMD EPYC SYS-220GQ-TNAR/+ 2U 32.7\u201d 4 NVIDIA HGX A100-4GPU CX6/7, BF2-CPU 4 3rd Gen Intel Xeon Scalable SYS-740GP-TNRT 4U/Tower 26.5\u201d 4 NVIDIA A100, A30, A40 CX6/7, BF2-DPU 8 3rd Gen Intel Xeon Scalable AS-4124GS-TNR 4U 29\u201d 8 NVIDIA A100, A30, A40 CX6/7, BF2-DPU 16 3rd Gen AMD EPYC 8 8 Conclusion Supermicro NVIDIA- Certified Systems offer flexible solutions to support NVIDIA AI Enterprise in the VMware environment, enabling AI developments and delivery to run small and large AI models for AI training and inference. Using the highest performing NVIDIA A100, A30, and A40 GPUs, enterprise developers minimize their valuable time to run experiments and development on their AI models, delivering fast and cost effective AI features into new and existing products and services. In addition, by selecting the appropriate Supermicro systems that provide the best performance, I/O, power, and cooling, from the many choices Supermicro offer, IT managers can deliver the best AI capable additions to their VMware infrastructure. Supermicro offers these as integrated solutions, including systems, software, and support. Please call your Supermicro representative", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "90fcca7b-644f-4c69-9b47-47d1b60302ca": {"__data__": {"id_": "90fcca7b-644f-4c69-9b47-47d1b60302ca", "embedding": null, "metadata": {"file_name": "Solution-Brief_SAP-HANA_IntelSelect.pdf", "publication_date": "November 2019", "referenced_websites": ["www.supermicro.com", "https://www.supermicro.com/en/solutions/sap"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 2 SAP HANA CERTIFIED APPLIANCES 3 SAP HANA APPLIANCE CERTIFICATION 3 SAP HANA APPLIANCE\u2014TAILORED DATA CENTER INTEGRATION 4 SAP HANA HARDWARE SIZING AND CONSULTING SAP HANA CERTIFIED APPLIANCE - Digital transformation is a top priority for any enterprise or business looking to gain a competitive advantage in the rapidly evolving information economy. Real time, actionable business insights and continuous operational improvements, once just wishful thinking, have become standard requirements for today\u2019s information-driven CEOs. Your digital corporation now requires a powerful, scalable platform for enterprise resource planning (ERP), supply chain management (SCM), or customer relationship management (CRM) to run. You require the ability to manipulate, extract, and analyze large volumes of live transactional data, all in real time, without interruption to business operations. Supermicro and SAP are here to help. SAP HANA enables your digital transformation by providing a real-time, in-memory computing platform that is 10,000 times faster than traditional databases,* all while allowing real-time, Online Transaction Processing (OLTP) and Online Analytical Processing (OLAP) on the same system or environment. Supermicro has partnered with SAP to pre certify, validate, and architect SAP HANA appliances to power your digital transformation infrastructure. Supermicro SAP HANA Certified Appliance 2 SAP HANA APPLIANCES The Supermicro quad-socket system, SYS-2049U, a multi-processor (MP) SuperServers were designed for the most demanding, mission-critical workloads in use by top enterprises and cloud service providers. The SYS-2049U with eleven PCI-E 3.0 slots for I/O expansion supports the highest- performance Intel Xeon Scalable processors, the largest memory capacity available, the latest in Intel Optane DC persistent memory technology, and fastest all-flash NVMe or SSD storage options available for the SAP HANA platform. The combination of these cutting edge technologies makes Supermicro MP Servers the most powerful 4 Socket single-node SAP HANA platforms available on the market today. The SAP Appliance is the ideal building blocks for your SAP S/4HANA, BW/4HANA, or SAP HANA database deployments. Supermicro has partnered with Intel and SAP to certify Intel Optane DC persistent memory for use with SAP HANA version 2.0 SPS03, or higher, on 2nd Gen Intel Xeon Scalable Processors. Intel Optane DC persistent memory is an innovative memory technology that delivers affordable large capacity uniquely combined with support for data persistence. As validated by SAP and Intel, SAP HANA reboot time using a 6TB database was dramatically reduced from 20 minutes down to 90 seconds\u2014a 13x improvement over traditional SSD to DDR load times1. In addition to fast load times for HANA database, Intel Optane DC persistent memory delivers an optimized balance between persistence and performance at a lower cost per Gigabyte than DRAM. For large in-memory deployments, the use of Intel Optane DC persistent memory can dramatically lower the initial acquisition cost of your SAP HANA hardware. Intel Optane DC persistent memory is not only lower cost than DRAM, but is also available in larger sizes, up to 512GB per unit. The combination of DRAM plus Intel Optane DC persistent memory allows for much larger SAP HANA deployments, per socket, than use of traditional DDR memory alone1. Key Advantages: 2U 4 Socket SAP HANA Appliance (SYS-2049U-TR4) \u2022 Quad Socket 2nd Generation Intel Xeon Scalable processors, up to 112 cores \u2022 Appliance model supports up to 6 TB DRAM \u2022 Tailored Datacenter Integration (TDI) model supports up to 18 TB (DRAM + Intel Optane DC Persistent Memory) \u2022 24 Hot-swap 2.5\u201d SAS3/SATA3 drive bays supported via optional Add-on RAID controller card; 4 Hybrid ports with NVMe support via extra AOC \u2022 Networking flexibility with choices of 1Gb, 10Gb, 25Gb, 40Gb, 100Gb, RJ45, SFP+, and Fibre Channel \u2022 SAP HANA Scale-Up/Scale-Out appliance certified Supermicro SAP HANA Certified Appliance 3 - SAP HANA CERTIFIED APPLIANCES (Scale from 192GB to 24.6TB AEP + DRAM) SYSTEM SPECIFICATIONS (BWoH, BW/4H, S/4H and DM) SYS-2049U-TR4 2 Socket configuration (Up to 56 cores) 192 GB to 7.6 TB (12 \u00d7 128GB DDR4) + (12 \u00d7 512GB Intel Optane DC Persistent Memory) SYS-2049U-TR4 4 Socket configuration (Up to 112 cores) 192 GB to 15.4 TB (24 \u00d7 128GB DDR4) + (24 \u00d7 512GB Intel Optane DC Persistent Memory) SAP HANA APPLIANCE \u2014TAILORED DATA CENTER INTEGRATION All SAP Certified Appliances are eligible for Tailored Datacenter Integration (TDI) deployment, which allows the customer to build an SAP HANA server with their own choice of CPU, RAM, Disk, and add-on cards. The SAP HANA TDI option offers you more flexibility and freedom of choice to deploy SAP HANA hardware matching your existing data center infrastructure. The Supermicro Intel Select Solution for SAP HANA leverage TDI phase 5 approach based on Supermicro certified SAP HANA appliance, SYS-2049U-TR4 and Intel Optane DC persistent memory. The latter is perfectly aligning with large database use case supporting up to hundreds of Gigabytes or Terabytes of memory to reduce TCO by automatically placing large amount of warm data in the less costly persistent memory than DRAM drastically improve start-up time of the database while other business cases are coming in real-time. Again, to emphasize, SAP HANA Appliances are designed as fixed BOM turnkey solutions, whereas SAP HANA TDI deployments allow the customer to mix and match certified components. TDI open architecture allows the customer to request a HANA system with a certified configuration from Supermicro. SAP certifies computing nodes and storage products with SAP HANA hardware partners (e.g. Supermicro) and requires that customers only use these certified configurations for SAP HANA TDI deployments. SAP HANA APPLIANCE CERTIFICATION The SAP HANA Appliance certification guarantees that the S/4 HANA database software performs as intended on the certified system. SAP HANA Appliances are offered in various sizes with predefined, fixed BOMs and sizing as listed on SAP\u2019s HANA certified hardware directory. Scale-up appliances are specifically designed to run as a single autonomous compute node with internal or, connected to, external storage. To increase the size and performance of a scale up system, you simply upgrade the CPU, RAM, or Disk in the node. All SAP HANA Appliances are designed to be turn-key solutions. As such, Supermicro pre-installs the HW components, operating system, and SAP HANA before delivering the appliance. (See recommended configuration below) Supermicro SAP HANA Certified Appliance 4 SAP HANA HARDWARE SIZING AND CONSULTING To assist you on your SAP HANA infrastructure and hardware selection, Supermicro\u2019s SAP architects and solutions managers offer free hardware sizing and consulting services. Whether you are a greenfield customer considering SAP HANA adoption or brownfield customer looking to migrate SAP ECC to S/4HANA, Supermicro\u2019s SAP HANA experts are available to guide you and help you optimize your hardware stack for performance and cost. To get started, please contact sapexpert@supermicro.com. Supermicro SAP HANA certified solutions: ABOUT SUPER MICRO COMPUTER, INC. Supermicro (NASDAQ: SMCI), the leading innovator in high-performance, high-efficiency server technology is a premier provider of advanced server Building Block Solutions for Data Center, Cloud Computing, Enterprise IT, Hadoop/Big Data, HPC and Embedded Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy-efficient, environmentally-friendly solutions available on the market. ABOUT INTEL SELECT SOLUTIONS Intel is driving the next wave of data center innovation with Intel Select Solutions, based on Intel technologies. Intel Select Solutions are verified solutions configurations that are aimed to speed selection and deployment of data center and communications network infrastructure. The solutions are developed from deep Intel experience with industry solution providers, as well as extensive collaboration with the world\u2019s leading data center and service providers. 1 Legal Disclaimer for Faster Start Time and Increase Memory Capacity Claims. Based on Intel testing as of March 1, 2019. Columnar store entire reload into DRAM for 1.3 TB dataset is 20 mins. Entire system restart before is 32 minutes and with Intel Optane DC persistent memory is 13.5 minutes (12 mins for OS + 1.5 mins). Configuration details: baseline: 4S Intel Xeon Platinum 8280M processor (28 cores), 6 TB memory (48 x 128 GB DDR4 at 2,666 megatransfers per second [MT/s]), 10Gb Intel Ethernet Converged Network Adapter X520, 60 x 480 GB Intel SSD DC S4600 Serial ATA (SATA), BIOS: WW48\u201918, SUSE 15*, Intel IT workload, 3 TB SAP HANA database, security mitigations: variants 1, 2, 3 enabled. AD 2-2-2 config: 4S Intel Xeon Platinum 8280L processor (28 cores), 9 TB memory (24 x 256 GB Intel Optane DC persistent memory, 24 x 128 GB DDR4 at 2,666 MT/s), 10Gb Intel Ethernet Converged Network AdapterX520, 90 x 480 GB Intel SSD DC S4600, BIOS: WW48\u201918, SUSE 15, Intel IT workload, 6 TB SAP HANA database, security mitigations: variants 1, 2, 3 enabled. No part of this document covered by copyright may be reproduced in any form or by any means \u2014 graphic, electronic, or mechanical, including photo- copying, recording, taping, or storage in an electronic retrieval system \u2014 without prior written permission of the copyright owner. Supermicro, the Supermicro logo, Building Block Solutions, We Keep IT Green, SuperServer, Twin, BigTwin, TwinPro, TwinPro\u00b2, SuperDoctor are", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "788adbdc-7f5a-41ac-a7e8-8273ffc54972": {"__data__": {"id_": "788adbdc-7f5a-41ac-a7e8-8273ffc54972", "embedding": null, "metadata": {"file_name": "Solution-Brief_Private_5G_ZeroTrust.pdf", "publication_date": "February 2023", "referenced_websites": ["https://www.whitehouse.gov/wp-content/uploads/2022/01/M-22-09.pdf", "https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207.pdf"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Private 5G with Zero-Trust Protection With the three main use cases, eMBB, URLLC, and mMTC, 5G changes the way of network deployment not only in telecom operators but also in enterprises. In recent years, private 5G is gradually turning to commercial deployment from proof of concept (POC) since performance is no longer the key issue. Network security threat is becoming the next critical challenge in a commercial network. Open RAN using a COTS server as its infrastructure, the same as other IT networks. The malicious actor may gain access to your network and damage it, exposing your organization to a data breach. For different capability and use case requirements in large enterprise 5G network, two typical configurations of Supermicro Secured 5G Enterprise Network, designed for commercial deployment, have been validated and bundled with ecosystem partners\u2019 technologies. 1 1 5G BBU Of High Flexibility and Reliability 2 Zero-Trust 5G Core Of Rich Functionality and Top Security 3 Application Operation Management for Total Solution Integration 5 Conclusion 6 2 Private 5G with Zero-Trust Protection 5G BBU Of High Flexibility and Reliability The Base Band Unit (BBU) is the most essential element of a private 5G network. However, in the Open RAN architecture, the BBU is compromised by the Distributed Unit (DU) and the Centralized Unit (CU), which is deployed on top of the standard X86 COTS server. Supermicro is collaborating with HTC, a professional RAN software solution supplier for the private 5G, to deploy HTC RAN on Edge Server SYS-110P-FWTR and SYS-220HE-FTRN, consisting of CU, DU, and FlexRAN (L1) specialized in UL Centric, DL Centric, and VR Traffic. RAN-CU comprises Layer 3, RRM, CU-OAM, and PDCP/GTPu software. The RAN-DU includes the MAC, RLC, F1-U, DU Manager, and DU-OAM software. The interface between RAN and RU is O-RAN compliant option 7.2x split (eCPRI), which is comprised of FlexRAN (L1) utilizing the Forward Error Correction (FEC) Hardware Accelerator. Benefits from Supermicro Edger Server: \u2022 Building Blocks Open hardware allows rapid, flexible deployment and cost-effective upgrade \u2022 Ready for edge Al inferencing for real-time, real-life services \u2022 Ready for streaming video content localized and optimized at the Edge \u2022 Rich I/O ports on board, reducing spending on addon NIC and saving PCIe slots Entry Level Solution \u2013 Supermicro SYS-110P-FWTR Key Performance Reference:1 \u2022 Network Mode: NR SA, Rel 15 \u2022 UE Number: Max. 32 active / Default 20 active \u2022 Bandwidth: 100MHz \u2022 Latency: Avg. 20~30 ms \u2022 Profile: DL 700Mbps / UL 120Mbps (Default Profile) SYS-110P-FWTR, a short-depth 1U rackmount server (NEBS Level3 certification optional) optimized for edge computing applications, supporting 3rd Gen Intel Xeon Scalable processors, supporting a maximum of three PCIe Gen4 x16 slots and an additional 2x 10GbE Base-T ports on board. To meet the low latency requirement between RU and DU, the Intel vRAN eASIC Accelerator ACC100 plays a crucial role in 5G LDPC FEC processing, saves the total system power consumption, reduces CPU core count requirements, and increases in cell capacity than FPGA accelerator. TPM 2.0 hardware-based security on the motherboard ensures that the encryption keys, passwords, and digital certificates are more secure from external software attacks and physical theft. Figure 1. HTC RAN Architecture Figure 2 - Supermicro SYS-110P-FWTR 3 Private 5G with Zero-Trust Protection High Performance Solution \u2013 SYS-220HE-FTNR Key Performance Reference:2 \u2022 Network Mode: NR SA, Rel 15 \u2022 Max. UE per Cell: Max. 256 connected / 128 active \u2022 Bandwidth: Up to 100MHz \u2022 Latency: Avg. 20~30 ms \u2022 Throughput: Max. DL 1Gbps, Max. UL 350Mbps The Supermicro Hyper-E Configurable Edge Server is designed exclusively to provide flagship performance with maximum configurability for the most demanding 5G, Telco, and Edge environments, in a dense, short depth, front I/O, 2U form factor and has the option available of NEBS Level 3 Certification. The dual CPU architecture allows for a powerful computing capability, suitable for the heavy workload scenario such as 5G DU/CU plus edge computing. Hyper-E server provides flexible network options with 2 AIOM networking slots (OCP NIC 3.0 compatible) with 4 x 25GbE SFP283 ports, which meets the most networking requirements in mass deployment of private 5G. In addition, up to 8 PCIe slots4 greatly enhance the expansion capability in networking and GPU, making it possible to put the 5G base station and the MEC (Multi- Access Edge Computing) in a single server. Zero-Trust 5G Core Of Rich Functionality and Top Security 5G Core Developed for Private 5G In addition to the BBU, the 5G Core (5GC) network is the brain of the private 5G network and realizes the full potential of 5G services. Supermicro works with Saviah on the Core side, who has a highly experienced professional team, having made further improvements and enhancements over and beyond free5GC and accomplished a robust, commercially launched 5GC network software. The Core of the Supermicro Secured 5G Enterprise Network complies with 3GPP R15/R16 standards and has complete Network Functions (NFs), as shown in the figure below: The benefit of Saviah 5GC: \u2022 Open interfaces \u2022 Integrate off-the-shelf hardware \u2022 Fit RAN/Open RAN \u2022 Agile customization \u2022 Cost-effective \u2022 Collaborate multi-vendors Figure 3 - Supermicro SYS-220HE-FTNR Figure 4 \u2013 Saviah 5G Core Architecture 4 Private 5G with Zero-Trust Protection Reliability: Saviah 5GC guarantee 5x24* hours operation continuously. *Test by Spirent Landslide Flexibility: Saviah 5GC is very flexible in terms of hardware and software integration and can be deployed On-Premises or in the Cloud. Capacity: Control plane: 50* user registration per second 20,000* UE registered 1,000* gNB connection User plane: 30* Gbps data throughput (with DPDK 40G NIC) Zero-Trust Solution Cares the Security To ensure ultra-low latency communication, the compute capability gets denser and closer to the edge, involving much more intelligent devices and data packages on the edge side than before. It makes the 5G network a bigger attack surface and a steeper training curve than 4G. Besides, new technologies like network slicing and virtualization also introduce new risks. Supermicro needs to find an intelligent and effective way, with our cybersecurity solution partner Zscaler, to protect all the nodes of the Private 5G network from attack. In , President Joe Biden signed the 30-pages Executive Order5 on Improving the Nation's Cybersecurity, setting forth a Federal zero-trust architecture strategy. The National Institute of Standards and Technology (NIST) also publishes a guidance6 on Zero Trust Architecture. The mission of Zero-Trust is to make sure that every data packet on every network is \"verified and escorted\" from source to destination. A Zero-Trust approach includes: \u2022 Assumes that a breach is inevitable or has already occurred \u2022 Constantly limits access to only what is needed \u2022 Looks for anomalous and/or malicious activity everywhere Supermicro\u2019s Secured 5G Enterprise Network is deeply integrated with Zscaler's Zero-Trust security platform on both software and hardware, applies Zero-Trust from the Central DC/Cloud to each level of edge nodes till the terminal devices/Data Sources, ensure the safety of the complete data chain, and delivers exceptional user experience, reliability, and security. Specifically, we apply the policies in 5 ways: \u2022 Only authorized and identified users with validated devices are allowed access \u2022 Workloads must be isolated and only accessed if allowed by policy \u2022 Networks are a security control - they are used only for transport, not control \u2022 Processes are isolated and authorized only to speak to allowed processes \u2022 Monitor and report all connections end-to-end Figure 5 - Zero-Trust from the Edge to the Core 5 Private 5G with Zero-Trust Protection Application Operation Management for Total Solution Integration For cost-effective total solution deployment at scale, the most troublesome issue is the integration of the whole network and the applications, such as devices and sensors for smart manufacturing, smart traffic, and AI for video surveillance, etc. it is essential to achieve a one-stop operation management system on top of all these network elements. Therefore, Supermicro has worked with our ecosystem partners to implement a new application operations management (AOM) system SuperMEC. Key Benefits of SuperMEC: \u2022 A single-pane-of-glass platform with a streamlined, intuitive management interface \u2022 A standardized Redfish Northbound API Message Bus for easy third-party software platform integration \u2022 A scalable management platform without adding unnecessary complexity \u2022 A unified dashboard that encompasses compute, storage, networking, rack, base station, and 4G/5G core management \u2022 The ability to monitor and manage all elements of the resource pools in a Composable Disaggregated Infrastructure (CDI) \u2022 Open distributed infrastructure management & deployment framework, scalable containers base platform \u2022 Role-based access control to support modern data center security policies and zero trust architecture. \u2022 Rich analytics, telemetry, provision, and intelligent system lifecycle management \u2022 Parallel multi-system upgrade and configuration capability reducing hardware maintenance downtime \u2022 Topology views show the physical and logical graph of the network structure, networking relationship, and connection status \u2022 Infrastructure as a Service, Vertical SaaS, and Monitor as a Service are essential to smart manufacturing, private networks, telco cloud, retail, telemedicine, and smart city use cases. Figure 6 - Supermicro Secured 5G Enterprise Network Architecture 6 Private 5G with Zero-Trust Protection Conclusion Private 5G is a multi-vendor network. It breakthroughs the vendor lock to ensure the best cost-effectiveness. But on the other hand, it increases the complexity of integration between each network element and the cybersecurity system. Supermicro, HTC, Saviah, and Zscaler are working together to validate a new generation Secured 5G Enterprise Network, providing data-sensitive enterprises and governmental entities a flat path to own their 5G network with deeply integrated Zero-Trust cybersecurity protection. About HTC REIGN Technology Corporation (G REIGNS), a subsidiary of HTC Group, provides a 5G RAN solution that complies with O-RAN open interfaces and supports cloud-native vRAN. We focus on baseband unit software development and optimization. Instead of a general purpose 5G network, G REIGNS is dedicated to customizing our 5G network solution to fulfill enterprise use case requirements and beyond customers\u2019 expectations. About Saviah Saviah Technologies, Inc. was founded by Professor Jyh-Cheng Chen of National Yang Ming Chiao Tung University (NYCU), who, with his team, developed free5GC\u2014the world\u2019s first open-source 5G core (5GC) network that complies with 3GPP R15 standards. About Zscaler Zscaler, Inc. operates as a cloud security company worldwide. It offers Zscaler Internet Access solution that provides users, workloads, IoT, and OT devices secure access to externally managed applications, including software-as-a-service (SaaS) applications and internet destinations; and Zscaler Private Access solution, which is designed to provide access to managed applications hosted internally in data centers, and private or public clouds. Zscaler, Inc. was incorporated in 2007 and is headquartered in San Jose, California. Notes: 1. The performance indicators are only for reference. The numbers may change when using different Radio Unit(s), user devices, and in different electromagnetic environments. 2. The performance indicators are only for reference. The numbers may change when using different Radio Unit(s), user devices, and in different electromagnetic environments. 3. Optional 8 x 1Gb RJ45 ports is also available. 4. The PCIe Gen4 slots quantity may vary according to configuration. 5. Reference: 6. Reference: Case Study: Compact Integrated Setting \u2022 A portable 5G private network system puts all necessary network components in a compact rack such as a suitcase. \u2022 Other than Supermicro\u2019s servers installed with Saviah 5G core software and a L3 switch, the system includes a BBU and RRU equipped with HTC RAN software. \u2022 This \u201cready-to-go\u201d system, in complaint with 3GPP and O-RAN architecture, supports users to setup a 5G network easily and rapidly with predictable performances. Solution Description Max. UE 32 Connected / 16 active Cell Power 250mW Ant. MIMO 4T4R, DL 4 Layers, UL 2 Layers Bandwidth 100MHz Band FR1 (n41, n48, n78, n79) Latency Avg. 20~30 ms Profile Default Profile (DL 700Mbps / UL 80Mbps) OAM 5GC monitor Start/Stop Network Shutdown 5GC/RAN Profile switch SW/Profile update Dimension 515mm * 430mm * 670mm", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "c7fa4762-65f4-4be7-a68f-d425d458e045": {"__data__": {"id_": "c7fa4762-65f4-4be7-a68f-d425d458e045", "embedding": null, "metadata": {"file_name": "Solution-Brief_Habana_Gaudi.pdf", "publication_date": "April 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Demand for high-performance AI/Deep Learning (DL) training compute has doubled in size every 3.5 months since 2013 (according to OpenAI) and is accelerating with the growing number of applications and services based on computer vision, natural language processing, recommendation systems, and more. With the increased demand for greater training performance, throughput, and capacity, the industry needs training systems that offer increased efficiency, lower cost, flexibility to enable customization and ease of implementation, and scaling of training systems. AI is becoming an essential technology for diverse areas such as virtual assistants, manufacturing operations, autonomous vehicle operations, and medical imaging, to name a few. Supermicro has partnered with Habana Labs to address these growing requirements. The Habana Gaudi AI processor is designed to maximize training throughput and efficiency while providing developers with optimized software and tools that scale to many workloads and systems. 1 Supermicro X12 Gaudi System Overview 2 ResNet-50 Performance Summary 4 Case Study: San Diego Supercomputing Center 5 Summary/Additional Resources 6 Habana Gaudi Processor As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. Supermicro SYS-420GH-TNGR 2 Supporting Gaudi processor deployment is the Habana SynapseAI Software Platform, created with developers and data scientists in mind, providing versatility and ease of programming to address end-users unique needs while allowing for simple and seamless transition of their existing models over to Gaudi. This provides an overview of the Supermicro X12 Gaudi AI Training system to enable high-performance computing for deep learning workloads. Supermicro X12 Gaudi AI Training System Overview The Supermicro X12 Gaudi AI Training System (SYS-420GH-TNGR), powered by Habana Gaudi Deep Learning Processors, pushes the boundaries of deep learning training and can scale up to hundreds of Gaudi processors in one AI cluster. Gaudi is the first DL training processor with integrated RDMA over Converged Ethernet (RoCE v2) engines on-chip. With bi-directional throughput of up to 2 TB/s, these engines play a critical role in the inter-processor communication needed during the training process. This native integration of RoCE allows customers to use the same scaling technology, both inside the server and rack (scale-up) and across racks (scale-out). These can be connected directly between Gaudi processors or through any number of standard Ethernet switches. With high compute utilization for GEMM and convolutions, low-power system design, and Bfloat16 support enabling FP32 accuracy with 16bit training speed, the Supermicro X12 Gaudi AI Training System is built to prioritize two key real-world considerations: training an AI model as fast as possible and reducing the cost of training. The system enables high-efficiency AI model training for vision applications such as manufacturing defects, resulting in better products with fewer warranty issues and fraud detection, saving billions of dollars annually. Inventory management is another area that benefits from AI technologies by allowing enterprises to become more efficient. Using AI technologies, medical imaging becomes more accurate and faster at detecting abnormalities, and identification from photos or videos can enhance security where needed. AI also enables language applications, including question answering, subject matter query, chatbots, translations, and sentiment analysis for recommendation systems, enhancing customer service organizations with more accurate and consistent knowledge. System Specifications The 420GH-TNGR system contains eight Gaudi HL-205 mezzanine cards, dual 3rd Gen Intel Xeon Scalable processors, two PCIe Gen 4 switches, four hot swappable NVMe/SATA hybrid hard drives, fully redundant power supplies, and 24 x 100GbE RDMA (6 QSFP-DDs) for unprecedented scale-out system bandwidth. This system contains up to 8TB of DDR4-3200MHz memory, unlocking the Gaudi processors' full potential. The HL-205 is OCP-OAM (Open Compute Project Accelerator Module) specification compliant. Each card incorporates the Gaudi HL-2000 processors with 32GB HBM2 memory and ten natively integrated ports of 100GbE RoCE v2 RDMA. 3 Figure1: SYS-420GH-TNGR Specifications Each of the Gaudi processors dedicates seven of its ten 100GbE RoCE ports to an all-to-all connectivity within the system, with three ports are available for scaling out for a total of 24 x100GbE RoCE ports per 8-card system. This allows end customers to scale their deployment using standard 100GbE switches. The high throughput of RoCE bandwidth inside and outside the box and the unified standard protocol used for scale-out make the solution easily scalable and cost-effective. The diagram below shows the Gaudi HL-205 processors and the communication paths between processors and the server CPUs. Figure 2: SYS-420GH-TNGR Specifications 4 The Figure below shows how a large scale, distributed training solution is built using the Gaudi AI System as a basic component with standard Ethernet connectivity. It offers three reduction levels \u2013 one within the system, another between 11 Gaudi AI Systems, and another between 12 islands. Altogether, this system hosts 8*11*12 = 1056 Gaudi cards. Larger systems can be built with an additional aggregation layer or with less bandwidth per Gaudi. Figure 3: Topologies for scaling Different Training Models 420GH-TNGR SHOWCASES THE BENEFITS OF THE HABANA GAUDI AI TRAINING PROCESSOR \u2022 High-performance, high efficiency o Price performance that enables more access to more end-customers to AI training o Performance at scale: high throughput at low batch size o Low system power \u2022 First-of-its-kind scalability with native Ethernet scale-out o Avoids proprietary interfaces with industry standard Ethernet o Eliminates bottlenecks with integrated NIC with built-in RDMA over Converged Ethernet (RoCE v2) \u2022 Reduces system complexity, cost, and power with component integration o Leverages wide availability of standard Ethernet switches \u2022 Solution flexibility and support for customization and ease of implementation o Habana SynapseAI Software Platform featuring \u25aa Programmable TPC and rich TPC kernel libraries \u25aa Software Infrastructure and Tools \u25aa Graph compiler and runtime \u25aa Support for popular frameworks and models \u2022 Open Compute Project (OCP) Accelerator Module (OAM) compliance 5 ResNet-50 Performance The Supermicro 420GH-TNGR with dual 3rd Gen Intel Xeon Scalable Processors and eight Habana Gaudi AI training processors has shown excellent performance and scalability when running ResNet-50 in the TensorFlow framework. Below is a chart showing how, as the number of Habana Gaudi AI training cards is increased, the throughput, as measured in the number of images per second, increases with near linear scale. When compared to other systems on a price and performance basis, this solution shines. Case Study: Large scale, distributed AI training at San Diego Supercomputer Center The San Diego Supercomputer Center (SDSC) is a leader and pioneer in high-performance and data-intensive computing, providing cyberinfrastructure resources, services, and expertise to the national research community, academia, and industry. Located on the UC San Diego campus, SDSC supports hundreds of multidisciplinary programs spanning a wide variety of domains, from astrophysics and earth sciences to disease research and drug discovery. The National Science Foundation (NSF) has awarded the San Diego Supercomputer Center (SDSC) at UC San Diego a grant to develop a high-performance resource for conducting artificial intelligence (AI) research across a wide swath of science and engineering domains. Called Voyager, the system will be the first-of-its-kind available in the NSF resource portfolio. As part of their mission to develop algorithms for these domains, SDSC required a cost effective yet powerful system to accelerate AI Training algorithms. SDSC chose the combination of Supermicro Intel Xeon-based CPU servers and the Habana Gaudi AI training systems. When complete, the Voyager system will contain over 42 Supermicro X12 Gaudi AI Training Systems, 336 Habana Gaudi processors, and 16 Habana Goya processors for inference. Supermicro has worked closely with Habana and SDSC to create a large-scale AI training system. An efficient and performance- oriented system can be implemented based on the users' needs by selecting the right components, as shown below. Expertise in many areas, combined with a wide range of server and storage hardware, enables Supermicro to deliver custom solutions Figure 4 - Performance as Gaudi Cards are Increased 6 based on industry standards. Supermicro builds the systems from the ground up with a complete manufacturing facility, from board testing up through multi-rack configuration and testing. This results in more confidence and fewer issues when delivered to innovative customers. The large and efficient Voyager installation for AI training and inference consists of multiple racks of the Habana Gaudi AI Training systems, a Goya Inference rack, storage nodes, and an appropriate rack of networking equipment to support the high speeds necessary for the very fast training scale-out system and inference, as this diagram depicts. Figure 5 \u2013 Supermicro Large Scale Gaudi Training System example Summary Deep Learning revolutionizes computing, impacting enterprises across multiple industrial and research sectors. The computational complexity of deep neural networks is becoming exponentially greater, driving massive demand for compute power. The challenge of deep neural network training is to improve upon multiple criteria at once: first, to complete the job faster with reduced training time; second, to achieve improved price/performance, thus lowering total cost of ownership to enable access to more AI training to more end-users; third, to reduce overall system energy consumption; fourth, to provide flexible scalability with standard interfaces that eliminate vendor lock-in; and lastly, to enable end-customers to customize workloads to address their unique needs. Supermicro has partnered with Habana Labs and Intel to deliver a high performance and cost-effective system for AI training, coupled with the 3rd Gen Intel Xeon Scalable Processor. The combination of the expertise of Supermicro in systems design and Habana Labs with AI processor design will enable high-performance training at reasonable prices and make AI training more accessible to a wide range of industries. The Supermicro X12 Gaudi AI Training System provides superior scalability and has been substantiated by demanding AI customers. By designing, configuring, and testing, customers can be confident that the clusters are operational and optimized for their intended use. 7 The 420GH-TNGR presents several key advantages over traditional AI training solutions: \u2022 Performance leadership that results in significantly lower training time, improved price/performance efficiency, and lower system size \u2022 High throughput at small batch size and near linear scaling \u2022 Low overall system power \u2022 Native integration of Ethernet for scaling \u2022 Lower system cost through wide availability of Ethernet switches of any size from multiple vendors \u2022 Large scale distributed training with near linear scaling \u2022 Support for popular frameworks and models, with the Habana Synapse AI Software Platform \u2022 Open Compute Project (OCP) Accelerator Module (OAM) compliant The 420GH-TNGR provides organizations with an opportunity to lower the total cost of ownership (TCO) and a flexible and easy path to scale their systems as they grow and evolve.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "011457ea-546b-411c-9315-9e18d908c25b": {"__data__": {"id_": "011457ea-546b-411c-9315-9e18d908c25b", "embedding": null, "metadata": {"file_name": "Solution-Brief_World_record_Performance_on_Data_Analytics_Workloads.pdf", "publication_date": "January 2022", "referenced_websites": ["http://tpc.org/5551", "http://tpc.org/5556", "www.tpc.org/tpcx-hs.", "http://tpc.org/5532", "http://tpc.org/5553", "http://tpc.org/5555", "http://tpc.org/5532;", "http://tpc.org/5533;", "https://www.amd.com/en/processors/epyc-world-records", "http://tpc.org/5548", "http://tpc.org/5552;", "http://tpc.org/5557", "http://tpc.org/5533", "http://tpc.org/5554;", "http://tpc.org/5555;", "http://tpc.org/5554", "http://tpc.org/5552"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Introduction Big Data technologies such as Apache Hadoop and Spark are an essential part of the enterprise IT ecosystem. The TPC Express Benchmark HS (TPCx-HS) provides an objective measure of hardware, operating system, and commercial Apache Hadoop Filesystem API compatible software distributions. It also delivers the industry's verifiable performance, price-performance, and availability metrics. The benchmark models a continuous system availability of 24 hours a day, seven days a week. TPCx- HS can assess a broad range of system topologies and implementation methodologies in a technically rigorous and directly comparable, and vendor-neutral manner. Introduction 1 Test Submissions 2 System Under Test (SUT) 2 Cluster Configuration 3 Benchmark Workload 3 Scale Factors 4 Measurements 4 Interpreting Results 5 Results 5 Conclusions 6 Footnotes 7 Additional Resources 8 2 Test Submissions Supermicro's ongoing benchmarking efforts yielded five TPCx-HS results that set 10 world records2 with data sizes ranging from 1TB to 100TB on Supermicro WIO servers powered by 3rd Gen AMD EPYC processors. TPC Express (TPCx-HS) Big Data benchmark categorizes results by data sizes called Scale Factors (SF). This paper showcases Big Data performance results at both the low-end 1 TB SF and the high-end 100 TB SF. In addition, it includes detailed TPCx-HS results and describes their meaning and relevance to Big Data uses from aficionados to engineering, marketing, and sales professionals. System Under Test (SUT) Supermicro , the leading innovator in high-performance, high-efficiency server and storage technology is a premier provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems worldwide. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative and provides customers with the most energy- efficient, environmentally-friendly solutions available on the market Figure 1: Supermicro Hadoop cluster (SUT) 3 Cluster Configuration Hardware # of Servers 16x AS-1114S-WN10RT (1P) 1x AS-1114S-WTRT (1P) # Cores/Threads 544/ 1,088 Configuration DATA NODES 16x Supermicro AS-1114S-WN10RT 1x AMD EPYC 75F3 (32 cores) 256 GiB (8x 32GB RDIMM 3200 MT/s dual rank) 1x NVMe (OS): \u2022 Kioxia XG6 1 TB M.2 22x80mm - used in 12 nodes \u2022 Micron 960 GB M.2 22x80mm - used in 4 nodes 7x 3.84 TB NVMe (data): \u2022 Kioxia CM6 PCIe 4x4 2.5\" 15mm SIE 1DWPD) 1x 100 GbE (Mellanox ConnectX-5) 1x 10 GbE (Broadcom NIC) MASTER NODE 1x Supermicro AS-1114S-WTRT 1x AMD EPYC 75F3 (32 cores) 256 GiB (8x 32GB RDIMM 3200 MT/s dual rank) 2x 1 TB NVMe: \u2022 Kioxia XG6 NVMe M.2 22x80mm 1x 100 GbE (Mellanox ConnectX-5) 1x 100 GbE (Mellanox ConnectX-5) 1x 10 GbE (Broadcom NIC) Connectivity 1x SSE-C3632R 32-port 100 GbE switch 1x E1031 48-port 1/10 GbE switch Software Operating System SUSE Linux Enterprise Server 12 SP5 Apache Hadoop CDP Private Cloud Base Edition 7.1.6 Java OpenJDK 1.8.0_232-cloudera Table 1: Hardware and Software Stack Benchmark Workload TPCx-HS is the first Big Data industry-standard benchmark based on Apache HDFS API-compatible distributions that stress both hardware and software. TPCx-HS extends the TeraSuite workload definitions (TeraGen, TeraSort, TeraValidate) with formal implementation, execution, metrics, result verification, publication, and pricing rules. As a result, it can assess a broad range of Big Data Hadoop system topologies, implementation methodologies, and systems in a technically rigorous, directly comparable, and vendor-neutral manner. Please visit the TPC Documentation webpage to view the current TPCx-HS specification. You can download the latest TPCx-HS kit from However, if you want to publish a compliant TPC Express result, you must use the TPC-provided kit for your selected benchmark, TPCx-HS. The TPCx-HS benchmark workload consists of the following modules: \u2022 HSGen: Generates data at a particular Scale Factor; based on TeraGen. \u2022 HSDataCheck: Checks the validity of the dataset and replication. 4 \u2022 HSSort: Sorts and orders the data; based on TeraSort. \u2022 HSValidate: Validates the sorted output; based on TeraValidate. The benchmark test occurs in five phases run from a TPCx-HS-master script. These phases must run sequentially without any overlaps. The benchmark test consists of Run 1 and Run 2 that follow the run phases shown in Figure 2. No activities are allowed between Run 1 and Run 2 except filesystem cleanup. The TPCx-HS Performance Metric calculation uses the total elapsed runtime T in seconds. The performance run is defined as the run (either Run 1 or Run 2) with the lower TPCx-HS Performance Metric. The repeatability run is defined as the run (either Run 1 or Run 2) with the higher TPCx-HS Performance Metric. The reported Performance Metric is the TPCx-HS Performance Metric for the performance run. Scale Factors The SF is the dataset size relative to the minimum required size of a test dataset. TPCx-HS requires selecting a test dataset size from the following set of fixed SFs: 1 TB 3 TB 10 TB 30 TB 100 TB 300 TB 1000 TB Measurements All TPC-published results disclose a Primary Metric that consists of a Performance metric, Price/Performance metric, and an availability date. For TPCx-HS: 1. Performance Metric (HSph@SF) reflects the throughput of a run (Run 1 or Run 2) at Scale Factor SF. This metric is the elapsed time T for a performance run to perform all five phases shown in Figure 2. \ud835\udc3b\ud835\udc46\ud835\udc5d\u210e@\ud835\udc46\ud835\udc39 = \ud835\udc46\ud835\udc39 \ud835\udc47 3600 \u2044 2. Price/Performance Metric ($/HSph@SF) indicates the Total Cost of Ownership P needed to own and sustain the SUT that scored the Performance Metric. $/\ud835\udc3b\ud835\udc46\ud835\udc5d\u210e@\ud835\udc46\ud835\udc39 = \ud835\udc43 \ud835\udc3b\ud835\udc46\ud835\udc5d\u210e@\ud835\udc46\ud835\udc39 Run 2 Figure 2: TPCx-HS sequence and runs Run 1 HS Data Check HSGen HSSort HSValidate HS Data Check HS Data Check File System Cleanup 5 3. System availability date is the day all components used in the Performance test will be available to customers, as defined in the TPC Pricing specification. Interpreting Results In general, faster performance run completion translates to a higher performance score. The score is obtained by normalizing the run times using the above formulas. For Price/Performance, the lower the metric score, the better. In this case, a higher Performance score achieved on a SUT with a lower Total Cost of Ownership P will show a better Price/Performance metric. Results Supermicro published five TPCx-HS results on September 16th, 2021, across multiple scale factors from 1 TB to 100 TB. These results used Supermicro WIO servers powered by AMD EPYC 75F3 processors and configured as described in Table 1. Table 2 shows these published results, which set 10 new world records2 for the Performance and Price/Performance metrics. Data Size (Scale Factor) SF 1 TB SF 3 TB SF 10 TB SF 30 TB SF 100 TB Run1 Run2 Run1 Run2 Run1 Run2 Run1 Run2 Run1 Run2 Number of nodes 17 Framework Spark MapReduce HSGen (s) 25.1 24.8 62.365 63.3 174.2 173.0 515.92 517.9 1,624.5 1,637.5 HSSort (s) 79.0 78.6 187.5 187.6 552.9 552.5 1,547.6 1,572.9 5,820.7 5,799.4 HSValidate (s) 15.8 16.4 36.50 37.5 87.1 88.4 256.5 261.4 751.0 747.3 Elapsed run time (s) 131.0 130.0 294.0 296.0 828.0 828.0 2,353.0 2,381.0 8,218.0 8,206.0 TPCx-HS Performance Metric (HSph@SF) 27.54 27.70 36.76 36.49 43.47 43.47 45.89 45.36 43.80 43.87 TPCx-HS Price/Performance ($/HSph) $32,166.53 $24,276.96 $20,378.79 $19,529.68 $20,225.26 Table 2: Supermicro TPCx-HS results published on September 16th, 2021 ** The lowest of the Run1 & Run2 (shown in bold) is the reported Performance Run, and the other is Repeatability Run 6 Conclusions Single-socket 1U and 2U Supermicro WIO servers powered by 3rd Gen AMD EPYC processors support up to 10 PCIe 4.0 NVMe drives to accommodate ever-growing Big Data deployment storage requirements. Supermicro WIO servers deliver the following benefits compared to both other OEMs and systems powered by previous-generation AMD EPYC processors: \u2022 Consistently superior performance across multiple scale factors \u2022 Up to 83% Performance metric uplift \u2022 Up to 35% lower Total Cost of Ownership (TCO) based on Price/Performance metrics. Figure 3: Performance gain over a previous generation or competition3,4,5,6,7 Figure 4: Price/Performance (TCO) savings over the previous generation or competition3,4,5,6,7 7 Supermicro WIO servers powered by AMD EPYC 7003 Series Processors help leading enterprises reduce time-to-solution across a wide range of applications, provide enhanced security features, and allow running all workloads either on-premises or in a public or private cloud. Supermicro offers many certified solutions and reference architectures that empower organizations to create deployments that deliver data insights faster than ever before. These solutions include servers optimized for: \u2022 AI/ML/DL traininginference \u2022 Hyperconverged infrastructure (HCI) \u2022 Software-defined infrastructure (SDI) \u2022 Software-defined storage, such as CEPH, VMWare vSAN, and Weka.IO. \u2022 Data management, such as Oracle 19c, Apache Hadoop, and Cassandra. \u2022 HPC application optimization, such as Ansys Fluent, OpenFOAM, and WRF. Footnotes 1. These results held world record performance prior to new results from Supermicro: Dell R6515 (AMD EPYC 75F3 processor) cluster HSph@1TB 24.69: HSph@3TB 34.52: HSph@100TB 43.76: HPE DL325 (AMD EPYC 7502P) cluster: HSph@10TB 23.66: ; HSph@30TB 25.47 ; 2. Supermicro WIO cluster 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 27.54 HSph@1TB, 32,166.53 USD per HSph@1TB, 2 world records in price and price-performance for 1TB SF ; 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 36.49 HSph@3TB, 24,276.96 USD per HSph@3TB, 2 world records in price and price- performance for 3TB SF AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 43.47 HSph@10TB, 20,378.79 USD per HSph@10TB, 2 world records in price and price-performance for 1-TB SF AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 45.36 HSph@30TB, 19,529.68 USD per HSph@30TB, 2 world records in price and price-performance for 30TB SF ; AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 43.80 HSph@100TB, 20,225.26 USD per HSph@100TB, 2 world records in price and price-performance for 100TB SF ; see also: 3. Supermicro WIO cluster 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 27.54 HSph@1TB, 32,166.53 USD per HSph@1TB, ; Dell R6515 (AMD EPYC 75F3 processor) cluster HSph@1TB 24.69 49,795.35 USD per HSph@1TB ; 27.54/24.69=11.54%, $32166.53/$49795.35=-35.40% 4. Supermicro WIO cluster 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 36.49 HSph@3TB, 24,276.96 USD per HSph@3TB, ; Dell R6515 (AMD EPYC 75F3 processor) cluster HSph@3TB 34.52, 35,615.50 USD per HSph@3TB ; 36.49/34.52=5.71%, $24276.96/$35615.5=-31.84% 5. Supermicro WIO cluster 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 43.47 HSph@10TB, 20,378.79 USD per HSph@10TB, . HPE DL325 (AMD EPYC 7502P) HSph@10TB 23.66 USD per HSph@10TB 25,057.91 43.47/23.66=83.73%, $20378.79/$25057.91=-18.67% 8 6. Supermicro WIO cluster 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 45.36 HSph@30TB, 19,529.68 USD per HSph@30TB, . HPE DL325 (AMD EPYC 7502P) HSph@30TB 25.47 USD per HSph@30TB 27,649.40 45.36/25.47=78.09%, 19529.68/27649.4=-29.37% 7. Supermicro WIO cluster 3rd Gen AMD EPYC 75F3 17 Nodes, 17 processors, 544 cores 43.80 HSph@100TB, 20,225.26 USD per HSph@100TB, [tpc.org] ; Dell R6515 (AMD EPYC 75F3 processor) cluster HSph@100TB 43.76 USD per HSph@100TB 30,732.52 [tpc.org]; 43.8/43.76=0.09% ; 20225.26/30732.52=-34.19%", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "140da6f2-965b-4f03-b748-14aa4653c4e1": {"__data__": {"id_": "140da6f2-965b-4f03-b748-14aa4653c4e1", "embedding": null, "metadata": {"file_name": "Solution_Brief_CloudDC_Cloudera_Dataflow.pdf", "publication_date": "September 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Businesses create incredible value using data they have on their systems, including edge systems. Retail, financial transactions, machine time series data, security, or manufacturing video feeds bring valuable insight to the corresponding business, enabling process improvements and the creation of new products and services. Supermicro offers a complete line of edge systems to collect data at business edge locations, such as storefronts. Supermicro also offers a range of high density CloudDC systems to run Cloudera Data Flow, the Data-in-Motion platform. The Cloudera Data Flow reliably collects structured and unstructured data (i.e., transactions, time-series data, images, videos) from data sources and edge systems. The data in motion is reliably collected and pipelined to downstream analytics and AI systems. These systems then identify issues or defects while learning real-time changes. The learning could turn into new opportunities for the business. Cloudera Data Flow Management and Stream Processing \u2022 Cloudera Data Flow(CDF) is a scalable, real-time streaming data platform that makes it easy to collect, curate, and analyze data to gain key insights for immediate actionable intelligence. Figure 2. Data flow architecture using Supermicro CloudDC Figure 1. Open source protocols to collect data. 2 \u2022 CDF does this through Flow Management, where customers can build scalable data movement flows from the edge to the data center using a low-code/no-code interface. The Flow Management is powered by open source Apache NiFi, MiniFi, and Edge Flow Manager. \u2022 Stream Processing, which provides an enterprise-grade stream management and stateful processing capability to build real time applications. The stream processing is powered by SQL Stream Builder, Apache Flink, and Apache Kafka. \u2022 This is secured and governed through the Cloudera Shared Data Experience, called SDX. Supermicro Data Center X13 CloudDC Servers and Edge Systems \u2022 Supermicro X13 CloudDC systems provide an all-in-one rackmount platform for cloud data centers. They come in either 1U or 2U for optimal deployment. These systems offer the latest Intel 4th Gen Xeon Scalable processors that support DDR-5 4800MHz memory and PCIe 5.0 I/O. \u2022 Supermicro Edge systems come in various form factors to provide optimal deployment in edge locations to collect business data. Implementation of Cloudera Data Flow on Supermicro X13 CloudDC Servers 5 Nodes SYS-121C-TN10R X13 CloudDC 1U, 10x 2.5\" , Component Description Qty P4X-SPR6430-SRM7A-XCC SPR 6430 2P 32C 2.1G 270W 60MB BI(1000) 2 MEM-DR532L-SL06-ER48 32GB DDR5 4800 ECC REG---MEM-DR532L-SL06-ER48 16 HDS-MMN-MTFDKBA960TFR-15 Micron 7450 PRO 960GB NVMe PCIe 4.0 M.2 22x80mm 2 HDS-I2T0-SSDSC2KB019TZ D3 S4520 1.92TB SATA6Gb/s 3D TLC 2.5\" 7.0mm 1 AOC-A100G-m2CM-O AIOM 2-port 100GbE QSFP28,Mellanox CX-6 DX 1 3 Nodes SYS-621C-TN12R X13 CloudDC 2U, 12x 3.5\" Component Description Qty P4X-SPR6430-SRM7A-XCC SPR 6430 2P 32C 2.1G 270W 60MB BI(1000) 2 MEM-DR532L-CL01-ER48 32GB DDR5 4800 ECC REG 16 HDS-MMN-MTFDKBA400TFS1BC Micron 7450 MAX 400GB NVMe PCIe 4.0 3D TLC M.2 22x80 mm, 3DWPD 2 HDS-M2T-MTFDDAK7T6TGA-15 5400 PRO 7.68TB, SATA, 2.5\", 3D TLC, 0.6DWPD,7mm,TCG OPAL 2.0 4 AOC-A100G-m2CM-O AIOM 2-port 100GbE QSFP28,Mellanox CX-6 DX 1 Figure 3. Hybrid data center architecture Figure 4. Cloudera Data Flow on Supermicro CloudDC servers 3 Conclusion Supermicro systems running on the edge and data center, running the Cloudera data platform, help businesses collect their data and turn the data into reliable business operations, new insights, and business opportunities.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "6db82861-a963-41df-a73b-5b5c2b36f3e9": {"__data__": {"id_": "6db82861-a963-41df-a73b-5b5c2b36f3e9", "embedding": null, "metadata": {"file_name": "Solution-Brief_Workstations_AEC.pdf", "publication_date": "December 2021", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro Workstation Family Workstations are currently used to fuel design and visual capabilities innovation in architecture, engineering, and construction (AEC) industries. The world of professional visualization is undergoing a significant shift as advancements such as real-time ray tracing, engineering simulation, immersive virtual reality (VR), and tools augmented by artificial intelligence (AI) drive improvements across the AEC space. With IT and operational requirements changing quickly, companies feel pressure to manage their most demanding applications in dispersed locations. Today, many AEC companies work remotely as projects become increasingly complex, challenging teams to find new and better ways to optimize workflows, communication, and collaboration. To succeed, companies are enhancing their environments with the latest computing capabilities, with powerful CPUs and GPUs, more memory, increased storage, and intuitive management software. When combined, these technologies create 1 Working with Proven Partners 2 Building The Ideal Production Environment 3 Summary 5 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. 2 comprehensive workstations that enable companies to use a broad range of AEC applications with unprecedented performance. Workstation solutions optimize the most graphics-intensive applications, including computer-aided design (CAD), computer-aided engineering (CAE), 3D modeling, and rendering. These technologies dramatically accelerate time to value for tasks like solid modeling, design visualization, structural analysis, and civil engineering. Now, teams of architects and engineers can speed up design iteration and work effectively with construction firms to accelerate development cycles while increasing cost savings. AEC companies depend on visual computing platforms to empower teams wherever they need to work. The ideal solutions will deliver high levels of performance to increase productivity and deliver measurable ROI. These technologies are the foundation for greater efficiency, smarter decisions, and better business results\u2014 built on extreme computational power right at everyone\u2019s desk. Working with Proven Partners Supermicro and NVIDIA are delivering the next generation of visual computing to accelerate the future of work. Together, Supermicro and NVIDIA provide the right visual computing solutions to improve the speed and quality of any project. Supermicro is a global leader in high-performance, high-efficiency technology, offering the broadest product portfolio for robust workstations. With operations in more than 100 countries, Supermicro is a leader in enterprise, cloud, AI, edge, and IoT, developing state-of-the-art products ahead of the competition. The goal is to enable the success of every customer. Supermicro achieves this through extensive engineering expertise and the industry\u2019s broadest product portfolio, which offers green computing technologies that reduce energy costs, effectively allocate resources to tackle complex workflows, and improve the overall total cost of ownership. In addition, Supermicro provides a range of performance-boosting solutions to help AEC firms work better, smarter, and faster in partnership with NVIDIA. Supermicro is committed to building work environments that provide industry-leading energy efficiency, acceleration, and reliability. Leveraging first-to-market innovations from Supermicro and NVIDIA RTX technology, each workstation is purpose- built for unprecedented rendering, graphics, compute, and AI at scale to enhance any application. In addition, these server- grade workstations are expertly designed to optimize workloads that require powerful compute and graphics capabilities so that companies can complete their projects in record time. Workstations from Supermicro and NVIDIA offer critical advantages at each stage of development: \u2022 Supporting the unique software applications and requirements of different types of users \u2022 Improving collaboration among geographically dispersed teams \u2022 Accelerating performance to eliminate slow render times and limited render interactivity \u2022 Expanding the ability to edit design elements, such as materials and lighting, in real-time based on client feedback \u2022 Enhancing operational efficiency and project planning AEC Companies can expect a number of advantages with cutting-edge workstations solutions: \u2022 Supporting seamless remote work with graphics-intensive software applications. \u2022 Improving collaboration among geographically dispersed teams. \u2022 Reducing render times and increased render interactivity. 3 Our joint solutions make it possible to create realistic, immersive experiences that leverage the latest advancements in workstation technology to shorten design reviews and ensure more efficient construction workflows with enhanced worksite safety, immersive construction rehearsals, and safety training, all in VR. With these technologies, AEC companies can streamline project delivery and minimize delays while providing a safer work environment. Now, companies have the ability to ramp up development from planning to the final product. Building The Ideal Production Environment Supermicro offers a comprehensive portfolio of workstations to fit an organization's unique requirements. Supermicro offers a high degree of flexibility and upgradability to put unparalleled compute, graphics, and AI capabilities at the core of professional environments. The workstations in this groundbreaking product line include mid-tower form factor systems, high memory bandwidth, and massive acceleration to equip architects, engineers, and builders with maximum throughput. Supermicro workstations are fast and reliable and meet the demands of various businesses and lead the industry. Each platform is built on enterprise-grade technologies tested and validated to power critical applications for any AEC task. Solutions from Supermicro and NVIDIA feature a wide range of industry standard components to optimally configure the platform to accelerate innovative projects\u2014including NVMe storage, powerful CPUs, and breakneck acceleration from NVIDIA professional GPUs. These configurations are engineered to be cost-efficient while providing the right level of performance to empower different types of users running diverse applications. By partnering with Supermicro and NVIDIA, every company can adopt the latest workstation solutions to power innovation anywhere. Supermicro equips engineers and designers with the right tools for success: \u2022 Performance at scale for demanding AEC projects \u2022 Increased operational performance and reliability for the enterprise \u2022 Expansive visual workspaces with stunning imagery \u2022 Unmatched GPU acceleration to accelerate development cycles 4 530A-IL 530AD-I 5014A-TT Single-processor workstations are engineered to be cost-efficient while providing exceptional power to handle mission-critical workloads Entry-level configurations deliver the right level of performance for teams using leading design software for applications such as CAD and 2D modeling. Workstations with advanced graphics capabilities enable users to enjoy desktop-level usability on a personal workstation without sacrificing performance or features Mainstream configurations deliver unmatched performance for a variety of 3D modeling and animation applications. Purpose-built to execute high-end workflows with robust visual computing capabilities and interactive performance for a new age of design Expert configurations allow companies to harness extreme compute capacity and acceleration for complex 3D modeling and animation applications. - Intel Xeon W-1200 / W-1300 processors, up to 10 cores - 32GB DDR4-3200 Memory - NVIDIA RTX A2000 - 1TB M.2 NVMe + 4TB HDD - Windows 10/11 Pro 64 - 11th Gen Intel Core processor, up to 8 cores - 64GB DDR4-3200 Memory - NVIDIA RTX A4500 - 2TB M.2 NVMe + 6TB HDD - Windows 10/11 Pro 64 - AMD Ryzen Threadripper PRO 3900WX processor, up to 64 cores - 128GB DDR4-3200 Memory - NVIDIA RTX A6000 - 2x 2TB M.2 PCIe Gen 4 NVMe + 2x 3.8TB U.2 PCIe Gen 4 SSD - Windows 10/11 Pro 64 5 Summary Supermicro and NVIDIA are empowering AEC firms to work better and smarter with solutions that are expertly engineered to boost productivity, creativity, and innovation. Supermicro makes it faster and simpler to design, review, modify, and accurately visualize detailed building models anywhere, from the office to customer locations and places in between. As a result, organizations can benefit from solutions and capabilities that are the best in the industry: \u2022 Best performance: Highest memory and storage capacities available in a single tower system, featuring up to four passively cooled GPUs in tower form factor. Supermicro is the only manufacturer to offer up to four NVIDIA A100 Tensor Core GPUs in multiple models, with up to 80 cores, 4TB of memory, 61.44TB of NVMe, and optional DCPMM support. \u2022 Best expandability Up to six PCIe Gen4 x16 expansion slots, or up to four PCIe Gen4 M.2 with optional hardware RAID 0/1/5/10 support. \u2022 Best component selection: Supermicro validates a wide variety of memory, storage, and networking components with different specifications to help organizations configure an optimized system for demanding needs without locking into one brand. \u2022 Best assembly and local support: All workstation systems shipped in the Americas are built and tested at Supermicro headquarters in San Jose, California, and include technical support services by in-house Supermicro engineers and product managers. Our cutting-edge workstations are transforming AEC operations from the ground up. Together, Supermicro and NVIDIA can help organizations deploy the ideal workstation to create the designs of tomorrow today. It\u2019s time for enterprises to execute all of their graphics work with ease and innovate without limits. Visit us online to learn more.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "9691b69a-6f5f-4fe0-8f02-308e885bb786": {"__data__": {"id_": "9691b69a-6f5f-4fe0-8f02-308e885bb786", "embedding": null, "metadata": {"file_name": "Solution-Brief_Zscalar_SD_WAN_Container.pdf", "publication_date": "May 2023", "referenced_websites": ["www.supermicro.com", "https://www.issd.com.tr/en/46652", "https://networkbuilders.intel.com/intel-technologies/intel-select-solutions/secure-access-service-edge", "https://www.lloyds.com/about-lloyds/media-centre/press-releases/cyber-attack-on-apac-ports-could-cost-110bn", "https://www.supermicro.com/en/products/system/iot/1u/sys-110d-8c-frdn8tp)", "https://unctad.org/publication/review-maritime-transport-2022", "https://www.rafay.co", "https://www.supermicro.com/en/products/system/iot/2u/sys-211se-31a", "https://www.supermicro.com/en/products/system/iot/2u/sys-211se-", "https://www.supermicro.com/en/products/system/iot/1u/sys-110d-14c-frdn8tp", "https://www.zscaler.com/resources/data-sheets/zscaler-zero-trust-sd-wan.pdf"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Processing data at the network edge, close to its point of origin, enables low-latency apps and services while also reducing backhaul bandwidth costs. However, enterprise architects must meet the following challenges when designing edge computing solutions: - Provide robust, scalable compute at remote locations, including demanding edge workloads such as artificial intelligence (AI)/deep learning and analytics. - Protect the expanded attack surface created by distributed services and work-from-home scenarios that operate outside any network perimeter. - Deliver a cloud-native implementation that supports transformation with ease of use and agility through cloudification of the edge. Supermicro, along with partners such as Intel, has created two solutions for cloud-native applications at the edge. Solution1: SYS-110D-8C/14C-FRDN8TP is a verified Intel Select Solution for SASE workload-optimized server solution based on the operating system(s) Red Hat/ Canonical Ubuntu that eases interoperability and speeds deployment. \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 1 Solution 1: Overview and Benefits 2 Intel Select Solutions for SASE 3 Solution 2: Overview and Benefits 4 Track Containers with ConScan\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026. 5 Rafay Automates Edge Network Lifecycle 6 Secure Demonstration MEC Server\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026 7 Zscaler Zero Trust\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.8 Summary\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.9 SYS-110D-8C/14C-FRDN8TP SYS-211SE-31A 2 Solution 2: SYS-211SE-31A is a verified container tracking application with Zscaler, Rafay, and Supermicro collaboration to create multi-access edge compute solutions and deployed ISSD ConScan to demonstrate the application with security service edge and orchestration capabilities. Solution 1: Overview and Benefits To serve this market, Supermicro has chosen to partner with Intel to develop and launch its SYS-110D-14C- FRDN8TP and SYS- 110D-8C-FRDN8TP ( as a verified Intel Select Solution for SASE. Converging software-defined WAN (SD-WAN) network services with cloud-hosted security services, Intel Select Solutions for SASE provide pre-validated blueprints for edge compute points of presence based on Intel Xeon D-2700 processors that lower the barriers to implementation and speeds deployment. \u2022 High core counts and per-core performance ensure remote workloads have reliable, optimized computational throughput with agility, flexibility, and excellent ROI. \u2022 Compact, power-efficient system-on-chip (SoC) platform with integrated accelerators and Ethernet, with networking accelerated by Remote Direct Memory Access (RDMA) and Dynamic Device Personalization (DDP). \u2022 Streamlined path to cloud-native operations, replacing hub-and-spoke topologies that made data centers choke points with multi-cloud ones that embrace modern approaches such as microservices and DevOps. \u2022 Accelerated AI inference using Intel Deep Learning Boost (Intel DL Boost), which eliminates unneeded precision in calculations so they can be completed more quickly. \u2022 Accelerated encryption and compression to reduce workload overhead with enhanced Intel AES New Instructions (Intel AES-NI) and integrated Intel QuickAssist Technology (Intel QAT). Servers Used Base Configuration Plus Configuration Server Name SuperServer SYS-110D-8C-FRDN8TP SuperServer SYS-110D-14C-FRDN8TP Processor Intel Xeon D-2733NT Processor 8C/16T, TDP 80W Intel Xeon D-2766NT Processor 14C/28T, TDP 97W Memory 32GB 64GB Intel QAT Yes Yes Intel Ethernet option 4x 1GbE 2x 25GbE SFP28 2x 10GbE Base-T 4x 1GbE 2x 25GbE SFP28 2x 10GbE Base-T Storage (NVMe / SATA) 256GB NVMe M.2 2280 Supports 2x Internal 2.5\" drive bays (2x PCIe 4.0 NVMe x8 SlimSAS and 1x OCuLink options) 1x M.2 M-Key 2242/2280 (SATA/PCIe 3.0 x4) 512GB NVMe M.2 2280 Supports 2x Internal 2.5\" drive bays (2x PCIe 4.0 NVMe x8 SlimSAS and 1x OCuLink options) 1x M.2 M-Key 2242/2280 (SATA/PCIe 3.0 x4) 3 Why Intel Select Solutions for SASE? Figure 1 \u2013 Intel Select Solution for SASE for robust cloud-first initiatives that combine enterprise distributed networking and security services. Benefits of Intel Select Solutions for SASE: Intel Select Solutions for SASE provides a pre-validated solution blueprint that accelerates the time to production for robust cloud-first initiatives that combine enterprise distributed networking and security services. \u2022 Superior performance for crypto and AI inference, boosting throughput with Intel QAT for public key exchange & cryptography acceleration, and crypto and AI inference instruction set architecture enhancements, silicon- integrated accelerators, and PCI Express add-in accelerator cards. \u2022 Distributed, cloud hosted security services based on containerized network functions bound to individual workloads as they traverse private, public, and hybrid clouds. \u2022 Enabler of cloudification at the edge, creating a converged, standards-based infrastructure based on containers and microservices that maintains high levels of performance and security. \u2022 Software consistency with Intel Atom and Intel Xeon Scalable Processors, with back-compatibility and a single standard architecture for Cloud Native and network functions virtualization infrastructure (NFVI). 4 Solution 2: Overview and Benefits The chances are good that the item you ordered with next-day delivery started its journey to you months before on a ship and came to you through a maritime port. According to the United Nations Conference on Trade and Development, ships carry 80%1 of global trade volume, including food and farm products, fuel, forest products, iron and steel, clothing, shoes, electronics, toys, and cars. This makes ports a crucial connection to supply chains around the world. The importance of maritime ports makes them a constant target of cyber criminals and hackers that want to steal goods or disrupt operations. The impact of a significant successful attack could be immense; insurance provider Lloyds reports that a single cyber-attack on ports in Asia could cost $110 billion2. Improving cyber security is a top priority for ports. Working with other partners, Intel is addressing this challenge by developing secure multi-access edge (MEC) solutions powered by 4th Gen Intel Xeon Scalable processors. One use case for this MEC solution is Marine Ports Container ID Recognition and Scanning, which scans shipping container identification information at the points of ingress and egress to the port and as they move through the port. This data is then used to track containers and to know if they are being misdirected, stolen, or lost. In addition, the MEC server that is the basis of this application supports security features to significantly inhibit cyber thieves from accessing or manipulating the data. 1 2 Figure 2 \u2013 The ConScan Container and Truck Identification Recognition and Tracking System Output 5 A demonstration of this application was organized by Intel using ISSD ConScan as the workload and including Rafay for application orchestration. Zscaler provided Zero Trust Network Access to enable a secured environment, and Supermicro provided the compute platform. Why Track Containers with ConScan? The workload in this demonstration is ConScan, a marine port container ID recognition system from Integrated Systems and Systems Design (ISSD). The software automatically collects container information while transiting through the port. The software aggregates video streams from multiple cameras throughout a port and uses image processing technology and storage of collected data to track containers. ConScan is designed for complex and constantly moving port environments. This requires a highly automated solution with advanced data analysis. All collected information is recorded in real time and is accessible to port staff and shippers via a web interface. As a result, ConScan reduces the need for humans at entrances and checkpoints and ensures containers are routed to the appropriate loading docks and ships. Supermicro MEC Server Uses Latest Intel CPUs Supermicro provides the IoT SuperServer SYS-211SE-31A ( 31a) servers powered by 4th Gen Intel Xeon Scalable processors with connectivity provided by the Intel Ethernet 800 Series network adapters. The 4th Gen Intel Xeon Scalable processor accelerates performance across the most demanding workloads. The new processor combines high-performance processor cores with up to eight built-in accelerators to help improve performance and processing efficiency for demanding workloads like cryptographic and artificial intelligence acceleration. The Intel 800 Series Network Adapters improve application efficiency and network performance with innovative and versatile capabilities that optimize high-performance server workloads. The Intel 800 Series Network Adapters deliver bandwidth and increased application throughput required for demanding cloud workloads and provide packet classification and sorting optimizations for high-bandwidth network and communications workloads. Base Configuration Server Name SuperServer SYS-211SE-31A Processor 4th Gen Intel Xeon Scalable processors Supports 85W - 300W TDP CPUs Memory Up to 2TB: DDR5 Intel Ethernet option 1 RJ45 GbE LAN port (shared with IPMI) Storage 2 M.2 NVMe M-Key, 2280/22110 6 Rafay Automates Edge Network Server Lifecycle The MEC server in the container ID demonstration uses Rafay\u2019s Kubernetes Operations Platform (KOP) for Edge, a Software-as- a-Service (SaaS) platform for managing cloud-native edge network infrastructure. KOP for Edge is part of a family of SaaS platforms designed to simplify the lifecycle management of Kubernetes clusters and applications located in data centers, public clouds, or at the edge. Benefits of KOP for Edge \u2022 Network administrators can centrally manage the full lifecycle of their Kubernetes clusters and applications at remote edge locations, such as maritime ports. \u2022 KOP for Edge integrates so-called \u201cstovepipe\u201d services such as continuous deployment (CD), logging, monitoring, policy management, authorization, and backups. \u2022 The KOP for Edge interface is designed to deploy these integrated services in minutes via the cloud. \u2022 KOP for Edge simplifies the deployment of Kubernetes in an edge network by providing central management of the infrastructure and applications each edge site depends on. \u2022 Rafay\u2019s KOP for Edge delivers centralized, policy-based management, automation, standardized operations, and advanced security. Key features of Rafay Kubernetes Operation Platform (KOP) for Edge: \u2022 Multicluster Management \u2022 GitOps Pipelines \u2022 Zero Trust Access \u2022 K8s policy management \u2022 Backup and restore SYS-211SE-31A SYS-211SE-31A-Single Node 7 \u2022 Visibility and monitoring Creating the Secure Demonstration MEC Server The architecture of the solution built for the Marine Ports Container ID Recognition and Scanning is shown in the Figure below. Figure 4 \u2013 The MEC server in the center of this figure is a security enabled Intel architecture server with remote management running a container scanning workload. The ConScan application is the basis for the Marine Ports Container ID Recognition and Scanning server scans video streams from designated security cameras. In addition, it can isolate containers and record their identification information. Figure 3 \u2013 The KOP platform offers lifecycle management services to a wide variety of Kubernetes distros and can be delivered via the most popular public data center providers 8 Benefits of ConScan: A single ConScan deployment will support up to 256 cameras and scanners throughout the property, with cameras at each entry and exit point. The ConScan program will scan a container and track it through the port until it is either loaded on a ship or on a truck exiting the Port for local delivery. Orchestrating the computer systems in a port environment is a challenge because ports are distributed and disaggregated, providing the potential for a large attack surface that is easy to infiltrate. Zscaler helps eliminate that risk. Server maintenance and ongoing patches and updates are critical components of securing the system. The Rafay KOP for Edge product is designed for the comprehensive and secure provision of software from a central control point. The software running on the computer systems can be maintained in an automated fashion using the Rafay platform. Since a port is a location that has many moving parts and can cover a very large footprint, it is not reasonable to house IoT systems in a controlled data center environment with standard off-the-shelf rack mount servers. As a result, the computers required to support these devices and use cases must be designed for rugged environments and have the compute resources to support high demand processes. The Supermicro SuperServer platforms using the Intel Xeon processors are designed for such deployments. Additionally, these systems can be deployed in hardened cases that reside throughout the port to ensure reliable processing of ConScan data. Zscaler Zero Trust SD-WAN: One requirement is to establish zero trust access for all the cameras and scanners that connect to the ConScan application. With the Zscaler Zero Trust Exchange, all IoT devices and clients were authenticated and authorized before connecting to the application. Figure 5 \u2013 The Zero Trust Exchange from Zscaler directly connects users with devices, applications, and machines reducing the cyber-attack surface. 9 Benefits of Zscaler: \u2022 Reduced attack surface: By making apps visible only to authorized devices, the Zero Trust Exchange eliminates those apps from an organization\u2019s attack surface. \u2022 Users connected to apps, not the network: The Zero Trust Exchange connects users directly to apps, providing a fast user experience and reducing latency by eliminating the need to backhaul traffic through centralized security controls. \u2022 Proxy, not passthrough, architecture: Passthrough security applications can get bogged down by inspecting TLS/SSL-encrypted traffic, which is the vast majority of all traffic. The Zero Trust Exchange proxy architecture is designed for full content inspection, including encrypted traffic at scale, providing fast throughput and enabling effective cyber threat protection and data loss prevention. \u2022 Secure access service edge: The secure access service edge (SASE) is defined as a framework for securely connecting users and machines to apps and services without regard to the device\u2019s physical location. As a SASE-based solution, Zero Trust Exchange can enforce policy at the edge and/or distributed across data centers globally. \u2022 Multitenant Architecture: Zero Trust Exchange is built on a multitenant cloud architecture to provide the scalability to meet the growing security needs of the increasingly interconnected world. Summary With the SYS-110D-8C/14C-FRDN8TP verified as an Intel Select Solutions for SASE, Supermicro is delivering a differentiated Intel Xeon D-2700 processor based platform that can simplify and accelerate the process of selecting and deploying the hardware and software needed for today\u2019s enterprise edge workloads and applications. Intel Select Solutions for SASE represent the latest technology that will accelerate the transformation of the network from end to end. With the SYS-211SE-31A verified as a marine port container ID recognition system, it is one of several \u201csmart\u201d use cases increasingly used in industry, cities, schools, and other public-facing organizations. However, all these smart use cases with the large number of IOT devices feeding and communicating information are prime targets for hackers who pose a real threat to the economy and people\u2019s private information. The MEC solution specified in this application has the performance, security features, and remote lifecycle management capabilities to be deployed in various use cases. In addition, it provides a security posture that significantly reduces the attack surface that hackers exploit. Intel and its partners have demonstrated a streamlined approach to securing these use cases. We encourage further exploration and engagement for you to set up a SASE POP-based service or a marine port container ID recognition system on our servers. Reach out to us to set up an evaluation for your use case. Learn More", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "2fbadd82-0dbd-4831-9dba-229d04001ee8": {"__data__": {"id_": "2fbadd82-0dbd-4831-9dba-229d04001ee8", "embedding": null, "metadata": {"file_name": "Solution_Brief_GrandTwin_Cloudera_Dataflow.pdf", "publication_date": "September 2023", "referenced_websites": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Businesses create incredible value using data they have on their systems, including edge systems. Retail, financial transactions, machine time series data, security, or manufacturing video feeds bring valuable insight to the corresponding business, enabling process improvements and the creation of new products and services. Supermicro offers a complete line of edge systems to collect data at business edge locations, such as storefronts. Supermicro also offers a range of multi-node GrandTwin systems to run Cloudera Data Flow, the Data-in-Motion platform. The Cloudera Data Flow reliably collects structured and unstructured data (i.e., transactions, time- series data, images, videos) from data sources and edge systems. The data in motion is reliably collected and pipelined to downstream analytics and AI systems. These systems then identify issues or defects while learning real-time changes. The learning could turn into new opportunities for the business. Cloudera Data Flow Management and Stream Processing \u2022 Cloudera Data Flow(CDF) is a scalable, real-time streaming data platform that makes it easy to collect, curate, and analyze data to gain key insights for immediate actionable intelligence. Figure 2. Data flow architecture using Supermicro GrandTwin servers Figure 1. Open source protocols to collect data. 2 \u2022 CDF does this through Flow Management, where customers can build scalable data movement flows from the edge to the data center using a low-code/no-code interface. The Flow Management is powered by open source Apache NiFi, MiniFi, and Edge Flow Manager. \u2022 Stream Processing, which provides an enterprise-grade stream management and stateful processing capability to build real time applications. The stream processing is powered by SQL Stream Builder, Apache Flink, and Apache Kafka. \u2022 All of this is secured and governed through the Cloudera Shared Data Experience, called SDX. Supermicro Data Center H13 GrandTwin Servers and Edge Systems \u2022 Supermicro H13 GrandTwin systems provide a multi-node rackmount platform for cloud data centers. They come in 2U with four nodes for optimal deployment. These systems offer the latest AMD 4th Gen EPYC processors that support DDR-5 4800 memory and PCI Express Gen 5 I/O. \u2022 Supermicro Edge systems come in various form factors to provide optimal deployment in edge locations to collect business data. Implementation of Cloudera Data Flow on Supermicro H13 GrandTwin Servers or 8 Nodes AS -2115GT-HNTR H13 GrandTwin, 2 x 2U/4 nodes, Rear I/O Component Description Qty PSE-GEN9334-0800 SPR 6430 2P 32C 2.1G 270W 60MB BI(1000) 2 MEM-DR532L-HL02-ER48 32GB DDR5 4800 ECC REG---MEM-DR532L-SL06-ER48 12 HDS-MMN-MTFDKBA960TFR-15 Micron 7450 PRO 960GB NVMe PCIe 4.0 M.2 22x80mm 2 HDS-I2T0-SSDSC2KB019TZ D3 S4520 7.68TB SATA6Gb/s 3D TLC 2.5\" 7.0mm 4 AOC-A100G-m2CM-O AIOM 2-port 100GbE QSFP28,Mellanox CX-6 DX 1 8 Nodes AS -2115GT-HNTF H13 GrandTwin, 2 x 2U/4 nodes, Front I/O Component Description Qty PSE-GEN9334-0800 SPR 6430 2P 32C 2.1G 270W 60MB BI(1000) 2 MEM-DR532L-HL02-ER48 32GB DDR5 4800 ECC REG---MEM-DR532L-SL06-ER48 12 HDS-MMN-MTFDKBA960TFR-15 Micron 7450 PRO 960GB NVMe PCIe 4.0 M.2 22x80mm 2 HDS-I2T0-SSDSC2KB019TZ D3 S4520 7.68TB SATA6Gb/s 3D TLC 2.5\" 7.0mm 4 AOC-A100G-m2CM-O AIOM 2-port 100GbE QSFP28,Mellanox CX-6 DX 1 Figure 3. Hybrid data center architecture Figure 4. Cloudera Data Flow on Supermicro GrandTwin servers 3 Streaming Transactions Time Series Video Energy \u2713 \u2713 \u2713 Finance \u2713 Healthcare \u2713 \u2713 Manufacturing \u2713 \u2713 \u2713 Media \u2713 \u2713 Retail \u2713 \u2713 Telecom \u2713 Others \u2713 \u2713 \u2713 Conclusion Supermicro systems running on the edge and data center, running the Cloudera data platform help businesses collect their data and turn the data into reliable business operations, new insights, and business opportunities.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "aa8f19b0-2e3e-4225-bc67-bf5ebfd30f7d": {"__data__": {"id_": "aa8f19b0-2e3e-4225-bc67-bf5ebfd30f7d", "embedding": null, "metadata": {"file_name": "Solution-Brief_VCDN.pdf", "publication_date": "August 2021", "referenced_websites": ["www.supermicro.com"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "As a global leader in high-performance, high- efficiency server technology, and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs and enables us to build and deliver application-optimized solutions based upon your requirements. RED HAT Red Hat is the world's leading provider of open source enterprise IT solutions. We're here to help you address change with open principles so that you can navigate today's need for transformation and prepare for the future. With engineers connected to open source communities, the freedom of our subscription model, and a broad portfolio of products that are constantly expanding, Red Hat is here to help you face your business challenges head-on. INTEL Intel is an industry leader, creating world- changing technology that enables global progress and enriches lives. Inspired by Moore's Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers' greatest challenges. In addition, by embedding intelligence in the cloud, network, edge, and every kind of computing device, we unleash the potential of data to transform business and society for the better. Drive Visual Services Innovation Supermicro, Intel, and Red Hat have partnered to develop a first-in-class services delivery platform based on industry-leading Supermicro SuperServer and SuperStorage technologies, 3rd Gen Intel Xeon Scalable processors, and either CentOS or Red Hat Enterprise Linux. Using this innovative solution, communications service providers can rapidly add visual services in their networks to: \u2022 Offer emerging visual services like cloud gaming, virtual reality, and volumetric video are driving the need for more network capacity, higher bandwidth, and ultra-low latency. \u2022 Streamline infrastructure procurement and deployment with a low total cost of ownership (TCO) while ensuring high-quality services for consumers by utilizing pre-configured and pre-tested offerings. \u2022 Reduce the risk of advanced technology with a proven hardware and software reference design that lets you select exactly the best configuration for your application, scaling naturally as your needs expand. Supermicro Solution Overview The Intel Select Solutions for Visual Cloud Delivery Network (VCDN) consists of optimized hardware resources and an open-source software stack residing within a virtualized infrastructure. The solution stack uses the most common and popular open source CDN caching frameworks such as NGINX, Apache Traffic Server (ATS), and Varnish. It also leverages open source media libraries such as FFmpeg and Scalable Video Technology for media transcoding. Acceleration is built into the system for key functions such as cryptography, data compression, and transcoding. The verified Supermicro solution for Service Provider VCDN provides high- performance, well-balanced server systems and flexible configuration options to meet diverse requirements. The solutions utilize NUMA-balanced I/O for maximum throughput and consistent latency. They also feature new memory and storage solution options for improved scalability, reduced latency, and cost savings. Refer to Tables 1 - 3 for configuration details. 12 U.2 NVMe drives in 1U Offers unrivaled performance, flexibility and serviceability Optimized for Enterprise applications and workloads NVME SUPERSTORAGE 10 U.2 NVMe drives in 1U Optimal choice for small to midsize workloads Cost-optimized single-processor design SYS-120U-TNR Ultra SSG-110P-NTR10 SuperStorage Supermicro Solutions for VCDN Performance Configurations Ingredient Base Configuration (DP) Plus Configuration (DP) Server Supermicro Ultra SYS-120U-TNR Supermicro Ultra SYS-120U-TNR Processor 2x Intel Xeon Gold 5318N processor (2.1 GHz 24C/48T, 150W), or 20C/40T @135W, or higher core count/frequency 2x Intel Xeon Gold 6338N processor (2.2 GHz 32C/64T, 185W), or higher core count/frequency DRAM 256GB required Intel Optane Technology 2-1-1-1 128GB (512GB Total) recommended; or, 3x Intel Optane DC SSD P5800X series (400GB) recommended 2-1-1-1 128GB (1TB Total) required Intel Ethernet Network Adapters 1x 100GbE Intel Ethernet 800 series network adapter Total: 100 Gbps 2x 100GbE Intel Ethernet 800 series network adapter Total: 200 Gbps Accelerator 1x Intel server GPU recommended Storage Capacity 6x Intel SSD D7-P5510 series (3.84TB) required; or, 6x Intel SSD D5-P5316 series (7.68TB) required 10x Intel SSD D7-P5510 series (7.68TB) required; or, 10x Intel SSD D5-P5316 series (15.36TB) required Storage Boot Drive 2x SATA SSD S4510 @480GB required Table 1: Hardware configurations for dual-processor Supermicro Solution for VCDN Ingredient Base Configuration (UP) Plus Configuration (UP) Server Supermicro SuperStorage SSG-110P- NTR10 Supermicro SuperStorage SSG-110P- NTR10 Processor 1x Intel Xeon Gold 6312U processor (2.4 GHz 24C/48T, 185W), or higher core count/frequency 1x Intel Xeon Platinum 8351N processor (2.4 GHz 36C/72T, 225W), or highercore count/frequency DRAM 256GB required Intel Optane Technology 1x 400GB P5800X Intel Optane SSD recommended 4x 400GB P5800X Intel Optane SSD recommended Intel Ethernet Network Adapters 1x 25GbE Intel Ethernet 800 series network adapter Total: 50 Gbps 1x 100 GbE Intel Ethernet 800 series network adapter Total: 100 Gbps Storage Capacity 4x Intel SSD D7-P5510 series (3.84TB) required; or, 4x Intel SSD D5-5316 series (7.68TB) required 6x Intel SSD D7-P5510 series (3.84TB) required; or, 6x Intel SSD D5-P5316 series (7.68TB) required Storage Boot Drive 2x SATA SSD S4510 @480GB required Table 2: Hardware configurations for single-processor Supermicro Solution for VCDN Media Acceleration Library Intel Media SDK Media Framework FFmpeg Containers Platform KVM OS Support Linux Media Codecs Encode and Decode AVC, HEVC, MPEG2, VP9 Table 3: Media Platform Components Dual-Processor and Single-Processor Base and Plus Configurations Supermicro offers carefully designed hardware platforms that meet or exceed the Intel Visual Cloud Delivery Network (VCDN) reference design guide's requirements to deliver performance and efficiency for exponentially growing consumer streaming media- based applications. Reflecting the flexibility of platforms based on the 3rd Generation Intel Xeon Scalable processor, both dual- and single-processor solutions are offered, each with Base and Plus configurations available. This breadth of offerings by Supermicro gives customers control over the value-performance tradeoffs for different use cases.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "93607f05-856a-450b-b8de-edd9ddfa5a75": {"__data__": {"id_": "93607f05-856a-450b-b8de-edd9ddfa5a75", "embedding": null, "metadata": {"file_name": "Solution_Brief_StratusCore_Ravel.pdf", "publication_date": "July 2023", "referenced_websites": ["www.ravelinc.com", "https://ravelinc.com/partner/#", "https://www.supermicro.com/en/products/gpu", "www.supermicro.com", "https://www.supermicro.com/en/products/superworkstation?pro=cpu%3D2", "https://www.supermicro.com/en/support/resources/cpu-4th-gen-intel-xeon-scalable", "https://ravelinc.com/orchestrate-verify-supermicro/"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "1 Generative AI and Generative Design have emerged as critical considerations in various industries such as Media & Entertainment, Product Design, Manufacturing, Gaming, and AEC. Efficiently building and managing secure turnkey environments for these industries is paramount. To achieve a thriving Generative AI and Design environment, three primary challenges need to be addressed: 1. Adequate computing power: A powerful machine, workstation, or server is essential to handle complex computational requirements. 2. Data and workflow management: Effectively managing the data and image workflows associated with content generation is crucial. 3. Orchestration layer: An orchestration layer is needed to enable seamless communication and coordination between the 1 Solution Highlights 2 For More Information 8 Additional Resources 8 SYS-751GE-TNRT 2 infrastructure and the workflow, yielding desired results. Supermicro and StratusCore have collaborated to develop the industry's first turnkey SuperWorkstation designed specifically for Generative AI and Generative Design. This SuperWorkstation caters to the needs of DevOps administrators, managers, and other end users, empowering them to manage, control, and scale Generative Design workloads for both local and remote content creation teams. The inclusion of StratusCore's no-code RAVEL Orchestrate further enhances the practical utilization of our AI SuperWorkstation within the content creation industries, allowing teams to quickly and efficiently commence their work. By managing Supermicro's Liquid Cooled AI SuperWorkstation's technical resources and other ecosystem components, this solution provides customers with a comprehensive and integrated approach. This solution enables complex workflows and heavy workloads to be efficiently executed within a desk-sized space or easily integrated into existing infrastructures. Its small power footprint ensures a lower total cost of operation and ownership, making it a clear advantage for all stakeholders. Today's DevOps customers, who require swift and efficient initiation of complex workflows with substantial workloads for their content creation teams, will find this solution highly beneficial. While the SuperWorkstation excels as a dedicated AI compute machine, it also offers the versatility of being transformed into a virtualized command center through RAVEL Orchestrate. This solution allows administrators to deploy virtualized technical resources to local and remote content creative team members, showcasing unparalleled range and flexibility. This solution effectively addresses the needs of modern content creation workflows by offering quick start capabilities, managing large workloads, and providing extensive utility through its SuperWorkstation and virtualized command center functionalities facilitated by RAVEL Orchestrate. Solution Highlights A deeper look at Supermicro\u2019s Secure Liquid Cooled SuperWorkstation integrated with RAVEL Orchestrate\u2019s SMART Assembly: Creators and intellectual property (IP) owners are increasingly interested in harnessing the potential of Generative AI and Generative Design technologies. They have a range of options at their disposal, including open-source technologies such as Stable Diffusion, Open AI, and Midjourney, as well as Adobe's Firefly, which offers a content authenticity model. Recognizing users' diverse needs and preferences, the SuperWorkstation solution ensures flexibility to support exploration and IP protection. This collaborative solution allows creators and IP owners to freely explore the open-source technologies mentioned, empowering them to experiment and innovate with Generative AI and Generative Design. Simultaneously, it caters to those who prioritize safeguarding their intellectual property via engines such as Adobe's Firefly, which offers robust content authenticity measures. By providing support for both options, our SuperWorkstation solution ensures that users can choose the best approach to their objectives, whether exploration or protection of their valuable IP assets. 3 Use Case #1 \u2013The Generative AI/Design Compute Working Server (GPU SuperServer) In this specific use case, an existing environment is already in place, whether on-premise, in the cloud, or a hybrid setup. The objective is to integrate the Liquid Cooled Workstation seamlessly with the existing systems. To accomplish this, two primary requirements need to be addressed: \u2022 Validate the equipment and architecture outlined above as the optimized and approved schematic that will maximize the utilization of the Liquid Cooled AI Workstation. \u2022 Deploy RAVEL Orchestrate to manage the associated infrastructure and environment efficiently. By implementing RAVEL Orchestrate, the Generative AI and Generative Design workflows can be effectively managed in conjunction with virtual workstations located either on-premise or in a data center. It ensures seamless integration with the associated infrastructure components, including license servers, storage area networks (SANs), network-attached storage (NAS), and more. Additionally, the flexibility of RAVEL Orchestrate extends to managing and enabling virtual environments for various content creation workflows. This configuration provides comprehensive support for AI engine training, inference, 3D modeling, rendering, high-powered virtual workstations, as well as persistent servers and workstations. Moreover, it enables remote users to access and utilize the system efficiently, regardless of location. 4 Use Case #2: A clustered environment for Generative AI and Generative Design for SMBs or smaller installations with the ability to scale and collaborate with other team members. This solution is scalable in an established environment, whether on-premise, in the cloud, or in a hybrid setup, and this configuration provides a streamlined infrastructure solution. It focuses on deploying a compact and scalable system that efficiently supports GPU and AI/ML generative content production. This setup is particularly suitable for demonstration purposes, allowing for easy node expansion to enhance disaster recovery and ensure high availability in production scenarios. RAVEL Orchestrate is critical in managing Generative AI and Generative Design workflows, seamlessly integrating with virtual workstations on-premise or in a data center. It effectively handles associated infrastructure components such as license servers, storage area networks (SANs), network-attached storage (NAS), and more. Furthermore, RAVEL Orchestrate exhibits the necessary flexibility to manage and enable virtual environments for any content creation workflow. This configuration provides robust support for various tasks, including AI engine training, inference, 3D modeling, rendering, high-powered virtual workstations, and persistent servers and workstations. Moreover, it offers the advantage of facilitating remote user access, effectively allowing individuals to utilize the system regardless of physical location. Design achieving unprecedented peak performance. 5 General Use Case #3: A core cluster ready to scale immediately for medium and larger organizations and team members. This configuration is intended for teams that have already established their environment, whether on-premise, in the cloud, or a hybrid setup and are prepared to leverage the power of GenAI/Design for their operations. Designed to optimize medium to large-scale infrastructures, this configuration is adaptable to various established environments, including on-premise, cloud, and hybrid systems. Utilizing virtualized servers enables efficient GPU and AI/ML- driven content generation. This solution is particularly well-suited for production environments where high availability and disaster recovery mechanisms are already in place. It provides an optimal approach for deploying GPU-enabled workstations on a medium-to-large scale, regardless of whether the operating environment is cloud-based, hybrid, or on-premise. RAVEL Orchestrate is the management tool for overseeing Generative AI and Generative Design workflows, seamlessly integrating with virtual workstations on-premise or in a data center. It effectively handles the associated infrastructure components, including license servers, storage area networks (SANs), network-attached storage (NAS), and more. Furthermore, RAVEL Orchestrate is versatile enough to manage and enable virtual environments for any content creation workflow. This configuration offers comprehensive support for a wide range of tasks, such as AI engine training, inference, 3D modeling, rendering, high-powered virtual workstations, and persistent servers and workstations. Additionally, it facilitates remote access, allowing users to operate the system efficiently from anywhere. 6 Supermicro, in connection with StratusCore\u2019s RAVEL Orchestrate, supports the following Generative AI and Design workflows: AutoDesk, Inc Adobe, Inc AVID, Inc. AI Generative Software Knowledge Generative Game Development Media & Entertainment Collection including: Maya, 3DS Max, Motion Builder, Creative Cloud Including: Photoshop, AfterEffects, Premiere Pro NEXIS Storage Stable Diffusion Llama - Large Language Models (LLM) Unity Unreal Architecture, Engineering, and Construction: Collection including AutoCAD, Revit, Civil 3D Generative AI & Design: Plug-in support includes Stability Diffusion, File Transfer Service Media Central - Production Engine Media Index Production Services Cloud UX Ingest Asset Management Stability-AI StableStudio Lamda Stanford Alpaca Product Design & Manufacturing: Collection including Inventor, AutoCAD, Fusion360 *Other uses cases, including Life Sciences and AI & Deep Learning, are also applicable Supermicro Hardware Configurations: Product Type Supermicro Product Processor Memory OS Expansion Network Storage Display Power A-100 box for Gen AI/Desi gn SYS-751GE- TNRT Dual 4th Gen Intel Xeon Scalable processo rs 8480+ - up to 112 Cores 64GB - Up to 1 TB DDR5 RAM Windows 11 Pro 2 or 4 NVIDIA A100 80GB GPU 2x 10GB Base T Lan ports 1 -2x NVME for OS and Apps & 1 - 8x 4TB NVMe PNY NVIDIA T1000 1+1 2200W Redundan t 80 PLUS Titanium Level ESXi Host SYS-751A-I Dual 4th Gen Intel Xeon Scalable processo rs 8480+ - up to 112 Cores 256GB - Up to 1 TB RAM VMWare ESXi v8 u3 with NVIDIA Drivers 2x 10GB Base T Lan ports 2x 6.7TB 2.5\" Magnetic (OS and App installatio n) RAID Cluster 2x NVIDIA RTX 4000 2000W PS2 Multi- output 80PLUS Platinum Level ESXi Host - Storage for SSG-631E- E1CR16L - - - - - Storage SAN - iSCSI or FC connection - - 7 vSphere . RAID 5 or better ESXi - Virtual workstat ions - 16 Core - Up to 96 per compute resource 96GB of RAM Windows 10 Pro, 11 Pro, Server 2019, or Server 2022 - - - GPU Pass- through required for graphic acceleratio n - The Supermicro SYS-751A-I workstation is an air cooled system. Specifically, the layout is detailed below: 8 The Trial and the \u201cVerify\u201d Opportunity: The Liquid Cooled AI SuperWorkstation powered by StratusCore\u2019s RAVEL Orchestrate is now available for trial. The trial program is called Verify. StratusCore and Supermicro have collaboratively developed a comprehensive turn-key solution allowing end users to test and experience a sophisticated Generative AI and Generative Design workflow, executed on Supermicro's AI SuperWorkstation, and integrated with RAVEL Orchestrate, a no-code SMART Assembly product, ensuring seamless workflow management. This demonstration leverages a combination of cutting-edge technologies, including: 1. Open source latent text-to-image and image-to-image diffusion models, utilizing Stable Diffusion, to generate high-quality content. 2. Adobe's Creative Tools, such as Adobe Photoshop and Adobe Premiere Pro , enable creative enhancements and content refinement. 3. Autodesk's Maya and 3DS Max provide robust 3D modeling and animation capabilities. 4. Virtualization technology for efficient resource allocation and management. 5. Secure access control and identity management to ensure data integrity and user authentication. Sign-up for our VERIFY turnkey Proof Of Concept: Select customers and partners are granted virtualized access to the SuperWorkstation trial, hosted at Supermicro's state-of- the-art lab in San Jose. Please note that availability for these trials is limited and provided on a first-come, first-serve basis. For further information and to sign up for this valuable opportunity to trial the solution, please visit the following link:", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "cbb945ea-f537-4e09-be5a-eb511e465983": {"__data__": {"id_": "cbb945ea-f537-4e09-be5a-eb511e465983", "embedding": null, "metadata": {"file_name": "Solution-Brief_NETINT_4K_Streaming.pdf", "publication_date": "April 2022", "referenced_websites": ["https://www.supermicro.com/en/Aplus/system/1U/1114/AS-1114S-WN10RT.cfm"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "With the birth of the metaverse and interactive streaming video applications such as cloud gaming and video conferencing, streaming video platforms face operational pressure to improve encoding performance and power efficiency while minimizing their environmental footprint. The Supermicro 4K Video Transcoding Solution future proofs hyper-scale real-time streaming video platforms with higher performance levels than CPU-based software-encoding systems. With NETINT Codensity ASIC-powered video processing units, video services provide can reduce their TCO and server footprint by 5x (80 channels vs. 16 channels) while also reducing carbon emissions significantly as compared to CPU-powered software video transcoders. This increase in encoding density expands the number of channels that can be encoded without increasing the rack footprint. Reduced power and HVAC cost mean a lower TCO and higher density can be achieved without sacrificing video quality or latency. 1 Supermicro NETINT Solution 1 Key Benefits of Supermicro 4K Streaming Solution 2 Total Cost of Ownership 2 Simple Integration 4 Summary and Additional Resources 4 Supermicro is the leading innovator in high- performance, high-efficiency server and storage technologies and a premier worldwide provider of advanced server Building Block Solutions for Enterprise Data Center, Cloud Computing, Artificial Intelligence, and Edge Computing Systems. Supermicro is committed to protecting the environment through its \u201cWe Keep IT Green\u201d initiative by providing customers with the most energy-efficient, environmentally friendly solutions available on the market. Supermicro AS-1114S-WN10RT 2 The Supermicro NETINT Solution The Supermicro 4K Video Transcoding Solution is built on the Supermicro A+ Server 1114S-WN10RT platform and features advanced encoding capability enabled by ten NETINT T408 Video Processing Units. The T408 VPU is powered by the Codensity G4 ASIC video transcoder and supports HEVC and H.264 video encoding at up to 4K resolution and with 10-bit HDR. The high throughput of the Supermicro 4K VideoTranscoding Solution enables ultra low latency encoding of 40 broadcast quality 1080p60 streams in a compact 1RU form factor. Figure 1- Supermicro 4K Real-time streaming solution (AS-1114S-WN10RT and NETINT Codensity T408 Video Transcoder) Figure 2 - NETINT Codensity T408 Video Transcoder as PCI-E or NVMe form factor 3 Key Benefits of Supermicro 4K Streaming Solution \u2022 Ultra-High Density: Ten times increase in video encoding density as compared to the software encoding approach \u2022 Real-Time Encoding: Optimized for live streaming and interactive video applications \u2022 Low Latency: Enables Interactive video applications, including Cloud Mobile Gaming, AR, and VR \u2022 4K/UHDTV/HDTV: Supports a wide variety of streaming applications. \u2022 HEVC, H.264: Multi-format Transcoding, Encoding, and Decoding support \u2022 Scalable: High capacity encoding throughput for rapid deployment of additional channels (streams). Total Cost of Ownership (TCO) The Supermicro 4K Video Transcoding Solution enables a reduction in TCO for hyperscale cloud platforms and video service providers. Power Consumption Using Codensity ASIC-powered video processing units, video services, and platforms can reduce their TCO and server footprint significantly. The Supermicro 4K Video Transcoding solution can process 80 streams compared to the software only 16 streams simultaneously, a 5X improvement. The ASIC-powered solution used only 323 watts compared in this test, compared to 460 watts for the software solution, a 30 % improvement. With reduced power consumption, carbon emissions are lowered as well. This increase in encoding density expands the number of channels that can be encoded without increasing the rack footprint. In addition, with reduced power, the HVAC costs are reduced, meaning a lower TCO without sacrificing video quality or latency. See below for the testing result comparing between traditional x86 server (using 3rd Gen AMD EPYC cores) and the Supermicro 4K streaming solution (with 10 NETINT408 modules) while doing the H.264 to H.264 transcoding. Figure 3 - Power Consumption Comparison of The Supermicro 4K Video Transcoding Solution vs. Software Only 0 100 200 300 400 500 0 10 20 30 40 50 60 70 80 POWER CONSUMPTION CHANNELS CHANNEL VS POWER CONSUMPTION SMCI 4K streaming server SW encoding (128 x86 threads) 4 Channel Throughput Regarding the video quality and performance, please refer to the below chart. This metric represents the FPS (frame per second) on every single channel. Supermicro 4K streaming Solution can support higher density channels with lower power consumption and performs with a much better FPS rate than the traditional SW transcoding approach. With support for up to 64 channels simultaneously, the Supermicro 4K streaming solution can still support up to 1080p at 32 FPS rate. Figure 4 - Performance Comparison of The Supermicro 4K Video Transcoding Solution vs. Software Only Simple integration Leveraging FFmpeg, the Supermicro 4K Video Transcoding Solution provides an open-source suite of video processing tools. Video operators can easily and quickly integrate the Supermicro 4K Video Transcoding Solution into their existing encoding infrastructure. Supermicro partner NETINT also provides excellent documentation support such as Quickstart Guide, System integration, and programming guide to help the whole evaluation process. The complete API Guide allows the customer to seamlessly integrate such high-performance, low-cost streaming servers into their systems. Integrating NETINT's next Gen product, Quadra, with Supermicro system management software is ongoing to provide a more intuitive hardware health status via the Supermicro server Web GUI interface. Summary The Supermicro AS- 1114S-WN10RT server with NETINT Codensity T408 Video Transcoder offers a higher performance with less resource requirements than software only 4K streaming solutions that are currently available. It is well-suited for high- resolution video streaming markets showcased by these test results. In addition, the fully integrated system has solved the challenge of high power costs caused by growing video demand. With a workload optimization mindset in mind, Supermicro 0 20 40 60 80 100 120 140 160 180 200 0 10 20 30 40 50 60 70 FRAME PER SECOND CHANNELS FPS VS CHANNELS SMCI 4K streaming server SW encoding (128 x86 threads) 5 once again brings the faster, better, and greener solution to the market, and $200 for a single High definition channel stream is no longer a dream. Specifications of the Supermicro AS-1114S-WN10RT with NETINT Codensity T408: Compute AMD EPYC 7002/7003 Series Processor Memory Up to 4TB (16 DIMMS) NVMe Support 10x PCI-E Expansion Up to 3 x PCI-E Slots Network Options Dual 10GBase-T LAN Maximum Power 700W: 100 -140Vac 750W: 200 \u2013 240Vac 750W: 200 \u2013 240Vdc (for CCC only) Transcoders 10 x NETINT T408 Transcoding Capacity 4K @ 60 FPS | 1080p@240fps x 10 T408 VPUs Codec Support H.264 \u2013 Encode & Decode H.265 \u2013 Encode & Decode Table 1 - Supermicro 4K Streaming Solution Specifications", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "fc3d5aee-2772-450e-a73e-ce0223fb5c29": {"__data__": {"id_": "fc3d5aee-2772-450e-a73e-ce0223fb5c29", "embedding": null, "metadata": {"file_name": "Solution-Brief_cnvrg.io.pdf", "publication_date": "April 2021", "referenced_websites": ["https://cnvrg.io/wp-content/uploads/2020/10/cnvrg-data-sheet.pdf)", "www.gartner.com/document/3994947?ref=solrAll&refval=282401476."]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Machine Learning (ML) has seen extraordinary growth in the last two years. While 70% of enterprise AI practitioners are exploring AI use cases, only 7% are able to deploy and scale across business units.1 Over the next two years, it's predicted by Gartner that 50% of IT leaders will struggle to move their AI predictive projects past proof of concept to a production level of maturity.2 The top barrier enterprises face to scaling AI is the complexity of integrating the solution within existing enterprise applications and infrastructure. Supermicro provides state-of-the-art servers for computing, storage, and networking and works with partners to provide integrated, differentiated, and affordable solutions for various use-cases. cnvrg.io delivers an operating system for machine learning that provides Data Science and IT practitioners a unified control plane that manages diverse ML and DL workloads and enables ML in production at scale. 1 Shimmin, Bradley. Omdia, 2020, Fundamentals of MLOps, omdia.tech.informa.com/OM012245/Fundamentals-of-MLOps. 2 Brethenoux, Erick. Gartner, 2020, Top Strategic Technology Trends for 2021: AI Engineering, 1 An End-to-End AI Solution 2 Focus on Speed and Best in Class Experience 4 Key Features 5 Conclusion 7 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to-end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application- optimized solutions based upon your requirements. 2 Supermicro and cnvrg.io \u2013 An End-to-End AI Solution Industry Problem 65% of data scientists\u2019 time is being spent on heavy engineering tasks like data verification, monitoring, configuration, compute resource management, serving infrastructure, and feature extraction.3 This is causing \u201cTechnical Debt\u201d that reduces AI applications\u2019 ROI and a loss in revenue. On the other hand, data scientists work in silos. IT managers cannot provide scalability and implement required compliance over the operations performed by the data scientists. Unified AI Operating System Solution Supermicro worked with cnvrg.io to provide an end-to-end solution for this problem. The foundation of this solution is built on top of a scalable storage platform using Supermicro storage servers. Then the control and compute layers were built using Supermicro\u2019s state-of-the-art CloudDC and GPU systems. Ceph storage and Kubernetes are installed on these control, compute, and storage components which together provide a scalable infrastructure as a service (IAAS) layer. 3 cnvrg.io internal survey ( 3 Below is the rack diagram and the sample configuration for the cnvrg.io POC cluster. cnvrg.io is installed on top of this Supermicro IAAS layer. cnvrg.io serves the extreme needs of DevOps and IT Ops by providing: \u2022 Sophisticated meta-scheduling that accomplish high infrastructure utilization (>90%) \u2022 Infrastructure utilization dashboards with different views (per data scientist, project, server, etc.) providingability to segment available compute infrastructure per team or as one pool. \u2022 It is quick and easy onboarding, all based on containers and packaged for simple installation and stand-up (helm, Kubernetes, etc.). \u2022 Integration with one container catalog optimized to increase the performance of Supermicro servers, featuring 3rd Gen Intel Xeon Scalable Processors for accelerated AI workloads. \u2022 Accelerated workloads, with the ability to launch any ML or DL framework in one click with direct integration to optimized containers from NVIDIA NGC \u2022 Compatible with existing infrastructure, hence no silos need to be created. Scaling your Supermicro AI servers with cnvrg.io is simple. With one click, you can add more installed hardware to the managed infrastructure. Launch Any ML or DL Framework with One-Click Accelerated workloads, with the ability to launch any ML or DL frameworks in just one click with direct integration to optimized containers from both Intel and NVIDIA, engineered to increase the performance of Supermicro servers featuring 3rd Gen Intel Xeon Processors and NVIDIA GPUs for AI workloads. 4 Accelerate Time to Value with Frictionless MLOps Workflows The cnvrg.io platform, running on Supermicro AI-ready servers, provides data scientists with accelerated project execution from research, to training, to production. cnvrg.io enables enterprises to manage and scale ML in any environment quickly. Data scientists can run ML pipelines on diverse workloads to achieve maximum performance and accelerate time to production. Increase Data Science Productivity Data scientists can easily manage, experiment, track, version, and deploy models in one click in one unified solution. Its container-based framework is designed to be agnostic and portable. It solves key MLOps challenges to help data scientists deliver more models to production fast. Maximize Server Utilization with AI Workload Visibility This solution allows real-time visibility of your AI workloads. The MLOps Dashboard summarizes granular perspectives of your entire workflows to identify bottlenecks so you can maximize Supermicro server utilization. cnvrg.io MLOps helps streamline AI application delivery, so data science teams and IT can more effectively manage users, workloads, models, datasets, experiments, and more while speeding continuous application delivery. 5 Focus on Speed and Best in Class Experience \u2022 cnvrg.io running on Supermicro AI-ready servers delivers data scientists and AI practitioners one unified control plane to build, deploy and manage machine learning workloads. With cnvrg.io, data scientists can bring high-impact models to production faster and monitor models on top of the Supermicro AI purpose-built solutions. \u2022 Supermicro and cnvrg.io integrated solutions improve collaboration and governance, providing a single place for IT engineers, DevOps engineers, ML engineers, data scientists, and researchers to share and achieve AI-driven results. \u2022 cnvrg.io offers data scientists execution of a complete pipeline on Supermicro servers without understanding the infrastructure or configurations. With cnvrg.io and Supermicro, data scientists can build dynamic end-to-end ML/DL solutions on heterogeneous compute by running different tasks on maximized CPU and GPUs. \u2022 Data scientists designed cnvrg.io for data scientists. Through research, experimentation, and deployment, all pipeline stages from datasets versioning and management are either Python SDK, CLI, REST APIs, or GUI. \u2022 cnvrg.io offers a quick onboarding for data scientists and improves accessibility to Supermicro servers for any ML or DL workload. Industry-known tools and GUI are used for each stage of the pipeline, optimizing the data scientists' experience and eliminating the learning curve for new tools/GUI. \u2022 cnvrg.io improves the scalability of your AI infrastructure. cnvrg.io makes the coordination of resources easier to manage and effectively pools your infrastructure into a more consumable manner. \u2022 While cnvrg.io offers one-click development and deployment of ML pipelines to Supermicro Servers, it can also auto- detect the lack of resources and burst your workload to the cloud of your choice. \u2022 Unlike other platforms, each stage of the pipeline can be attached to a different resource, including the support of multi-cluster and heterogeneous compute pipelines. \u2022 cnvrg.io will support the environment of your choice, be it Kubernetes, bare-metal, or any hypervisor (e.g., KVM. All can co-exist within your Supermicro clusters. Key Features: Heterogeneous Compute Pipelines: Launch and manage end-to-end heterogeneous ML pipelines where each component or stage (in a single pipeline) can run on a different compute architecture optimized for the specific use-case: preprocessing and/or inferencing on CPU, deep learning training on GPUs, and inference in the edge. MLOps Utilization Dashboard: Improve visibility across all ML runs. cnvrg.io dashboards have been proven to increase infrastructure utilization by up to 80% with advanced resource management. cnvrg.io gives data engineers and IT the tools to monitor utilization, properly size the compute components and visualize who uses what, with extensive cluster utilization visualization. Open Platform: cnvrg.io was designed to be an open and flexible platform. As a code-first platform, users are free to build in any environment, in the language of their choice, and with the tools they love. cnvrg.io is container-based making it easy to use any image or framework easily. 6 High-performance Infrastructure: cnvrg.io will help increase utilization of your infrastructure while Supermicro delivers the highest performance for both your AI training, inferencing, and deployment workloads. Sample Configurations: For use cases that require acceleration for frequent training or high throughput inferencing of deep models. 2U 6-GPU System Configuration Type Description Per System Cluster Config System SYS-220GP-TNR 2U 6-GPU SuperServer 1 6 CPU 3rd Gen Intel Xeon Gold 6330N Processor (28C, 165W, 2.2GHz) 2 12 GPU NVIDIA A100 40GB HBM2 PCIe 4.0 6 36 Memory 64GB DDR4-3200 2Rx4 LP (16Gb) ECC RDIMM 16 6TB AOC M.2 LP, PCIe3 x8, dual-port NVMe M.2 carrier 1 6 OS M.2 Intel DC P4511 2T NVMe M.2 22x110mm up to 1DWPD 2 12TB Storage Intel D3-S4510 3.84T SATA 6Gb/s 3D TLC 2.5\" 7mm <2DWPD Rev.2 4 92TB AOC [NR]Mellanox MCX651105A-EDAT PCIe Single-port 100Gb/s IB-HDR QSFP56 1 6 AIOM AIOM dual-port 10GBase-T, Intel X550 2 12 7 Use cases targeting, general or uniform infrastructure, traditional ML-algorithms, DL inferencing, and training in both single instance/node and distributed execution patterns. CloudDC System Configuration Type Description Per System Cluster Config System SYS-120C-TN10R CloudDC Server 1 3 CPU 3rd Gen Intel Xeon Platinum 8368 (38C, 2.40G, 270W) 2 6 Memory 64GB DDR4-3200 2Rx4 LP (16Gb) ECC RDIMM 16 3TB OS M.2 Kioxia XG6-P 2TB NVMe M.2 22x80mm 0.3DWPD 2 6TB Storage Kioxia CD6 7.68TB NVMe PCIe 4x4 BiCS4 2.5\"15mm SIE 1DWPD 10 230TB AOC Standard low-profile card based on Broadcom BCM57504. Two QSFP28 100Gbps Ethernet port PCIe 4.0 x 16 1 3 AIOM AIOM dual-port 10GBase-T, Intel X550 2 6 Fans Counter-rotating, 23.3K-20.3K RPM 6 18 Conclusion With a wide variety of Supermicro systems, cnvrg.io could maximize its AI OS potential, significantly reduce the time-to- market value, clearly visualized ML pipeline workflow, and dramatically improve end-user experiences. For on-prem private cloud, the 1U CloudDC fits in the role of infrastructure and ML inferencing nodes. The 2U GPU server, on the other hand, is equipped with six NVIDIA A100 PCIe 40GB GPUs to provide ample resources for cnvrg.io AI OS to train large and extensive models. Combining new 3rd Gen Intel Xeon Scalable processor-powered Supermicro systems with the cnvrg.io platform is one of the best AI solutions on the market. About cnvrg.io cnvrg.io is an AI OS, transforming the way enterprises manage, scale, and accelerate AI and data science development from research to production. The code-first platform is built by data scientists for data scientists and offers unrivaled flexibility to run on-premise or cloud. From advanced MLOps to continual learning, cnvrg.io brings top-of-the-line technology to data science teams so they can spend less time on DevOps and focus on the real magic - algorithms. Since using cnvrg.io, teams across industries have gotten more models to production resulting in increased business value.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}, "0d72b45b-56f5-475e-9569-1b2d9edefa49": {"__data__": {"id_": "0d72b45b-56f5-475e-9569-1b2d9edefa49", "embedding": null, "metadata": {"file_name": "Solution-Brief_SMCI_NVIDIA_Cloudera_Spark.pdf", "publication_date": "August 2021", "referenced_websites": ["https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark.html", "https://www.nvidia.com/en-us/data-center/a100/", "https://www.supermicro.com/en/products/ultra/", "https://www.nvidia.com/en-us/data-center/products/a30-gpu/", "https://developer.nvidia.com/blog/accelerating-apache-spark-3-0-with-gpus-and-rapids/", "https://www.infoq.com/articles/deep-learning-apache-spark-nvidia-gpu/", "https://www.supermicro.com/solutions/Solution-Brief_SuperCloud_Composer.pdf"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": ["file_name", "publication_date", "referenced_websites", "section_summary", "excerpt_keywords", "questions_this_excerpt_can_answer"], "relationships": {}, "text": "Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 1 Enterprises have embraced digital transformation to extract insight from their data to improve business processes, increase productivity with the same investment envelope, reduce costs, and create a new offering to generate higher revenue and profit. Across industry sectors, enterprises are collecting more data, increasingly applying machine learning and deep learning to leapfrog their competition and grow faster. Supermicro has partnered with Cloudera and NVIDIA to create a platform consisting of Supermicro's Ultra Servers, Cloudera Data Platform Private Cloud Base (CDP-PVC-Base), and NVIDIA RAPIDS on GPU. Cloudera provides enterprise-level support for Apache Spark 3.x and other open-source software. Supermicro Ultra servers are powered by NVIDIA A30/NVIDIA A100 GPUs and NVIDIA Networking to accelerate Apache Spark 3.x workloads significantly \u2013 5X faster than CPU based computing. 1 Supermicro Ultra Servers and NVIDIA GPUs 2 Addressing Customer Problems using Insights from Data 2 Delivering the Infrastructure for Data Solutions 5 Enterprise Data Analytics / ML Applications (1) 5 Data Preparation for Deep Learning Pipelines (2) 6 Apache Spark 3.x with NVIDIA GPU Acceleration 6 Cloudera Data Platform Private Cloud Base 7.1.7 7 Red Hat Enterprise Linux 7 Supermicro SuperCloud Composer 7 Supermicro Server Cluster running CDP PVC Base, Spark 3.x . 8 Conclusion, References 8 As a global leader in high performance, high efficiency server technology and innovation, we develop and provide end-to- end green computing solutions to the data center, cloud computing, enterprise IT, big data, HPC, and embedded markets. Our Building Block Solutions approach allows us to provide a broad range of SKUs, and enables us to build and deliver application-optimized solutions based upon your requirements. Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 2 In addition, the platform can also prepare, cleanse, and feed data into deep learning training pipelines. This shows the Apache Spark 3.x cluster's benefits and critical components for deployment in enterprise hybrid data centers. The platform accelerates business insights from customer data to optimize the business and deliver higher revenue. Supermicro Ultra Servers and NVIDIA GPUs Supermicro Ultra servers are high performance systems that support GPUs. They support either 3rd Gen Intel Xeon Scalable processors or 3rd Gen AMD EPYC processors, using the latest PCI-E 4.0 interfaces and NVMe drives. Each server supports up to two NVIDIA A30 or NVIDIA A100 GPUs, which run NVIDIA RAPIDS to drive Apache Spark 3.x acceleration. In addition, high performance system memory supporting up to 8TB is available to support the in-memory processing for Apache Spark. Additionally, a Supermicro 1U Ultra server may be used as part of the cluster for tasks that are not accelerated with the NVIDIA A30 or NVIDIA A100 GPUs. Addressing Customer Problems using Insights from Data Enterprises across all industries have seen the emerging power of analytics and machine learning from their data. For example, credit analysts minimize loan loss provision in the finance industry using analytics and machine learning based on customer data, macro- economic information, and transaction data. Likewise, in media entertainment, marketers can better maneuver through GDPR rules by applying analytics and machine learning to the customer, location, and country-specific information. These examples are early indicators of how machine learning can improve business results. SERVER CLUSTERS SUPPORT CLOUDERA DATA PLATFORM PRIVATE CLOUD BASE AND SPARK 3.X WITH NVIDIA GPU/RAPIDS ACCELERATION Supermicro server cluster with NVIDIA A30/ NVIDIA A100 GPU delivers scalable machine learning processing using Cloudera CDP Private Cloud, NVIDIA RAPIDS, and Spark 3.x. The Supermicro Super Cloud Composer manages the cluster using Redfish v1.8 and IPMI. Glossary Apache Spark 3.x Software to build resilient, scalable cluster for machine learning, with programming interface. Spark 3.x provides the latest feature and performance enhancement, adding GPU acceleration Cloudera CDP Private Cloud Base Software platform that delivers integrated Apache Spark and other functions with enterprise support NVIDIA A30 NVIDIA GPU for DL/ML, 3584 CUDA cores, 24GB HBM2 NVIDIA A100 NVIDIA GPU for DL/ML, 6912 CUDA cores, 40/80GB HBM2e NVIDIA RAPIDS NVIDIA suite of software libraries, built on CUDA-X AI, to execute data science and analytics pipelines using GPUs. Supermicro Ultra server 1U or 2U volume server supporting GPU. Choice of 3rd Gen Intel Xeon Scalable Processors and 3rd Gen AMD EPYC CPUs. SuperCloud Composer Supermicro management software providing a single-pane- of-glass monitoring of server clusters, in-band and out-of-band control, network OS booting. SYS-220U-TNR SYS-120U-TNR Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 3 Table 1 shows examples of different industry sectors, their specific data, and the consequential results from applying machine learning and deep learning to the data. As part of their digital transformation initiatives, enterprises are collecting more data. Data come from customer interactions, industry information, databases, and even sensors. In addition, enterprises now adopt machine learning and deep learning, as these technologies have matured for business deployment. Cloudera has evolved its offering for machine learning pipelines in the past decade for enterprises. Cloudera Data Platform Private Cloud Base's (CDP-PVC-Base) broad capability enables implementing the entire data pipeline, from data collection using Kafka, to retention and access on unstructured and structured data, to data analytics running on Apache Spark 3.x. CDP-PVC-Base can also provide data preprocessing to front-end the deep learning pipeline using deep neural networks running in intensive GPU clusters. Using data processing algorithms in Apache Spark 3.x in CDP-PVC-Base, enterprises can optimally clean and prepare data for deep learning training. The resulting deep learning inference models then process new incoming data to make predictions or decisions. Thus, the deep learning system enhances business operations for the enterprise. Supermicro offers Ultra server clusters running CDP-PVC-Base and NVIDIA GPUs to accelerate Apache Spark 3.x, delivered with Cloudera software. In addition, the Cloudera Data Platform Private Cloud software has incorporated the NVIDIA RAPIDS libraries, which enables compute acceleration on the NVIDIA GPU for components of Spark 3.x. Supermicro's Ultra Server Clusters support NVIDIA A30/NVIDIA A100 GPUs, and they are validated for performance, manageability, security, and scalability backed by enterprise-grade support. This platform enables enterprises to increase revenue and productivity by gaining insights from their data. Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 4 Industry Selective Data Selective Results Finance Asset prices, policies, call recordings, compliant logs, claims, economics, credit, loan, regulatory information. Credit risk analysis, fraud detection, return on equity Telecom Subscribers, cells, connections Network quality, OSS, Geospatial Healthcare Confidential patient records Patient flow forecasting, nurse staffing levels Life Sciences Clinical trials, reports Health diagnosis, data extraction automation Media Entertainment Mobile data, search data, customer viewing data Advertising fraud detection, Enforcing GDPR, User behavior analytics Transportation Public transportation operation data, passenger ride data Efficient operation of a transportation system Travel Hotel data and pricing Customer trip planning, Customer recommendations Public Sector Intelligence data, public records data (tax, welfare claims, etc.) Crime prevention, cyberattack prevention, reduced fraud costs Retail, E-commerce Merchant and user interactions Targeted offers, enhanced customer experience Energy Sensor data, consumption data Optimal energy generation in Smart Grid Manufacturing Picture and video data, equipment data Efficient manufacturing flow Others Large amount of data, time-series data Trend identification, Outlier detection, Process improvements, cost optimization Table 1. Example results of machine learning from selective data in different industries. Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 5 Delivering the Infrastructure for Data Solutions Cloudera CDP-PVC-Base and Apache Spark 3.x deployed on a cluster of NVIDIA GPU-accelerated servers offer a very scalable data analytics solution for terabytes to petabytes of continuous data. Furthermore, Supermicro offers the latest state-of-the-art Intel or AMD CPUs and NVIDIA GPUs with the best price/performance efficiency. The server reliability with built-in redundancies ensures minimal cluster downtime. Supermicro's Super Cloud Composer (SCC) makes it easy to manage server clusters and deploy them in the hybrid data center. SCC monitors the servers, network, and storage from a single pane of glass interface. In addition, Cloudera offers a simple means to deploy the CDP-PVC-Base suite onto the servers. Overall, hardware, software, cluster setup is well organized and ensure correct cluster operations. For enterprise level support, Supermicro offers 24x7 hardware support, while Cloudera provides enterprise class software support. This cluster delivers many applications to process customer data. This presents two of these applications: (1) Data analytics features in Apache Spark 3.x, delivered by Cloudera CDP Private Cloud-Base. (2) Data preparation using Apache Spark 3.x and CDP Private Cloud-Base capabilities to process the incoming data to feed into another AI cluster to perform Deep Learning (DL) training. The DL training produces AI models, which run in DL inference to make predictions or decisions on new incoming data. Enterprise Data Analytics / Machine Learning Applications (1) Data analytics applies statistical and mathematical algorithms to extract insights from data. Be it linear regression on time series data or feature extraction from images or voice or complex data, these algorithms enable fast insights from continuously available data to businesses in various industries. Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 6 Cloudera CDP PVC-Base includes many data analytics capabilities, including: \u2022 Regression to find trends \u2022 Classification and Clustering to put data in different buckets \u2022 Collaborative filtering to build recommender systems \u2022 Frequent pattern mining to analyze large scale dataset \u2022 Model selection and tuning to find the best model or parameters By running data through these and additional algorithms in the Cloudera / Apache Spark cluster, customers can quickly get great insights and make efficient business decisions. Data Preparation, Feature Extraction for Deep Learning Pipelines (2) Deep Learning (DL), using neural network architectures, often enables deeper insight than machine learning. This does require additional technologies, which involve a GPU-based training server cluster and inference servers. When data scientists in an enterprise determine that neural networks or other deep learning algorithms could get even more insights from the available data, Cloudera/Apache Spark has mechanisms to prepare the data to pipeline into DL training clusters. These include the following. Data scientists can combine these programmatically to perform high performance data preparation: \u2022 TF-IDF for word frequency \u2022 Word2Vec for word embedding \u2022 Feature transformers to index, scale, convert data \u2022 Feature selectors to select features using statistical rules Whether the data consist of text, images, or other forms, customers can set up data preparation and extraction to pre-process data to pipeline into DL training, ensuring quick and efficient operations. CDP PVC-Base uses GPUs to accelerate SQL and Data Frame API processing, enabling faster data preparation. Apache Spark 3.x with NVIDIA GPU Acceleration Apache Spark 3.x provides the integrated components for easy deployment of tens to thousands of servers to run scalable in-memory graph processing and computation. Apache Spark 3.x has improved significantly from previous versions. Now, CDP PVC-Base with Apache Spark 3.x supports NVIDIA GPU acceleration natively. CPD PVC-Base uses the GPUs to accelerate SQL, Data Frame API processing. Using a single GPU, we see five times or more performance speedup over CPU based systems. Using multiple GPUs, we see over 43X performance speedups. NVIDIA and Cloudera have worked together to incorporate the NVIDIA RAPIDS libraries, using GPUs, into the CDP PVC-Ba software stack to achieve these performance speedups. Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 7 Supermicro delivers Ultra servers with NVIDIA A30 or NVIDIA A100 GPUs. When adding these GPU servers to a running CPU- based Cloudera cluster, CDP PVC-Base automatically incorporates the GPU systems to accelerate the Apache Spark 3.x workloads, especially for those running Spark SQL and Data Frame APIs. Cloudera Data Platform Private Cloud-Base 7.1.7 Cloudera Data Platform Private Cloud Base provides an integrated platform to run data streaming, storage, and data science and machine learning in server clusters. The software can be easily deployed onto a cluster of servers and be managed using built-in in-band management. In addition, both public cloud and hybrid data center server clusters come with enterprise level support. CDP PVC-Base 7.1.7 incorporates Apache Spark 3.x with NVIDIA RAPIDS GPU acceleration to deliver over five times more performance speedup over CPU based clusters. Red Hat Enterprise Linux Red Hat Enterprise Linux (RHEL) is the operating system supporting Cloudera Data Platform Private Cloud Base. RHEL provides enterprise level support for the operating environment that enables reliable and scalable operations in each Supermicro Ultra server. Supermicro SuperCloud Composer Supermicro SuperCloud Composer (SCC) provides monitoring, management, and server operating systems deployment for server clusters. Using out-of-band IPMI and Redfish management, SCC monitors the health and operation of each server in the cluster. While server clusters are usually set up with multiple networks to support out-of-band, in-band, and data networks, SCC configures the network IP addresses on the servers. SCC can also deploy operating systems images onto one or all the servers. This makes the management and deployment of racks of servers much more manageable. Supermicro, Cloudera, & NVIDIA Accelerate Enterprise Data Analytics 8 Supermicro Server Cluster running Cloudera Data Platform Private Cloud Base and Spark 3.x The starting base Cloudera Data Platform Private Cloud Base has 10 Ultra servers (either 1U or 2U). Many more servers can be added to scale the cluster depending on the amount of data and computing needed. There are options for high availability and data storage. To accelerate Spark Apache 3.x operations, we can add Supermicro Ultra servers with NVIDIA A30 or NVIDIA A100. The Cloudera cluster automatically incorporates additional servers to scale the cluster performance. Supermicro is providing a reference architecture for this cluster in a separate document. Conclusion In collaboration with Cloudera and NVIDIA, Supermicro is delivering high performance server clusters supporting GPUs to provide enterprise level support to customers to turn their data into valuable insights to run their business. The GPU acceleration provides five times and more speedup over CPU operations for Apache Spark 3.x jobs. The CPU-based servers support the other Cloudera streaming, security, governance, and storage functions. Supermicro's SuperCloud Composer monitors the server hardware operations to provide high availability. SCC also deploys the appropriate operating systems to the servers in the cluster, while Cloudera offers a simplified means to deploy the Cloudera applications. Together, Supermicro, NVIDIA, and Cloudera deliver high performance clusters to process customer data into valuable insights to run their business. The entire solution comes with enterprise level support. Contact your Supermicro Sales Team", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n\n", "class_name": "Document"}, "__type__": "4"}}, "Solutions Briefs/metadata": {"86fe0a86-1d46-49f9-a8a9-80c3dc3f9c0f": {"doc_hash": "44c3321ca32a02820d71dce569c3489a62d72562c5f323f5943edf572331e4d4"}, "ffe7d5a1-85e7-4c34-a03e-4f663f0f1489": {"doc_hash": "c45724ea2bda3d882b64cb9aa3a3406acea9931eb733cb54763f46dde2d38059"}, "d2ee3dd3-0b19-4519-995b-35a771683964": {"doc_hash": "772ccc3ae284eea6f3ec3a4be41a2710e78bbde85f0fdc79b5638507e02f4550"}, "7bbdbd71-932e-4a0c-9900-b8f3aea6739d": {"doc_hash": "598bd00092b1232e81e33f0f97a2f82ce56a5cd67740387e14863384b34420ea"}, "924abb07-0347-4dea-bfd1-3a5560150f24": {"doc_hash": "cad3111b16550aee0382fbc72b6b350e454257e75a13213abacdbc85be8d1c60"}, "772d64c8-a099-44b4-8330-361509d8b1a0": {"doc_hash": "32a5f8bffa3565016990191dcdc3f3bfa2b4459630c4c61be8e8e1d13b624ffe"}, "3ad2dd55-4b47-40e6-9177-242646ef40ae": {"doc_hash": "c83228167b8d383404cb38c898ac5f4995226b856305129cbded5639eac3bfe3"}, "a172fcfb-4977-4d19-80f1-7f141afe659b": {"doc_hash": "881fc4cc604e426af6b7a53606d9bab524ecbb0b106e7ac8c5b4fc29fa68fd56"}, "70d43e15-268e-4c7a-b257-13d09bcbd612": {"doc_hash": "78128c961978abbcecb748731be760f8f0d12b7c28dc71bd07040966d9728dde"}, "2cc111cd-9fb3-4c7a-b6c8-dae996c3d096": {"doc_hash": "580d5c4f67c2a9a845c98c25af3ed86b6167c97346090c28bea2780f7465860d"}, "6766352f-50ae-4d7a-829e-548a47b7825d": {"doc_hash": "431011120a43746d988069f9f642e335018c274f4fbd956c42f8e8d06bf3cf19"}, "c4b18504-abe3-474d-9f65-9e08f8f33d31": {"doc_hash": "85e88792cff03320c113403154a02d9cf33b538c8d99cadced9c3c78c7a90219"}, "fd1813f4-de07-4bf7-a85b-5071542441c9": {"doc_hash": "3587df29eecb99200e93a970c5abed357ad371efc79ae80f63c43502b076cc2a"}, "443727e0-5a3d-423d-81c3-b9cf663425a8": {"doc_hash": "979b48c3164b33187564b27638213a8a81eb7c88725719aee727e9570e8338b1"}, "8d5b93df-fb39-4a77-8a7b-0885d709c468": {"doc_hash": "e35884953ee0c35b3a464050ed8cb5d82a0aae5f7da1a6a738acc1ce1a3b7bf4"}, "28a96997-1204-4a98-9799-19bd446ddb81": {"doc_hash": "8b688643e43a0afb0201d43fd30b96b0d02b3efd0d95377436cd140f0a5b4fbe"}, "edcee397-75b8-4588-8b9a-99d89249d537": {"doc_hash": "78986bf890a048e1bfa521801c9aa95edafbe4efaded8f40059fa617ff21dbfe"}, "dc710347-f01c-4a75-bada-e0a1f1d8107f": {"doc_hash": "6438fb5d3ee78fa4636a4fee993fde84719b025389c90009925a0ea1409976f8"}, "5007af9b-ef9e-46f6-9091-cc33ade7bcf7": {"doc_hash": "3ba54450c44cc0463a5de29b971951ee2c7f7b244547838d875075440edf960d"}, "6e692e30-9b52-4af4-bd7d-e29e6d9c9831": {"doc_hash": "99ad51cc30e1c51278e9dd0038d4db8a874100f3162e3bb37617b5f045a25eb4"}, "3d8b2b17-3c26-48d4-b185-ad61d32451bf": {"doc_hash": "2dda10b576358b2a3c5cd9a1e4da8a29160857607aa5913f81a1ba358dc3f670"}, "8cf38e48-7157-4faf-8aa8-750c552c0951": {"doc_hash": "5db715c13ad6d9f647675e0ccccdb702c729614231b531e3696b8debea581845"}, "a945bce4-5e4d-44e8-ab32-e41bae6628e6": {"doc_hash": "09a856d03c206fa6575579cc6f5c184387e6ea66e2a67d3305c646ebc49da31d"}, "dc8d9ce7-39da-4a5b-b0da-27f7cfd87bcb": {"doc_hash": "d10ed5b447ba9618a76e061193e55cddb45f6ceabb69b471cf90bca7b223eb8b"}, "f30a3347-4d2c-4a5e-8ccc-e518c203b6cd": {"doc_hash": "c60ab0ef4937b9ba172418d6fd455f0f41aa395ba80ae2df798a5032701a6f1e"}, "35853b02-f478-4cb5-9551-8f92c37027d6": {"doc_hash": "1fb249af7b35c358269b970665c22f9f5bd960a5cda732c0a916ba6cc4957c8f"}, "37b582cd-dbb9-4089-8711-4635b56ddd2c": {"doc_hash": "8c9ca260e836cf014e4b1c5456eb0095e2294643f44aa8408b78575320f0392d"}, "31dfbc3e-e10a-4655-8287-fe458f064f26": {"doc_hash": "5daeb33d96b4011052c2e8284412829618a2b84f7ac9a074f7b4ecdecb80a28c"}, "b3153eb7-9d8b-43c4-867c-2575ea33215f": {"doc_hash": "27b0c032c5fc1a0049c0df1b0e54e0b23ba0c3068a3e568863a9a6605f5d3786"}, "94e5904d-7b0a-4bfd-ad0d-a806f83cc08d": {"doc_hash": "10262b6893703ec2e0481e926b229d728934e5f04c024c9f628b5725a849dd10"}, "47fdbd38-cbb3-4447-89f9-7e33afddee38": {"doc_hash": "e27911de5e11f099f772d6da19bbd0dcf460468ea362878303d460b1389ff49d"}, "cf3486bf-2196-4496-ac4a-8fb56c902aa3": {"doc_hash": "1ff25eeb78a3845691c2401e804d3935c50cb9a17ae8d153e7826988b46073fb"}, "f062cb4e-0faa-45f6-b677-456d8297ff05": {"doc_hash": "fcc0e3c8d2afe58f7fab310fca9884bf4a1b7624ef14993bf0001ec7fc640df4"}, "1ecb7b94-3e1a-4280-9bfb-a2fcaf0dd584": {"doc_hash": "9fff90da3a880a3cabdcade9c47071adeee8e73d1fa0d8f3fe71b37872711efb"}, "673c0621-8c38-4485-bf97-0f671903ee63": {"doc_hash": "bc5a0b4812f6df458432a482910a2088c73082e1efc49917532e87368f964c5d"}, "b6f484ae-9679-4eff-aa11-3e4319e882ab": {"doc_hash": "048f8116eaba4dfa5e4a8247333937e129f1f8755a308f551970e08aab840e49"}, "d66a1015-657b-46f4-99ca-956e9ae72b66": {"doc_hash": "aea93353779801770c85e1e311e35dd1285f58986f246e14e575ef031b89b63e"}, "c337cc2f-0b50-422f-a66c-b8bdc18ec840": {"doc_hash": "8a9c802e492645e0c9531494f1b39e24be70f42074f51ffdab4122092d2def2d"}, "4c9958f3-f2ef-4c03-b6ae-6b1c812e2832": {"doc_hash": "a1994138d109dc81f719446fd395803765662d858b993bcaf173494ea1f969ca"}, "f17c0ab3-f86e-4f2d-b4ea-62baf9280643": {"doc_hash": "bcc3487bcb807d04a784b7f48bf2df16c7a41e8b44cc5e3b6c781a1c0125da34"}, "d520f882-25d6-49a6-bed5-3eb727b98ecc": {"doc_hash": "8a253ec488025358a4e8985b7266f6ec62b8cbe951910e565e338f3455ce90cf"}, "54f0563b-9dfa-481d-908c-14f5fc2c1068": {"doc_hash": "cda1ba42710235ec02dc36e8fa9f1d4f85e70f2faab55b1965f4280f4cbf18a1"}, "70bac528-b446-49a8-8d9a-b14cbf190e68": {"doc_hash": "92e952ad83be90e19eb956b9d226fee86ee9227bb88231ff07c8df08c335097f"}, "7802d602-b114-43bc-bc1b-0a7eee91835a": {"doc_hash": "37068c00d0318c7c0d40b776fd3909fb48ae55c5dfb0dce11ed04c608322877b"}, "eb10622c-22dc-49a9-9016-9e739c33b588": {"doc_hash": "eaf6089c5330f1444c980790bb8e01996f5b73d823d36644a7741e736595bab8"}, "5573867b-da14-49bc-9224-e17357027d64": {"doc_hash": "c4f4339b39cbba9f9e7322367f5648d9be222d4735866fa8d5b818d032e08f84"}, "0e5aaf01-72e1-4bbe-bb36-e581b080f46c": {"doc_hash": "498e3e2a2a631a7f78f34a538181ae3a5ce47e0f82aaa2bb73bfa9c7c4b9af7e"}, "a6ef55b5-53db-40c7-9d20-dbec4638d85f": {"doc_hash": "86f9e1dc817b033159acefcc8905be283f939749861f3221b1810b73921a7245"}, "ba5ff580-03bd-4850-a91e-44afef00b2b6": {"doc_hash": "3df0fb12a231143e669d95ac7974f7ea719249b94a0045ed4c381bc7533dda84"}, "da99104f-0446-4b42-82b6-9002bfbfc1a8": {"doc_hash": "44d045790b77ebab57e42095ae02a92cdafc328a5e10d29cd94ffda79674c0d5"}, "778adc61-63ec-4676-bde7-8ca9e4e680d4": {"doc_hash": "d8d0d128a703bf65478d5a6727e6e1250b00a563341b52160045b2d459bf27be"}, "c20d2fbf-6578-494a-9206-3312ccce89bf": {"doc_hash": "17e70b426b7690733f99edddbafeb1e78e91c6562143f61c14d4af56bb8504fb"}, "6a2ffa8c-b573-4d54-8782-75dcb69af3fd": {"doc_hash": "69bea2d4e33713cf6eb331a3ff61a0d22d19096a5980ea5f66b0acac9c260b0e"}, "3af86ea8-8180-4495-8103-fba605e48081": {"doc_hash": "e4d8e96b3c675b454ddb4a94e47be597c3981e902cfd42e1be1ea64b7ea21077"}, "27c208e5-3141-42e0-8bd3-5fd676f49010": {"doc_hash": "f8529a06ed6e9026abc0c6098c93f2782adc2bcca1ffa24ebf5ffdb8455fff73"}, "55a65f6e-2dc0-4476-86aa-b951ccbe6445": {"doc_hash": "e735bee5ea980231e89d0692fa3cbe05aa9ed05644202447f5800bedf839db1c"}, "a8a22770-8aeb-4db7-b6b9-a93c150d8149": {"doc_hash": "22d73576af07ee18e081693aa2a9cbe2e2be27129112f428c3ab99cab643c89a"}, "0739bd8d-3315-4197-a08f-7d65853966ab": {"doc_hash": "f5afa19d8118e8fffa047cfc6f6d00d678ea5e7dc32f1b2489a082ebd1fe0de8"}, "8ee35d51-ff3d-45bc-9c78-fa5abfdfce92": {"doc_hash": "86175b5895ff2ba35dc5867cbd3afa9e6dbf2c122a80d78fc182cac6c8e6112f"}, "8ad73ba0-f779-45e2-a0e2-efb524ef8d0b": {"doc_hash": "11a91768770236ca3c51fee79a2d1832de2bb9e8e5d774770d80118ab9c2de7b"}, "3f505baa-3275-4888-b5b5-f750beb86a44": {"doc_hash": "a2a81af018fa4ffca633d41dd315243a77c288eb09e8c57872f188ab4495a67d"}, "f8d459fb-fe26-4e2e-bf64-404f782c4e0a": {"doc_hash": "9a37e7fb20dbe4442bafe5b15a06b89cd3222b1a90c23db3debdec1926f78b81"}, "1b48f32f-cc7f-44b7-9f23-3ebdacc23912": {"doc_hash": "d3842b812d3ed71261b33880cf7937c6fd41289641414ef002905cd4cc0755cc"}, "79c6edd1-bb7d-4129-aa86-54d41a0d655b": {"doc_hash": "6b2fa90a916636ae4141a6192b8333ad316ecd483b38fc1f8e32e3ad478c2243"}, "224b4963-9d84-4a2c-a93c-ebb1eeff4609": {"doc_hash": "5bdc137d3bbc9dd007b0c234f906aef762cf8fb079b2905a6152ece343369985"}, "831992ef-9760-407f-9817-e87de86e9e70": {"doc_hash": "12224f111959baac63a4224c49fecc11ea3295342a6177ac786bb681a3d3a83a"}, "a4731e2d-3b3b-46af-b230-4d6b49f903b7": {"doc_hash": "1bf59ebecc8d2eda4876307ce9849906e1c34a7de8dd01f04bb88bbde0e45ba2"}, "1ef4cb95-5db0-4a7a-a63b-e61054fcfaae": {"doc_hash": "5d99aa71df97b9399bf5d2f6cc589f478bf13441635f89d0948d93e15ef72f98"}, "2798ba4b-2db7-453e-b440-5f82e4844120": {"doc_hash": "3efd6614bf3802fc1324b1df283b4633e72742c52112b4b93289675229ef6d2c"}, "0a196c04-5a8d-4221-9604-3a4ea6a223e8": {"doc_hash": "1a5057e687f89ace9eaee44e1e1364948509d0f700b7605728b1c4e76ba56345"}, "130b32a3-5d81-4922-85f8-7a619cb8aa6c": {"doc_hash": "93dcc94485b98babfa52d3c8bc85473483e2519028935b4206783b26cb219d92"}, "81d4b2c2-ab24-450d-9f63-018ead99033f": {"doc_hash": "30d07edc0cac87d6a46db8a5083204ca1e5fd20d8733c6895477a487c2d424a0"}, "5cee4769-2d41-458a-a0d1-9c9cca9fb36d": {"doc_hash": "0f1808f095378de21cf1b865b4d92a46357c2111acc0b59538e33c6e58d80016"}, "afb5cd69-8cb0-43e2-82f0-6dbe7b30d3d4": {"doc_hash": "9c5b632d5f24b288b586a9cf59f809ac4a21815cca38f1a358d962775fad41f5"}, "a3da80fd-11ac-4dde-a56c-b435bb634a1e": {"doc_hash": "2c3d27b5e06259af7bb43865bcf1ba2d2954f5c8de6f35f4793fa3942a8a9d70"}, "2e3efce5-201c-4c06-9360-26192e01a3ce": {"doc_hash": "7741b04799fdf2f20c7670ffc554a7b2a8cb4d2448b18aee8e515bc23d649751"}, "8451bc53-62da-424e-a184-9a5840cd7f6f": {"doc_hash": "f750f4ea6d55584934a582fed15a295124bc5b02ccf7a3b720c77b23e2e759c4"}, "a4da9962-551f-4335-b4e5-dfd95ed28a1a": {"doc_hash": "86bcc1f1ace0b900d3adb1982c0211c81bda717422e335987679f541859e392a"}, "e882fed3-6a2c-4748-9a78-b0ce4248839a": {"doc_hash": "904725eb38ccf7c78b4ac288ceb61df33c484e2bea0cb79caa0b37cf6e35e093"}, "7838aa35-8a52-4d3d-b905-889caf14918e": {"doc_hash": "845114b4542fa22a32362d61525a11b1f4eecaa1a7804d2f87cf089f91244f94"}, "bb03a8d6-aa47-46cf-b290-7e21eb758ceb": {"doc_hash": "9935cf7b751f5116ba08382a1437c27c4fa3851fbee27b276b0fbd0859e5b0a3"}, "35c93b62-474d-44ca-8ac7-42ebc0440be5": {"doc_hash": "ef665ed784ca47de02f9d8683816792e66ca448f8d1126adb9d34ca2bfc6a5b3"}, "7fdfc929-1269-4177-abe0-493230887159": {"doc_hash": "79c951ad6fd8998b5e244f176f01be455a67e98f00cf26f66ac8240fa0c5dd0c"}, "7f95ba51-808f-4376-b6c6-031f7f5cea7f": {"doc_hash": "d5b0f2a81a11b97be2bc79b0e5e28bf89ce15b40ba2e874212bcca99ece8bc7d"}, "4741b0ea-13ba-4c77-bcbc-945a0c57cf03": {"doc_hash": "2c385c0c6f85fcb65fce635d218c0b4d2837158187b6a91d30d1e7e04cc99400"}, "55d824ff-7eb0-4779-9946-75be2ef326ff": {"doc_hash": "6c95415b45926e1c0e93688f1b245b1344788aac1b0a313165af7be25c74a1ce"}, "90fcca7b-644f-4c69-9b47-47d1b60302ca": {"doc_hash": "24c07e8fa6a75a937f2ec0e2902717ced1ea7a03eb01355931e70338916f3137"}, "788adbdc-7f5a-41ac-a7e8-8273ffc54972": {"doc_hash": "ff30b8052e1fc57479f242862e1c543cbb01204a49a92ac4dff5eb6e211a1be8"}, "c7fa4762-65f4-4be7-a68f-d425d458e045": {"doc_hash": "7ab1ddfcd256299c8f7e76f6a97e28b323e13fcfb576ac1a9063a446c26a6a33"}, "011457ea-546b-411c-9315-9e18d908c25b": {"doc_hash": "ffb44cb41111ac928cf1329252b3bc3d391a841a6c4283030113aaaeb5c0ca90"}, "140da6f2-965b-4f03-b748-14aa4653c4e1": {"doc_hash": "37ef213c9c12442f7f1f900503a5e4054216c6f059462c896dcd39efb1148ab3"}, "6db82861-a963-41df-a73b-5b5c2b36f3e9": {"doc_hash": "7a4912a68af6aecf359c6435fd1cbc2c7b9041f312ea9d5325c1358af6ad3d7b"}, "9691b69a-6f5f-4fe0-8f02-308e885bb786": {"doc_hash": "179b97b2fb2a6d457aebe053d6266f6e01765fc5442fd33985bf41792ce6a91a"}, "2fbadd82-0dbd-4831-9dba-229d04001ee8": {"doc_hash": "eb55a55e1d6e5ba9d8af050866a00d1ab538ef3d7f11ea23e5381bbc22532403"}, "aa8f19b0-2e3e-4225-bc67-bf5ebfd30f7d": {"doc_hash": "c4f12bdcb8b1678ac5104072fb1f81af00d1e738a8614d2bdcd9a9739dad54e4"}, "93607f05-856a-450b-b8de-edd9ddfa5a75": {"doc_hash": "0efc884c2d2e7dad2e2283fa3bfa69d56bcf2503470e80844388d7b887201e70"}, "cbb945ea-f537-4e09-be5a-eb511e465983": {"doc_hash": "693cecdf350524c7292ca8d1063b85829083e556f361ae93b0b9fd959de93be6"}, "fc3d5aee-2772-450e-a73e-ce0223fb5c29": {"doc_hash": "e5a573d42434686053b4307151f3c2fee91c2b81d7a8a5592a799ad29912b9d3"}, "0d72b45b-56f5-475e-9569-1b2d9edefa49": {"doc_hash": "131897b27ab2603edcc9adeab0b916e2c859a578d5cc4f0958abe797a6532acb"}}}